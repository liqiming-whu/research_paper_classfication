Multi-Atlas Segmentation of Anatomical Brain Structures Using Hierarchical Hypergraph Learning.,"Accurate segmentation of anatomical brain structures is crucial for many neuroimaging applications, e.g., early brain development studies and the study of imaging biomarkers of neurodegenerative diseases. Although multi-atlas segmentation (MAS) has achieved many successes in the medical imaging area, this approach encounters limitations in segmenting anatomical structures associated with poor image contrast. To address this issue, we propose a new MAS method that uses a hypergraph learning framework to model the complex subject-within and subject-to-atlas image voxel relationships and propagate the label on the atlas image to the target subject image. To alleviate the low-image contrast issue, we propose two strategies equipped with our hypergraph learning framework. First, we use a hierarchical strategy that exploits high-level context features for hypergraph construction. Because the context features are computed on the tentatively estimated probability maps, we can ultimately turn the hypergraph learning into a hierarchical model. Second, instead of only propagating the labels from the atlas images to the target subject image, we use a dynamic label propagation strategy that can gradually use increasing reliably identified labels from the subject image to aid in predicting the labels on the difficult-to-label subject image voxels. Compared with the state-of-the-art label fusion methods, our results show that the hierarchical hypergraph learning framework can substantially improve the robustness and accuracy in the segmentation of anatomical brain structures with low image contrast from magnetic resonance (MR) images.",4
Teacher-Student Curriculum Learning.,"We propose Teacher-Student Curriculum Learning (TSCL), a framework for automatic curriculum learning, where the Student tries to learn a complex task, and the Teacher automatically chooses subtasks from a given set for the Student to train on. We describe a family of Teacher algorithms that rely on the intuition that the Student should practice more those tasks on which it makes the fastest progress, i.e., where the slope of the learning curve is highest. In addition, the Teacher algorithms address the problem of forgetting by also choosing tasks where the Student's performance is getting worse. We demonstrate that TSCL matches or surpasses the results of carefully hand-crafted curricula in two tasks: addition of decimal numbers with long short-term memory (LSTM) and navigation in Minecraft. Our automatically ordered curriculum of submazes enabled to solve a Minecraft maze that could not be solved at all when training directly on that maze, and the learning was an order of magnitude faster than a uniform sampling of those submazes.",4
Synchronization and Consensus in Networks of Linear Fractional-Order Multi-Agent Systems via Sampled-Data Control.,"This article addresses synchronization and consensus problems in networks of linear fractional-order multi-agent systems (LFOMAS) via sampled-data control. First, under very mild assumptions, the necessary and sufficient conditions are obtained for achieving synchronization in networks of LFOMAS. Second, the results of synchronization are applied to solve some consensus problems in networks of LFOMAS. In the obtained results, the coupling matrix does not have to be a Laplacian matrix, its off-diagonal elements do not have to be nonnegative, and its row-sum can be nonzero. Finally, the validity of the theoretical results is verified by three simulation examples.",4
Backpropagation With N-D Vector-Valued Neurons Using Arbitrary Bilinear Products.,"Vector-valued neural learning has emerged as a promising direction in deep learning recently. Traditionally, training data for neural networks (NNs) are formulated as a vector of scalars; however, its performance may not be optimal since associations among adjacent scalars are not modeled. In this article, we propose a new vector neural architecture called the Arbitrary BIlinear Product NN (ABIPNN), which processes information as vectors in each neuron, and the feedforward projections are defined using arbitrary bilinear products. Such bilinear products can include circular convolution, 7-D vector product, skew circular convolution, reversed-time circular convolution, or other new products that are not seen in the previous work. As a proof-of-concept, we apply our proposed network to multispectral image denoising and singing voice separation. Experimental results show that ABIPNN obtains substantial improvements when compared to conventional NNs, suggesting that associations are learned during training.",4
Homophily Preserving Community Detection.,"As a fundamental problem in social network analysis, community detection has recently attracted wide attention, accompanied by the output of numerous community detection methods. However, most existing methods are developed by only exploiting link topology, without taking node homophily (i.e., node similarity) into consideration. Thus, much useful information that can be utilized to improve the quality of detected communities is ignored. To overcome this limitation, we propose a new community detection approach based on nonnegative matrix factorization (NMF), namely, homophily preserving NMF (HPNMF), which models not only link topology but also node homophily of networks. As such, HPNMF is able to better reflect the inherent properties of community structure. In order to capture node homophily from scratch, we provide three similarity measurements that naturally reveal the association relationships between nodes. We further present an efficient learning algorithm with convergence guarantee to solve the proposed model. Finally, extensive experiments are conducted, and the results demonstrate that HPNMF has strong ability to outperform the state-of-the-art baseline methods.",4
SRGC-Nets: Sparse Repeated Group Convolutional Neural Networks.,"Group convolution is widely used in many mobile networks to remove the filter's redundancy from the channel extent. In order to further reduce the redundancy of group convolution, this article proposes a novel repeated group convolutional (RGC) kernel, which has M primary groups, and each primary group includes N tiny groups. In every primary group, the same convolutional kernel is repeated in all the tiny groups. The RGC filter is the first kernel to remove the redundancy from group extent. Based on RGC, a sparse RGC (SRGC) kernel is also introduced in this article, and its corresponding network is called SRGC neural networks (SRGC-Net). The SRGC kernel is the summation of RGC kernel and pointwise group convolutional (PGC) kernel. The number of PGC's groups is M. Accordingly, in each primary group, besides the center locations in all channels, the values of parameters located in other N-1 tiny groups are all zero. Therefore, SRGC can significantly reduce the parameters. Moreover, it can also effectively retrieve spatial and channel-difference features by utilizing RGC and PGC to preserve the richness of produced features. Comparative experiments were performed on the benchmark classification data sets. Compared with the traditional popular networks, SRGC-Nets can perform better with timely reducing the model size and computational complexity. Furthermore, it can also achieve better performances than other latest state-of-the-art mobile networks on most of the databases and effectively decrease the test and training runtime.",4
Large Margin Partial Label Machine.,"Partial label learning (PLL) is a multi-class weakly supervised learning problem where each training instance is associated with a set of candidate labels but only one label is the ground truth. The main challenge of PLL is how to deal with the label ambiguities. Among various disambiguation techniques, large margin (LM)-based algorithms attract much attention due to their powerful discriminative performance. However, existing LM-based algorithms either neglect some potential candidate labels in constructing the margin or introduce auxiliary estimation of class capacities which is generally inaccurate. As a result, their generalization performances are deteriorated. To address the above-mentioned drawbacks, motivated by the optimistic superset loss, we propose an LM Partial LAbel machiNE (LM-PLANE) by extending multi-class support vector machines (SVM) to PLL. Compared with existing LM-based disambiguation algorithms, LM-PLANE considers the margin of all potential candidate labels without auxiliary estimation of class capacities. Furthermore, an efficient cutting plane (CP) method is developed to train LM-PLANE in the dual space. Theoretical insights into the effectiveness and convergence of our CP method are also presented. Extensive experiments on various PLL tasks demonstrate the superiority of LM-PLANE over existing LM based and other representative PLL algorithms in terms of classification accuracy.",4
Barrier Function-Based Adaptive Control for Uncertain Strict-Feedback Systems Within Predefined Neural Network Approximation Sets.,"In this article, a globally stable adaptive control strategy for uncertain strict-feedback systems is proposed within predefined neural network (NN) approximation sets, despite the presence of unknown system nonlinearities. In contrast to the conventional adaptive NN control results in the literature, a primary benefit of the developed approach is that the barrier Lyapunov function is employed to predefine the compact set for maintaining the validity of NN approximation at each step, thus accomplishing the global boundedness of all the closed-loop signals. Simulation results are performed to clarify the effectiveness of the proposed methodology.",4
Optimizing for Measure of Performance in Max-Margin Parsing.,"Many learning tasks in the field of natural language processing including sequence tagging, sequence segmentation, and syntactic parsing have been successfully approached by means of structured prediction methods. An appealing property of the corresponding training algorithms is their ability to integrate the loss function of interest into the optimization process improving the final results according to the chosen measure of performance. Here, we focus on the task of constituency parsing and show how to optimize the model for the F(1)-score in the max-margin framework of a structural support vector machine (SVM). For reasons of computational efficiency, it is a common approach to binarize the corresponding grammar before training. Unfortunately, this introduces a bias during the training procedure as the corresponding loss function is evaluated on the binary representation, while the resulting performance is measured on the original unbinarized trees. Here, we address this problem by extending the inference procedure presented by Bauer et al. Specifically, we propose an algorithmic modification that allows evaluating the loss on the unbinarized trees. The new approach properly models the loss function of interest resulting in better prediction accuracy and still benefits from the computational efficiency due to binarized representation. The presented idea can be easily transferred to other structured loss functions.",4
Scalable Distributed Filtering for a Class of Discrete-Time Complex Networks Over Time-Varying Topology.,"This article is concerned with the distributed filtering problem for a class of discrete complex networks over time-varying topology described by a sequence of variables. In the developed scalable filtering algorithm, only the local information and the information from the neighboring nodes are used. As such, the proposed filter can be implemented in a truly distributed manner at each node, and it is no longer necessary to have a certain center node collecting information from all the nodes. The aim of the addressed filtering problem is to design a time-varying filter for each node such that an upper bound of the filtering error covariance is ensured and the desired filter gain is then calculated by minimizing the obtained upper bound. The filter is established by solving two sets of recursive matrix equations, and thus, the algorithm is suitable for online application. Sufficient conditions are provided under which the filtering error is exponentially bounded in mean square. The monotonicity of the filtering error with respect to the coupling strength is discussed as well. Finally, an illustrative example is presented to demonstrate the feasibility and effectiveness of our distributed filtering strategy.",4
Nonpooling Convolutional Neural Network Forecasting for Seasonal Time Series With Trends.,"This article focuses on a problem important to automatic machine learning: the automatic processing of a nonpreprocessed time series. The convolutional neural network (CNN) is one of the most popular neural network (NN) algorithms for pattern recognition. Seasonal time series with trends are the most common data sets used in forecasting. Both the convolutional layer and the pooling layer of a CNN can be used to extract important features and patterns that reflect the seasonality, trends, and time lag correlation coefficients in the data. The ability to identify such features and patterns makes CNN a good candidate algorithm for analyzing seasonal time-series data with trends. This article reports our experimental findings using a fully connected NN (FNN), a nonpooling CNN (NPCNN), and a CNN to study both simulated and real time-series data with seasonality and trends. We found that convolutional layers tend to improve the performance, while pooling layers tend to introduce too many negative effects. Therefore, we recommend using an NPCNN when processing seasonal time-series data with trends. Moreover, we suggest using the Adam optimizer and selecting either a rectified linear unit (ReLU) function or a linear activation function. Using an NN to analyze seasonal time series with trends has become popular in the NN community. This article provides an approach for building a network that fits time-series data with seasonality and trends automatically.",4
Neural Probabilistic Graphical Model for Face Sketch Synthesis.,"Neural network learning for face sketch synthesis from photos has attracted substantial attention due to its favorable synthesis performance. However, most existing deep-learning-based face sketch synthesis models stacked only by multiple convolutional layers without structured regression often lose the common facial structures, limiting their flexibility in a wide range of practical applications, including intelligent security and digital entertainment. In this article, we introduce a neural network to a probabilistic graphical model and propose a novel face sketch synthesis framework based on the neural probabilistic graphical model (NPGM) composed of a specific structure and a common structure. In the specific structure, we investigate a neural network for mapping the direct relationship between training photos and sketches, yielding the specific information and characteristic features of a test photo. In the common structure, the fidelity between the sketch pixels generated by the specific structure and their candidates selected from the training data are considered, ensuring the preservation of the common facial structure. Experimental results on the Chinese University of Hong Kong face sketch database demonstrate, both qualitatively and quantitatively, that the proposed NPGM-based face sketch synthesis approach can more effectively capture specific features and recover common structures compared with the state-of-the-art methods. Extensive experiments in practical applications further illustrate that the proposed method achieves superior performance.",4
A Deep One-Class Neural Network for Anomalous Event Detection in Complex Scenes.,"How to build a generic deep one-class (DeepOC) model to solve one-class classification problems for anomaly detection, such as anomalous event detection in complex scenes? The characteristics of existing one-class labels lead to a dilemma: it is hard to directly use a multiple classifier based on deep neural networks to solve one-class classification problems. Therefore, in this article, we propose a novel DeepOC neural network, termed as DeepOC, which can simultaneously learn compact feature representations and train a DeepOC classifier. Only with the given normal samples, we use the stacked convolutional encoder to generate their low-dimensional high-level features and train a one-class classifier to make these features as compact as possible. Meanwhile, for the sake of the correct mapping relation and the feature representations' diversity, we utilize a decoder in order to reconstruct raw samples from these low-dimensional feature representations. This structure is gradually established using an adversarial mechanism during the training stage. This mechanism is the key to our model. It organically combines two seemingly contradictory components and allows them to take advantage of each other, thus making the model robust and effective. Unlike methods that use handcrafted features or those that are separated into two stages (extracting features and training classifiers), DeepOC is a one-stage model using reliable features that are automatically extracted by neural networks. Experiments on various benchmark data sets show that DeepOC is feasible and achieves the state-of-the-art anomaly detection results compared with a dozen existing methods.",4
Errata: Distributed Event-Triggered Adaptive Control for Cooperative Output Regulation of Heterogeneous Multi-Agent Systems Under Switching Topology.,"This article aims to point out an error in the concerned paper and a possible correction to address the error. The correction is achieved by several revisions made on the corresponding assumption, event-triggering function, adaptive laws, and event-triggered control law.",4
Debiasing and Distributed Estimation for High-Dimensional Quantile Regression.,"Distributed and parallel computing is becoming more important with the availability of extremely large data sets. In this article, we consider this problem for high-dimensional linear quantile regression. We work under the assumption that the coefficients in the regression model are sparse; therefore, a LASSO penalty is naturally used for estimation. We first extend the debiasing procedure, which is previously proposed for smooth parametric regression models to quantile regression. The technical challenges include dealing with the nondifferentiability of the loss function and the estimation of the unknown conditional density. In this article, the main objective is to derive a divide-and-conquer estimation approach using the debiased estimator which is useful under the big data setting. The effectiveness of distributed estimation is demonstrated using some numerical examples.",4
The Strength of Nesterov's Extrapolation in the Individual Convergence of Nonsmooth Optimization.,"The extrapolation strategy raised by Nesterov, which can accelerate the convergence rate of gradient descent methods by orders of magnitude when dealing with smooth convex objective, has led to tremendous success in training machine learning tasks. In this article, the convergence of individual iterates of projected subgradient (PSG) methods for nonsmooth convex optimization problems is theoretically studied based on Nesterov's extrapolation, which we name individual convergence. We prove that Nesterov's extrapolation has the strength to make the individual convergence of PSG optimal for nonsmooth problems. In light of this consideration, a direct modification of the subgradient evaluation suffices to achieve optimal individual convergence for strongly convex problems, which can be regarded as making an interesting step toward the open question about stochastic gradient descent (SGD) posed by Shamir. Furthermore, we give an extension of the derived algorithms to solve regularized learning tasks with nonsmooth losses in stochastic settings. Compared with other state-of-the-art nonsmooth methods, the derived algorithms can serve as an alternative to the basic SGD especially in coping with machine learning problems, where an individual output is needed to guarantee the regularization structure while keeping an optimal rate of convergence. Typically, our method is applicable as an efficient tool for solving large-scale l(1)-regularized hinge-loss learning problems. Several comparison experiments demonstrate that our individual output not only achieves an optimal convergence rate but also guarantees better sparsity than the averaged solution.",4
Pay Attention to Them: Deep Reinforcement Learning-Based Cascade Object Detection.,"This paper proposes a novel and effective approach, namely pay attention to them (PAT), to general object detection, which integrates the bottom-up single-shot convolutional neural networks (CNNs) and a top-down operating strategy. PAT starts by routinely applying a CNN regression detector to the entire input image. It then conducts refinement, which locates a sub-region that probably contains relevant objects through an intelligent agent built with an attentional mechanism and zooms it in to launch the detector again. This refining step is repeated in a cascaded way, where all the bounding boxes produced are scaled according to the original resolution and the sub-marginal and overlapping parts are wiped out to generate the final output. Due to such progressive processing, PAT improves the detection accuracy, especially for the objects of small sizes. Extensive experiments are conducted on the Pascal VOC and MS COCO benchmarks, and the results show that PAT is able to improve the representative baseline detectors, i.e., single shot multibox detector, YOLOv2, and Faster regions with CNN features, with remarkable accuracy gains [about 2%-5% mean Average Precision (mAP)], which demonstrates its competency.",4
Exploring Duality in Visual Question-Driven Top-Down Saliency.,"Top-down, goal-driven visual saliency exerts a huge influence on the human visual system for performing visual tasks. Text generations, like visual question answering (VQA) and visual question generation (VQG), have intrinsic connections with top-down saliency, which is usually involved in both VQA and VQG processes in an unsupervised manner. However, it is shown that the regions that humans choose to look at to answer questions are very different from the unsupervised attention models. In this brief, we aim to explore the intrinsic relationship between top-down saliency and text generations, and to figure out whether an accurate saliency response benefits text generation. To this end, we propose a dual supervised network with dynamic parameter prediction. Dual-supervision explicitly exploits the probabilistic correlation between the primal task top-down saliency detection and the dual task text generation, while dynamic parameter prediction encodes the given text (i.e., question or answer) into the fully convolutional network. Extensive experiments show the proposed top-down saliency method achieves the best correlation with human attention among various baselines. In addition, the proposed model can be guided by either questions or answers, and output the counterpart. Furthermore, we show that combining human-like visual question-saliency improves the performance of both answer and question generations.",4
Adaptive Neural Network Finite-Time Control for Multi-Input and Multi-Output Nonlinear Systems With Positive Powers of Odd Rational Numbers.,"This article investigates the adaptive neural network (NN) finite-time output tracking control problem for a class of multi-input and multi-output (MIMO) uncertain nonlinear systems whose powers are positive odd rational numbers. Such designs adopt NNs to approximate unknown continuous system functions, and a controller is constructed by combining backstepping design and adding a power integrator technique. By constructing new iterative Lyapunov functions and using finite-time stability theory, the closed-loop stability has been achieved, which further verifies that the entire system possesses semiglobal practical finite-time stability (SGPFS), and the tracking errors converge to a small neighborhood of the origin within finite time. Finally, a simulation example is given to elaborate the effectiveness and superiority of the developed.",4
Benchmarking Neural Networks For Quantum Computations.,"The power of quantum computers is still somewhat speculative. Although they are certainly faster than classical ones at some tasks, the class of problems they can efficiently solve has not been mapped definitively onto known classical complexity theory. This means that we do not know for which calculations there will be a ``quantum advantage,'' once an algorithm is found. One way to answer the question is to find those algorithms, but finding truly quantum algorithms turns out to be very difficult. In previous work, over the past three decades, we have pursued the idea of using techniques of machine learning to develop algorithms for quantum computing. Here, we compare the performance of standard real- and complex-valued classical neural networks with that of one of our models for a quantum neural network, on both classical problems and on an archetypal quantum problem: the computation of an entanglement witness. The quantum network is shown to need far fewer epochs and a much smaller network to achieve comparable or better results.",4
Semi-Supervised Non-Negative Matrix Factorization With Dissimilarity and Similarity Regularization.,"In this article, we propose a semi-supervised non-negative matrix factorization (NMF) model by means of elegantly modeling the label information. The proposed model is capable of generating discriminable low-dimensional representations to improve clustering performance. Specifically, a pair of complementary regularizers, i.e., similarity and dissimilarity regularizers, is incorporated into the conventional NMF to guide the factorization. And, they impose restrictions on both the similarity and dissimilarity of the low-dimensional representations of data samples with labels as well as a small number of unlabeled ones. The proposed model is formulated as a well-posed constrained optimization problem and further solved with an efficient alternating iterative algorithm. Moreover, we theoretically prove that the proposed algorithm can converge to a limiting point that meets the Karush-Kuhn-Tucker conditions. Extensive experiments as well as comprehensive analysis demonstrate that the proposed model outperforms the state-of-the-art NMF methods to a large extent over five benchmark data sets, i.e., the clustering accuracy increases to 82.2% from 57.0%.",4
Adaptive Weighted Sparse Principal Component Analysis for Robust Unsupervised Feature Selection.,"Current unsupervised feature selection methods cannot well select the effective features from the corrupted data. To this end, we propose a robust unsupervised feature selection method under the robust principal component analysis (PCA) reconstruction criterion, which is named the adaptive weighted sparse PCA (AW-SPCA). In the proposed method, both the regularization term and the reconstruction error term are constrained by the l2,1-norm: the l2,1-norm regularization term plays a role in the feature selection, while the l2,1-norm reconstruction error term plays a role in the robust reconstruction. The proposed method is in a convex formulation, and the selected features by it can be used for robust reconstruction and clustering. Experimental results demonstrate that the proposed method can obtain better reconstruction and clustering performance, especially for the corrupted data.",4
Learning Markov Blankets From Multiple Interventional Data Sets.,"Learning Markov blankets (MBs) plays an important role in many machine learning tasks, such as causal Bayesian network structure learning, feature selection, and domain adaptation. Since variables included in the MB of a target variable of interest have causal relationships with the target, the MB can serve as the basis of learning the global structure of a causal Bayesian network or as a reliable and robust feature set for classification, both within the same domain or across domains. In this article, we study the problem of learning the MB of a target variable from multiple interventional data sets. Data sets attained from interventional experiments contain richer causal information than passively observed data (observational data) for MB discovery. However, almost all existing MB discovery methods are designed for learning MBs from a single observational data set. To learn MBs from multiple interventional data sets, we face two challenges: 1) unknown intervention variables and 2) nonidentical data distributions. To address these challenges, we theoretically analyze: 1) under what conditions we can find the correct MB of a target variable and 2) under what conditions we can identify the causes of the target variable via discovering its MB. Based on the theoretical analysis, we propose a new algorithm for learning MBs from multiple interventional data sets, and we present the conditions/assumptions that assure the correctness of the algorithm. To the best of our knowledge, this article is the first to present the theoretical analyses about the conditions for MB discovery in multiple interventional data sets and the algorithm to find the MBs in relation to the conditions. Using benchmark Bayesian networks and real-world data sets, the experiments have validated the effectiveness and efficiency of the proposed algorithm in this article.",4
Tensor Networks for Latent Variable Analysis: Higher Order Canonical Polyadic Decomposition.,"The canonical polyadic decomposition (CPD) is a convenient and intuitive tool for tensor factorization; however, for higher order tensors, it often exhibits high computational cost and permutation of tensor entries, and these undesirable effects grow exponentially with the tensor order. Prior compression of tensor in-hand can reduce the computational cost of CPD, but this is only applicable when the rank $R$ of the decomposition does not exceed the tensor dimensions. To resolve these issues, we present a novel method for CPD of higher order tensors, which rests upon a simple tensor network of representative inter-connected core tensors of orders not higher than 3. For rigor, we develop an exact conversion scheme from the core tensors to the factor matrices in CPD and an iterative algorithm of low complexity to estimate these factor matrices for the inexact case. Comprehensive simulations over a variety of scenarios support the proposed approach.",4
Precise Measurement of Position and Attitude Based on Convolutional Neural Network and Visual Correspondence Relationship.,"Accurate measurement of position and attitude information is particularly important. Traditional measurement methods generally require high-precision measurement equipment for analysis, leading to high costs and limited applicability. Vision-based measurement schemes need to solve complex visual relationships. With the extensive development of neural networks in related fields, it has become possible to apply them to the object position and attitude. In this paper, we propose an object pose measurement scheme based on convolutional neural network and we have successfully implemented end-to-end position and attitude detection. Furthermore, to effectively expand the measurement range and reduce the number of training samples, we demonstrated the independence of objects in each dimension and proposed subadded training programs. At the same time, we generated generating image encoder to guarantee the detection performance of the training model in practical applications.",4
Dynamically Spatiotemporal Regularized Correlation Tracking.,"Recently, due to the high performance, spatially regularized strategy has been widely applied to addressing the issue of boundary effects existed in correlation filter (CF)-based visual tracking. Specifically, it introduces a spatially regularized term to penalize the coefficients of the CFs to be learned depending on their spatial locations. However, the regularization weights are often formed as a fixed Gaussian function, and hence may cause the learned model degenerate due to the inflexible constraints on the ever-changing CFs to be learned over time during tracking. To address this issue, in this paper, we develop a dynamically spatiotemporal regularization model to constrain the CFs to be learned with the ever-changing regularization weights learned from two consecutive frames. The proposed method jointly learns the CFs along with the dynamically spatiotemporal constraint term, which can be efficiently solved in the Fourier domain by the alternative direction method. Extensive evaluations on the popular data sets OTB-100 and VOT-2016 demonstrate that the proposed tracker performs favorably against the baseline tracker and several recently proposed state-of-the-art methods.",4
Real-Time Object Detection With Reduced Region Proposal Network via Multi-Feature Concatenation.,"In recent years, object detection became more and more important following the successful results from studies in deep learning. Two types of neural network architectures are used for object detection: one-stage and two-stage. In this paper, we analyze a widely used two-stage architecture called Faster R-CNN to improve the inference time and achieve real-time object detection without compromising on accuracy. To increase the computation efficiency, pruning is first adopted to reduce the weights in convolutional and fully connected (FC) layers. However, this reduces the accuracy of detection. To address this loss in accuracy, we propose a reduced region proposal network (RRPN) with dilated convolution and concatenation of multi-scale features. In the assisted multi-feature concatenation, we propose the intra-layer concatenation and proposal refinement to efficiently integrate the feature maps from different convolutional layers; this is then provided as an input to the RRPN. Using the proposed method, the network can find object bounding boxes more accurately, thus compensating for the loss arising from compression. Finally, we test the proposed architecture using ZF-Net and VGG16 as a backbone network on the image sets in PASCAL VOC 2007 or VOC 2012. The results show that we can compress the parameters of the ZF-Net-based network by 81.2% and save 66% of computation. The parameters of VGG16-based network are compressed by 73% and save 77% of computation. Consequently, the inference speed is improved from 27 to 40 frames/s for ZF-Net and 9 to 27 frames/s for VGG16. Despite significant compression rates, the accuracy of ZF-Net is increased from 2.2% to 60.2% mean average precision (mAP) and that of VGG16 is increased from 2.6% to 69.1% mAP.",4
A Taxonomy for Neural Memory Networks.,"An increasing number of neural memory networks have been developed, leading to the need for a systematic approach to analyze and compare their underlying memory structures. Thus, in this paper, we first create a framework for memory organization and then compare four popular dynamic models: vanilla recurrent neural network, long short-term memory, neural stack, and neural RAM. This analysis helps to open the dynamic neural networks' black box from the memory usage prospective. Accordingly, a taxonomy for these networks and their variants is proposed and proved using a unifying architecture. With the taxonomy, both network architectures and learning tasks are classified into four classes, and a one-to-one mapping is built between them to help practitioners select the appropriate architecture. To exemplify each task type, four synthetic tasks with different memory requirements are selected. Moreover, we use some signal processing applications and two natural language processing applications to evaluate the methodology in a realistic setting.",4
A Generic Improvement to Deep Residual Networks Based on Gradient Flow.,"Preactivation ResNets consistently outperforms the original postactivation ResNets on the CIFAR10/100 classification benchmark. However, these results surprisingly do not carry over to the standard ImageNet benchmark. First, we theoretically analyze this incongruity in terms of how the two variants differ in handling the propagation of gradients. Although identity shortcuts are critical in both variants for improving optimization and performance, we show that postactivation variants enable early layers to receive a diverse dynamic composition of gradients from effectively deeper paths in comparison to preactivation variants, enabling the network to make maximal use of its representational capacity. Second, we show that downsampling projections (while only a few in number) have a significantly detrimental effect on performance. We show that by simply replacing downsampling projections with identitylike dense-reshape shortcuts, the classification results of standard residual architectures such as ResNets, ResNeXts, and SE-Nets improve by up to 1.2% on ImageNet, without any increase in computational complexity (FLOPs).",4
Robust Student Network Learning.,"Deep neural networks bring in impressive accuracy in various applications, but the success often relies on heavy network architectures. Taking well-trained heavy networks as teachers, classical teacher-student learning paradigm aims to learn a student network that is lightweight yet accurate. In this way, a portable student network with significantly fewer parameters can achieve considerable accuracy, which is comparable to that of a teacher network. However, beyond accuracy, the robustness of the learned student network against perturbation is also essential for practical uses. Existing teacher-student learning frameworks mainly focus on accuracy and compression ratios, but ignore the robustness. In this paper, we make the student network produce more confident predictions with the help of the teacher network, and analyze the lower bound of the perturbation that will destroy the confidence of the student network. Two important objectives regarding prediction scores and gradients of examples are developed to maximize this lower bound, to enhance the robustness of the student network without sacrificing the performance. Experiments on benchmark data sets demonstrate the efficiency of the proposed approach to learning robust student networks that have satisfying accuracy and compact sizes.",4
Two Projection Neural Networks With Reduced Model Complexity for Nonlinear Programming.,"Recent reports show that projection neural networks with a low-dimensional state space can enhance computation speed obviously. This paper proposes two projection neural networks with reduced model dimension and complexity (RDPNNs) for solving nonlinear programming (NP) problems. Compared with existing projection neural networks for solving NP, the proposed two RDPNNs have a low-dimensional state space and low model complexity. Under the condition that the Hessian matrix of the associated Lagrangian function is positive semi-definite and positive definite at each Karush-Kuhn-Tucker point, the proposed two RDPNNs are proven to be globally stable in the sense of Lyapunov and converge globally to a point satisfying the reduced optimality condition of NP. Therefore, the proposed two RDPNNs are theoretically guaranteed to solve convex NP problems and a class of nonconvex NP problems. Computed results show that the proposed two RDPNNs have a faster computation speed than the existing projection neural networks for solving NP problems.",4
Siamese Neural Networks for User Identity Linkage Through Web Browsing.,"Linking online identities of users among countless heterogeneous network services on the Internet can provide an explicit digital representation of users, which can benefit both research and industry. In recent years, user identity linkage (UIL) through the Internet has become an emerging task with great potential and many challenges. Existing works mainly focus on online social networks that consider inconsistent profiles, content, and networks as features or use sparse location-based data sets to link the online behaviors of a real person. To extend the UIL problem to a general scenario, we try to link the web-browsing behaviors of users, which can help to distinguish specific users from others, such as children or malicious users. More specifically, we propose a Siamese neural network (NN) architecture-based UIL (SAUIL) model that learns and compares the highest-level feature representation of input web-browsing behaviors with deep NNs. Although the number of matching and nonmatching pairs for the UIL problem is highly imbalanced, previous studies have not considered imbalanced UIL data sets. Therefore, we further address the imbalanced learning issue by proposing cost-sensitive SAUIL (C-SAUIL) model, which assumes higher costs for misclassifying the minority class. In the experiments, the proposed model is robust and exhibits a good performance on very large, real-world data sets collected from different regions with distinct characteristics.",4
Deep Reinforcement Learning for Sequence-to-Sequence Models.,"In recent times, sequence-to-sequence (seq2seq) models have gained a lot of popularity and provide state-of-the-art performance in a wide variety of tasks, such as machine translation, headline generation, text summarization, speech-to-text conversion, and image caption generation. The underlying framework for all these models is usually a deep neural network comprising an encoder and a decoder. Although simple encoder--decoder models produce competitive results, many researchers have proposed additional improvements over these seq2seq models, e.g., using an attention-based model over the input, pointer-generation models, and self-attention models. However, such seq2seq models suffer from two common problems: 1) exposure bias and 2) inconsistency between train/test measurement. Recently, a~completely novel point of view has emerged in addressing these two problems in seq2seq models, leveraging methods from reinforcement learning (RL). In this survey, we~consider seq2seq problems from the RL point of view and provide a formulation combining the power of RL methods in decision-making with seq2seq models that enable remembering long-term memories. We present some of the most recent frameworks that combine the concepts from RL and deep neural networks. Our work aims to provide insights into some of the problems that inherently arise with current approaches and how we can address them with better RL models. We also provide the source code for implementing most of the RL models discussed in this paper to support the complex task of abstractive text summarization and provide some targeted experiments for these RL models, both in terms of performance and training~time.",4
Effective Data-Aware Covariance Estimator From Compressed Data.,"Estimating covariance matrix from massive high-dimensional and distributed data is significant for various real-world applications. In this paper, we propose a data-aware weighted sampling-based covariance matrix estimator, namely DACE, which can provide an unbiased covariance matrix estimation and attain more accurate estimation under the same compression ratio. Moreover, we extend our proposed DACE to tackle multiclass classification problems with theoretical justification and conduct extensive experiments on both synthetic and real-world data sets to demonstrate the superior performance of our DACE.",4
Label-less Learning for Emotion Cognition.,"In this paper, we propose a label-less learning for emotion cognition (LLEC) to achieve the utilization of a large amount of unlabeled data. We first inspect the unlabeled data from two perspectives, i.e., the feature layer and the decision layer. By utilizing the similarity model and the entropy model, this paper presents a hybrid label-less learning that can automatically label data without human intervention. Then, we design an enhanced hybrid label-less learning to purify the automatic labeled data. To further improve the accuracy of emotion detection model and increase the utilization of unlabeled data, we apply enhanced hybrid label-less learning for multimodal unlabeled emotion data. Finally, we build a real-world test bed to evaluate the LLEC algorithm. The experimental results show that the LLEC algorithm can improve the accuracy of emotion detection significantly.",4
Disturbance Observer-Based Neural Network Control of Cooperative Multiple Manipulators With Input Saturation.,"In this paper, the complex problems of internal forces and position control are studied simultaneously and a disturbance observer-based radial basis function neural network (RBFNN) control scheme is proposed to: 1) estimate the unknown parameters accurately; 2) approximate the disturbance experienced by the system due to input saturation; and 3) simultaneously improve the robustness of the system. More specifically, the proposed scheme utilizes disturbance observers, neural network (NN) collaborative control with an adaptive law, and full state feedback. Utilizing Lyapunov stability principles, it is shown that semiglobally uniformly bounded stability is guaranteed for all controlled signals of the closed-loop system. The effectiveness of the proposed controller as predicted by the theoretical analysis is verified by comparative experimental studies.",4
Adaptive Neural Network Prescribed Performance Bounded-Hinfinity Tracking Control for a Class of Stochastic Nonlinear Systems.,"This paper aims to give a design strategy on the prescribed performance Hinfinity tracking control problem for a class of strict-feedback stochastic nonlinear systems based on the backstepping technique. Generally, by using the backstepping design method, the stochastic nonlinear systems can only be made to be bounded in probability and it is difficult to achieve the Hinfinity performance criterion due to the positive constant term appeared in the stability analysis. Thus, a novel concept with regard to the bounded-Hinfinity performance is proposed in this paper to overcome the design difficulty. By using the new concept and the adaptive neural network technique as well as Gronwall inequality, an adaptive neural network prescribed performance bounded-Hinfinity tracking controller is designed. Therein, neural networks are used to approximate the unknown packaged nonlinear functions. The assumption that the approximation errors of neural networks are square-integrable in some literature is eliminated. The designed controller guarantees that all the signals in the closed-loop stochastic nonlinear systems are bounded in probability, the tracking error is constrained into an adjustable neighborhood of the origin with the prescribed performance bounds, and the controlled system has a given Hinfinity disturbance attenuation performance for external disturbances. Finally, the simulation results are provided to illustrate the effectiveness and feasibility of the proposed approach.",4
Deep Model Compression and Inference Speedup of Sum-Product Networks on Tensor Trains.,"Sum-product networks (SPNs) constitute an emerging class of neural networks with clear probabilistic semantics and superior inference speed over other graphical models. This brief reveals an important connection between SPNs and tensor trains (TTs), leading to a new canonical form which we call tensor SPNs (tSPNs). Specifically, we demonstrate the intimate relationship between a valid SPN and a TT. For the first time, through mapping an SPN onto a tSPN and employing specially customized optimization techniques, we demonstrate improvements up to a factor of 100 on both model compression and inference speedup for various data sets with negligible loss in accuracy.",4
Output Feedback Control for Set Stabilization of Boolean Control Networks.,"In this paper, the output feedback set stabilization problem for Boolean control networks (BCNs) is investigated with the help of the semi-tensor product (STP) tool. The concept of output feedback control invariant (OFCI) subset is introduced, and novel methods are developed to obtain the OFCI subsets. Based on the OFCI subsets, a technique, named spanning tree method, is further introduced to calculate all possible output feedback set stabilizers. An example concerning lac operon for the bacterium Escherichia coli is given to illustrate the effectiveness of the proposed method. This technique can also be used to solve the state feedback (set) stabilization problem for BCNs. Compared with the existing results, our method can dramatically reduce the computational cost when designing all possible state feedback stabilizers for BCNs.",4
Distributed Finite-Time Fault-Tolerant Containment Control for Multiple Unmanned Aerial Vehicles.,"This paper investigates the distributed finite-time fault-tolerant containment control problem for multiple unmanned aerial vehicles (multi-UAVs) in the presence of actuator faults and input saturation. The distributed finite-time sliding-mode observer (SMO) is first developed to estimate the reference for each follower UAV. Then, based on the estimated knowledge, the distributed finite-time fault-tolerant controller is recursively designed to guide all follower UAVs into the convex hull spanned by the trajectories of leader UAVs with the help of a new set of error variables. Moreover, the unknown nonlinearities inherent in the multi-UAVs system, computational burden, and input saturation are simultaneously handled by utilizing neural network (NN), minimum parameter learning of NN (MPLNN), first-order sliding-mode differentiator (FOSMD) techniques, and a group of auxiliary systems. Furthermore, the graph theory and Lyapunov stability analysis methods are adopted to guarantee that all follower UAVs can converge to the convex hull spanned by the leader UAVs even in the event of actuator faults. Finally, extensive comparative simulations have been conducted to demonstrate the effectiveness of the proposed control scheme.",4
Low-Rank Matrix Learning Using Biconvex Surrogate Minimization.,"Many machine learning problems involve learning a low-rank positive semidefinite matrix. However, existing solvers for this low-rank semidefinite program (SDP) are often expensive. In this paper, by factorizing the target matrix as a product of two matrices and using a Courant penalty to penalize for their difference, we reformulate the SDP as a biconvex optimization problem. This allows the use of multiconvex optimization techniques to define simple surrogates, which can be minimized easily by block coordinate descent. Moreover, while traditionally this biconvex problem approaches the original problem only when the penalty parameter is infinite, we show that the two problems are equivalent when the penalty parameter is sufficiently large. Experiments on a number of SDP applications in machine learning show that the proposed algorithm is as accurate as other state-of-the-art algorithms, but is much faster, especially on large data sets.",4
Impulsive Consensus of Nonlinear Multi-Agent Systems via Edge Event-Triggered Control.,"In this paper, we mainly investigate two kinds of consensuses of multi-agent systems (MASs) with nonlinear dynamics based on impulsive control, event-triggered control, and sampled-data control. The two types of impulsive protocols are proposed for the case without and with leader agent. Edge event-triggered technique is presented, where for each communication link, occurrence of edge event can activate the mutual state sampling and controller update of the corresponding agents. The control approach combines the characteristics of impulsive control and edge event-triggered control and is defined as ``impulsive edge event-triggered control.'' It has good performance in robustness against disturbance and reduces the communication cost. The results with the aid of the Lyapunov function approach and stability theory of impulsive control show that if some sufficient conditions are satisfied, the consensus of MASs can be guaranteed and the rate of convergence can be exponentially estimated. Additionally, Zeno-behavior can be eliminated by using impulsive edge event-triggered control, which reduces the burden of event detectors. Finally, two simulations are provided to illustrate the effectiveness and performance of our theoretical analysis.",4
Deep Reinforcement Learning-Based Automatic Exploration for Navigation in Unknown Environment.,"This paper investigates the automatic exploration problem under the unknown environment, which is the key point of applying the robotic system to some social tasks. The solution to this problem via stacking decision rules is impossible to cover various environments and sensor properties. Learning-based control methods are adaptive for these scenarios. However, these methods are damaged by low learning efficiency and awkward transferability from simulation to reality. In this paper, we construct a general exploration framework via decomposing the exploration process into the decision, planning, and mapping modules, which increases the modularity of the robotic system. Based on this framework, we propose a deep reinforcement learning-based decision algorithm that uses a deep neural network to learning exploration strategy from the partial map. The results show that this proposed algorithm has better learning efficiency and adaptability for unknown environments. In addition, we conduct the experiments on the physical robot, and the results suggest that the learned policy can be well transferred from simulation to the real robot.",4
Discrete Deep Hashing With Ranking Optimization for Image Retrieval.,"For large-scale image retrieval task, a hashing technique has attracted extensive attention due to its efficient computing and applying. By using the hashing technique in image retrieval, it is crucial to generate discrete hash codes and preserve the neighborhood ranking information simultaneously. However, both related steps are treated independently in most of the existing deep hashing methods, which lead to the loss of key category-level information in the discretization process and the decrease in discriminative ranking relationship. In order to generate discrete hash codes with notable discriminative information, we integrate the discretization process and the ranking process into one architecture. Motivated by this idea, a novel ranking optimization discrete hashing (RODH) method is proposed, which directly generates discrete hash codes (e.g., +1/-1) from raw images by balancing the effective category-level information of discretization and the discrimination of ranking information. The proposed method integrates convolutional neural network, discrete hash function learning, and ranking function optimizing into a unified framework. Meanwhile, a novel loss function based on label information and mean average precision (MAP) is proposed to preserve the label consistency and optimize the ranking information of hash codes simultaneously. Experimental results on four benchmark data sets demonstrate that RODH can achieve superior performance over the state-of-the-art hashing methods.",4
A Limitation of Gradient Descent Learning.,"Over decades, gradient descent has been applied to develop learning algorithm to train a neural network (NN). In this brief, a limitation of applying such algorithm to train an NN with persistent weight noise is revealed. Let V(w) be the performance measure of an ideal NN. V(w) is applied to develop the gradient descent learning (GDL). With weight noise, the desired performance measure (denoted as J(w)) is E[V(w)| w], where w is the noisy weight vector. Applying GDL to train an NN with weight noise, the actual learning objective is clearly not V(w) but another scalar function L(w). For decades, there is a misconception that L(w) = J(w), and hence, the actual model attained by the GDL is the desired model. However, we show that it might not: 1) with persistent additive weight noise, the actual model attained is the desired model as L(w) = J(w); and 2) with persistent multiplicative weight noise, the actual model attained is unlikely the desired model as L(w) not equal J(w). Accordingly, the properties of the models attained as compared with the desired models are analyzed and the learning curves are sketched. Simulation results on 1) a simple regression problem and 2) the MNIST handwritten digit recognition are presented to support our claims.",4
Optimal Power Management Based on Q-Learning and Neuro-Dynamic Programming for Plug-in Hybrid Electric Vehicles.,"Energy optimization for plug-in hybrid electric vehicles (PHEVs) is a challenging problem due to the system complexity and many physical and operational constraints in PHEVs. In this paper, we present a Q-learning-based in-vehicle learning system that is free of physical models and can robustly converge to an optimal energy control solution. The proposed machine learning algorithms combine neuro-dynamic programming (NDP) with future trip information to effectively estimate the expected future energy cost (expected cost-to-go) for a given vehicle state and control actions. The convergences of these learning algorithms were demonstrated on both fixed and randomly selected drive cycles. Based on the characteristics of these learning algorithms, we propose a two-stage deployment solution for PHEV power management applications. Furthermore, we introduce a new initialization strategy, which combines the optimal learning with a properly selected penalty function. This initialization scheme can reduce the learning convergence time by 70%, which is a significant improvement for in-vehicle implementation efficiency. Finally, we develop a neural network (NN) for predicting battery state-of-charge (SoC), rendering the proposed power management controller completely free of physical models.",4
A Maximally Split and Relaxed ADMM for Regularized Extreme Learning Machines.,"One of the salient features of the extreme learning machine (ELM) is its fast learning speed. However, in a big data environment, the ELM still suffers from an overly heavy computational load due to the high dimensionality and the large amount of data. Using the alternating direction method of multipliers (ADMM), a convex model fitting problem can be split into a set of concurrently executable subproblems, each with just a subset of model coefficients. By maximally splitting across the coefficients and incorporating a novel relaxation technique, a maximally split and relaxed ADMM (MS-RADMM), along with a scalarwise implementation, is developed for the regularized ELM (RELM). The convergence conditions and the convergence rate of the MS-RADMM are established, which exhibits linear convergence with a smaller convergence ratio than the unrelaxed maximally split ADMM. The optimal parameter values of the MS-RADMM are obtained and a fast parameter selection scheme is provided. Experiments on ten benchmark classification data sets are conducted, the results of which demonstrate the fast convergence and parallelism of the MS-RADMM. Complexity comparisons with the matrix-inversion-based method in terms of the numbers of multiplication and addition operations, the computation time and the number of memory cells are provided for performance evaluation of the MS-RADMM.",4
A Projection Neural Network for the Generalized Lasso.,"The generalized lasso (GLasso) is an extension of the lasso regression in which there is an l(1) penalty term (or regularization) of the linearly transformed coefficient vector. Finding the optimal solution of GLasso is not straightforward since the penalty term is not differentiable. This brief presents a novel one-layer neural network to solve the generalized lasso for a wide range of penalty transformation matrices. The proposed neural network is proven to be stable in the sense of Lyapunov and converges globally to the optimal solution of the GLasso. It is also shown that the proposed neural solution can solve many optimization problems, including sparse and weighted sparse representations, (weighted) total variation denoising, fused lasso signal approximator, and trend filtering. Disparate experiments on the above problems illustrate and confirm the excellent performance of the proposed neural network in comparison to other competing techniques.",4
Graphical Nash Equilibria and Replicator Dynamics on Complex Networks.,"Pairwise-interaction graphical games have been widely used in the study and design of strategic interaction in multiagent systems. With regard to this issue, one entitative problem is actually to understand how the interaction structure of agents affects the strategy configuration of Nash equilibria. This paper intends to study the effect of interaction networks on Nash equilibria in pairwise-interaction graphical games. We first show that interaction networks may induce new strategy equilibria in pairwise-interaction graphical games and then provide graphical conditions for the existence of these network-induced equilibria. Furthermore, to determine Nash equilibria of pairwise-interaction graphical games, a graphical replicator dynamics model is formulated, and its connection with graphical games is established. In detail, it is shown that every Nash equilibrium of the graphical games corresponds to a fixed point of the graphical replicator dynamics and that every asymptotically stable fixed point of the graphical replicator dynamics corresponds to a strict pure Nash equilibrium of the graphical games. The obtained results are applied in understanding coordination in complex networks and determination of structural conflicts in signed graphs. This work may provide new insights into understanding and designing strategy equilibria and dynamics in games on networks.",4
Approximate Policy-Based Accelerated Deep Reinforcement Learning.,"In recent years, the deep reinforcement learning (DRL) algorithms have been developed rapidly and have achieved excellent performance in many challenging tasks. However, due to the complexity of network structure and a large amount of network parameters, the training of deep network is time-consuming, and consequently, the learning efficiency of DRL is limited. In this paper, aiming to speed up the learning process of DRL agent, we propose a novel approximate policy-based accelerated (APA) algorithm from the viewpoint of the error analysis of approximate policy iteration reinforcement learning algorithms. The proposed APA is proven to be convergent even with a more aggressive learning rate, making the DRL agent have a faster learning speed. Furthermore, to combine the accelerated algorithm with deep Q-network (DQN), Double DQN and deep deterministic policy gradient (DDPG), we proposed three novel DRL algorithms: APA-DQN, APA-Double DQN, and APA-DDPG, which demonstrates the adaptability of the accelerated algorithm with DRL algorithms. We have tested the proposed algorithms on both discrete-action and continuous-action tasks. Their superior performance demonstrates their great potential in the practical applications.",4
Pinning Synchronization of Directed Coupled Reaction-Diffusion Neural Networks With Sampled-Data Communications.,"This paper focuses on the design of a pinning sampled-data control mechanism for the exponential synchronization of directed coupled reaction-diffusion neural networks (CRDNNs) with sampled-data communications (SDCs). A new Lyapunov-Krasovskii functional (LKF) with some sampled-instant-dependent terms is presented, which can fully utilize the actual sampling information. Then, an inequality is first proposed, which effectively relaxes the restrictions of the positive definiteness of the constructed LKF. Based on the LKF and the inequality, sufficient conditions are derived to exponentially synchronize the directed CRDNNs with SDCs. The desired pinning sampled-data control gain is precisely obtained by solving some linear matrix inequalities (LMIs). Moreover, a less conservative exponential synchronization criterion is also established for directed coupled neural networks with SDCs. Finally, simulation results are provided to verify the effectiveness and merits of the theoretical results.",4
Error-Based Learning Mechanism for Fast Online Adaptation in Robot Motor Control.,"Existing state-of-the-art frequency adaptation mechanisms of central pattern generators (CPGs) for robot locomotion control typically rely on correlation-based learning. They do not account for the tracking error that may occur between the actual system motion and CPG output, leading to the loss of precision, unwanted movement, inefficient energy locomotion, and in the worst cases, motor collapse. To overcome this problem, we developed online error-based learning for frequency adaptation of CPGs. The learning mechanism used for error reduction is a novel modification of the dual learner (DL) called dual integral learner (DIL). Being able to reduce tracking and steady-state errors, it can also perform fast and stable learning, adapting the CPG frequency to match the performance of robotic systems. Control parameters of the DIL are more straightforward for complex systems (like walking robots), compared to traditional correlation-based learning, since they correspond to error reduction. Due to its embedded memory, the DIL can relearn quickly and recover spontaneously from the previously learned parameters. All these features are not covered by the existing frequency adaptation mechanisms. We integrated the DIL into a neural CPG-based motor control system for use on different legged robots with various morphologies for evaluation. The results show that: 1) the DIL does not require precise adjustment of its parameters to fit specific robots; and 2) the DIL can automatically and quickly adapt the CPG frequency to the robots such that the entire trajectory of the CPG can be precisely followed with very low tracking and steady-state errors. Consequently, the robots can perform the desired movements with more energy-efficient locomotion compared to the state-of-the-art correlation-based learning mechanism called frequency adaptation through fast dynamical coupling (AFDC). In the future, the proposed error-based learning mechanism for fast online adaptation in robot motor control can be used as a basis for trajectory optimization, universal controllers, and other studies concerning the change of intrinsic or extrinsic parameters.",4
Learning Deep Landmarks for Imbalanced Classification.,"We introduce a deep imbalanced learning framework called learning DEep Landmarks in laTent spAce (DELTA). Our work is inspired by the shallow imbalanced learning approaches to rebalance imbalanced samples before feeding them to train a discriminative classifier. Our DELTA advances existing works by introducing the new concept of rebalancing samples in a deeply transformed latent space, where latent points exhibit several desired properties including compactness and separability. In general, DELTA simultaneously conducts feature learning, sample rebalancing, and discriminative learning in a joint, end-to-end framework. The framework is readily integrated with other sophisticated learning concepts including latent points oversampling and ensemble learning. More importantly, DELTA offers the possibility to conduct imbalanced learning with the assistancy of structured feature extractor. We verify the effectiveness of DELTA not only on several benchmark data sets but also on more challenging real-world tasks including click-through-rate (CTR) prediction, multi-class cell type classification, and sentiment analysis with sequential inputs.",4
Stubborn State Estimation for Delayed Neural Networks Using Saturating Output Errors.,"This paper is concerned with the stubborn state estimation of delayed neural networks that subject to a general class of disturbances in measurements, including outliers and impulsive disturbances as its special cases. This class of disturbances may be unbounded, irregular, and assorted; therefore, they can hardly be suppressed by existing identification-based estimation approaches. In this paper, a stubborn state estimator is constructed by intentionally devising a saturation scheme on the injection of output estimation error. The embedded saturation can effectively resist the influences from these measurement disturbances by saturating them. Moreover, the saturation threshold in the designed scheme is not constant but governed by a dynamic equation with parameters to be designed. Benefiting from this adaptiveness, the estimator obtains more freedom in dealing with various disturbances. By combining a novel Lyapunov functional, the generalized sector condition and two latest integral inequalities, a delay-dependent criterion is derived in a less conservative way to check whether the estimation error system with this dynamic saturation is globally stable. A sufficient condition with two tuning scalars is further provided to codesign the gain of the state estimator and the evolution law of the saturation threshold. Finally, two numerical examples are used to illustrate the stubbornness of this state estimator in the presence of measurement outliers or impulsive disturbances.",4
Event-Based Adaptive Neural Tracking Control for Discrete-Time Stochastic Nonlinear Systems: A Triggering Threshold Compensation Strategy.,"This paper investigates the event-triggered (ET) tracking control problem for a class of discrete-time strict-feedback nonlinear systems subject to both stochastic noises and limited controller-to-actuator communication capacities. The ET mechanism with fixed triggering threshold is designed to decide whether the current control signal should be transmitted to the actuator. A systematic framework is developed to construct a novel adaptive neural controller by directly applying the backstepping procedure to the underlying system. The proposed framework overcomes the noncausality problem, avoids the possible controller-related singularity problem, and gets rid of the neural approximation of the virtual control laws. Under the ET mechanism, the corresponding ET-based actuator is put forward by introducing an ET threshold compensation operator. Such a compensation operator (with an adjustable design parameter) is subtly designed based on a hyperbolic tangent function and a sign function. The threshold compensation error is analytically characterized in terms of a time-varying parameter, and the error bound is shown to be relatively small that is dependent on the adjustable design parameter. Compared with the traditional ET-based actuator without the compensation operator, the proposed ET-based actuator exhibits several distinguished features including: 1) improvement of the tracking accuracy (especially at the triggering instants); 2) further mitigation of the communication load; and 3) enlargement of the allowable range of the ET threshold. These features are illustrated by numerical and practical examples.",4
Variance-Constrained Recursive State Estimation for Time-Varying Complex Networks With Quantized Measurements and Uncertain Inner Coupling.,"In this paper, a new recursive state estimation problem is discussed for a class of discrete time-varying stochastic complex networks with uncertain inner coupling and signal quantization under the error-variance constraints. The coupling strengths are allowed to be varying within certain intervals, and the measurement signals are subject to the quantization effects before being transmitted to the remote estimator. The focus of the conducted topic is on the design of a variance-constrained state estimation algorithm with the aim to ensure a locally minimized upper bound on the estimation error covariance at every sampling instant. Furthermore, the boundedness of the resulting estimation error is analyzed, and a sufficient criterion is established to ensure the desired exponential boundedness of the state estimation error in the mean square sense. Finally, some simulations are proposed with comparisons to illustrate the validity of the newly developed variance-constrained estimation method.",4
Adaptive Neural Quantized Control for a Class of MIMO Switched Nonlinear Systems With Asymmetric Actuator Dead-Zone.,"This paper concentrates on the adaptive state-feedback quantized control problem for a class of multipleinput-multiple-output (MIMO) switched nonlinear systems with unknown asymmetric actuator dead-zone. In this study, we employ different quantizers for different subsystem inputs. The main challenge of this study is to deal with the coupling between the quantizers and the dead-zone nonlinearities. To solve this problem, a novel approximation model for the coupling between quantizer and dead-zone is proposed. Then, the corresponding robust adaptive law is designed to eliminate this nonlinear term asymptotically. A direct neural control scheme is employed to reduce the number of adaptive laws significantly. The backstepping-based adaptive control scheme is also presented to guarantee the system performance. Finally, two simulation examples are presented to show the effectiveness of our control scheme.",4
Multistability of Almost Periodic Solution for Memristive Cohen-Grossberg Neural Networks With Mixed Delays.,"This paper presents the multistability analysis of almost periodic state solutions for memristive Cohen-Grossberg neural networks (MCGNNs) with both distributed delay and discrete delay. The activation function of the considered MCGNNs is generalized to be nonmonotonic and nonpiecewise linear. It is shown that the MCGNNs with n-neuron have (K+1)(n) locally exponentially stable almost periodic solutions, where nature number K depends on the geometrical structure of the considered activation function. Compared with the previous related works, the number of almost periodic state solutions of the MCGNNs is extensively increased. The obtained conclusions in this paper are also capable of studying the multistability of equilibrium points or periodic solutions of the MCGNNs. Moreover, the enlarged attraction basins of attractors are estimated based on original partition. Some comparisons and convincing numerical examples are provided to substantiate the superiority and efficiency of obtained results.",4
Stress-Testing Memcomputing on Hard Combinatorial Optimization Problems.,"Memcomputing is a novel computing paradigm that employs time non-local dynamical systems to compute with and in memory. The digital version of these machines [digital memcomputing machines or (DMMs)] is scalable, and is particularly suited to solve combinatorial optimization problems. One of its possible realizations is by means of standard electronic circuits, with and without memory. Since these elements are non-quantum, they can be described by ordinary differential equations. Therefore, the circuit representation of DMMs can also be simulated efficiently on our traditional computers. We have indeed previously shown that these simulations only require time and memory resources that scale linearly with the problem size when applied to finding a good approximation to the optimum of hard instances of the maximum-satisfiability problem. The state-of-the-art algorithms, instead, require exponential resources for the same instances. However, in that work, we did not push the simulations to the limit of the processor used. Since linear scalability at smaller problem sizes cannot guarantee linear scalability at much larger sizes, we have extended these results in a stress-test up to 64x10(6) variables (corresponding to about 1 billion literals), namely the largest case that we could fit on a single core of an Intel Xeon E5-2860 with 128 GB of dynamic random-access memory (DRAM). For this test, we have employed a commercial simulator, Falcon of MemComputing, Inc. We find that the simulations of DMMs still scale linearly in both time and memory up to these very large problem sizes versus the exponential requirements of the state-of-the-art solvers. These results further reinforce the advantages of the physics-based memcomputing approach compared with traditional ones.",4
Generative Memory for Lifelong Learning.,"Lifelong learning is a crucial issue in advanced artificial intelligence. It requires the learning system to learn and accumulate knowledge from sequential tasks. The learning system needs to deal with increasingly more domains and tasks. We consider that the key to an effective and efficient lifelong learning system is the ability to memorize and recall the learned knowledge using neural networks. Following this idea, we propose Generative Memory (GM) as a novel memory module, and the resulting lifelong learning system is referred to as the GM Net (GMNet). To make the GMNet feasible, we propose a novel learning mechanism, referred to as P-invariant learning method. It replaces the memory of the real data by a memory of the data distribution, which makes it possible for the learning system to accurately and continuously accumulate the learned experiences. We demonstrate that GMNet achieves the state-of-the-art performance on lifelong learning tasks.",4
Incremental Reinforcement Learning in Continuous Spaces via Policy Relaxation and Importance Weighting.,"In this paper, a systematic incremental learning method is presented for reinforcement learning in continuous spaces where the learning environment is dynamic. The goal is to adjust the previously learned policy in the original environment to a new one incrementally whenever the environment changes. To improve the adaptability to the ever-changing environment, we propose a two-step solution incorporated with the incremental learning procedure: policy relaxation and importance weighting. First, the behavior policy is relaxed to a random one in the initial learning episodes to encourage a proper exploration in the new environment. It alleviates the conflict between the new information and the existing knowledge for a better adaptation in the long term. Second, it is observed that episodes receiving higher returns are more in line with the new environment, and hence contain more new information. During parameter updating, we assign higher importance weights to the learning episodes that contain more new information, thus encouraging the previous optimal policy to be faster adapted to a new one that fits in the new environment. Empirical studies on continuous controlling tasks with varying configurations verify that the proposed method achieves a significantly faster adaptation to various dynamic environments than the baselines.",4
On Optimal Time-Varying Feedback Controllability for Probabilistic Boolean Control Networks.,"This brief studies controllability for probabilistic Boolean control network (PBCN) with time-varying feedback control laws. The concept of feedback controllability with an arbitrary probability for PBCNs is formulated first, and a control problem to maximize the probability of time-varying feedback controllability is investigated afterward. By introducing semitensor product (STP) technique, an equivalent multistage decision problem is deduced, and then a novel optimization algorithm is proposed to obtain the maximum probability of controllability and the corresponding optimal feedback law simultaneously. The advantages of the time-varying optimal controller obtained by the proposed algorithm, compared to the time-invariant one, are illustrated by numerical simulations.",4
Episodic Memory in Minicolumn Associative Knowledge Graphs.,"A generalization of active neural associative knowledge graphs (ANAKGs) to their minicolumn form is presented in this paper. Each minicolumn represents a single symbol, and the activation of an individual neuron in a minicolumn depends on the context of the activation of the presynaptic neuron. The implemented memory model combines the ANAKG associative spiking neuron idea with the idea of the hierarchical temporal memory. This new associative memory organization preserves all properties of ANAKG memories, such as storage of knowledge based on the association of spatiotemporal input sequences, self-organization, quick learning, and recall of the sequential memories, while increasing the recall quality and the memory capacity. The recall quality advantage of the new approach over ANAKG increases with the length of the recalled episodes and the number of neurons used in each minicolumn. We introduced a new distance measure to compare the recalled sequences and defined a recall quality to determine the memory capacity. Performed tests confirmed our claims. Additional tests were performed to illustrate the computational complexity and the efficiency of the developed approach.",4
Contrastive Hebbian Feedforward Learning for Neural Networks.,"This paper addresses the biological plausibility of both backpropagation (BP) and contrastive Hebbian learning (CHL) used in the Boltzmann machines. The main claim of this paper is that CHL is a general learning algorithm that can be used to steer feedforward networks toward desirable outcomes, and steer them away from undesirable outcomes without any need for the specialized feedback circuit of BP or the symmetric connections used by the Boltzmann machines. After adding perturbations during the learning phase to all the neurons in the network, multiple feedforward outcomes are classified into Hebbian and anti-Hebbian sets based on the network predictions. The algorithm is applied to networks when optimizing a loss objective where BP excels and is also applied to networks with stochastic binary outputs where BP cannot be easily applied. The power of the proposed algorithm lies in its simplicity where both learning and gradient estimation through stochastic binary activations are combined into a single local Hebbian rule. We will also show that both Hebbian and anti-Hebbian correlations are evaluated from the readily available signals that are fundamentally different from CHL used in the Boltzmann machines. We will demonstrate that the new learning paradigm where Hebbian/anti-Hebbian correlations are based on correct/incorrect predictions is a powerful concept that separates this paper from other biologically inspired learning algorithms.",4
Change Detection in Graph Streams by Learning Graph Embeddings on Constant-Curvature Manifolds.,"The space of graphs is often characterized by a nontrivial geometry, which complicates learning and inference in practical applications. A common approach is to use embedding techniques to represent graphs as points in a conventional Euclidean space, but non-Euclidean spaces have often been shown to be better suited for embedding graphs. Among these, constant-curvature Riemannian manifolds (CCMs) offer embedding spaces suitable for studying the statistical properties of a graph distribution, as they provide ways to easily compute metric geodesic distances. In this paper, we focus on the problem of detecting changes in stationarity in a stream of attributed graphs. To this end, we introduce a novel change detection framework based on neural networks and CCMs, which takes into account the non-Euclidean nature of graphs. Our contribution in this paper is twofold. First, via a novel approach based on adversarial learning, we compute graph embeddings by training an autoencoder to represent graphs on CCMs. Second, we introduce two novel change detection tests operating on CCMs. We perform experiments on synthetic data, as well as two real-world application scenarios: the detection of epileptic seizures using functional connectivity brain networks and the detection of hostility between two subjects, using human skeletal graphs. Results show that the proposed methods are able to detect even small changes in a graph-generating process, consistently outperforming approaches based on Euclidean embeddings.",4
Improved Sliding Mode Control for Finite-Time Synchronization of Nonidentical Delayed Recurrent Neural Networks.,"This brief further explores the problem of finite-time synchronization of delayed recurrent neural networks with the mismatched parameters and neuron activation functions. An improved sliding mode control approach is presented for addressing the finite-time synchronization problem. First, by employing the drive-response concept and the synchronization error of drive-response systems, a novel integral sliding mode surface is constructed such that the synchronization error can converge to zero in finite time along the constructed integral sliding mode surface. Second, a suitable sliding mode controller is designed by relying on Lyapunov stability theory such that all system state trajectories can be driven onto the predefined sliding mode surface in finite time. Moreover, it is found that the presented control approach can be conveniently verified and does not need to solve any linear matrix inequality (LMI) to guarantee the finite-time synchronization of delayed recurrent neural networks. Finally, three numerical examples are exploited to demonstrate the effectiveness of the presented control approach.",4
Design of State-Dependent Switching Laws for Stability of Switched Stochastic Neural Networks With Time-Delays.,"We study the stability properties of switched stochastic neural networks (SSNNs) with time-varying delays whose subsystem is not necessarily stable. We introduce state-dependent switching (SDS) as a tool for stability analysis. Some SDS laws for asymptotic stability and pth moment exponentially stable are designed by employing Lyapunov-Krasovskii (L-K) functional and Lyapunov-Razumikhin (L-R) method, respectively. It is shown that the stability of SSNNs with time-varying delays composed of unstable subsystems can be achieved by using SDS law. The control gains in the designed SDS laws can be derived by solving the LMIs in derived stability criteria. Two numerical examples are provided to demonstrate the effectiveness of the proposed SDS laws.",4
Knowledge-Driven Deep Unrolling for Robust Image Layer Separation.,"Single-image layer separation targets to decompose the observed image into two independent components in terms of different application demands. It is known that many vision and multimedia applications can be (re)formulated as a separation problem. Due to the fundamentally ill-posed natural of these separations, existing methods are inclined to investigate model priors on the separated components elaborately. Nevertheless, it is knotty to optimize the cost function with complicated model regularizations. Effectiveness is greatly conceded by the settled iteration mechanism, and the adaption cannot be guaranteed due to the poor data fitting. What is more, for a universal framework, the most taxing point is that one type of visual cue cannot be shared with different tasks. To partly overcome the weaknesses mentioned earlier, we delve into a generic optimization unrolling technique to incorporate deep architectures into iterations for adaptive image layer separation. First, we propose a general energy model with implicit priors, which is based on maximum a posterior, and employ the extensively accepted alternating direction method of multiplier to determine our elementary iteration mechanism. By unrolling with one general residual architecture prior and one task-specific prior, we attain a straightforward, flexible, and data-dependent image separation framework successfully. We apply our method to four different tasks, including single-image-rain streak removal, high-dynamic-range tone mapping, low-light image enhancement, and single-image reflection removal. Extensive experiments demonstrate that the proposed method is applicable to multiple tasks and outperforms the state of the arts by a large margin qualitatively and quantitatively.",4
Minimization of Fraction Function Penalty in Compressed Sensing.,"In this paper, we study the minimization problem of a non-convex sparsity-promoting penalty function, i.e., fraction function, in compressed sensing. First, we discuss the equivalence of l(0) minimization and fraction function minimization. It is proved that the optimal solution to fraction function minimization solves l(0) minimization and the optimal solution to the regularization problem also solves fraction function minimization if the certain conditions are satisfied, which is similar to the regularization problem in a convex optimization theory. Second, we study the properties of the optimal solution to the regularization problem, including the first-order and second-order optimality conditions and the lower and upper bounds of the absolute value for its nonzero entries. Finally, we derive the closed-form representation of the optimal solution to the regularization problem and propose an iterative FP thresholding algorithm to solve the regularization problem. We also provide a series of experiments to assess the performance of the FP algorithm, and the experimental results show that the FP algorithm performs well in sparse signal recovery with and without measurement noise.",4
Direct Error-Driven Learning for Deep Neural Networks With Applications to Big Data.,"In this brief, heterogeneity and noise in big data are shown to increase the generalization error for a traditional learning regime utilized for deep neural networks (deep NNs). To reduce this error, while overcoming the issue of vanishing gradients, a direct error-driven learning (EDL) scheme is proposed. First, to reduce the impact of heterogeneity and data noise, the concept of a neighborhood is introduced. Using this neighborhood, an approximation of generalization error is obtained and an overall error, comprised of learning and the approximate generalization errors, is defined. A novel NN weight-tuning law is obtained through a layer-wise performance measure enabling the direct use of overall error for learning. Additional constraints are introduced into the layer-wise performance measure to guide and improve the learning process in the presence of noisy dimensions. The proposed direct EDL scheme effectively addresses the issue of heterogeneity and noise while mitigating vanishing gradients and noisy dimensions. A comprehensive simulation study is presented where the proposed approach is shown to mitigate the vanishing gradient problem while improving generalization by 6%.",4
Deep Spiking Neural Network for Video-Based Disguise Face Recognition Based on Dynamic Facial Movements.,"With the increasing popularity of social media and smart devices, the face as one of the key biometrics becomes vital for person identification. Among those face recognition algorithms, video-based face recognition methods could make use of both temporal and spatial information just as humans do to achieve better classification performance. However, they cannot identify individuals when certain key facial areas, such as eyes or nose, are disguised by heavy makeup or rubber/digital masks. To this end, we propose a novel deep spiking neural network architecture in this paper. It takes dynamic facial movements, the facial muscle changes induced by speaking or other activities, as the sole input. An event-driven continuous spike-timing-dependent plasticity learning rule with adaptive thresholding is applied to train the synaptic weights. The experiments on our proposed video-based disguise face database (MakeFace DB) demonstrate that the proposed learning method performs very well, i.e., it achieves from 95% to 100% correct classification rates under various realistic experimental scenarios.",4
A Semisupervised Recurrent Convolutional Attention Model for Human Activity Recognition.,"Recent years have witnessed the success of deep learning methods in human activity recognition (HAR). The longstanding shortage of labeled activity data inherently calls for a plethora of semisupervised learning methods, and one of the most challenging and common issues with semisupervised learning is the imbalanced distribution of labeled data over classes. Although the problem has long existed in broad real-world HAR applications, it is rarely explored in the literature. In this paper, we propose a semisupervised deep model for imbalanced activity recognition from multimodal wearable sensory data. We aim to address not only the challenges of multimodal sensor data (e.g., interperson variability and interclass similarity) but also the limited labeled data and class-imbalance issues simultaneously. In particular, we propose a pattern-balanced semisupervised framework to extract and preserve diverse latent patterns of activities. Furthermore, we exploit the independence of multi-modalities of sensory data and attentively identify salient regions that are indicative of human activities from inputs by our recurrent convolutional attention networks. Our experimental results demonstrate that the proposed model achieves a competitive performance compared to a multitude of state-of-the-art methods, both semisupervised and supervised ones, with 10% labeled training data. The results also show the robustness of our method over imbalanced, small training data sets.",4
Lightweight Pyramid Networks for Image Deraining.,"Existing deep convolutional neural networks (CNNs) have found major success in image deraining, but at the expense of an enormous number of parameters. This limits their potential applications, e.g., in mobile devices. In this paper, we propose a lightweight pyramid networt (LPNet) for single-image deraining. Instead of designing a complex network structure, we use domain-specific knowledge to simplify the learning process. In particular, we find that by introducing the mature Gaussian-Laplacian image pyramid decomposition technology to the neural network, the learning problem at each pyramid level is greatly simplified and can be handled by a relatively shallow network with few parameters. We adopt recursive and residual network structures to build the proposed LPNet, which has less than 8K parameters while still achieving the state-of-the-art performance on rain removal. We also discuss the potential value of LPNet for other low- and high-level vision tasks.",4
Reconstruction Regularized Deep Metric Learning for Multi-Label Image Classification.,"In this paper, we present a novel deep metric learning method to tackle the multi-label image classification problem. In order to better learn the correlations among images features, as well as labels, we attempt to explore a latent space, where images and labels are embedded via two unique deep neural networks, respectively. To capture the relationships between image features and labels, we aim to learn a two-way deep distance metric over the embedding space from two different views, i.e., the distance between one image and its labels is not only smaller than those distances between the image and its labels' nearest neighbors but also smaller than the distances between the labels and other images corresponding to the labels' nearest neighbors. Moreover, a reconstruction module for recovering correct labels is incorporated into the whole framework as a regularization term, such that the label embedding space is more representative. Our model can be trained in an end-to-end manner. Experimental results on publicly available image data sets corroborate the efficacy of our method compared with the state of the arts.",4
Neural Network-Based Information Transfer for Dynamic Optimization.,"In dynamic optimization problems (DOPs), as the environment changes through time, the optima also dynamically change. How to adapt to the dynamic environment and quickly find the optima in all environments is a challenging issue in solving DOPs. Usually, a new environment is strongly relevant to its previous environment. If we know how it changes from the previous environment to the new one, then we can transfer the information of the previous environment, e.g., past solutions, to get new promising information of the new environment, e.g., new high-quality solutions. Thus, in this paper, we propose a neural network (NN)-based information transfer method, named NNIT, to learn the transfer model of environment changes by NN and then use the learned model to reuse the past solutions. When the environment changes, NNIT first collects the solutions from both the previous environment and the new environment and then uses an NN to learn the transfer model from these solutions. After that, the NN is used to transfer the past solutions to new promising solutions for assisting the optimization in the new environment. The proposed NNIT can be incorporated into population-based evolutionary algorithms (EAs) to solve DOPs. Several typical state-of-the-art EAs for DOPs are selected for comprehensive study and evaluated using the widely used moving peaks benchmark. The experimental results show that the proposed NNIT is promising and can accelerate algorithm convergence.",4
Energy Disaggregation via Deep Temporal Dictionary Learning.,"This paper presents a novel nonlinear dictionary learning (DL) model to address the energy disaggregation (ED) problem, i.e., decomposing the electricity signal of a home to its operating devices. First, ED is modeled as a new temporal DL problem where a set of dictionary atoms is learned to capture the most representative temporal features of electricity signals. The sparse codes corresponding to these atoms show the contribution of each device in the total electricity consumption. To learn powerful atoms, a novel deep temporal DL (DTDL) model is proposed that computes complex nonlinear dictionaries in the latent space of a long short-term memory autoencoder (LSTM-AE). While the LSTM-AE captures the deep temporal manifold of electricity signals, the DTDL model finds the most representative atoms inside this manifold. To simultaneously optimize the dictionary and the deep temporal manifold, a new optimization algorithm is proposed that alternates between finding the optimal LSTM-AE and the optimal dictionary. To the best of authors' knowledge, DTDL is the only DL model that understands the deep temporal structures of the data. Experiments on the Reference ED Data Set show an outstanding performance compared with the recent state-of-the-art algorithms in terms of precision, recall, accuracy, and F-score.",4
GANE: A Generative Adversarial Network Embedding.,"Network embedding is capable of providing low-dimensional feature representations for various machine learning applications. Current work focuses on: 1) designing the embedding as an unsupervised learning task to explicitly preserve the structural connectivity in the network or 2) generating the embedding as a by-product during the supervised learning of a specific discriminative task in a deep neural network. In this paper, we aim to take advantage of these two lines of research in the view of multi-output learning. That is, we propose a generative adversarial network embedding (GANE) model to adapt the generative adversarial framework to achieve the network embedding learning during the specific machine learning tasks. GANE has a generator to generate link edges, and a discriminator to distinguish the generated link edges from real connections (edges) in the network. Wasserstein-1 distance is adopted to train the generator to gain better stability. GANE is further extended by utilizing the pairwise connectivity of vertices to preserve the structural information in the original network. Experiments with real-world network data sets demonstrate that our models constantly outperform state-of-the-art solutions with significant improvements for the tasks of link prediction, clustering, and network alignment.",4
Deep Class-Wise Hashing: Semantics-Preserving Hashing via Class-Wise Loss.,"Deep supervised hashing has emerged as an effective solution to large-scale semantic image retrieval problems in computer vision. Convolutional neural network-based hashing methods typically seek pairwise or triplet labels to conduct similarity-preserving learning. However, complex semantic concepts of visual contents are hard to capture by similar/dissimilar labels, which limits the retrieval performance. Generally, pairwise or triplet losses not only suffer from expensive training costs but also lack sufficient semantic information. In this paper, we propose a novel deep supervised hashing model to learn more compact class-level similarity-preserving binary codes. Our model is motivated by deep metric learning that directly takes semantic labels as supervised information in training and generates corresponding discriminant hashing code. Specifically, a novel cubic constraint loss function based on Gaussian distribution is proposed, which preserves semantic variations while penalizes the overlapping part of different classes in the embedding space. To address the discrete optimization problem introduced by binary codes, a two-step optimization strategy is proposed to provide efficient training and avoid the problem of gradient vanishing. Extensive experiments on five large-scale benchmark databases show that our model can achieve the state-of-the-art retrieval performance.",4
Associative Memories With Synaptic Delays.,"In this paper, we introduce a new concept of associative memories in which synaptic connections of the self-organizing neural network learn time delays between input sequence elements. Synaptic connections represent both the synaptic weights and expected delays between the network inputs. This property of synaptic connections facilitates recognition of time sequences and provides context-based associations between sequence elements. Characteristics of time delays are learned and are updated each time an input sequence is presented. There are no separate learning and testing modes typically used in other neural networks, as the network starts to predict the next input element as soon as there is no expected input signal. The network generates output signals useful for associative recall and prediction. These output signals depend on the presented input context and the knowledge stored in the graph. Such a mode of operation is preferred for the organization of episodic memories used to store the observed episodes and to recall them if a sufficient context is provided. The associative sequential recall is useful for the operation of working memory in a cognitive agent. Test results demonstrate that the network correctly recognizes the input sequences with variable delays and that it is more efficient than other recently developed sequential memory networks based on associative neurons.",4
Estimation of Domain of Attraction for Aperiodic Sampled-Data Switched Delayed Neural Networks Subject to Actuator Saturation.,"In this paper, for the case of the asynchronous switching caused by that subsystem's switching occuring during a sampling interval, the domain of attraction estimation problem is investigated for aperiodic sampled-data switched delayed neural networks (ASDSDNNs) subject to actuator saturation. A parameters-dependent time-scheduled Lyapunov functional consisting of a novel looped-functional is constructed using segmentation technology and linear interpolation. By employing this novel functional and using an average dwell time (ADT) approach, exponential stability criteria are proposed for polytopic uncertain ASDSDNNs subject to actuator saturation. And a relationship between ADT and sampling period is revealed for ASDSDNNs. As a corollary, exponential stability criteria are proposed for nominal ASDSDNNs subject to actuator saturation. Furthermore, by describing the domain of attraction as a time-varying ellipsoid determined by the time-scheduled Lyapunov matrix, the proposed theoretical conditions are transformed into a linear matrix inequality (LMI)-based multi-objective optimization problem. The dynamic estimates of the domain of attraction for ASDSDNNs are solved. Numerical simulation examples are provided to illustrate the effectiveness of the proposed method.",4
Skip-Connected Covariance Network for Remote Sensing Scene Classification.,"This paper proposes a novel end-to-end learning model, called skip-connected covariance (SCCov) network, for remote sensing scene classification (RSSC). The innovative contribution of this paper is to embed two novel modules into the traditional convolutional neural network (CNN) model, i.e., skip connections and covariance pooling. The advantages of newly developed SCCov are twofold. First, by means of the skip connections, the multi-resolution feature maps produced by the CNN are combined together, which provides important benefits to address the presence of large-scale variance in RSSC data sets. Second, by using covariance pooling, we can fully exploit the second-order information contained in such multi-resolution feature maps. This allows the CNN to achieve more representative feature learning when dealing with RSSC problems. Experimental results, conducted using three large-scale benchmark data sets, demonstrate that our newly proposed SCCov network exhibits very competitive or superior classification performance when compared with the current state-of-the-art RSSC techniques, using a much lower amount of parameters. Specifically, our SCCov only needs 10% of the parameters used by its counterparts.",4
Adaptive Decentralized Neural Network Tracking Control for Uncertain Interconnected Nonlinear Systems With Input Quantization and Time Delay.,"This study investigates the problem of adaptive decentralized tracking control for a class of interconnected nonlinear systems with input quantization, unknown function, and time-delay, where the time-delay and interconnection terms are supposed to be bounded by some completely unknown functions. An adaptive decentralized tracking controller is constructed via the backstepping method and neural network technique, where a sliding-mode differentiator is presented to estimate the derivative of the virtual control law and reduce the complexity of the control scheme. On the basis of Lyapunov analysis scheme and graph theory, all the signals of the closed-loop system are uniformly ultimately bounded. Finally, an application example of an inverted pendulum system is given to demonstrate the effectiveness of the developed methods.",4
An Efficient Entropy-Based Causal Discovery Method for Linear Structural Equation Models With IID Noise Variables.,"The discovery of causal relationships from the observational data is an important task. To identify the unique causal structure belonging to a Markov equivalence class, a number of algorithms, such as the linear non-Gaussian acyclic model (LiNGAM), have been proposed. However, two challenges remain to be met: 1) these algorithms fail to work on the data which follow linear structural equation model with Gaussian noise and 2) they misjudge the causal direction when the data contain additional measurement errors. In this paper, we propose an entropy-based two-phase iterative algorithm for arbitrary distribution data with additional measurement errors under some mild assumptions. In the first phase of the algorithm, based on the property that entropy can measure the amount of information behind the data with arbitrary distribution, we design a general approach for the identification of exogenous variable on both Gaussian and non-Gaussian data, and we give the corresponding theoretical derivation. In the second phase, to eliminate the effects of measurement errors, we revise the value of the exogenous variable by removing its measurement error and further use the revised value to remove its effect on the remaining variables. Experimental results on real-world causal structures are presented to demonstrate the effectiveness and stability of our method. We also apply the proposed algorithm on the mobile-base-station data with measurement errors, and the results further prove the effectiveness of our algorithm.",4
Cascade Superpixel Regularized Gabor Feature Fusion for Hyperspectral Image Classification.,"A 3-D Gabor wavelet provides an effective way to obtain the spectral-spatial-fused features for hyperspectral image, which has shown advantageous performance for material classification and recognition. In this paper, instead of separately employing the Gabor magnitude and phase features, which, respectively, reflect the intensity and variation of surface materials in local area, a cascade superpixel regularized Gabor feature fusion (CSRGFF) approach has been proposed. First, the Gabor filters with particular orientation are utilized to obtain Gabor features (including magnitude and phase) from the original hyperspectral image. Second, a support vector machine (SVM)-based probability representation strategy is developed to fully exploit the decision information in SVM output, and the achieved confidence score can make the following fusion with Gabor phase more effective. Meanwhile, the quadrant bit coding and Hamming distance metric are applied to encode the Gabor phase features and measure sample similarity in sequence. Third, the carefully defined characteristics of two kinds of features are directly combined together without any weighting operation to describe the weight of samples belonging to each class. Finally, a series of superpixel graphs extracted from the raw hyperspectral image with different numbers of superpixels are employed to successively regularize the weighting cube from over-segmentation to under-segmentation, and the classification performance gradually improves with the decrease in the number of superpixels in the regularization procedure. Four widely used real hyperspectral images have been conducted, and the experimental results constantly demonstrate the superiority of our CSRGFF approach over several state-of-the-art methods.",4
Person Reidentification via Multi-Feature Fusion With Adaptive Graph Learning.,"The goal of person reidentification (Re-ID) is to identify a given pedestrian from a network of nonoverlapping surveillance cameras. Most existing works follow the supervised learning paradigm which requires pairwise labeled training data for each pair of cameras. However, this limits their scalability to real-world applications where abundant unlabeled data are available. To address this issue, we propose a multi-feature fusion with adaptive graph learning model for unsupervised Re-ID. Our model aims to negotiate comprehensive assessment on the consistent graph structure of pedestrians with the help of special information of feature descriptors. Specifically, we incorporate multi-feature dictionary learning and adaptive multi-feature graph learning into a unified learning model such that the learned dictionaries are discriminative and the subsequent graph structure learning is accurate. An alternating optimization algorithm with proved convergence is developed to solve the final optimization objective. Extensive experiments on four benchmark data sets demonstrate the superiority and effectiveness of the proposed method.",4
Cooperative Adaptive Output Regulation for Lower Triangular Nonlinear Multi-Agent Systems Subject to Jointly Connected Switching Networks.,"The cooperative global robust output regulation problem for multi-agent systems is a generalization of the leader-following consensus problem. The problem has been studied for various multi-agent systems over connected static networks and for some special classes of nonlinear multi-agent systems over jointly connected switching networks. In this paper, we further consider the same problem for a class of heterogeneous lower triangular nonlinear multi-agent systems over jointly connected switching networks. This class of systems is quite general in that it contains inverse dynamics, is of any order, and its subsystems can have different relative degrees. We will integrate the adaptive distributed observer and the distributed internal model approach to come up with a recursive approach to deal with our problem. We will also apply our approach to a leader-following consensus problem for a group of hyperchaotic Lorenz systems.",4
SVRG-MKL: A Fast and Scalable Multiple Kernel Learning Solution for Features Combination in Multi-Class Classification Problems.,"In this paper, we present a novel strategy to combine a set of compact descriptors to leverage an associated recognition task. We formulate the problem from a multiple kernel learning (MKL) perspective and solve it following a stochastic variance reduced gradient (SVRG) approach to address its scalability, currently an open issue. MKL models are ideal candidates to jointly learn the optimal combination of features along with its associated predictor. However, they are unable to scale beyond a dozen thousand of samples due to high computational and memory requirements, which severely limits their applicability. We propose SVRG-MKL, an MKL solution with inherent scalability properties that can optimally combine multiple descriptors involving millions of samples. Our solution takes place directly in the primal to avoid Gram matrices computation and memory allocation, whereas the optimization is performed with a proposed algorithm of linear complexity and hence computationally efficient. Our proposition builds upon recent progress in SVRG with the distinction that each kernel is treated differently during optimization, which results in a faster convergence than applying off-the-shelf SVRG into MKL. Extensive experimental validation conducted on several benchmarking data sets confirms a higher accuracy and a significant speedup of our solution. Our technique can be extended to other MKL problems, including visual search and transfer learning, as well as other formulations, such as group-sensitive (GMKL) and localized MKL (LMKL) in convex settings.",4
Distributed Training for Multi-Layer Neural Networks by Consensus.,"Over the past decade, there has been a growing interest in large-scale and privacy-concerned machine learning, especially in the situation where the data cannot be shared due to privacy protection or cannot be centralized due to computational limitations. Parallel computation has been proposed to circumvent these limitations, usually based on the master-slave and decentralized topologies, and the comparison study shows that a decentralized graph could avoid the possible communication jam on the central agent but incur extra communication cost. In this brief, a consensus algorithm is designed to allow all agents over the decentralized graph to converge to each other, and the distributed neural networks with enough consensus steps could have nearly the same performance as the centralized training model. Through the analysis of convergence, it is proved that all agents over an undirected graph could converge to the same optimal model even with only a single consensus step, and this can significantly reduce the communication cost. Simulation studies demonstrate that the proposed distributed training algorithm for multi-layer neural networks without data exchange could exhibit comparable or even better performance than the centralized training model.",4
Stabilization of Mode-Dependent Impulsive Hybrid Systems Driven by DFA With Mixed-Mode Effects.,"This paper is concerned with mode-dependent impulsive hybrid systems driven by deterministic finite automaton (DFA) with mixed-mode effects. In the hybrid systems, a complex phenomenon called mixed mode, caused in time-varying delay switching systems, is considered explicitly. Furthermore, mode-dependent impulses, which can exist not only at the instants coinciding with mode switching but also at the instants when there is no system switching, are also taken into consideration. First, we establish a rigorous mathematical equation expression of this class of hybrid systems. Then, several criteria of stabilization of this class of hybrid systems are presented based on semi-tensor product (STP) techniques, multiple Lyapunov-Krasovskii functionals, as well as the average dwell time approach. Finally, an example is simulated to illustrate the effectiveness of the obtained results.",4
Multidimensional Gains for Stochastic Approximation.,"This paper deals with iterative Jacobian-based recursion technique for the root-finding problem of the vector-valued function, whose evaluations are contaminated by noise. Instead of a scalar step size, we use an iterate-dependent matrix gain to effectively weigh the different elements associated with the noisy observations. The analytical development of the matrix gain is built on an iterative-dependent linear function interfered by additive zero-mean white noise, where the dimension of the function is M>/= 1 and the dimension of the unknown variable is N>/= 1. Necessary and sufficient conditions for M>/= N algorithms are presented pertaining to algorithm stability and convergence of the estimate error covariance matrix. Two algorithms are proposed: one for the case where M>/= N and the second one for the antithesis. The two algorithms assume full knowledge of the Jacobian. The recursive algorithms are proposed for generating the optimal iterative-dependent matrix gain. The proposed algorithms here aim for per-iteration minimization of the mean square estimate error. We show that the proposed algorithm satisfies the presented conditions for stability and convergence of the covariance. In addition, the convergence rate of the estimation error covariance is shown to be inversely proportional to the number of iterations. For the antithesis M<N, contraction of the error covariance is guaranteed. This underdetermined system of equations can be helpful in training neural networks. Numerical examples are presented to illustrate the performance capabilities of the proposed multidimensional gain while considering nonlinear functions.",4
Fault Diagnosis of Complex Processes Using Sparse Kernel Local Fisher Discriminant Analysis.,"As an outstanding discriminant analysis technique, Fisher discriminant analysis (FDA) gained extensive attention in supervised dimensionality reduction and fault diagnosis fields. However, it typically ignores the multimodality within the measured data, which may cause infeasibility in practice. In addition, it generally incorporates all process variables without emphasizing the key faulty ones when modeling the complex process, thus leading to degraded fault classification capability and poor model interpretability. To ease the above two drawbacks of conventional FDA, this brief presents an advantageously sparse local FDA (SLFDA) model, it first preserves the within-class multimodality by introducing local weighting factors into scatter matrix. Then, the responsible faulty variables are identified automatically through the elastic net algorithm, and the current optimization problem is subsequently settled through the feasible gradient direction method. Since then, the local data structure characteristics are exploited from both the sample dimension and variable dimension so that the fault diagnosis performance and model interpretability are significantly enhanced. In addition, we naturally extend SLFDA model to nonlinear variant (i.e., sparse kernel local FDA) by the kernel trick, which is substantially more resistant to strong nonlinearity. The simulation studies on Tennessee Eastman (TE) benchmark process and real-world diesel engine working process both validate that the novel diagnosis strategy is more accurate and reliable than the existing state-of-the-art methods.",4
Distributed Synchronization Control of Nonaffine Multiagent Systems With Guaranteed Performance.,"This paper deals with the synchronization control problem in the leader-follower format of a class of high-order nonaffine nonlinear multiagent systems under a directed communication protocol. A novel adaptive neural distributed synchronization scheme with guaranteed performance is proposed. The main contribution lies in the fact that both nonaffine agent dynamics, which basically makes most existing agent dynamics as special cases, and guaranteed synchronization performance are taken into account. The difficulty lies mainly in the nonaffine terms and coupling terms due to the interactions of agents. To overcome this challenge, an augmented quadratic Lyapunov function by incorporating the lower bounds of control gains is proposed. The problems resulting from the nonaffine dynamics and the coupling terms among agents are solved by incorporating the special property of radial basis function neural network into the derivative of the augmented quadratic Lyapunov function. The unknown nonaffine terms are addressed by using an indirected neural network approach. A nonlinear mapping is built to relate the local consensus error to a new one, which is subsequently stabilized via Lyapunov synthesis. As a result, the proposed approach can ensure the outputs of all follower agents to track the outputs of the leader, while the synchronization performance bounds can be quantified on both transient and steady-state stages. All other signals in the closed loop are ensured to be semiglobally, uniformly, and ultimately bounded. Finally, the effectiveness of the proposed controller is verified through a heterogeneous four-agent example.",4
Finite-Time Consensus of Second-Order Switched Nonlinear Multi-Agent Systems.,"In this brief, the practical finite-time consensus (FTC) problem is investigated for the second-order heterogeneous switched nonlinear multi-agent systems (MASs), where the subsystems and the switching signal for each agent are different. Mainly due to that agents' dynamics are switched and the unknown nonlinearities in the systems are more general, the practical FTC problem of the MASs is rather difficult to be solved by existing methods. As such, a new protocol design framework for the FTC problem is developed. Then, a novel adaptive protocol is proposed for the switched nonlinear MASs based on the developed design framework and the neural network method. The sufficient conditions for the practical FTC of nonlinear MASs under arbitrary switching are given. Finally, a numerical example is presented to demonstrate the effectiveness of the proposed control scheme.",4
A Training Data Set Cleaning Method by Classification Ability Ranking for the k-Nearest Neighbor Classifier.,"The k-nearest neighbor (KNN) rule is a successful technique in pattern classification due to its simplicity and effectiveness. As a supervised classifier, KNN classification performance usually suffers from low-quality samples in the training data set. Thus, training data set cleaning (TDC) methods are needed for enhancing the classification accuracy by cleaning out noisy, or even wrong, samples in the original training data set. In this paper, we propose a classification ability ranking (CAR)-based TDC method to improve the performance of a KNN classifier, namely CAR-based TDC method. The proposed classification ability function ranks a training sample in terms of its contribution to correctly classify other training samples as a KNN through the leave-one-out (LV1) strategy in the cleaning stage. The training sample that likely misclassifies the other samples during the KNN classifications according to the LV1 strategy is considered to have lower classification ability and will be cleaned out from the original training data set. Extensive experiments, based on ten real-world data sets, show that the proposed CAR-based TDC method can significantly reduce the classification error rates of KNN-based classifiers, while reducing computational complexity thanks to a smaller cleaned training data set.",4
Hyperspectral Pansharpening With Deep Priors.,"Hyperspectral (HS) image can describe subtle differences in the spectral signatures of materials, but it has low spatial resolution limited by the existing technical and budget constraints. In this paper, we propose a promising HS pansharpening method with deep priors (HPDP) to fuse a low-resolution (LR) HS image with a high-resolution (HR) panchromatic (PAN) image. Different from the existing methods, we redefine the spectral response function (SRF) based on the larger eigenvalue of structure tensor (ST) matrix for the first time that is more in line with the characteristics of HS imaging. Then, we introduce HFNet to capture deep residual mapping of high frequency across the upsampled HS image and the PAN image in a band-by-band manner. Specifically, the learned residual mapping of high frequency is injected into the structural transformed HS images, which are the extracted deep priors served as additional constraint in a Sylvester equation to estimate the final HR HS image. Comparative analyses validate that the proposed HPDP method presents the superior pansharpening performance by ensuring higher quality both in spatial and spectral domains for all types of data sets. In addition, the HFNet is trained in the high-frequency domain based on multispectral (MS) images, which overcomes the sensitivity of deep neural network (DNN) to data sets acquired by different sensors and the difficulty of insufficient training samples for HS pansharpening.",4
Deep Inception-Residual Laplacian Pyramid Networks for Accurate Single-Image Super-Resolution.,"With exploiting contextual information over large image regions in an efficient way, the deep convolutional neural network has shown an impressive performance for single-image super-resolution (SR). In this paper, we propose a new deep convolutional network by cascading multiple well-designed inception-residual blocks within the deep Laplacian pyramid framework to progressively restore the missing high-frequency details in the low-resolution images. By optimizing our network structure, the trainable depth of our proposed network gains a significant improvement, which in turn improves super-resolving accuracy. However, the saturation and degradation of training accuracy remains a critical problem. With regard to this, we propose an effective two-stage training strategy, in which we first use the images downsampled from the ground-truth high-resolution (HR) images to pretrain the inception-residual blocks on each pyramid level with an extremely high learning rate enabled by gradient clipping, and then the original ground-truth HR images are used to fine-tune all the pretrained inception-residual blocks for obtaining our final SR models. Furthermore, we present a new loss function operating in both image space and local rank space to optimize our network for exploiting the contextual information among different output components. Extensive experiments on benchmark data sets validate that the proposed method outperforms the existing state-of-the-art SR methods in terms of the objective evaluation as well as the visual quality.",4
New Criteria for Stability of Neutral-Type Neural Networks With Multiple Time Delays.,"This research work studies stability problems for more general models of neutral-type neural systems where both neuron states and the time derivative of neuron states involve multiple delays. Some new sufficient criterion is presented, which guarantee the existence, uniqueness, and global asymptotic stability of equilibrium points of the considered neural network model. These obtained stability conditions, which can be applied to some larger classes of general neural network models, are based on the analysis of a new and improved suitable Lyapunov functional. The proposed conditions are independent of time delay parameters and can be easily justified by examining some certain relationships among the relevant neural network parameters. This paper also shows that the obtained stability criteria can be considered as the generalization of some previously reported corresponding stability conditions for neural networks, including multiple time delay parameters.",4
A Novel Neural Network for Solving Nonsmooth Nonconvex Optimization Problems.,"In this paper, a novel recurrent neural network (RNN) is presented to deal with a kind of nonsmooth nonconvex optimization problem in which the objective function may be nonsmooth and nonconvex, and the constraints include linear equations and convex inequations. Under certain suitable assumptions, from an arbitrary initial state, each solution to the proposed RNN exists globally and is bounded, and it enters the feasible region within a limited time. Moreover, the solution to the RNN with an arbitrary initial state can converge to the critical point set of the optimization problem. In particular, the RNN does not need the following: 1) abounded feasible region; 2) the computation of an exact penalty parameter; or 3) the initial state being chosen from a given bounded set. Numerical experiments are provided to show the effectiveness and advantages of the RNN.",4
Finite-Horizon Hinfinity State Estimation for Periodic Neural Networks Over Fading Channels.,"The problem of finite-horizon Hinfinity state estimator design for periodic neural networks over multiple fading channels is studied in this paper. To characterize the measurement signals transmitted through different channels experiencing channel fading, a multiple fading channels model is considered. For investigating the situation of correlated fading channels, a set of correlated random variables is introduced. Specifically, the channel coefficients are described by white noise processes and are assumed to be correlated. Two sufficient criteria are provided, by utilizing a stochastic analysis approach, to guarantee that the estimation error system is stochastically stable and achieves the prescribed Hinfinity performance. Then, the parameters of the estimator are derived by solving recursive linear matrix inequalities. Finally, some simulation results are shown to illustrate the effectiveness of the proposed method.",4
Hybrid Classifier Ensemble for Imbalanced Data.,"The class imbalance problem has become a leading challenge. Although conventional imbalance learning methods are proposed to tackle this problem, they have some limitations: 1) undersampling methods suffer from losing important information and 2) cost-sensitive methods are sensitive to outliers and noise. To address these issues, we propose a hybrid optimal ensemble classifier framework that combines density-based undersampling and cost-effective methods through exploring state-of-the-art solutions using multi-objective optimization algorithm. Specifically, we first develop a density-based undersampling method to select informative samples from the original training data with probability-based data transformation, which enables to obtain multiple subsets following a balanced distribution across classes. Second, we exploit the cost-sensitive classification method to address the incompleteness of information problem via modifying weights of misclassified minority samples rather than the majority ones. Finally, we introduce a multi-objective optimization procedure and utilize connections between samples to self-modify the classification result using an ensemble classifier framework. Extensive comparative experiments conducted on real-world data sets demonstrate that our method outperforms the majority of imbalance and ensemble classification approaches.",4
Multiple Kernel Clustering With Neighbor-Kernel Subspace Segmentation.,"Multiple kernel clustering (MKC) has been intensively studied during the last few decades. Even though they demonstrate promising clustering performance in various applications, existing MKC algorithms do not sufficiently consider the intrinsic neighborhood structure among base kernels, which could adversely affect the clustering performance. In this paper, we propose a simple yet effective neighbor-kernel-based MKC algorithm to address this issue. Specifically, we first define a neighbor kernel, which can be utilized to preserve the block diagonal structure and strengthen the robustness against noise and outliers among base kernels. After that, we linearly combine these base neighbor kernels to extract a consensus affinity matrix through an exact-rank-constrained subspace segmentation. The naturally possessed block diagonal structure of neighbor kernels better serves the subsequent subspace segmentation, and in turn, the extracted shared structure is further refined through subspace segmentation based on the combined neighbor kernels. In this manner, the above two learning processes can be seamlessly coupled and negotiate with each other to achieve better clustering. Furthermore, we carefully design an efficient iterative optimization algorithm with proven convergence to address the resultant optimization problem. As a by-product, we reveal an interesting insight into the exact-rank constraint in ridge regression by careful theoretical analysis: it back-projects the solution of the unconstrained counterpart to its principal components. Comprehensive experiments have been conducted on several benchmark data sets, and the results demonstrate the effectiveness of the proposed algorithm.",4
Redundancy and Attention in Convolutional LSTM for Gesture Recognition.,"Convolutional long short-term memory (ConvLSTM) networks have been widely used for action/gesture recognition, and different attention mechanisms have also been embedded into ConvLSTM networks. This paper explores the redundancy of spatial convolutions and the effects of the attention mechanism in ConvLSTM, based on our previous gesture recognition architectures that combine the 3-D convolutional neural network (CNN) and ConvLSTM. Depthwise separable, group, and shuffle convolutions are used to replace the convolutional structures in ConvLSTM for the redundancy analysis. In addition, four ConvLSTM variants are derived for attention analysis: 1) by removing the convolutional structures of the three gates in ConvLSTM; 2) by applying the attention mechanism on the ConvLSTM input; and 3) by reconstructing the input and 4) output gates with the modified channelwise attention mechanism. Evaluation results demonstrate that the spatial convolutions in the three gates scarcely contribute to the spatiotemporal feature fusion and that the attention mechanisms embedded into the input and output gates cannot improve the feature fusion. In other words, ConvLSTM mainly contributes to the temporal fusion along with the recurrent steps to learn long-term spatiotemporal features when taking spatial or spatiotemporal features as input. A new LSTM variant is derived on this basis in which the convolutional structures are embedded only into the input-to-state transition of LSTM. The code of the LSTM variants is publicly available.\footnotehttps://github.com/GuangmingZhu/ConvLSTMForGR.",4
Projective Synchronization of Delayed Neural Networks With Mismatched Parameters and Impulsive Effects.,"In this paper, the impulsive effects on projective synchronization between the parameter mismatched neural networks with mixed time-varying delays have been analyzed. Since complete synchronization is not possible due to the existence of parameter mismatch and projective factor, a drive has been taken to achieve the weak projective synchronization of different neural networks under impulsive control strategies. Through the use of matrix measure technique and the extended comparison principle based on the formula of variation of parameters for mixed time-varying delayed impulsive systems, sufficient criteria have been derived for exponential convergence of the networks under the effects of extensive range of impulse. Instead of upper or lower bound of the impulsive interval, the concept of the average impulsive interval is applied to estimate the number of impulsive points in an interval. The concept of calculus is applied for optimizing the synchronization error bounds which are obtained because of different ranges of impulse. Finally, the numerical simulations for various impulsive ranges for different cases are presented graphically to validate the efficiency of the theoretical results.",4
Adaptive Neural Output-Feedback Decentralized Control for Large-Scale Nonlinear Systems With Stochastic Disturbances.,"This paper addresses the problem of adaptive neural output-feedback decentralized control for a class of strongly interconnected nonlinear systems suffering stochastic disturbances. An state observer is designed to approximate the unmeasurable state signals. Using the approximation capability of radial basis function neural networks (NNs) and employing classic adaptive control strategy, an observer-based adaptive backstepping decentralized controller is developed. In the control design process, NNs are applied to model the uncertain nonlinear functions, and adaptive control and backstepping are combined to construct the controller. The developed control scheme can guarantee that all signals in the closed-loop systems are semiglobally uniformly ultimately bounded in fourth-moment. The simulation results demonstrate the effectiveness of the presented control scheme.",4
Multimodal Deep Network Embedding With Integrated Structure and Attribute Information.,"Network embedding is the process of learning low-dimensional representations for nodes in a network while preserving node features. Existing studies only leverage network structure information and emphasize the preservation of structural features. However, nodes in real-world networks often have a rich set of attributes providing extra semantic information. It has been demonstrated that both structural and attribute features are important for network analysis tasks. To preserve both features, we investigate the problem of integrating structure and attribute information to perform network embedding and propose a multimodal deep network embedding (MDNE) method. MDNE captures the non-linear network structures and the complex interactions among structures and attributes using a deep model consisting of multiple layers of non-linear functions. Since structures and attributes are two different types of information, a multimodal learning method is adopted to pre-process them and help the model to better capture the correlations between node structure and attribute information. We define the loss function employing structural and attribute proximities to preserve the respective features, and the representations are obtained by minimizing the loss function. Results of extensive experiments on four real-world data sets show that the proposed method performs significantly better than baselines on a variety of tasks, which demonstrates the effectiveness and generality of our method.",4
Composite Neural Learning-Based Nonsingular Terminal Sliding Mode Control of MEMS Gyroscopes.,"The efficient driving control of MEMS gyroscopes is an attractive way to improve the precision without hardware redesign. This paper investigates the sliding mode control (SMC) for the dynamics of MEMS gyroscopes using neural networks (NNs). Considering the existence of the dynamics uncertainty, the composite neural learning is constructed to obtain higher tracking precision using the serial-parallel estimation model (SPEM). Furthermore, the nonsingular terminal SMC (NTSMC) is proposed to achieve finite-time convergence. To obtain the prescribed performance, a time-varying barrier Lyapunov function (BLF) is introduced to the control scheme. Through simulation tests, it is observed that under the BLF-based NTSMC with composite learning design, the tracking precision of MEMS gyroscopes is highly improved.",4
Incremental Local Distribution-Based Clustering Using Bayesian Adaptive Resonance Theory.,"Most of the existing Bayesian clustering algorithms perform well on the balanced data. When the data are highly imbalanced, these Bayesian clustering algorithms tend to strongly favor the larger clusters, but provide a notably low detection of the smaller clusters. In this paper, we present an incremental local distribution-based clustering algorithm with the Bayesian adaptive resonance theory (ILBART). This algorithm is developed to adapt itself to a changing environment without using any predefined parameters. The algorithm not only accurately finds the clusters, even in data sets with a severely imbalanced distribution, but also efficiently processes the dynamic data according to the evolving relationships among the clusters. We test our proposed algorithm with experiments conducted on several imbalanced data sets. The experimental results show that our proposed algorithm performs well for clustering imbalanced data and can also obtain a better performance than many other relevant clustering algorithms in several performance indices.",4
Riemannian Curvature of Deep Neural Networks.,"We analyze deep neural networks using the theory of Riemannian geometry and curvature. The objective is to gain insight into how Riemannian geometry can characterize and predict the trained behavior of neural networks. We define a method for calculating Riemann and Ricci curvature tensors, and Ricci scalar curvature values for a trained neural net, in such a way that the output classifier softmax values are related to the input transformations, through the curvature equations. We also measure these curvature tensors experimentally for different networks which are pretrained with stochastic gradient descent and offer a way of visualizing and understanding the measurements to gain insight into the effect curvature has on behavior the neural networks locally, and possibly predict their behavior for different transformations of the test data. We also analyze the effect of variation in depth of the neural networks as well as how it behaves for different choices of data set.",4
Online Model-Free N-Step HDP With Stability Analysis.,"Because of a powerful temporal-difference (TD) with lambda [TD(lambda)] learning method, this paper presents a novel n-step adaptive dynamic programming (ADP) architecture that combines TD(lambda) with regular TD learning for solving optimal control problems with reduced iterations. In contrast with a backward view learning of TD(lambda) that is required an extra parameter named eligibility traces to update at the end of each episode (offline training), the new design in this paper has forward view learning, which is updated at each time step (online training) without needing the eligibility trace parameter in various applications without mathematical models. Therefore, the new design is called the online model-free n-step action-dependent (AD) heuristic dynamic programming [NSHDP(lambda)]. NSHDP(lambda) has three neural networks: the critic network (CN) with regular one-step TD [TD(0)], the CN with n-step TD learning [or TD(lambda)], and the actor network (AN). Because the forward view learning does not require any extra eligibility traces associated with each state, the NSHDP(lambda) architecture has low computational costs and is memory efficient. Furthermore, the stability is proven for NSHDP(lambda) under certain conditions by using Lyapunov analysis to obtain the uniformly ultimately bounded (UUB) property. We compare the results with the performance of HDP and traditional action-dependent HDP(lambda) [ADHDP(lambda)] with different lambda values. Moreover, a complex nonlinear system and 2-D maze problem are two simulation benchmarks in this paper, and the third one is an inverted pendulum simulation benchmark, which is presented in the supplemental material part of this paper. NSHDP(lambda) performance is examined and compared with other ADP methods.",4
RBFNN-Based Data-Driven Predictive Iterative Learning Control for Nonaffine Nonlinear Systems.,"In this paper, a novel data-driven predictive iterative learning control (DDPILC) scheme based on a radial basis function neural network (RBFNN) is proposed for a class of repeatable nonaffine nonlinear discrete-time systems subjected to nonrepetitive external disturbances. First, by utilizing the dynamic linearization technique (DLT) with a newly introduced and unknown system parameter pseudopartial derivative (PPD) and designing a new RBFNN estimation algorithm along the iterative learning axis for addressing the unknown PPD and the unknown nonrepetitive external disturbances, a data-driven prediction model is established. It is theoretically shown that by constructing a composite energy function (CEF) with respect to the modeling error for the first time, the convergence of the modeling error via the proposed DLT-based RBFNN modeling method can be guaranteed, and the convergence speed is tunable. Then, a DDPILC with a disturbance compensation term is designed, and the convergence of the tracking control error is analyzed. Finally, simulations of a train operation system reveal that even if the train suffers from randomly varying load disturbances and nonlinear running resistance, the proposed scheme can make both the modeling error and the tracking control error decrease successively with increasing operation number.",4
Online Incremental Classification Resonance Network and Its Application to Human-Robot Interaction.,"In human-robot interaction (HRI), classification is one of the most important problems, and it is essential particularly when the robot recognizes the surroundings and chooses a reaction based on a certain situation. Each interaction is different since new people appear or the environment changes, and the robot should be able to adapt to different situations during a brief interaction. Thus, it is imperative that the classification is performed incrementally in real time. In this sense, we propose an online incremental classification resonance network (OICRN) that enables incremental class learning in multi-class classification with high performance online. In OICRN, a scale-preserving projection process is introduced to use the raw input vectors online without a normalization process in advance. The integrated network of the convolutional neural network (CNN) for feature extraction and the OICRN for classification is applied to a robotic system that learns human identities through HRIs. To demonstrate the effectiveness of our network, experiments are carried out on benchmark data sets and on a humanoid robot, Mybot, developed in the Robot Intelligence Technology Laboratory, KAIST.",4
Dual Adversarial Autoencoders for Clustering.,"As a powerful approach for exploratory data analysis, unsupervised clustering is a fundamental task in computer vision and pattern recognition. Many clustering algorithms have been developed, but most of them perform unsatisfactorily on the data with complex structures. Recently, adversarial autoencoder (AE) (AAE) shows effectiveness on tackling such data by combining AE and adversarial training, but it cannot effectively extract classification information from the unlabeled data. In this brief, we propose dual AAE (Dual-AAE) which simultaneously maximizes the likelihood function and mutual information between observed examples and a subset of latent variables. By performing variational inference on the objective function of Dual-AAE, we derive a new reconstruction loss which can be optimized by training a pair of AEs. Moreover, to avoid mode collapse, we introduce the clustering regularization term for the category variable. Experiments on four benchmarks show that Dual-AAE achieves superior performance over state-of-the-art clustering methods. In addition, by adding a reject option, the clustering accuracy of Dual-AAE can reach that of supervised CNN algorithms. Dual-AAE can also be used for disentangling style and content of images without using supervised information.",4
Evolving Local Plasticity Rules for Synergistic Learning in Echo State Networks.,"Existing synaptic plasticity rules for optimizing the connections between neurons within the reservoir of echo state networks (ESNs) remain to be global in that the same type of plasticity rule with the same parameters is applied to all neurons. However, this is biologically implausible and practically inflexible for learning the structures in the input signals, thereby limiting the learning performance of ESNs. In this paper, we propose to use local plasticity rules that allow different neurons to use different types of plasticity rules and different parameters, which are achieved by optimizing the parameters of the local plasticity rules using the evolution strategy (ES) with covariance matrix adaptation (CMA-ES). We show that evolving neural plasticity will result in a synergistic learning of different plasticity rules, which plays an important role in improving the learning performance. Meanwhile, we show that the local plasticity rules can effectively alleviate synaptic interferences in learning the structure in sensory inputs. The proposed local plasticity rules are compared with a number of the state-of-the-art ESN models and the canonical ESN using a global plasticity rule on a set of widely used prediction and classification benchmark problems to demonstrate its competitive learning performance.",4
Multilinear Multitask Learning by Rank-Product Regularization.,"Multilinear multitask learning (MLMTL) considers an MTL problem in which tasks are arranged by multiple indices. By exploiting the higher order correlations among the tasks, MLMTL is expected to improve the performance of traditional MTL, which only considers the first-order correlation across all tasks, e.g., low-rank structure of the coefficient matrix. The key to MLMTL is designing a rational regularization term to represent the latent correlation structure underlying the coefficient tensor instead of matrix. In this paper, we propose a new MLMTL model by employing the rank-product regularization term in the objective, which on one hand can automatically rectify the weights along all its tensor modes and on the other hand have an explicit physical meaning. By using this regularization, the intrinsic high-order correlations among tasks can be more precisely described, and thus, the overall performance of all tasks can be improved. To solve the resulted optimization model, we design an efficient algorithm by applying the alternating direction method of multipliers (ADMM). We also analyze the convergence and show that the proposed algorithm, with certain restriction, is asymptotically regular. Experiments on both synthetic and real data sets substantiate the superiority of the proposed method beyond the existing MLMTL methods in terms of accuracy and efficiency.",4
Multi-Objective Evolutionary Federated Learning.,"Federated learning is an emerging technique used to prevent the leakage of private information. Unlike centralized learning that needs to collect data from users and store them collectively on a cloud server, federated learning makes it possible to learn a global model while the data are distributed on the users' devices. However, compared with the traditional centralized approach, the federated setting consumes considerable communication resources of the clients, which is indispensable for updating global models and prevents this technique from being widely used. In this paper, we aim to optimize the structure of the neural network models in federated learning using a multi-objective evolutionary algorithm to simultaneously minimize the communication costs and the global model test errors. A scalable method for encoding network connectivity is adapted to federated learning to enhance the efficiency in evolving deep neural networks. Experimental results on both multilayer perceptrons and convolutional neural networks indicate that the proposed optimization method is able to find optimized neural network models that can not only significantly reduce communication costs but also improve the learning performance of federated learning compared with the standard fully connected neural networks.",4
Adaptive Global Sliding-Mode Control for Dynamic Systems Using Double Hidden Layer Recurrent Neural Network Structure.,"In this paper, a full-regulated neural network (NN) with a double hidden layer recurrent neural network (DHLRNN) structure is designed, and an adaptive global sliding-mode controller based on the DHLRNN is proposed for a class of dynamic systems. Theoretical guidance and adaptive adjustment mechanism are established to set up the base width and central vector of the Gaussian function in the DHLRNN structure, where six sets of parameters can be adaptively stabilized to their best values according to different inputs. The new DHLRNN can improve the accuracy and generalization ability of the network, reduce the number of network weights, and accelerate the network training speed due to the strong fitting and presentation ability of two-layer activation functions compared with a general NN with a single hidden layer. Since the neurons of input layer can receive signals which come back from the neurons of output layer in the output feedback neural structure, it can possess associative memory and rapid system convergence, achieving better approximation and superior dynamic capability. Simulation and experiment on an active power filter are carried out to indicate the excellent static and dynamic performances of the proposed DHLRNN-based adaptive global sliding-mode controller, verifying its best approximation performance and the most stable internal state compared with other schemes.",4
Training Spiking Neural Networks for Cognitive Tasks: A Versatile Framework Compatible With Various Temporal Codes.,"Recent studies have demonstrated the effectiveness of supervised learning in spiking neural networks (SNNs). A trainable SNN provides a valuable tool not only for engineering applications but also for theoretical neuroscience studies. Here, we propose a modified SpikeProp learning algorithm, which ensures better learning stability for SNNs and provides more diverse network structures and coding schemes. Specifically, we designed a spike gradient threshold rule to solve the well-known gradient exploding problem in SNN training. In addition, regulation rules on firing rates and connection weights are proposed to control the network activity during training. Based on these rules, biologically realistic features such as lateral connections, complex synaptic dynamics, and sparse activities are included in the network to facilitate neural computation. We demonstrate the versatility of this framework by implementing three well-known temporal codes for different types of cognitive tasks, namely, handwritten digit recognition, spatial coordinate transformation, and motor sequence generation. Several important features observed in experimental studies, such as selective activity, excitatory-inhibitory balance, and weak pairwise correlation, emerged in the trained model. This agreement between experimental and computational results further confirmed the importance of these features in neural function. This work provides a new framework, in which various neural behaviors can be modeled and the underlying computational mechanisms can be studied.",4
Event-Triggered Neural Control of Nonlinear Systems With Rate-Dependent Hysteresis Input Based on a New Filter.,"In controlling nonlinear uncertain systems, compensating for rate-dependent hysteresis nonlinearity is an important, yet challenging problem in adaptive control. In fact, it can be illustrated through simulation examples that instability is observed when existing control methods in canceling hysteresis nonlinearities are applied to the networked control systems (NCSs). One control difficulty that obstructs these methods is the design conflict between the quantized networked control signal and the rate-dependent hysteresis characteristics. So far, there is still no solution to this problem. In this paper, we consider the event-triggered control for NCSs subject to actuator rate-dependent hysteresis and failures. A new second-order filter is proposed to overcome the design conflict and used for control design. With the incorporation of the filter, a novel adaptive control strategy is developed from a neural network technique and a modified backstepping recursive design. It is proved that all the control signals are semiglobally uniformly ultimately bounded and the tracking error will converge to a tunable residual around zero.",4
Completely Automated CNN Architecture Design Based on Blocks.,"The performance of convolutional neural networks (CNNs) highly relies on their architectures. In order to design a CNN with promising performance, extensive expertise in both CNNs and the investigated problem domain is required, which is not necessarily available to every interested user. To address this problem, we propose to automatically evolve CNN architectures by using a genetic algorithm (GA) based on ResNet and DenseNet blocks. The proposed algorithm is completely automatic in designing CNN architectures. In particular, neither preprocessing before it starts nor postprocessing in terms of CNNs is needed. Furthermore, the proposed algorithm does not require users with domain knowledge on CNNs, the investigated problem, or even GAs. The proposed algorithm is evaluated on the CIFAR10 and CIFAR100 benchmark data sets against 18 state-of-the-art peer competitors. Experimental results show that the proposed algorithm outperforms the state-of-the-art CNNs hand-crafted and the CNNs designed by automatic peer competitors in terms of the classification performance and achieves a competitive classification accuracy against semiautomatic peer competitors. In addition, the proposed algorithm consumes much less computational resource than most peer competitors in finding the best CNN architectures.",4
Event-Based Dissipative Analysis for Discrete Time-Delay Singular Jump Neural Networks.,"This paper investigates the event-triggered dissipative filtering issue for discrete-time singular neural networks with time-varying delays and Markovian jump parameters. Via event-triggered communication technique, a singular jump neural network (SJNN) model of network-induced delays is first given, and sufficient criteria are then provided to guarantee that the resulting augmented SJNN is stochastically admissible and strictly stochastically dissipative (SASSD) with respect to (Xiota,Yiota,Ziota,delta) by using slack matrix scheme. Furthermore, employing filter equivalent technique, codesigned filter gains, and event-triggered matrices are derived to make sure that the augmented SJNN model is SASSD with respect to (Xiota,Yiota,Ziota,delta). An example is also given to illustrate the effectiveness of the proposed method.",4
Direct Adaptive Preassigned Finite-Time Control With Time-Delay and Quantized Input Using Neural Network.,"This paper investigates an adaptive finite-time control (FTC) problem for a class of strict-feedback nonlinear systems with both time-delays and quantized input from a new point of view. First, a new concept, called preassigned finite-time performance function (PFTF), is defined. Then, another novel notion, called practically preassigned finite-time stability (PPFTS), is introduced. With PFTF and PPFTS in hand, a novel sufficient condition of the FTC is given by using the neural network (NN) control and direct adaptive backstepping technique, which is different from the existing results. In addition, a modified barrier function is first introduced in this work. Moreover, this work is first to focus on the FTC for the situation that the time-delay and quantized input simultaneously exist in the nonlinear systems. Finally, simulation results are carried out to illustrate the effectiveness of the proposed scheme.",4
Performance Enhancement of Learning Tracking Systems Over Fading Channels With Multiplicative and Additive Randomness.,"This paper applies learning control to repetitive systems over fading channels at both output and input sides to improve tracking performance without applying restrictive fading conditions. Both multiplicative and additive randomness of the fading channel are addressed, and the effects of fading communication on the data are carefully analyzed. A decreasing gain sequence and a moving-average operator are introduced to modify the generic learning control algorithm to reduce the fading effect and improve control system performance. Results reveal that the tracking error converges to zero in the mean-square sense as the iteration number increases. Illustrative simulations are presented to verify the theoretical results.",4
Error Bounds for Piecewise Smooth and Switching Regression.,"This paper deals with regression problems, in which the nonsmooth target is assumed to switch between different operating modes. Specifically, piecewise smooth (PWS) regression considers target functions switching deterministically via a partition of the input space, while switching regression considers arbitrary switching laws. This paper derives generalization error bounds in these two settings by following the approach based on Rademacher complexities. For PWS regression, our derivation involves a chaining argument and a decomposition of the covering numbers of PWS classes in terms of the ones of their component function classes and the capacity of the classifier partitioning the input space. This yields error bounds with a radical dependence on the number of modes. For switching regression, the decomposition can be performed directly at the level of the Rademacher complexities, which yields bounds with a linear dependence on the number of modes. By using once more chaining and decomposition at the level of covering numbers, we show how to recover a radical dependence. Examples of applications are given in particular for PWS and swichting regression with linear and kernel-based component functions.",4
An Improved N-Step Value Gradient Learning Adaptive Dynamic Programming Algorithm for Online Learning.,"In problems with complex dynamics and challenging state spaces, the dual heuristic programming (DHP) algorithm has been shown theoretically and experimentally to perform well. This was recently extended by an approach called value gradient learning (VGL). VGL was inspired by a version of temporal difference (TD) learning that uses eligibility traces. The eligibility traces create an exponential decay of older observations with a decay parameter (lambda). This approach is known as TD(lambda), and its DHP extension is known as VGL(lambda), where VGL(0) is identical to DHP. VGL has presented convergence and other desirable properties, but it is primarily useful for batch learning. Online learning requires an eligibility-trace-work-space matrix, which is not required for the batch learning version of VGL. Since online learning is desirable for many applications, it is important to remove this computational and memory impediment. This paper introduces a dual-critic version of VGL, called N-step VGL (NSVGL), that does not need the eligibility-trace-work-space matrix, thereby allowing online learning. Furthermore, this combination of critic networks allows an NSVGL algorithm to learn faster. The first critic is similar to DHP, which is adapted based on TD(0) learning, while the second critic is adapted based on a gradient of n-step TD(lambda) learning. Both networks are combined to train an actor network. The combination of feedback signals from both critic networks provides an optimal decision faster than traditional adaptive dynamic programming (ADP) via mixing current information and event history. Convergence proofs are provided. Gradients of one- and n-step value functions are monotonically nondecreasing and converge to the optimum. Two simulation case studies are presented for NSVGL to show their superior performance.",4
Performance Evaluation of Probabilistic Methods Based on Bootstrap and Quantile Regression to Quantify PV Power Point Forecast Uncertainty.,"This paper presents two probabilistic approaches based on bootstrap method and quantile regression (QR) method to estimate the uncertainty associated with solar photovoltaic (PV) power point forecasts. Solar PV output power forecasts are obtained using a hybrid intelligent model, which is composed of a data filtering technique based on wavelet transform (WT) and a soft computing model (SCM) based on radial basis function neural network (RBFNN) that is optimized by particle swarm optimization (PSO) algorithm. The point forecast capability of the proposed hybrid WT+RBFNN+PSO intelligent model is examined and compared with other hybrid models as well as individual SCM. The performance of the proposed bootstrap method in the form of probabilistic forecasts is compared with the QR method by generating different prediction intervals (PIs). Numerical tests using real data demonstrate that the point forecasts obtained from the proposed hybrid intelligent model can be effectively used to quantify PV power uncertainty. The performance of these two uncertainty quantification methods is assessed through reliability.",4
Continuously Constructive Deep Neural Networks.,"Traditionally, deep learning algorithms update the network weights, whereas the network architecture is chosen manually using a process of trial and error. In this paper, we propose two novel approaches that automatically update the network structure while also learning its weights. The novelty of our approach lies in our parameterization, where the depth, or additional complexity, is encapsulated continuously in the parameter space through control parameters that add additional complexity. We propose two methods. In tunnel networks, this selection is done at the level of a hidden unit, and in budding perceptrons, this is done at the level of a network layer; updating this control parameter introduces either another hidden unit or layer. We show the effectiveness of our methods on the synthetic two-spiral data and on three real data sets of MNIST, MIRFLICKR, and CIFAR, where we see that our proposed methods, with the same set of hyperparameters, can correctly adjust the network complexity to the task complexity.",4
Constrained Quaternion-Variable Convex Optimization: A Quaternion-Valued Recurrent Neural Network Approach.,"This paper proposes a quaternion-valued one-layer recurrent neural network approach to resolve constrained convex function optimization problems with quaternion variables. Leveraging the novel generalized Hamilton-real (GHR) calculus, the quaternion gradient-based optimization techniques are proposed to derive the optimization algorithms in the quaternion field directly rather than the methods of decomposing the optimization problems into the complex domain or the real domain. Via chain rules and Lyapunov theorem, the rigorous analysis shows that the deliberately designed quaternion-valued one-layer recurrent neural network stabilizes the system dynamics while the states reach the feasible region in finite time and converges to the optimal solution of the considered constrained convex optimization problems finally. Numerical simulations verify the theoretical results.",4
Radial-Based Oversampling for Multiclass Imbalanced Data Classification.,"Learning from imbalanced data is among the most popular topics in the contemporary machine learning. However, the vast majority of attention in this field is given to binary problems, while their much more difficult multiclass counterparts are relatively unexplored. Handling data sets with multiple skewed classes poses various challenges and calls for a better understanding of the relationship among classes. In this paper, we propose multiclass radial-based oversampling (MC-RBO), a novel data-sampling algorithm dedicated to multiclass problems. The main novelty of our method lies in using potential functions for generating artificial instances. We take into account information coming from all of the classes, contrary to existing multiclass oversampling approaches that use only minority class characteristics. The process of artificial instance generation is guided by exploring areas where the value of the mutual class distribution is very small. This way, we ensure a smart oversampling procedure that can cope with difficult data distributions and alleviate the shortcomings of existing methods. The usefulness of the MC-RBO algorithm is evaluated on the basis of extensive experimental study and backed-up with a thorough statistical analysis. Obtained results show that by taking into account information coming from all of the classes and conducting a smart oversampling, we can significantly improve the process of learning from multiclass imbalanced data.",4
Task Assignment for Multivehicle Systems Based on Collaborative Neurodynamic Optimization.,"This paper addresses task assignment (TA) for multivehicle systems. Multivehicle TA problems are formulated as a combinatorial optimization problem and further as a global optimization problem. To fulfill heterogeneous tasks, cooperation among heterogeneous vehicles is incorporated in the problem formulations. A collaborative neurodynamic optimization approach is developed for solving the TA problems. Experimental results on four types of TA problems are discussed to substantiate the efficacy of the approach.",4
Genetic Algorithm-Based Sensor Allocation With Nonlinear Centralized Fusion Observable Degree.,"As the main performance self-evaluation index of the Kalman filter, the estimation error covariance (EEC) has been used to design the allocation cost function of task and resources for sensor tracking networks. For nonlinear systems, the sensor allocation method based on the EEC needs to adjust the allocation plans after obtaining the filtering results. Meanwhile, recent investigations have indicated that the self-evaluation function EEC of the Kalman filtering is universally inapplicable in practical applications, for which the estimation models are generally mismatched due to difficulty in accurately training parameters and approximation of nonlinear systems. Thereby, the sensors cannot be properly allocated by using the EEC as a preliminary criterion. Alternatively, observable degree (OD) is a naturally quantitative measure on observability and can be utilized to effectively measure the estimation performance. In this paper, the OD analysis with scale transform invariance for nonlinear systems is studied by using the unscented Kalman filter, the pseudostate transition matrix, and the pseudo observation matrix on the basis of the results of linear systems. Afterward, the OD of nonlinear fusion systems, the sensor utilization efficiency, the priority of tasks, and the sensor performance and sensitivity are jointly considered to formulate the optimization problem for sensor allocation. The genetic algorithm with intelligent learning function is employed to solve the optimization problem. Moreover, extensive simulation demonstrates the feasibility of the proposed approach.",4
A Probabilistic Synapse With Strained MTJs for Spiking Neural Networks.,"Spiking neural networks (SNNs) are of interest for applications for which conventional computing suffers from the nearly insurmountable memory-processor bottleneck. This paper presents a stochastic SNN architecture that is based on specialized logic-in-memory synaptic units to create a unique processing system that offers massively parallel processing power. Our proposed synaptic unit consists of strained magnetic tunnel junction (MTJ) devices and transistors. MTJs in our synapse are dual purpose, used as both random bit generators and as general-purpose memory. Our neurons are modeled as integrate-and-fire components with thresholding and refraction. Our circuit is implemented using CMOS 28-nm technology that is compatible with the MTJ technology. Our design shows that the required area for the proposed synapse is only 3.64 mu m(2)/unit. When idle, the synapse consumes 675 pW. When firing, the energy required to propagate a spike is 8.87 fJ. We then demonstrate an SNN that learns (without supervision) and classifies handwritten digits of the MNIST database. Simulation results show that our network presents high classification efficiency even in the presence of fabrication variability.",4
Learning Low-Dimensional Latent Graph Structures: A Density Estimation Approach.,"We aim to automatically learn a latent graph structure in a low-dimensional space from high-dimensional, unsupervised data based on a unified density estimation framework for both feature extraction and feature selection, where the latent structure is considered as a compact and informative representation of the high-dimensional data. Based on this framework, two novel methods are proposed with very different but intuitive learning criteria from existing methods. The proposed feature extraction method can learn a set of embedded points in a low-dimensional space by naturally integrating the discriminative information of the input data with structure learning so that multiple disconnected embedding structures of data can be uncovered. The proposed feature selection method preserves the pairwise distances only on the optimal set of features and selects these features simultaneously. It not only obtains the optimal set of features but also learns both the structure and embeddings for visualization. Extensive experiments demonstrate that our proposed methods can achieve competitive quantitative (often better) results in terms of discriminant evaluation performance and are able to obtain the embeddings of smooth skeleton structures and select optimal features to unveil the correct graph structures of high-dimensional data sets.",4
Where Computation and Dynamics Meet: Heteroclinic Network-Based Controllers in Evolutionary Robotics.,"In the fields of artificial neural networks and robotics, complicated, often high-dimensional systems can be designed using evolutionary/other algorithms to successfully solve very complex tasks. However, dynamical analysis of the underlying controller can often be near impossible, due to the high dimension and nonlinearities in the system. In this paper, we propose a more restricted form of controller, such that the underlying dynamical systems are forced to contain a dynamical object called a heteroclinic network. Systems containing heteroclinic networks share some properties with finite-state machines (FSMs) but are not discrete: both space and time are still described with continuous variables. Thus, we suggest that the heteroclinic networks can provide a hybrid between continuous and discrete systems. We investigate this innovated architecture in a minimal categorical perception task. The similarity of the controller to an FSM allows us to describe some of the system's behaviors as transition between states. However, other, essential behavior involves subtle ongoing interaction between the controller and the environment that eludes description at this level.",4
Robust Multiview Subspace Learning With Nonindependently and Nonidentically Distributed Complex Noise.,"Multiview Subspace Learning (MSL), which aims at obtaining a low-dimensional latent subspace from multiview data, has been widely used in practical applications. Most recent MSL approaches, however, only assume a simple independent identically distributed (i.i.d.) Gaussian or Laplacian noise for all views of data, which largely underestimates the noise complexity in practical multiview data. Actually, in real cases, noises among different views generally have three specific characteristics. First, in each view, the data noise always has a complex configuration beyond a simple Gaussian or Laplacian distribution. Second, the noise distributions of different views of data are generally nonidentical and with evident distinctiveness. Third, noises among all views are nonindependent but obviously correlated. Based on such understandings, we elaborately construct a new MSL model by more faithfully and comprehensively considering all these noise characteristics. First, the noise in each view is modeled as a Dirichlet process (DP) Gaussian mixture model (DPGMM), which can fit a wider range of complex noise types than conventional Gaussian or Laplacian. Second, the DPGMM parameters in each view are different from one another, which encodes the ``nonidentical'' noise property. Third, the DPGMMs on all views share the same high-level priors by using the technique of hierarchical DP, which encodes the ``nonindependent'' noise property. All the aforementioned ideas are incorporated into an integrated graphics model which can be appropriately solved by the variational Bayes algorithm. The superiority of the proposed method is verified by experiments on 3-D reconstruction simulations, multiview face modeling, and background subtraction, as compared with the current state-of-the-art MSL methods.",4
Robust Event-Triggered Control Invariance of Probabilistic Boolean Control Networks.,"In this brief, the robust control invariance problem of probabilistic Boolean control networks (PBCNs) is investigated by a class of event-triggered control (ETC), which is an intermittent control scheme in essential. By resorting to the semi-tensor product (STP) technique, a PBCN with ETC can be equivalently described in a form of an algebraic linear system. Based on which, a matrix testing condition is derived to judge whether the given set can be a robust ETC invariant set (RETCIS). Subsequently, a necessary and sufficient condition is developed for the existence of event-triggered controllers. Meanwhile, all feasible event-triggered controllers are designed for guaranteeing the given set to be an RETCIS. Finally, a biological example is employed to demonstrate the availability of theoretical results.",4
Self-Paced Balance Learning for Clinical Skin Disease Recognition.,"Class imbalance is a challenging problem in many classification tasks. It induces biased classification results for minority classes that contain less training samples than others. Most existing approaches aim to remedy the imbalanced number of instances among categories by resampling the majority and minority classes accordingly. However, the imbalanced level of difficulty of recognizing different categories is also crucial, especially for distinguishing samples with many classes. For example, in the task of clinical skin disease recognition, several rare diseases have a small number of training samples, but they are easy to diagnose because of their distinct visual properties. On the other hand, some common skin diseases, e.g., eczema, are hard to recognize due to the lack of special symptoms. To address this problem, we propose a self-paced balance learning (SPBL) algorithm in this paper. Specifically, we introduce a comprehensive metric termed the complexity of image category that is a combination of both sample number and recognition difficulty. First, the complexity is initialized using the model of the first pace, where the pace indicates one iteration in the self-paced learning paradigm. We then assign each class a penalty weight that is larger for more complex categories and smaller for easier ones, after which the curriculum is reconstructed by rearranging the training samples. Consequently, the model can iteratively learn discriminative representations via balancing the complexity in each pace. Experimental results on the SD-198 and SD-260 benchmark data sets demonstrate that the proposed SPBL algorithm performs favorably against the state-of-the-art methods. We also demonstrate the effectiveness of the SPBL algorithm's generalization capacity on various tasks, such as indoor scene image recognition and object classification.",4
Consensus Tracking Control of Switched Stochastic Nonlinear Multiagent Systems via Event-Triggered Strategy.,"In this paper, the consensus tracking problem is investigated for a class of continuous switched stochastic nonlinear multiagent systems with an event-triggered control strategy. For continuous stochastic multiagent systems via event-triggered protocols, it is rather difficult to avoid the Zeno behavior by the existing methods. Thus, we propose a new protocol design framework for the underlying systems. It is proven that follower agents can almost surely track the given leader signal with bounded errors and no agent exhibits the Zeno behavior by the given control scheme. Finally, two numerical examples are given to illustrate the effectiveness and advantages of the new design techniques.",4
Neural Networks-Based Distributed Adaptive Control of Nonlinear Multiagent Systems.,"The cooperative control problem of nonlinear multiagent systems is studied in this paper. The followers in the communication network are subject to unmodeled dynamics. A fully distributed neural-networks-based adaptive control strategy is designed to guarantee that all the followers are asymptotically synchronized to the leader, and the synchronization errors are within a prescribed level, where some global information, such as minimum and maximum singular value of graph adjacency matrix, is not necessarily to be known. Based on the Lyapunov stability theory and algebraic graph theory, the stability analysis of the resulting closed-loop system is provided. Finally, an numerical example illustrates the effectiveness and potential of the proposed new design techniques.",4
Adaptive Deep Modeling of Users and Items Using Side Information for Recommendation.,"In the existing recommender systems, matrix factorization (MF) is widely applied to model user preferences and item features by mapping the user-item ratings into a low-dimension latent vector space. However, MF has ignored the individual diversity where the user's preference for different unrated items is usually different. A fixed representation of user preference factor extracted by MF cannot model the individual diversity well, which leads to a repeated and inaccurate recommendation. To this end, we propose a novel latent factor model called adaptive deep latent factor model (ADLFM), which learns the preference factor of users adaptively in accordance with the specific items under consideration. We propose a novel user representation method that is derived from their rated item descriptions instead of original user-item ratings. Based on this, we further propose a deep neural networks framework with an attention factor to learn the adaptive representations of users. Extensive experiments on Amazon data sets demonstrate that ADLFM outperforms the state-of-the-art baselines greatly. Also, further experiments show that the attention factor indeed makes a great contribution to our method.",4
Global Stabilization of Fractional-Order Memristor-Based Neural Networks With Time Delay.,"This paper addresses the global stabilization of fractional-order memristor-based neural networks (FMNNs) with time delay. The voltage threshold type memristor model is considered, and the FMNNs are represented by fractional-order differential equations with discontinuous right-hand sides. Then, the problem is addressed based on fractional-order differential inclusions and set-valued maps, together with the aid of Lyapunov functions and the comparison principle. Two types of control laws (delayed state feedback control and coupling state feedback control) are designed. Accordingly, two types of stabilization criteria [algebraic form and linear matrix inequality (LMI) form] are established. There are two groups of adjustable parameters included in the delayed state feedback control, which can be selected flexibly to achieve the desired global asymptotic stabilization or global Mittag-Leffler stabilization. Since the existing LMI-based stability analysis techniques for fractional-order systems are not applicable to delayed fractional-order nonlinear systems, a fractional-order differential inequality is established to overcome this difficulty. Based on the coupling state feedback control, some LMI stabilization criteria are developed for the first time with the help of the newly established fractional-order differential inequality. The obtained LMI results provide new insights into the research of delayed fractional-order nonlinear systems. Finally, three numerical examples are presented to illustrate the effectiveness of the proposed theoretical results.",4
Deep Neural Architectures for Highly Imbalanced Data in Bioinformatics.,"In the postgenome era, many problems in bioinformatics have arisen due to the generation of large amounts of imbalanced data. In particular, the computational classification of precursor microRNA (pre-miRNA) involves a high imbalance in the classes. For this task, a classifier is trained to identify RNA sequences having the highest chance of being miRNA precursors. The big issue is that well-known pre-miRNAs are usually just a few in comparison to the hundreds of thousands of candidate sequences in a genome, which results in highly imbalanced data. This imbalance has a strong influence on most standard classifiers and, if not properly addressed, the classifier is not able to work properly in a real-life scenario. This work provides a comparative assessment of recent deep neural architectures for dealing with the large imbalanced data issue in the classification of pre-miRNAs. We present and analyze recent architectures in a benchmark framework with genomes of animals and plants, with increasing imbalance ratios up to 1:2000. We also propose a new graphical way for comparing classifiers performance in the context of high-class imbalance. The comparative results obtained show that, at a very high imbalance, deep belief neural networks can provide the best performance.",4
Heterogeneous Multilayer Generalized Operational Perceptron.,"The traditional multilayer perceptron (MLP) using a McCulloch-Pitts neuron model is inherently limited to a set of neuronal activities, i.e., linear weighted sum followed by nonlinear thresholding step. Previously, generalized operational perceptron (GOP) was proposed to extend the conventional perceptron model by defining a diverse set of neuronal activities to imitate a generalized model of biological neurons. Together with GOP, a progressive operational perceptron (POP) algorithm was proposed to optimize a predefined template of multiple homogeneous layers in a layerwise manner. In this paper, we propose an efficient algorithm to learn a compact, fully heterogeneous multilayer network that allows each individual neuron, regardless of the layer, to have distinct characteristics. Based on the complexity of the problem, the proposed algorithm operates in a progressive manner on a neuronal level, searching for a compact topology, not only in terms of depth but also width, i.e., the number of neurons in each layer. The proposed algorithm is shown to outperform other related learning methods in extensive experiments on several classification problems.",4
Heterogeneous Domain Adaptation via Nonlinear Matrix Factorization.,"Heterogeneous domain adaptation (HDA) aims to solve the learning problems where the source- and the target-domain data are represented by heterogeneous types of features. The existing HDA approaches based on matrix completion or matrix factorization have proven to be effective to capture shareable information between heterogeneous domains. However, there are two limitations in the existing methods. First, a large number of corresponding data instances between the source domain and the target domain are required to bridge the gap between different domains for performing matrix completion. These corresponding data instances may be difficult to collect in real-world applications due to the limited size of data in the target domain. Second, most existing methods can only capture linear correlations between features and data instances while performing matrix completion for HDA. In this paper, we address these two issues by proposing a new matrix-factorization-based HDA method in a semisupervised manner, where only a few labeled data are required in the target domain without requiring any corresponding data instances between domains. Such labeled data are more practical to obtain compared with cross-domain corresponding data instances. Our proposed algorithm is based on matrix factorization in an approximated reproducing kernel Hilbert space (RKHS), where nonlinear correlations between features and data instances can be exploited to learn heterogeneous features for both the source and the target domains. Extensive experiments are conducted on cross-domain text classification and object recognition, and experimental results demonstrate the superiority of our proposed method compared with the state-of-the-art HDA approaches.",4
Compact and Computationally Efficient Representation of Deep Neural Networks.,"At the core of any inference procedure, deep neural networks are dot product operations, which are the component that requires the highest computational resources. For instance, deep neural networks, such as VGG-16, require up to 15-G operations in order to perform the dot products present in a single forward pass, which results in significant energy consumption and thus limits their use in resource-limited environments, e.g., on embedded devices or smartphones. One common approach to reduce the complexity of the inference is to prune and quantize the weight matrices of the neural network. Usually, this results in matrices whose entropy values are low, as measured relative to the empirical probability mass distribution of its elements. In order to efficiently exploit such matrices, one usually relies on, inter alia, sparse matrix representations. However, most of these common matrix storage formats make strong statistical assumptions about the distribution of the elements; therefore, cannot efficiently represent the entire set of matrices that exhibit low-entropy statistics (thus, the entire set of compressed neural network weight matrices). In this paper, we address this issue and present new efficient representations for matrices with low-entropy statistics. Alike sparse matrix data structures, these formats exploit the statistical properties of the data in order to reduce the size and execution complexity. Moreover, we show that the proposed data structures can not only be regarded as a generalization of sparse formats but are also more energy and time efficient under practically relevant assumptions. Finally, we test the storage requirements and execution performance of the proposed formats on compressed neural networks and compare them to dense and sparse representations. We experimentally show that we are able to attain up to x42 compression ratios, x5 speed ups, and x90 energy savings when we bflossless convert the state-of-the-art networks, such as AlexNet, VGG-16, ResNet152, and DenseNet, into the new data structures and benchmark their respective dot product.",4
Convolutional Neural Networks as Asymmetric Volterra Models Based on Generalized Orthonormal Basis Functions.,"This paper introduces a convolutional neural network (CNN) approach to derive Volterra models of dynamical systems based on generalized orthonormal basis function (GOBF)-Volterra. The approach derives the parameters of the model through a CNN and the neural network's learned weights represent the poles of a system. Simulation results show that the parameters of the system can be exactly recovered when no noise is applied. Furthermore, when noise is present, the errors in the parameters are very small for both the linear and nonlinear cases. Finally, the approach is used to identify the model of a quadcopter using data from actual flight tests. Comparisons with previous works demonstrate that CNNs can be satisfactorily used for the identification of dynamical systems.",4
Composite Learning Enhanced Robot Impedance Control.,"The desired impedance dynamics can be achieved for a robot if and only if an impedance error converges to zero or a small neighborhood of zero. Although the convergence of impedance errors is important, it is seldom obtained in the existing impedance controllers due to robots modeling uncertainties and external disturbances. This brief proposes two composite learning impedance controllers (CLICs) for robots with parameter uncertainties based on whether a factorization assumption is satisfied or not. In the proposed control designs, the convergence of impedance errors, reflected by the convergence of parameter estimation errors and some auxiliary errors, is achieved by using composite learning laws under a relaxed excitation condition. The theoretical results are proven based on the Lyapunov theory. The effectiveness and advantages of the proposed CLICs are validated by simulations on a parallel robot in three cases.",4
Synchronization of the Networked System With Continuous and Impulsive Hybrid Communications.,"Many networked systems display some kind of dynamics behaving in a style with both continuous and impulsive communications. The cooperation behaviors of these networked systems with continuous connected or impulsive connected or both connected topologies of communications are important to understand. This paper is devoted to the synchronization of the networked system with continuous and impulsive hybrid communications, where each topology of communication mode is not connected in every moment. Two kind of structures, i.e., fixed structure and switching structures, are taken into consideration. A general concept of directed spanning tree (DST) is proposed to describe the connectivity of the networked system with hybrid communication modes. The suitable Lyapunov functions are constructed to analyze the synchronization stability. It is showed that for fixed topology having a jointly DST, the networked system with continuous and impulsive hybrid communication modes will achieve asymptotic synchronization if the feedback gain matrix and the average impulsive interval are properly selected. The results are then extended to the switching case where the graph has a frequently jointly DST. Some simple examples are then given to illustrate the derived synchronization criteria.",4
Bipartite Differential Neural Network for Unsupervised Image Change Detection.,"Image change detection detects the regions of change in multiple images of the same scene taken at different times, which plays a crucial role in many applications. The two most popular image change detection techniques are as follows: pixel-based methods heavily rely on accurate image coregistration while object-based approaches can tolerate coregistration errors to some extent but are sensitive to image segmentation or classification errors. To address these issues, we propose an unsupervised image change detection approach based on a novel bipartite differential neural network (BDNN). The BDNN is a deep neural network with two input ends, which can extract the holistic features from the unchanged regions in the two input images, where two learnable change disguise maps (CDMs) are used to disguise the changed regions in the two input images, respectively, and thus demarcate the unchanged regions therein. The network parameters and CDMs will be learned by optimizing an objective function, which combines a loss function defined as the likelihood of the given input image pair over all possible input image pairs and two constraints imposed on CDMs. Compared with the pixel-based and object-based techniques, the BDNN is less sensitive to inaccurate image coregistration and does not involve image segmentation or classification. In fact, it can even skip over coregistration if the degree of transformation (due to the different view angles and/or positions of the camera) between the two input images is not that large. We compare the proposed approach with several state-of-the-art image change detection methods on various homogeneous and heterogeneous image pairs with and without coregistration. The results demonstrate the superiority of the proposed approach.",4
Fast Semisupervised Learning With Bipartite Graph for Large-Scale Data.,"As the captured information in our real word is very scare and labeling sample is time cost and expensive, semisupervised learning (SSL) has an important application in computer vision and machine learning. Among SSL approaches, a graph-based SSL (GSSL) model has recently attracted much attention for high accuracy. However, for most traditional GSSL methods, the large-scale data bring higher computational complexity, which acquires a better computing platform. In order to dispose of these issues, we propose a novel approach, bipartite GSSL normalized (BGSSL-normalized) method, in this paper. This method consists of three parts. First, the bipartite graph between the original data and the anchor points is constructed, which is parameter-insensitive, scale-invariant, naturally sparse, and simple operation. Then, the label of the original data and anchors can be inferred through the graph. Besides, we extend our algorithm to handle out-of-sample for large-scale data by the inferred label of anchors, which not only retains good classification result but also saves a large amount of time. The computational complexity of BGSSL-normalized can be reduced to O(ndm+nm(2)), which is a significant improvement compared with traditional GSSL methods that need O(n(2)d+n(3)), where n, d, and m are the number of samples, features, and anchors, respectively. The experimental results on several publicly available data sets demonstrate that our approaches can achieve better classification accuracy with less time costs.",4
Joint Principal Component and Discriminant Analysis for Dimensionality Reduction.,"Linear discriminant analysis (LDA) is the most widely used supervised dimensionality reduction approach. After removing the null space of the total scatter matrix St via principal component analysis (PCA), the LDA algorithm can avoid the small sample size problem. Most existing supervised dimensionality reduction methods extract the principal component of data first, and then conduct LDA on it. However, ``most variance'' is very often the most important, but not always in PCA. Thus, this two-step strategy may not be able to obtain the most discriminant information for classification tasks. Different from traditional approaches which conduct PCA and LDA in sequence, we propose a novel method referred to as joint principal component and discriminant analysis (JPCDA) for dimensionality reduction. Using this method, we are able to not only avoid the small sample size problem but also extract discriminant information for classification tasks. An iterative optimization algorithm is proposed to solve the method. To validate the efficacy of the proposed method, we perform extensive experiments on several benchmark data sets in comparison with some state-of-the-art dimensionality reduction methods. A large number of experimental results illustrate that the proposed method has quite promising classification performance.",4
Robust State/Output-Feedback Control of Coaxial-Rotor MAVs Based on Adaptive NN Approach.,"The coaxial-rotor micro-aerial vehicles (CRMAVs) have been proven to be a powerful tool in forming small and agile manned-unmanned hybrid applications. However, the operation of them is usually subject to unpredictable time-varying aerodynamic disturbances and model uncertainties. In this paper, an adaptive robust controller based on a neural network (NN) approach is proposed to reject such perturbations and track both the desired position and orientation trajectories. A complete dynamic model of a CRMAV is first constructed. When all system states are assumed to be available, an NN-based state-feedback controller is proposed through feedback linearization and Lyapunov analysis. Furthermore, to overcome the practical challenge that certain states are not measurable, a high-gain observer is introduced to estimate the unavailable states, and then, an output-feedback controller is developed. Rigorous theoretical analysis verifies the stability of the entire closed-loop system. In addition, extensive simulation studies are conducted to validate the feasibility of the proposed scheme.",4
Log-Sum-Exp Neural Networks and Posynomial Models for Convex and Log-Log-Convex Data.,"In this paper, we show that a one-layer feedforward neural network with exponential activation functions in the inner layer and logarithmic activation in the output neuron is a universal approximator of convex functions. Such a network represents a family of scaled log-sum exponential functions, here named log-sum-exp (LSET). Under a suitable exponential transformation, the class of LSET functions maps to a family of generalized posynomials GPOST, which we similarly show to be universal approximators for log-log-convex functions. A key feature of an LSET network is that, once it is trained on data, the resulting model is convex in the variables, which makes it readily amenable to efficient design based on convex optimization. Similarly, once a GPOST model is trained on data, it yields a posynomial model that can be efficiently optimized with respect to its variables by using geometric programming (GP). The proposed methodology is illustrated by two numerical examples, in which, first, models are constructed from simulation data of the two physical processes (namely, the level of vibration in a vehicle suspension system, and the peak power generated by the combustion of propane), and then optimization-based design is performed on these models.",4
Robust and Sparse Linear Discriminant Analysis via an Alternating Direction Method of Multipliers.,"In this paper, we propose a robust linear discriminant analysis (RLDA) through Bhattacharyya error bound optimization. RLDA considers a nonconvex problem with the L(1)-norm operation that makes it less sensitive to outliers and noise than the L(2)-norm linear discriminant analysis (LDA). In addition, we extend our RLDA to a sparse model (RSLDA). Both RLDA and RSLDA can extract unbounded numbers of features and avoid the small sample size (SSS) problem, and an alternating direction method of multipliers (ADMM) is used to cope with the nonconvexity in the proposed formulations. Compared with the traditional LDA, our RLDA and RSLDA are more robust to outliers and noise, and RSLDA can obtain sparse discriminant directions. These findings are supported by experiments on artificial data sets as well as human face databases.",4
G-Softmax: Improving Intraclass Compactness and Interclass Separability of Features.,"Intraclass compactness and interclass separability are crucial indicators to measure the effectiveness of a model to produce discriminative features, where intraclass compactness indicates how close the features with the same label are to each other and interclass separability indicates how far away the features with different labels are. In this paper, we investigate intraclass compactness and interclass separability of features learned by convolutional networks and propose a Gaussian-based softmax (G-softmax) function that can effectively improve intraclass compactness and interclass separability. The proposed function is simple to implement and can easily replace the softmax function. We evaluate the proposed G-softmax function on classification data sets (i.e., CIFAR-10, CIFAR-100, and Tiny ImageNet) and on multilabel classification data sets (i.e., MS COCO and NUS-WIDE). The experimental results show that the proposed G-softmax function improves the state-of-the-art models across all evaluated data sets. In addition, the analysis of the intraclass compactness and interclass separability demonstrates the advantages of the proposed function over the softmax function, which is consistent with the performance improvement. More importantly, we observe that high intraclass compactness and interclass separability are linearly correlated with average precision on MS COCO and NUS-WIDE. This implies that the improvement of intraclass compactness and interclass separability would lead to the improvement of average precision.",4
LABIN: Balanced Min Cut for Large-Scale Data.,"Although many spectral clustering algorithms have been proposed during the past decades, they are not scalable to large-scale data due to their high computational complexities. In this paper, we propose a novel spectral clustering method for large-scale data, namely, large-scale balanced min cut (LABIN). A new model is proposed to extend the self-balanced min-cut (SBMC) model with the anchor-based strategy and a fast spectral rotation with linear time complexity is proposed to solve the new model. Extensive experimental results show the superior performance of our proposed method in comparison with the state-of-the-art methods including SBMC.",4
RoSeq: Robust Sequence Labeling.,"In this paper, we mainly investigate two issues for sequence labeling, namely, label imbalance and noisy data that are commonly seen in the scenario of named entity recognition (NER) and are largely ignored in the existing works. To address these two issues, a new method termed robust sequence labeling (RoSeq) is proposed. Specifically, to handle the label imbalance issue, we first incorporate label statistics in a novel conditional random field (CRF) loss. In addition, we design an additional loss to reduce the weights of overwhelming easy tokens for augmenting the CRF loss. To address the noisy training data, we adopt an adversarial training strategy to improve model generalization. In experiments, the proposed RoSeq achieves the state-of-the-art performances on CoNLL and English Twitter NER--88.07% on CoNLL-2002 Dutch, 87.33% on CoNLL-2002 Spanish, 52.94% on WNUT-2016 Twitter, and 43.03% on WNUT-2017 Twitter without using the additional data.",4
Cognitive Action Laws: The Case of Visual Features.,"This paper proposes a theory for understanding perceptual learning processes within the general framework of laws of nature. Artificial neural networks are regarded as systems whose connections are Lagrangian variables, namely, functions depending on time. They are used to minimize the cognitive action, an appropriate functional index that measures the agent interactions with the environment. The cognitive action contains a potential and a kinetic term that nicely resemble the classic formulation of regularization in machine learning. A special choice of the functional index, which leads to the fourth-order differential equations--Cognitive Action Laws (CAL)--exhibits a structure that mirrors classic formulation of machine learning. In particular, unlike the action of mechanics, the stationarity condition corresponds with the global minimum. Moreover, it is proven that typical asymptotic learning conditions on the weights can coexist with the initialization provided that the system dynamics is driven under a policy referred to as information overloading control. Finally, the theory is experimented for the problem of feature extraction in computer vision.",4
From Whole to Part: Reference-Based Representation for Clustering Categorical Data.,"Dissimilarity measures play a crucial role in clustering and, are directly related to the performance of clustering algorithms. However, effectively measuring the dissimilarity is not easy, especially for categorical data. The main difficulty of the dissimilarity measurement for categorical data is that its representation lacks a clear space structure. Therefore, the space structure-based representation has been proposed to provide the categorical data with a clear linear representation space. This representation improves the clustering performance obviously but only applies to small data sets because its dimensionality increases rapidly with the size of the data set. In this paper, we investigate the possibility of reducing the dimensionality of the space structure-based representation while maintaining the same representation ability. A lightweight representation scheme is proposed by taking a set of representative objects as the reference system (called the reference set) to position other objects in the Euclidean space. Moreover, a preclustering-based strategy is designed to select an appropriate reference set quickly. Finally, the representation scheme together with the k-means algorithm provides an efficient method to cluster the categorical data. The theoretical and the experimental analysis shows that the proposed method outperforms state-of-the-art methods in terms of both accuracy and efficiency.",4
Stability-Based Generalization Analysis of Distributed Learning Algorithmsfor Big Data.,"As one of the efficient approaches to deal with big data, divide-and-conquer distributed algorithms, such as the distributed kernel regression, bootstrap, structured perception training algorithms, and so on, are proposed and broadly used in learning systems. Some learning theories have been built to analyze the feasibility, approximation, and convergence bounds of these distributed learning algorithms. However, less work has been studied on the stability of these distributed learning algorithms. In this paper, we discuss the generalization bounds of distributed learning algorithms from the view of algorithmic stability. First, we introduce a definition of uniform distributed stability for distributed algorithms and study the distributed algorithms' generalization risk bounds. Then, we analyze the stability properties and generalization risk bounds of a kind of regularization-based distributed algorithms. Two generalization distributed risks obtained show that the generalization distributed risk bounds for the difference between their generalization distributed and empirical distributed/leave-one-computer-out risks are closely related to the size of samples n and the amount of working computers m as O(m/n1/2). Furthermore, the results in this paper indicate that, for a good generalization regularized distributed kernel algorithm, the regularization parameter lambda should be adjusted with the change of the term m/n1/2. These theoretic discoveries provide the useful guidance when deploying the distributed algorithms on practical big data platforms. We explore our theoretic analyses through two simulation experiments. Finally, we discuss some problems about the sufficient amount of working computers, nonequivalence, and generalization for distributed learning. We show that the rules for the computation on one single computer may not always hold for distributed learning.",4
Neural Network-Based Adaptive Antiswing Control of an Underactuated Ship-Mounted Crane With Roll Motions and Input Dead Zones.,"As a type of indispensable oceanic transportation tools, ship-mounted crane systems are widely employed to transport cargoes and containers on vessels due to their extraordinary flexibility. However, various working requirements and the oceanic environment may cause some uncertain and unfavorable factors for ship-mounted crane control. In particular, to accomplish different control tasks, some plant parameters (e.g., boom lengths, payload masses, and so on) frequently change; hence, most existing model-based controllers cannot ensure satisfactory control performance any longer. For example, inaccurate gravity compensation may result in positioning errors. Additionally, due to ship roll motions caused by sea waves, residual payload swing generally exists, which may result in safety risks in practice. To solve the above-mentioned issues, this paper designs a neural network-based adaptive control method that can provide effective control for both actuated and unactuated state variables based on the original nonlinear ship-mounted crane dynamics without any linearizing operations. In particular, the proposed update law availably compensates parameter/structure uncertainties for ship-mounted crane systems. Based on a 2-D sliding surface, the boom and rope can arrive at their preset positions in finite time, and the payload swing can be completely suppressed. Furthermore, the problem of nonlinear input dead zones is also taken into account. The stability of the equilibrium point of all state variables in ship-mounted crane systems is theoretically proven by a rigorous Lyapunov-based analysis. The hardware experimental results verify the practicability and robustness of the presented control approach.",4
A Switched Operation Approach to Sampled-Data Control Stabilization of Fuzzy Memristive Neural Networks With Time-Varying Delay.,"This paper investigates the issue of sampled-data stabilization for Takagi-Sugeno fuzzy memristive neural networks (FMNNs) with time-varying delay. First, the concerned FMNNs are transformed into the tractable fuzzy NNs based on the excitatory and inhibitory of memristive synaptic weights using a new convex combination technique. Meanwhile, a switched fuzzy sampled-data controller is employed for the first time to tackle stability problems related to FMNNs. Then, the novel stabilization criteria of the FMNNs are established using the fuzzy membership functions (FMFs)-dependent Lyapunov-Krasovskii functional. This sufficiently utilizes information from not only the delayed state and the actual sampling pattern but also the FMFs. Two simulation examples are presented to demonstrate the feasibility and validity of the proposed method.",4
Nonsynaptic Error Backpropagation in Long-Term Cognitive Networks.,"We introduce a neural cognitive mapping technique named long-term cognitive network (LTCN) that is able to memorize long-term dependencies between a sequence of input and output vectors, especially in those scenarios that require predicting the values of multiple dependent variables at the same time. The proposed technique is an extension of a recently proposed method named short-term cognitive network that aims at preserving the expert knowledge encoded in the weight matrix while optimizing the nonlinear mappings provided by the transfer function of each neuron. A nonsynaptic, backpropagation-based learning algorithm powered by stochastic gradient descent is put forward to iteratively optimize four parameters of the generalized sigmoid transfer function associated with each neuron. Numerical simulations over 35 multivariate regression and pattern completion data sets confirm that the proposed LTCN algorithm attains statistically significant performance differences with respect to other well-known state-of-the-art methods.",4
Recurrent Neural Networks With External Addressable Long-Term and Working Memory for Learning Long-Term Dependences.,"Learning long-term dependences (LTDs) with recurrent neural networks (RNNs) is challenging due to their limited internal memories. In this paper, we propose a new external memory architecture for RNNs called an external addressable long-term and working memory (EALWM)-augmented RNN. This architecture has two distinct advantages over existing neural external memory architectures, namely the division of the external memory into two parts--long-term memory and working memory--with both addressable and the capability to learn LTDs without suffering from vanishing gradients with necessary assumptions. The experimental results on algorithm learning, language modeling, and question answering demonstrate that the proposed neural memory architecture is promising for practical applications.",4
Trajectory Tracking on Uncertain Complex Networks via NN-Based Inverse Optimal Pinning Control.,"A new approach for trajectory tracking on uncertain complex networks is proposed. To achieve this goal, a neural controller is applied to a small fraction of nodes (pinned ones). Such controller is composed of an on-line identifier based on a recurrent high-order neural network, and an inverse optimal controller to track the desired trajectory; a complete stability analysis is also included. In order to verify the applicability and good performance of the proposed control scheme, a representative example is simulated, which consists of a complex network with each node described by a chaotic Lorenz oscillator.",4
A Robust Visual System for Small Target Motion Detection Against Cluttered Moving Backgrounds.,"Monitoring small objects against cluttered moving backgrounds is a huge challenge to future robotic vision systems. As a source of inspiration, insects are quite apt at searching for mates and tracking prey, which always appear as small dim speckles in the visual field. The exquisite sensitivity of insects for small target motion, as revealed recently, is coming from a class of specific neurons called small target motion detectors (STMDs). Although a few STMD-based models have been proposed, these existing models only use motion information for small target detection and cannot discriminate small targets from small-target-like background features (named fake features). To address this problem, this paper proposes a novel visual system model (STMD+) for small target motion detection, which is composed of four subsystems--ommatidia, motion pathway, contrast pathway, and mushroom body. Compared with the existing STMD-based models, the additional contrast pathway extracts directional contrast from luminance signals to eliminate false positive background motion. The directional contrast and the extracted motion information by the motion pathway are integrated into the mushroom body for small target discrimination. Extensive experiments showed the significant and consistent improvements of the proposed visual system model over the existing STMD-based models against fake features.",4
The Robustness of Outputs With Respect to Disturbances for Boolean Control Networks.,"In this brief, we investigate the robustness of outputs with respect to disturbances for Boolean control networks (BCNs) by semi-tensor product (STP) of matrices. First, BCNs are converted into the corresponding algebraic forms by STP, then two sufficient conditions for the robustness are derived. Moreover, the corresponding permutation system and permutation graph are constructed. It is proven that if there exist controllers such that the outputs of permutation systems are robust with respect to disturbances, then there must also exist controllers such that the outputs of the corresponding original systems achieve robustness with respect to disturbances. One effective method is proposed to construct controllers to achieve robustness. Examples are also provided to illustrate the correctness of the obtained results.",4
Discriminative Fisher Embedding Dictionary Learning Algorithm for Object Recognition.,"Both interclass variances and intraclass similarities are crucial for improving the classification performance of discriminative dictionary learning (DDL) algorithms. However, existing DDL methods often ignore the combination between the interclass and intraclass properties of dictionary atoms and coding coefficients. To address this problem, in this paper, we propose a discriminative Fisher embedding dictionary learning (DFEDL) algorithm that simultaneously establishes Fisher embedding models on learned atoms and coefficients. Specifically, we first construct a discriminative Fisher atom embedding model by exploring the Fisher criterion of the atoms, which encourages the atoms of the same class to reconstruct the corresponding training samples as much as possible. At the same time, a discriminative Fisher coefficient embedding model is formulated by imposing the Fisher criterion on the profiles (row vectors of the coding coefficient matrix) and coding coefficients, which forces the coding coefficient matrix to become a block-diagonal matrix. Since the profiles can indicate which training samples are represented by the corresponding atoms, the proposed two discriminative Fisher embedding models can alternatively and interactively promote the discriminative capabilities of the learned dictionary and coding coefficients. The extensive experimental results demonstrate that the proposed DFEDL algorithm achieves superior performance in comparison with some state-of-the-art dictionary learning algorithms on both hand-crafted and deep learning-based features.",4
Stabilization of Second-Order Memristive Neural Networks With Mixed Time Delays via Nonreduced Order.,"In this brief, we investigate a class of second-order memristive neural networks (SMNNs) with mixed time-varying delays. Based on nonsmooth analysis, the Lyapunov stability theory, and adaptive control theory, several new results ensuring global stabilization of the SMNNs are obtained. In addition, compared with the reduced-order method used in the existing research studies, we consider the global stabilization directly from the SMNNs themselves without the reduced-order method. Finally, we give some numerical simulations to show the effectiveness of the results.",4
Distributed Dissipative State Estimation for Markov Jump Genetic Regulatory Networks Subject to Round-Robin Scheduling.,"The distributed dissipative state estimation issue of Markov jump genetic regulatory networks subject to round-robin scheduling is investigated in this paper. The system parameters randomly change in the light of a Markov chain. Each node in sensor networks communicates with its neighboring nodes in view of the prescribed network topology graph. The round-robin scheduling is employed to arrange the transmission order to lessen the likelihood of the occurrence of data collisions. The main goal of the work is to design a compatible distributed estimator to assure that the distributed error system is strictly ( Lambda(1),Lambda(2),Lambda(3)) - -stochastically dissipative. By applying the Lyapunov stability theory and a modified matrix decoupling way, sufficient conditions are derived by solving some convex optimization problems. An illustrative example is given to verify the validity of the provided method.",4
Distribution-Free Probability Density Forecast Through Deep Neural Networks.,"Probability density forecast offers the whole distributions of forecasting targets, which brings greater flexibility and practicability than the other probabilistic forecast models such as prediction interval (PI) and quantile forecast. However, existing density forecast models have introduced various constraints on forecasted distributions, which has limited their ability to approximate real distributions and may result in suboptimality. In this paper, a distribution-free density forecast model based on deep learning is proposed, in which the real cumulative density functions (CDFs) of forecasting target are approximated by a large-capacity positive-weighted deep neural network (NN). Benefiting from the universal approximation ability of NNs, the range of forecasted distributions has been proven to contain all the distributions with continuous CDFs, which is superior to existing models' considering both width and accordance with reality. Three tests from different scenarios were implemented for evaluation, i.e., very-short-term wind power, wind speed, and day-ahead electricity price forecast, in which the proposed density forecast model has shown superior performance over the state of the art.",4
Exactly Robust Kernel Principal Component Analysis.,"Robust principal component analysis (RPCA) can recover low-rank matrices when they are corrupted by sparse noises. In practice, many matrices are, however, of high rank and, hence, cannot be recovered by RPCA. We propose a novel method called robust kernel principal component analysis (RKPCA) to decompose a partially corrupted matrix as a sparse matrix plus a high- or full-rank matrix with low latent dimensionality. RKPCA can be applied to many problems such as noise removal and subspace clustering and is still the only unsupervised nonlinear method robust to sparse noises. Our theoretical analysis shows that, with high probability, RKPCA can provide high recovery accuracy. The optimization of RKPCA involves nonconvex and indifferentiable problems. We propose two nonconvex optimization algorithms for RKPCA. They are alternating direction method of multipliers with backtracking line search and proximal linearized minimization with adaptive step size (AdSS). Comparative studies in noise removal and robust subspace clustering corroborate the effectiveness and the superiority of RKPCA.",4
Stability Analysis for Delayed Neural Networks With an Improved General Free-Matrix-Based Integral Inequality.,"This paper revisits the problem of stability analysis for neural networks with a time-varying delay. An improved general free-matrix-based (FMB) integral inequality is proposed with an undetermined number m. Compared with the conventional FMB ones, the improved inequality involves a much smaller number of free matrix variables. In particular, the improved FMB integral inequality is expressed in a concrete form for any value of m. By employing the new inequality with a properly constructed Lyapunov-Krasovskii functional, a new stability condition is derived for neural networks with a time-varying delay. Two commonly used numerical examples are given to show strong competitiveness of the proposed approach in both the conservatism and computation burdens.",4
Spatial Pyramid-Enhanced NetVLAD With Weighted Triplet Loss for Place Recognition.,"We propose an end-to-end place recognition model based on a novel deep neural network. First, we propose to exploit the spatial pyramid structure of the images to enhance the vector of locally aggregated descriptors (VLAD) such that the enhanced VLAD features can reflect the structural information of the images. To encode this feature extraction into the deep learning method, we build a spatial pyramid-enhanced VLAD (SPE-VLAD) layer. Next, we impose weight constraints on the terms of the traditional triplet loss (T-loss) function such that the weighted T-loss (WT-loss) function avoids the suboptimal convergence of the learning process. The loss function can work well under weakly supervised scenarios in that it determines the semantically positive and negative samples of each query through not only the GPS tags but also the Euclidean distance between the image representations. The SPE-VLAD layer and the WT-loss layer are integrated with the VGG-16 network or ResNet-18 network to form a novel end-to-end deep neural network that can be easily trained via the standard backpropagation method. We conduct experiments on three benchmark data sets, and the results demonstrate that the proposed model defeats the state-of-the-art deep learning approaches applied to place recognition.",4
Probabilistic Neural Network With Complex Exponential Activation Functions in Image Recognition.,"If the training data set in image recognition task is not very large, the feature extraction with a convolutional neural network is usually applied. Here, we focus on the nonparametric classification of extracted feature vectors using the probabilistic neural network (PNN). The latter is characterized by the high runtime and memory space complexity. We propose to overcome these drawbacks by replacing the exponential activation function in the Gaussian kernel to the complex exponential functions. Such complex nonlinearities make it possible to accurately approximate the unknown density function using the network with the number of neurons proportional to only cubic root of the database size. As a result, the proposed approach decreases the runtime and memory complexities of the PNN without losing its main advantages, namely, fast training and convergence to the Bayesian decision. In the experimental study, we describe a protocol for comparing recognition methods using the well-known visual object category data sets in the context of the small sample size problem. It has been experimentally shown that our approach rapidly obtains accurate decisions when compared to the known classifiers including the baseline PNN.",4
Passivity Analysis for Quaternion-Valued Memristor-Based Neural Networks With Time-Varying Delay.,"This paper is concerned with the problem of global exponential passivity for quaternion-valued memristor-based neural networks (QVMNNs) with time-varying delay. The QVMNNs can be seen as a switched system due to the memristor parameters are switching according to the states of the network. This is the first time that the global exponential passivity of QVMNNs with time-varying delay is investigated. By means of a nondecomposition method and structuring novel Lyapunov functional in form of quaternion self-conjugate matrices, the delay-dependent passivity criteria are derived in the forms of quaternion-valued linear matrix inequalities (LMIs) as well as complex-valued LMIs. Furthermore, the asymptotical stability criteria can be obtained from the proposed passivity criteria. Finally, a numerical example is presented to illustrate the effectiveness of the theoretical results.",4
RecSys-DAN: Discriminative Adversarial Networks for Cross-Domain Recommender Systems.,"Data sparsity and data imbalance are practical and challenging issues in cross-domain recommender systems (RSs). This paper addresses those problems by leveraging the concepts which derive from representation learning, adversarial learning, and transfer learning (particularly, domain adaptation). Although various transfer learning methods have shown promising performance in this context, our proposed novel method RecSys-DAN focuses on alleviating the cross-domain and within-domain data sparsity and data imbalance and learns transferable latent representations for users, items, and their interactions. Different from the existing approaches, the proposed method transfers the latent representations from a source domain to a target domain in an adversarial way. The mapping functions in the target domain are learned by playing a min-max game with an adversarial loss, aiming to generate domain indistinguishable representations for a discriminator. Four neural architectural instances of ResSys-DAN are proposed and explored. Empirical results on real-world Amazon data show that, even without using labeled data (i.e., ratings) in the target domain, RecSys-DAN achieves competitive performance as compared to the state-of-the-art supervised methods. More importantly, RecSys-DAN is highly flexible to both unimodal and multimodal scenarios, and thus it is more robust to the cold-start recommendation which is difficult for the previous methods.",4
Joint and Direct Optimization for Dictionary Learning in Convolutional Sparse Representation.,"Convolutional sparse coding (CSC) is a useful tool in many image and audio applications. Maximizing the performance of CSC requires that the dictionary used to store the features of signals can be learned from real data. The so-called convolutional dictionary learning (CDL) problem is formulated within a nonconvex, nonsmooth optimization framework. Most existing CDL solvers alternately update the coefficients and dictionary in an iterative manner. However, these approaches are prone to running redundant iterations, and their convergence properties are difficult to analyze. Moreover, most of those methods approximate the original nonconvex sparse inducing function using a convex regularizer to promote computational efficiency. This approach to approximation may result in nonsparse representations and, thereby, hinder the performance of the applications. In this paper, we deal with the nonconvex, nonsmooth constraints of the original CDL directly using the modified forward-backward splitting approach, in which the coefficients and dictionary are simultaneously updated in each iteration. We also propose a novel parameter adaption scheme to increase the speed of the algorithm used to obtain a usable dictionary and in so doing prove convergence. We also show that the proposed approach is applicable to parallel processing to reduce the computing time required by the algorithm to achieve convergence. The experimental results demonstrate that our method requires less time than the existing methods to achieve the convergence point while using a smaller final functional value. We also applied the dictionaries learned using the proposed and existing methods to an application involving signal separation. The dictionary learned using the proposed approach provides performance superior to that of comparable methods.",4
Hinfinity Static Output-Feedback Control Design for Discrete-Time Systems Using Reinforcement Learning.,"This paper provides necessary and sufficient conditions for the existence of the static output-feedback (OPFB) solution to the Hinfinity control problem for linear discrete-time systems. It is shown that the solution of the static OPFB Hinfinity control is a Nash equilibrium point. Furthermore, a Q-learning algorithm is developed to find the Hinfinity OPFB solution online using data measured along the system trajectories and without knowing the system matrices. This is achieved by solving a game algebraic Riccati equation online and using the measured data. A simulation example shows the effectiveness of the proposed method.",4
Marginalized Multiview Ensemble Clustering.,"Multiview clustering (MVC), which aims to explore the underlying cluster structure shared by multiview data, has drawn more research efforts in recent years. To exploit the complementary information among multiple views, existing methods mainly learn a common latent subspace or develop a certain loss across different views, while ignoring the higher level information such as basic partitions (BPs) generated by the single-view clustering algorithm. In light of this, we propose a novel marginalized multiview ensemble clustering (M(2)VEC) method in this paper. Specifically, we solve MVC in an EC way, which generates BPs for each view individually and seeks for a consensus one. By this means, we naturally leverage the complementary information of multiview data upon the same partition space. In order to boost the robustness of our approach, the marginalized denoising process is adopted to mimic the data corruptions and noises, which provides robust partition-level representations for each view by training a single-layer autoencoder. A low-rank and sparse decomposition is seamlessly incorporated into the denoising process to explicitly capture the consistency information and meanwhile compensate the distinctness between heterogeneous features. Spectral consensus graph partitioning is also involved by our model to make M(2)VEC as a unified optimization framework. Moreover, a multilayer M(2)VEC is eventually delivered in a stacked fashion to encapsulate nonlinearity into partition-level representations for handling complex data. Experimental results on eight real-world data sets show the efficacy of our approach compared with several state-of-the-art multiview and EC methods. We also showcase our method performs well with partial multiview data.",4
Eliminating the Permutation Ambiguity of Convolutive Blind Source Separation by Using Coupled Frequency Bins.,"Blind source separation (BSS) is a typical unsupervised learning method that extracts latent components from their observations. In the meanwhile, convolutive BSS (CBSS) is particularly challenging as the observations are the mixtures of latent components as well as their delayed versions. CBSS is usually solved in frequency domain since convolutive mixtures in time domain is just instantaneous mixtures in frequency domain, which allows to recover source frequency components independently of each frequency bin by running ordinary BSS, and then concatenate them to form the Fourier transformation of source signals. Because BSS has inherent permutation ambiguity, this category of CBSS methods suffers from a common drawback: it is very difficult to choose the frequency components belonging to a specific source as they are estimated from different frequency bins using BSS. This paper presents a tensor framework that can completely eliminate the permutation ambiguity. By combining each frequency bin with an anchor frequency bin that is chosen arbitrarily in advance, we establish a new virtual BSS model where the corresponding correlation matrices comply with a block tensor decomposition (BTD) model. The essential uniqueness of BTD and the sparse structure of coupled mixing parameters allow the estimation of the mixing matrices free of permutation ambiguity. Extensive simulation results confirmed that the proposed algorithm could achieve higher separation accuracy compared with the state-of-the-art methods.",4
Toward Compact ConvNets via Structure-Sparsity Regularized Filter Pruning.,"The success of convolutional neural networks (CNNs) in computer vision applications has been accompanied by a significant increase of computation and memory costs, which prohibits their usage on resource-limited environments, such as mobile systems or embedded devices. To this end, the research of CNN compression has recently become emerging. In this paper, we propose a novel filter pruning scheme, termed structured sparsity regularization (SSR), to simultaneously speed up the computation and reduce the memory overhead of CNNs, which can be well supported by various off-the-shelf deep learning libraries. Concretely, the proposed scheme incorporates two different regularizers of structured sparsity into the original objective function of filter pruning, which fully coordinates the global output and local pruning operations to adaptively prune filters. We further propose an alternative updating with Lagrange multipliers (AULM) scheme to efficiently solve its optimization. AULM follows the principle of alternating direction method of multipliers (ADMM) and alternates between promoting the structured sparsity of CNNs and optimizing the recognition loss, which leads to a very efficient solver (2.5x to the most recent work that directly solves the group sparsity-based regularization). Moreover, by imposing the structured sparsity, the online inference is extremely memory-light since the number of filters and the output feature maps are simultaneously reduced. The proposed scheme has been deployed to a variety of state-of-the-art CNN structures, including LeNet, AlexNet, VGGNet, ResNet, and GoogLeNet, over different data sets. Quantitative results demonstrate that the proposed scheme achieves superior performance over the state-of-the-art methods. We further demonstrate the proposed compression scheme for the task of transfer learning, including domain adaptation and object detection, which also show exciting performance gains over the state-of-the-art filter pruning methods.",4
Deep Least Squares Fisher Discriminant Analysis.,"While being one of the first and most elegant tools for dimensionality reduction, Fisher linear discriminant analysis (FLDA) is not currently considered among the top methods for feature extraction or classification. In this paper, we will review two recent approaches to FLDA, namely, least squares Fisher discriminant analysis (LSFDA) and regularized kernel FDA (RKFDA) and propose deep FDA (DFDA), a straightforward nonlinear extension of LSFDA that takes advantage of the recent advances on deep neural networks. We will compare the performance of RKFDA and DFDA on a large number of two-class and multiclass problems, many of them involving class-imbalanced data sets and some having quite large sample sizes; we will use, for this, the areas under the receiver operating characteristics (ROCs) curve of the classifiers considered. As we shall see, the classification performance of both methods is often very similar and particularly good on imbalanced problems, but building DFDA models is considerably much faster than doing so for RKFDA, particularly in problems with quite large sample sizes.",4
Selection and Optimization of Temporal Spike Encoding Methods for Spiking Neural Networks.,"Spiking neural networks (SNNs) receive trains of spiking events as inputs. In order to design efficient SNN systems, real-valued signals must be optimally encoded into spike trains so that the task-relevant information is retained. This paper provides a systematic quantitative and qualitative analysis and guidelines for optimal temporal encoding. It proposes a methodology of a three-step encoding workflow: method selection by signal characteristics, parameter optimization by error metrics between original and reconstructed signals, and validation by comparison of the original signal and the encoded spike train. Four encoding methods are analyzed: one stimulus estimation [Ben's Spiker algorithm (BSA)] and three temporal contrast [threshold-based, step-forward (SW), and moving-window (MW)] encodings. A short theoretical analysis is provided, and the extended quantitative analysis is carried out applying four types of test signals: step-wise signal, smooth (sinusoid) signal with added noise, trended smooth signal, and event-like smooth signal. Various time-domain and frequency spectrum properties are explored, and a comparison is provided. BSA, the only method providing unipolar spikes, was shown to be ineffective for step-wise signals, but it can follow smoothly changing signals if filter coefficients are scaled appropriately. Producing bipolar (positive and negative) spike trains, SW encoding was most effective for all types of signals as it proved to be robust and easy to optimize. Signal-to-noise ratio (SNR) can be recommended as the error metric for parameter optimization. Currently, only a visual check is available for final validation.",4
Metacognitive Octonion-Valued Neural Networks as They Relate to Time Series Analysis.,"In this paper, a metacognitive octonion-valued neural network (Mc-OVNN) learning algorithm and its application to diverse time series prediction are presented. The Mc-OVNN is comprised of two components: the octonion-valued neural network that represents the cognitive component and the metacognitive component that serves to self-regulate the learning algorithm. At each epoch, the metacognitive component decides if, how, and when learning occurs. The algorithm deletes unneeded samples and only stores those that will be used. This decision is determined by the octonion magnitude and the seven phases. To evaluate the Mc-OVNN algorithm's performance, it is applied to five real-world forecasting problems: the power consumption of a home in Honolulu, HI, USA, Box and Jenkins J series, Euro to Algerian Dinar (DZ) real-time conversion rates, the Mackey-Glass equation, and Europe Brent oil price prediction in a time series. When comparing the Mc-OVNN to other relevant techniques, Mc-OVNN displays its capability for efficient time series prediction. The real-time evaluation of the proposed algorithm is presented using the power consumption of a home in Boumerdes, Algeria, as a case study.",4
Greedy Projected Gradient-Newton Method for Sparse Logistic Regression.,"Sparse logistic regression (SLR), which is widely used for classification and feature selection in many fields, such as neural networks, deep learning, and bioinformatics, is the classical logistic regression model with sparsity constraints. In this paper, we perform theoretical analysis on the existence and uniqueness of the solution to the SLR, and we propose a greedy projected gradient-Newton (GPGN) method for solving the SLR. The GPGN method is a combination of the projected gradient method and the Newton method. The following characteristics show that the GPGN method achieves not only elegant theoretical results but also a remarkable numerical performance in solving the SLR: 1) the full iterative sequence generated by the GPGN method converges to a global/local minimizer of the SLR under weaker conditions; 2) the GPGN method has the properties of afinite identification for an optimal support set and local quadratic convergence; and 3) the GPGN method achieves higher accuracy and higher speed compared with a number of state-of-the-art solvers according to numerical experiments.",4
The Hierarchical Continuous Pursuit Learning Automation: A Novel Scheme for Environments With Large Numbers of Actions.,"Although the field of learning automata (LA) has made significant progress in the past four decades, the LA-based methods to tackle problems involving environments with a large number of actions is, in reality, relatively unresolved. The extension of the traditional LA to problems within this domain cannot be easily established when the number of actions is very large. This is because the dimensionality of the action probability vector is correspondingly large, and so, most components of the vector will soon have values that are smaller than the machine accuracy permits, implying that they will never be chosen. This paper presents a solution that extends the continuous pursuit paradigm to such large-actioned problem domains. The beauty of the solution is that it is hierarchical, where all the actions offered by the environment reside as leaves of the hierarchy. Furthermore, at every level, we merely require a two-action LA that automatically resolves the problem of dealing with arbitrarily small action probabilities. In addition, since all the LA invoke the pursuit paradigm, the best action at every level trickles up toward the root. Thus, by invoking the property of the ``max'' operator, in which the maximum of numerous maxima is the overall maximum, the hierarchy of LA converges to the optimal action. This paper describes the scheme and formally proves its epsilon-optimal convergence. The results presented here can, rather trivially, be extended for the families of discretized and Bayesian pursuit LA too. This paper also reports extensive experimental results (including for environments having 128 and 256 actions) that demonstrate the power of the scheme and its computational advantages. As far as we know, there are no comparable pursuit-based results in the field of LA. In some cases, the hierarchical continuous pursuit automaton requires less than 18% of the number of iterations than the benchmark LR-I scheme, which is, by all metrics, phenomenal.",4
Local Synchronization of Interconnected Boolean Networks With Stochastic Disturbances.,"This paper is concerned with the local synchronization problem for the interconnected Boolean networks (BNs) without and with stochastic disturbances. For the case without stochastic disturbances, first, the limit set and the transient period of the interconnected BNs are discussed by resorting to the properties of the reachable set for the global initial states set. Second, in terms of logical submatrices of a certain Boolean vector, a compact algebraic expression is presented for the limit set of the given initial states set. Based on it, several necessary and sufficient conditions are derived assuring the local synchronization of the interconnected BNs. Subsequently, an efficient algorithm is developed to calculate the largest domain of attraction. As for the interconnected BNs with stochastic disturbances, first, mutually independent two-valued random logical variables are introduced to describe the stochastic disturbances. Then, the corresponding local synchronization criteria are also established, and the algorithm to calculate the largest domain of attraction is designed. Finally, numerical examples are employed to illustrate the effectiveness of the obtained results/algorithms.",4
Distributed Fault-Tolerant Control of Multiagent Systems: An Adaptive Learning Approach.,"This paper focuses on developing a distributed leader-following fault-tolerant tracking control scheme for a class of high-order nonlinear uncertain multiagent systems. Neural network-based adaptive learning algorithms are developed to learn unknown fault functions, guaranteeing the system stability and cooperative tracking even in the presence of multiple simultaneous process and actuator faults in the distributed agents. The time-varying leader's command is only communicated to a small portion of follower agents through directed links, and each follower agent exchanges local measurement information only with its neighbors through a bidirectional but asymmetric topology. Adaptive fault-tolerant algorithms are developed for two cases, i.e., with full-state measurement and with only limited output measurement, respectively. Under certain assumptions, the closed-loop stability and asymptotic leader-follower tracking properties are rigorously established.",4
Adaptive Optimal Control for a Class of Nonlinear Systems: The Online Policy Iteration Approach.,"This paper studies the online adaptive optimal controller design for a class of nonlinear systems through a novel policy iteration (PI) algorithm. By using the technique of neural network linear differential inclusion (LDI) to linearize the nonlinear terms in each iteration, the optimal law for controller design can be solved through the relevant algebraic Riccati equation (ARE) without using the system internal parameters. Based on PI approach, the adaptive optimal control algorithm is developed with the online linearization and the two-step iteration, i.e., policy evaluation and policy improvement. The convergence of the proposed PI algorithm is also proved. Finally, two numerical examples are given to illustrate the effectiveness and applicability of the proposed method.",4
Hidden Bursting Firings and Bifurcation Mechanisms in Memristive Neuron Model With Threshold Electromagnetic Induction.,"Memristors can be employed to mimic biological neural synapses or to describe electromagnetic induction effects. To exhibit the threshold effect of electromagnetic induction, this paper presents a threshold flux-controlled memristor and examines its frequency-dependent pinched hysteresis loops. Using an electromagnetic induction current generated by the threshold memristor to replace the external current in 2-D Hindmarsh-Rose (HR) neuron model, a 3-D memristive HR (mHR) neuron model with global hidden oscillations is established and the corresponding numerical simulations are performed. It is found that due to no equilibrium point, the obtained mHR neuron model always operates in hidden bursting firing patterns, including coexisting hidden bursting firing patterns with bistability also. In addition, the model exhibits complex dynamics of the actual neuron electrical activities, which acts like the 3-D HR neuron model, indicating its feasibility. In particular, by constructing the fold and Hopf bifurcation sets of the fast-scale subsystem, the bifurcation mechanisms of hidden bursting firings are expounded. Finally, circuit experiments on hardware breadboards are deployed and the captured results well match with the numerical results, validating the physical mechanism of biological neuron and the reliability of electronic neuron.",4
PCNN Mechanism and Its Parameter Settings.,"The pulse-coupled neural network (PCNN) model is a third-generation artificial neural network without training that uses the synchronous pulse bursts of neurons to process digital images, but the lack of in-depth theoretical research limits its extensive application. By analyzing the working mechanism of the PCNN, we present an expression for the fire-extinguishing time of neurons that fire in the second iteration and an expression for the firing time of neurons that extinguish in the second iteration. In addition, we find a phenomenon of the PCNN and name it mathematically coupled fire extinguishing. Based on the above analysis, we propose a new working mode for the PCNN, where the refiring of fire-extinguishing neurons is only allowed when all firing neurons are extinguished. We also work out the constraint conditions of the parameter settings under this mode. Furthermore, we analyze the relationship between the network parameters and mathematically coupled fire extinguishing, the coupling of neighboring neurons, and the convergence rate of the PCNN, respectively. In addition, we demonstrate the essential regularity of extinguished neuron in the PCNN and then propose an optimal parameter setting to achieve the best comprehensive performance of the PCNN.",4
Flow Adversarial Networks: Flowrate Prediction for Gas-Liquid Multiphase Flows Across Different Domains.,"The solution of how to accurately and timely predict the flowrate of gas-liquid mixtures is the key to help petroleum and other related industries to reduce costs, improve efficiency, and optimize management. Although numerous studies have been carried out over the past decades, the problem is still significantly challenging due to the complexity of multiphase flows. This paper attempts to seek new possibilities for multiphase flow measurement and novel application scenarios for state-of-the-art machine learning (ML) techniques. Convolutional neural networks (CNNs) are applied to predict the flowrate of multiphase flows for the first time and can achieve promising performance. In addition, considering the difference between data distributions of training and testing samples and its negative impact on prediction accuracy of the CNN models on testing samples, we propose flow adversarial networks (FANs) that can distill both domain-invariant and flowrate-discriminative features from the raw input. The method is evaluated on dynamic experimental data of different multiphase flows on different flow conditions and operating environments. The experimental results demonstrate that FANs can effectively prevent the accuracy degradation caused by the gap between training and testing samples and have better performance than state-of-the-art approaches in the flowrate prediction field.",4
Information Transmitted From Bioinspired Neuron-Astrocyte Network Improves Cortical Spiking Network's Pattern Recognition Performance.,"We trained two spiking neural networks (SNNs), the cortical spiking network (CSN) and the cortical neuron-astrocyte network (CNAN), using a spike-based unsupervised method, on the MNIST and alpha-digit data sets and achieve an accuracy of 96.1% and 77.35%, respectively. We then connected CNAN to CSN by preserving maximum synchronization between them thanks to the concept of prolate spheroidal wave functions (PSWF). As a result, CSN receives additional information from CNAN without retraining. The important outcome is that CSN reaches 70.57% correct classification rate on capital letters without being trained on them. The overall contribution of transfer is 87.47%. We observed that for CSN the classifying neurons that relate to digits 0-9 of the alpha-digit data set are completely supported by the ones that relate to digits 0-9 of the MNIST data set. This means that CSN recognizes the similarity between the digits of the MNIST and alpha-digit data sets and classifies each digit of both data sets in the same class.",4
Attribute-Guided Network for Cross-Modal Zero-Shot Hashing.,"Zero-shot hashing (ZSH) aims at learning a hashing model that is trained only by instances from seen categories but can generate well to those of unseen categories. Typically, it is achieved by utilizing a semantic embedding space to transfer knowledge from seen domain to unseen domain. Existing efforts mainly focus on single-modal retrieval task, especially image-based image retrieval (IBIR). However, as a highlighted research topic in the field of hashing, cross-modal retrieval is more common in real-world applications. To address the cross-modal ZSH (CMZSH) retrieval task, we propose a novel attribute-guided network (AgNet), which can perform not only IBIR but also text-based image retrieval (TBIR). In particular, AgNet aligns different modal data into a semantically rich attribute space, which bridges the gap caused by modality heterogeneity and zero-shot setting. We also design an effective strategy that exploits the attribute to guide the generation of hash codes for image and text within the same network. Extensive experimental results on three benchmark data sets (AwA, SUN, and ImageNet) demonstrate the superiority of AgNet on both cross-modal and single-modal zero-shot image retrieval tasks.",4
Term Selection for a Class of Separable Nonlinear Models.,"In this paper, we consider the term selection problem for a class of separable nonlinear models. The strategy is a two-step process in which the nonlinear parameters of the model are first optimized by a variable projection method, and then the least absolute shrinkage and selection operator are adopted to obtain a sparse solution by picking out the critical terms automatically. This process may be repeated several times. The proposed algorithm is tested on parameter estimation problems for an exponential model and a neural network-based model. The numerical results show that the proposed algorithm can pick out the appropriate terms from the overparameterized model and the obtained parsimonious model performs better than other methods.",4
Neural Network-Based Distributed Cooperative Learning Control for Multiagent Systems via Event-Triggered Communication.,"In this paper, an event-based distributed cooperative learning (DCL) law is proposed for a group of adaptive neural control systems. The plants to be controlled have identical structures, but reference signals for each plant are different. During control process, each agent intermittently broadcasts its neural network (NN) weight estimation to its neighboring agents under an event-triggered condition that is only based on its own estimated NN weights. If communication topology is connected and undirected, the NN weights of all neural control systems can converge to a small neighborhood of their optimal values. The generalization ability of NNs is guaranteed in the event-triggered context, that is, the approximation domain of each NN is the union of all system trajectories. Furthermore, a strictly positive lower bound on the interevent intervals is also guaranteed to avoid the Zeno behavior. Finally, a numerical example is given to illustrate the effectiveness of the proposed learning law.",4
Natural Language Statistical Features of LSTM-Generated Texts.,"Long short-term memory (LSTM) networks have recently shown remarkable performance in several tasks that are dealing with natural language generation, such as image captioning or poetry composition. Yet, only few works have analyzed text generated by LSTMs in order to quantitatively evaluate to which extent such artificial texts resemble those generated by humans. We compared the statistical structure of LSTM-generated language to that of written natural language, and to those produced by Markov models of various orders. In particular, we characterized the statistical structure of language by assessing word-frequency statistics, long-range correlations, and entropy measures. Our main finding is that while both LSTM- and Markov-generated texts can exhibit features similar to real ones in their word-frequency statistics and entropy measures, LSTM-texts are shown to reproduce long-range correlations at scales comparable to those found in natural language. Moreover, for LSTM networks, a temperature-like parameter controlling the generation process shows an optimal value--for which the produced texts are closest to real language--consistent across different statistical features investigated.",4
Neural Network-Based Adaptive Consensus Control for a Class of Nonaffine Nonlinear Multiagent Systems With Actuator Faults.,"In this paper, the consensus problem is investigated for a class of nonaffine nonlinear multiagent systems (MASs) with actuator faults of partial loss of effectiveness fault and biased fault. To deal with the control difficulty caused by the nonaffine dynamics, a neural network (NN)-based adaptive consensus protocol is developed based on the Lyapunov analysis. The neuron input of the NN uses both the state information and the consensus error information. In addition, the negative feedback term of the NN weight update law is multiplied by an absolute value of the consensus error, which is helpful in improving the consensus accuracy. With the developed adaptive NN consensus protocol, semiglobal consensus with a bounded residual consensus error of the MAS is achieved, and the bounded NN weight matrix is guaranteed. Finally, simulation results show that the developed adaptive NN consensus protocol has advantages of fast convergence rate and good consensus accuracy and has the capability of rapid response with respect to the actuator faults.",4
"Kinodynamic Motion Planning With Continuous- Time Q-Learning: An Online, Model-Free, and Safe Navigation Framework.","This paper presents an online kinodynamic motion planning algorithmic framework using asymptotically optimal rapidly-exploring random tree (RRT*) and continuous-time Q-learning, which we term as RRT-Q*. We formulate a model-free Q-based advantage function and we utilize integral reinforcement learning to develop tuning laws for the online approximation of the optimal cost and the optimal policy of continuous-time linear systems. Moreover, we provide rigorous Lyapunov-based proofs for the stability of the equilibrium point, which results in asymptotic convergence properties. A terminal state evaluation procedure is introduced to facilitate the online implementation. We propose a static obstacle augmentation and a local replanning framework, which are based on topological connectedness, to locally recompute the robot's path and ensure collision-free navigation. We perform simulations and a qualitative comparison to evaluate the efficacy of the proposed methodology.",4
Deep Decision Tree Transfer Boosting.,"Instance transfer approaches consider source and target data together during the training process, and borrow examples from the source domain to augment the training data, when there is limited or no label in the target domain. Among them, boosting-based transfer learning methods (e.g., TrAdaBoost) are most widely used. When dealing with more complex data, we may consider the more complex hypotheses (e.g., a decision tree with deeper layers). However, with the fixed and high complexity of the hypotheses, TrAdaBoost and its variants may face the overfitting problems. Even worse, in the transfer learning scenario, a decision tree with deep layers may overfit different distribution data in the source domain. In this paper, we propose a new instance transfer learning method, i.e., Deep Decision Tree Transfer Boosting (DTrBoost), whose weights are learned and assigned to base learners by minimizing the data-dependent learning bounds across both source and target domains in terms of the Rademacher complexities. This guarantees that we can learn decision trees with deep layers without overfitting. The theorem proof and experimental results indicate the effectiveness of our proposed method.",4
A Novel Concept Drift Detection Method for Incremental Learning in Nonstationary Environments.,"We present a novel method for concept drift detection, based on: 1) the development and continuous updating of online sequential extreme learning machines (OS-ELMs) and 2) the quantification of how much the updated models are modified by the newly collected data. The proposed method is verified on two synthetic case studies regarding different types of concept drift and is applied to two public real-world data sets and a real problem of predicting energy production from a wind plant. The results show the superiority of the proposed method with respect to alternative state-of-the-art concept drift detection methods. Furthermore, updating the prediction model when the concept drift has been detected is shown to allow improving the overall accuracy of the energy prediction model and, at the same time, minimizing the number of model updatings.",4
HONN-Based Adaptive ILC for Pure-Feedback Nonaffine Discrete-Time Systems With Unknown Control Directions.,"Nearly all adaptive control techniques require that the control directions of dynamical systems are known in advance. In this paper, for a class of pure-feedback nonaffine discrete-time systems with unknown control directions (UCDs), a high-order neural network (HONN)-based adaptive iterative learning control (ILC) approach is presented to address a repetitive tracking control issue. The implicit function theorem is adopted to cope with the difficulty resulting from the nonaffine structure of control input. Employing a discrete Nussbaum-type function in the neural network weight adaptation law to suit the UCD, an HONN is used to iteratively estimate the ideal control signals. In addition, a novel dead-zone method is developed in the HONN-based adaptive ILC algorithm to enhance its robustness against nonrepetitive desired trajectories and random uncertainties in iterative initial errors and external disturbance. Consequently, the system output, except at the initial n time instants, is demonstrated to asymptotically converge to an adjustable range of the desired trajectory along the iteration axis, while all of the system signals remain bounded during the entire ILC process. Two simulation examples show the feasibility of the adaptive ILC approach.",4
Manifold Criterion Guided Transfer Learning via Intermediate Domain Generation.,"In many practical transfer learning scenarios, the feature distribution is different across the source and target domains (i.e., nonindependent identical distribution). Maximum mean discrepancy (MMD), as a domain discrepancy metric, has achieved promising performance in unsupervised domain adaptation (DA). We argue that the MMD-based DA methods ignore the data locality structure, which, up to some extent, would cause the negative transfer effect. The locality plays an important role in minimizing the nonlinear local domain discrepancy underlying the marginal distributions. For better exploiting the domain locality, a novel local generative discrepancy metric-based intermediate domain generation learning called Manifold Criterion guided Transfer Learning (MCTL) is proposed in this paper. The merits of the proposed MCTL are fourfold: 1) the concept of manifold criterion (MC) is first proposed as a measure validating the distribution matching across domains, and DA is achieved if the MC is satisfied; 2) the proposed MC can well guide the generation of the intermediate domain sharing similar distribution with the target domain, by minimizing the local domain discrepancy; 3) a global generative discrepancy metric is presented, such that both the global and local discrepancies can be effectively and positively reduced; and 4) a simplified version of MCTL called MCTL-S is presented under a perfect domain generation assumption for more generic learning scenario. Experiments on a number of benchmark visual transfer tasks demonstrate the superiority of the proposed MC guided generative transfer method, by comparing with the other state-of-the-art methods. The source code is available in https://github.com/wangshanshanCQU/MCTL.",4
A Conclusive Analysis of the Finite-Time Behavior of the Discretized Pursuit Learning Automaton.,"This paper deals with the finite-time analysis (FTA) of learning automata (LA), which is a topic for which very little work has been reported in the literature. This is as opposed to the asymptotic steady-state analysis for which there are, probably, scores of papers. As clarified later, unarguably, the FTA of Markov chains, in general, and of LA, in particular, is far more complex than the asymptotic steady-state analysis. Such an FTA provides rigid bounds for the time required for the LA to attain to a given convergence accuracy. We concentrate on the FTA of the Discretized Pursuit Automaton (DPA), which is probably one of the fastest and most accurate reported LA. Although such an analysis was carried out many years ago, we record that the previous work is flawed. More specifically, in all brevity, the flaw lies in the wrongly ``derived'' monotonic behavior of the LA after a certain number of iterations. Rather, we claim that the property should be invoked is the submartingale property. This renders the proof to be much more involved and deep. In this paper, we rectify the flaw and reestablish the FTA based on such a submartingale phenomenon. More importantly, from the derived analysis, we are able to discover and clarify, for the first time, the underlying dilemma between the DPA's exploitation and exploration properties. We also nontrivially confirm the existence of the optimal learning rate, which yields a better comprehension of the DPA itself.",4
Learning-Based Robust Tracking Control of Quadrotor With Time-Varying and Coupling Uncertainties.,"In this paper, a learning-based robust tracking control scheme is proposed for a quadrotor unmanned aerial vehicle system. The quadrotor dynamics are modeled including time-varying and coupling uncertainties. By designing position and attitude tracking error subsystems, the robust tracking control strategy is conducted by involving the approximately optimal control of associated nominal error subsystems. Furthermore, an improved weight updating rule is adopted, and neural networks are applied in the learning-based control scheme to get the approximately optimal control laws of the nominal error subsystems. The stability of tracking error subsystems with time-varying and coupling uncertainties is provided as the theoretical guarantee of learning-based robust tracking control scheme. Finally, considering the variable disturbances in the actual environment, three simulation cases are presented based on linear and nonlinear models of quadrotor with competitive results to demonstrate the effectiveness of the proposed control scheme.",4
A New Timing Error Cost Function for Binary Time Series Prediction.,"The ability to make predictions is central to the artificial intelligence problem. While machine learning algorithms have difficulty in learning to predict events with hundreds of time-step dependencies, animals can learn event timing within tens of trials across a broad spectrum of time scales. This suggests strongly a need for new perspectives on the forecasting problem. This paper focuses on binary time series that can be predicted within some temporal precision. We demonstrate that the sum of squared errors (SSE) calculated at every time step is not appropriate for this problem. Next, we look at the advantages and shortcomings of using a dynamic time warping (DTW) cost function. Then, we propose the squared timing error (STE) that uses DTW on the event space and applies SSE on the timing error instead of at each time step. We evaluate all three cost functions on different types of timing errors, such as phase shift, warping, and missing events, on synthetic and real-world binary time series (heartbeats, finance, and music). The results show that STE provides more information about timing error, is differentiable, and can be computed online efficiently. Finally, we devise a gradient descent algorithm for STE on a simplified recurrent neural network. We then compare the performance of the STE-based algorithm to SSE- and logit-based gradient descent algorithms on the same network architecture. The results in real-world binary time series show that the STE algorithm generally outperforms all the other cost functions considered.",4
Set-Membership Estimation for Complex Networks Subject to Linear and Nonlinear Bounded Attacks.,"This paper is concerned with the set-membership estimation problem for complex networks subject to unknown but bounded attacks. Adversaries are assumed to exist in the nonsecure communication channels from the nodes to the estimators. The transmitted measurements may be modified by an attack function with added noise that is determined by the adversary but unknown to the estimators. A novel set-membership estimation model against unknown but bounded attacks is presented. Two sufficient conditions are derived to guarantee the existence of the set-membership estimators for the cases that the attack functions are linear and nonlinear, respectively. Two strategies for the design of the set-membership estimator gains are presented. The effectiveness of the proposed estimator design method is verified by two simulation examples.",4
Insights Into Multiple/Single Lower Bound Approximation for Extended Variational Inference in Non-Gaussian Structured Data Modeling.,"For most of the non-Gaussian statistical models, the data being modeled represent strongly structured properties, such as scalar data with bounded support (e.g., beta distribution), vector data with unit length (e.g., Dirichlet distribution), and vector data with positive elements (e.g., generalized inverted Dirichlet distribution). In practical implementations of non-Gaussian statistical models, it is infeasible to find an analytically tractable solution to estimating the posterior distributions of the parameters. Variational inference (VI) is a widely used framework in Bayesian estimation. Recently, an improved framework, namely, the extended VI (EVI), has been introduced and applied successfully to a number of non-Gaussian statistical models. EVI derives analytically tractable solutions by introducing lower bound approximations to the variational objective function. In this paper, we compare two approximation strategies, namely, the multiple lower bounds (MLBs) approximation and the single lower bound (SLB) approximation, which can be applied to carry out the EVI. For implementation, two different conditions, the weak and the strong conditions, are discussed. Convergence of the EVI depends on the selection of the lower bound, regardless of the choice of weak or strong condition. We also discuss the convergence properties to clarify the differences between MLB and SLB. Extensive comparisons are made based on some EVI-based non-Gaussian statistical models. Theoretical analysis is conducted to demonstrate the differences between the weak and strong conditions. Experimental results based on real data show advantages of the SLB approximation over the MLB approximation.",4
Probabilistic Linear Discriminant Analysis With Vectorial Representation for Tensor Data.,"Linear discriminant analysis (LDA) has been a widely used supervised feature extraction and dimension reduction method in pattern recognition and data analysis. However, facing high-order tensor data, the traditional LDA-based methods take two strategies. One is vectorizing original data as the first step. The process of vectorization will destroy the structure of high-order data and result in high dimensionality issue. Another is tensor LDA-based algorithms that extract features from each mode of high-order data and the obtained representations are also high-order tensor. This paper proposes a new probabilistic LDA (PLDA) model for tensorial data, namely, tensor PLDA. In this model, each tensorial data are decomposed into three parts: the shared subspace component, the individual subspace component, and the noise part. Furthermore, the first two parts are modeled by a linear combination of latent tensor bases, and the noise component is assumed to follow a multivariate Gaussian distribution. Model learning is conducted through a Bayesian inference process. To further reduce the total number of model parameters, the tensor bases are assumed to have tensor CandeComp/PARAFAC (CP) decomposition. Two types of experiments, data reconstruction and classification, are conducted to evaluate the performance of the proposed model with the convincing result, which is superior or comparable against the existing LDA-based methods.",4
A White-Box Equivalent Neural Network Circuit Model for SoC Estimation of Electrochemical Cells.,"Smart grids, microgrids, and pure electric powertrains are the key technologies for achieving the expected goals concerning the restraint of CO(2) emissions and global warming. In this context, an effective use of electrochemical energy storage systems (ESSs) is mandatory. In particular, accurate state of charge (SoC) estimations are helpful for improving the ESS performances. To this aim, developing accurate models of electrochemical cells is necessary for implementing effective SoC estimators. Therefore, a novel neural network modeling technique is proposed in this paper. The main contribution consists in the development of a white-box neural design that provides helpful insights into the cell physics, together with a powerful nonlinear approximation capability, and a flexible system identification procedure. In order to do that, the system equations of a white-box equivalent circuit model (ECM) have been combined with computational intelligence techniques by approximating each circuit element with a dedicated neural network. The model performances have been analyzed in terms of model accuracy, SoC estimation effectiveness, and computational cost over two realistic data sets. Moreover, the proposed model has been compared with a white-box ECM and a gray-box neural network model. The results prove that the proposed modeling technique is able to provide useful improvements in the SoC estimation task with a competing computational cost.",4
Semisupervised Text Classification by Variational Autoencoder.,"Semisupervised text classification has attracted much attention from the research community. In this paper, a novel model, the semisupervised sequential variational autoencoder (SSVAE), is proposed to tackle this problem. By treating the categorical label of unlabeled data as a discrete latent variable, the proposed model maximizes the variational evidence lower bound of the data likelihood, which implicitly derives the underlying label distribution for the unlabeled data. Analytical work indicates that the autoregressive nature of the sequential model is the crucial issue that renders the vanilla model ineffective. To remedy this, two types of decoders are investigated in the SSVAE model and verified. In addition, a reweighting approach is proposed to circumvent the credit assignment problem that occurs during the reconstruction procedure, which can further improve performance for sparse text data. Experimental results show that our method significantly improves the classification accuracy compared with other modern methods.",4
Leader Selection via Supermodular Game for Formation Control in Multiagent Systems.,"Multiagent systems (MASs) are usually applied with agents classified into leaders and followers, where selecting appropriate leaders is an important issue for formation control applications. In this paper, we investigate two leader selection problems in second-order MAS, namely, the problem of choosing up to a given number of leaders to minimize the formation error and the problem of choosing the minimum number of leaders to achieve a tolerated level of error. We propose a game theoretical method to address them. Specifically, we design a supermodular game for the leader selection problems and theoretically prove its supermodularity. In order to reach Nash equilibrium of the game, we propose strategies for the agents to learn to select leaders based on stochastic fictitious play. Extensive simulation results demonstrate that our method outperforms existing ones.",4
A Time Wave Neural Network Framework for Solving Time-Dependent Project Scheduling Problems.,"This paper considers the time-dependent project scheduling problem (TPSP). We propose a time wave neural network (TWNN) framework that is able to achieve the global optimal solution (viz., the optimal project schedule) of the TPSP, which is very difficult to obtain using conventional methods (e.g., Dijkstra's algorithm). The proposed TWNN is a time wave neuron-based neural network without a requirement for any training. In the design of a TWNN, the overall project network of the TPSP is viewed as a neural network, while each node is considered as a wave-based neuron. With this new perspective, the wave-based neuron is constructed based on seven parts: an input, a wave receiver, a neuron state, a time-window selector, a wave generator, a wave sender, and an output. The first three parts are used to receive the waves coming from the predecessor neurons, the fourth part is used to choose the optimal feasible time window, and the remaining three parts are utilized to generate waves for the successive neurons. The main idea of a TWNN is based on the following mechanism: a wave generated from a neuron (node) means that all previous arcs (subprojects) of this neuron have been completed. In particular, the global optimal project scheduling is obtained when a wave is generated by the final destination neuron. To evaluate the performance of a TWNN, the well-known project scheduling problem library data sets are modified and considered in a comparative analysis. Numerical examples are also utilized to demonstrate the robustness of the method.",4
Further Results on Adaptive Stabilization of High-Order Stochastic Nonlinear Systems Subject to Uncertainties.,"This paper concerns the adaptive state-feedback control for a class of high-order stochastic nonlinear systems with uncertainties including time-varying delay, unknown control gain, and parameter perturbation. The commonly used growth assumptions on system nonlinearities are removed, and the adaptive control technique is combined with the sign function to deal with the unknown control gain. Then, with the help of the radial basis function neural network approximation approach and Lyapunov-Krasovskii functional, an adaptive state-feedback controller is obtained through the backstepping design procedure. It is verified that the constructed controller can render the closed-loop system semiglobally uniformly ultimately bounded. Finally, both the practical and numerical examples are presented to validate the effectiveness of the proposed scheme.",4
Leveraging Coupled Interaction for Multimodal Alzheimer's Disease Diagnosis.,"As the population becomes older worldwide, accurate computer-aided diagnosis for Alzheimer's disease (AD) in the early stage has been regarded as a crucial step for neurodegeneration care in recent years. Since it extracts the low-level features from the neuroimaging data, previous methods regarded this computer-aided diagnosis as a classification problem that ignored latent featurewise relation. However, it is known that multiple brain regions in the human brain are anatomically and functionally interlinked according to the current neuroscience perspective. Thus, it is reasonable to assume that the extracted features from different brain regions are related to each other to some extent. Also, the complementary information between different neuroimaging modalities could benefit multimodal fusion. To this end, we consider leveraging the coupled interactions in the feature level and modality level for diagnosis in this paper. First, we propose capturing the feature-level coupled interaction using a coupled feature representation. Then, to model the modality-level coupled interaction, we present two novel methods: 1) the coupled boosting (CB) that models the correlation of pairwise coupled-diversity on both inconsistently and incorrectly classified samples between different modalities and 2) the coupled metric ensemble (CME) that learns an informative feature projection from different modalities by integrating the intrarelation and interrelation of training samples. We systematically evaluated our methods with the AD neuroimaging initiative data set. By comparison with the baseline learning-based methods and the state-of-the-art methods that are specially developed for AD/MCI (mild cognitive impairment) diagnosis, our methods achieved the best performance with accuracy of 95.0% and 80.7% (CB), 94.9% and 79.9% (CME) for AD/NC (normal control), and MCI/NC identification, respectively.",4
A Unified Entropy-Based Distance Metric for Ordinal-and-Nominal-Attribute Data Clustering.,"Ordinal data are common in many data mining and machine learning tasks. Compared to nominal data, the possible values (also called categories interchangeably) of an ordinal attribute are naturally ordered. Nevertheless, since the data values are not quantitative, the distance between two categories of an ordinal attribute is generally not well defined, which surely has a serious impact on the result of the quantitative analysis if an inappropriate distance metric is utilized. From the practical perspective, ordinal-and-nominal-attribute categorical data, i.e., categorical data associated with a mixture of nominal and ordinal attributes, is common, but the distance metric for such data has yet to be well explored in the literature. In this paper, within the framework of clustering analysis, we therefore first propose an entropy-based distance metric for ordinal attributes, which exploits the underlying order information among categories of an ordinal attribute for the distance measurement. Then, we generalize this distance metric and propose a unified one accordingly, which is applicable to ordinal-and-nominal-attribute categorical data. Compared with the existing metrics proposed for categorical data, the proposed metric is simple to use and nonparametric. More importantly, it reasonably exploits the underlying order information of ordinal attributes and statistical information of nominal attributes for distance measurement. Extensive experiments show that the proposed metric outperforms the existing counterparts on both the real and benchmark data sets.",4
Weighted Mixed-Norm Regularized Regression for Robust Face Identification.,"Face identification (FI) via regression-based classification has been extensively studied during the recent years. Most vector-based methods achieve appealing performance in handing the noncontiguous pixelwise noises, while some matrix-based regression methods show great potential in dealing with contiguous imagewise noises. However, there is a lack of consideration of the mixture noises case, where both contiguous and noncontiguous noises are jointly contained. In this paper, we propose a weighted mixed-norm regression (WMNR) method to cope with the mixture image corruption. WMNR reveals certain essential characteristics of FI problems and bridges the vector- and matrix-based methods. Particularly, WMNR provides two advantages for both theoretical analysis and practical implementation. First, it generalizes possible distributions of the residuals into a unified feature weighted loss function. Second, it constrains the residual image as low-rank structure that can be quantified with general nonconvex functions and a weight factor. Moreover, a new reweighted alternating direction method of multipliers algorithm is derived for the proposed WMNR model. The algorithm exhibits great computational efficiency since it divides the original optimization problem into certain subproblems with analytical solution or can be implemented in a parallel manner. Extensive experiments on several public face databases demonstrate the advantages of WMNR over the state-of-the-art regression-based approaches. More specifically, the WMNR achieves an appealing tradeoff between identification accuracy and computational efficiency. Compared with the pure vector-based methods, our approach achieves more than 10% performance improvement and saves more than 70% of runtime, especially in severe corruption scenarios. Compared with the pure matrix-based methods, although it requires slightly more computation time, the performance benefits are even larger; up to 20% improvement can be obtained.",4
Efficient Recovery of Low-Rank Matrix via Double Nonconvex Nonsmooth Rank Minimization.,"Recently, there is a rapidly increasing attraction for the efficient recovery of low-rank matrix in computer vision and machine learning. The popular convex solution of rank minimization is nuclear norm-based minimization (NNM), which usually leads to a biased solution since NNM tends to overshrink the rank components and treats each rank component equally. To address this issue, some nonconvex nonsmooth rank (NNR) relaxations have been exploited widely. Different from these convex and nonconvex rank substitutes, this paper first introduces a general and flexible rank relaxation function named weighted NNR relaxation function, which is actually derived from the initial double NNR (DNNR) relaxations, i.e., DNNR relaxation function acts on the nonconvex singular values function (SVF). An iteratively reweighted SVF optimization algorithm with continuation technology through computing the supergradient values to define the weighting vector is devised to solve the DNNR minimization problem, and the closed-form solution of the subproblem can be efficiently obtained by a general proximal operator, in which each element of the desired weighting vector usually satisfies the nondecreasing order. We next prove that the objective function values decrease monotonically, and any limit point of the generated subsequence is a critical point. Combining the Kurdyka-Lojasiewicz property with some milder assumptions, we further give its global convergence guarantee. As an application in the matrix completion problem, experimental results on both synthetic data and real-world data can show that our methods are competitive with several state-of-the-art convex and nonconvex matrix completion methods.",4
Multiple Instance Learning for Multiple Diverse Hyperspectral Target Characterizations.,"A practical hyperspectral target characterization task estimates a target signature from imprecisely labeled training data. The imprecisions arise from the characteristics of the real-world tasks. First, accurate pixel-level labels on training data are often unavailable. Second, the subpixel targets and occluded targets cause the training samples to contain mixed data and multiple target types. To address these imprecisions, this paper proposes a new hyperspectral target characterization method to produce diverse multiple hyperspectral target signatures under a multiple instance learning (MIL) framework. The proposed method uses only bag-level training samples and labels, which solves the problems arising from the mixed data and lack of pixel-level labels. Moreover, by formulating a multiple characterization MIL and including a diversity-promoting term, the proposed method can learn a set of diverse target signatures, which solves the problems arising from multiple target types in training samples. The experiments on hyperspectral target detections using the learned multiple target signatures over synthetic and real-world data show the effectiveness of the proposed method.",4
Attack Detection and Approximation in Nonlinear Networked Control Systems Using Neural Networks.,"In networked control systems (NCS), a certain class of attacks on the communication network is known to raise traffic flows causing delays and packet losses to increase. This paper presents a novel neural network (NN)-based attack detection and estimation scheme that captures the abnormal traffic flow due to a class of attacks on the communication links within the feedback loop of an NCS. By modeling the unknown network flow as a nonlinear function at the bottleneck node and using a NN observer, the network attack detection residual is defined and utilized to determine the onset of an attack in the communication network when the residual exceeds a predefined threshold. Upon detection, another NN is used to estimate the flow injected by the attack. For the physical system, we develop an attack detection scheme by using an adaptive dynamic programming-based optimal event-triggered NN controller in the presence of network delays and packet losses. Attacks on the network as well as on the sensors of the physical system can be detected and estimated with the proposed scheme. The simulation results confirm theoretical conclusions.",4
The Forbidden Region Self-Organizing Map Neural Network.,"Self-organizing maps (SOMs) are aimed to learn a representation of the input distribution which faithfully describes the topological relations among the clusters of the distribution. For some data sets and applications, it is known beforehand that some regions of the input space cannot contain any samples. Those are known as forbidden regions. In these cases, any prototype which lies in a forbidden region is meaningless. However, previous self-organizing models do not address this problem. In this paper, we propose a new SOM model which is guaranteed to keep all prototypes out of a set of prespecified forbidden regions. Experimental results are reported, which show that our proposal outperforms the SOM both in terms of vector quantization error and quality of the learned topological maps.",4
Scalable Digital Neuromorphic Architecture for Large-Scale Biophysically Meaningful Neural Network With Multi-Compartment Neurons.,"Multicompartment emulation is an essential step to enhance the biological realism of neuromorphic systems and to further understand the computational power of neurons. In this paper, we present a hardware efficient, scalable, and real-time computing strategy for the implementation of large-scale biologically meaningful neural networks with one million multi-compartment neurons (CMNs). The hardware platform uses four Altera Stratix III field-programmable gate arrays, and both the cellular and the network levels are considered, which provides an efficient implementation of a large-scale spiking neural network with biophysically plausible dynamics. At the cellular level, a cost-efficient multi-CMN model is presented, which can reproduce the detailed neuronal dynamics with representative neuronal morphology. A set of efficient neuromorphic techniques for single-CMN implementation are presented with all the hardware cost of memory and multiplier resources removed and with hardware performance of computational speed enhanced by 56.59% in comparison with the classical digital implementation method. At the network level, a scalable network-on-chip (NoC) architecture is proposed with a novel routing algorithm to enhance the NoC performance including throughput and computational latency, leading to higher computational efficiency and capability in comparison with state-of-the-art projects. The experimental results demonstrate that the proposed work can provide an efficient model and architecture for large-scale biologically meaningful networks, while the hardware synthesis results demonstrate low area utilization and high computational speed that supports the scalability of the approach.",4
Noise Robust Projection Rule for Hyperbolic Hopfield Neural Networks.,"A complex-valued Hopfield neural network (CHNN) is a multistate Hopfield model. Low noise tolerance is the main disadvantage of CHNNs. The hyperbolic Hopfield neural network (HHNN) is a noise robust multistate Hopfield model. In HHNNs employing the projection rule, noise tolerance rapidly worsened as the number of training patterns increased. This result was caused by the self-loops. The projection rule for CHNNs improves noise tolerance by removing the self-loops, however, that for HHNNs cannot remove them. In this brief, we extended the stability condition for the self-loops of HHNNs and modified the projection rule. Thus, the HHNNs had improved noise tolerance.",4
Self-Tuning Neural Predictive Control Scheme for Ultrabattery to Emulate a Virtual Synchronous Machine in Autonomous Power Systems.,"An adaptive neural predictive controller (ANPC) is proposed for an ultrabattery energy storage system (UBESS) to enable its operation as a virtual synchronous machine (VSM) in an autonomous wind-diesel power system. The proposed VSM emulates the inertial response and oscillation damping capability of a typical synchronous machine (employed in conventional power plants) by adaptively controlling the power electronic interface of the UBESS. The control objective is to support the network frequency while ensuring efficient/economic use of the UBESS energy. During the load-generation mismatch, ANPC continuously searches for optimal VSM parameters to minimize the actual frequency variations, their rate of change of frequency (ROCOF), and the power flow through the UBESS while maintaining the state of the charge (voltage) of the ultrabattery bank to tackle subsequent disturbances. Simulations confirm that the proposed self-tuning VSM achieves similar performance as that of other VSM control schemes while substantially reducing the power flow through the UBESS and, hence, uses significantly less energy per hertz improvement (in frequency). An index is used to evaluate the performance of the proposed scheme. In addition, the self-tuning VSM has a better dynamic response (quantified as a reduction in ROCOF and settling times) while attenuating the frequency excursions for all simulated cases.",4
Cell-Coupled Long Short-Term Memory With L-Skip Fusion Mechanism for Mood Disorder Detection Through Elicited Audiovisual Features.,"In early stages, patients with bipolar disorder are often diagnosed as having unipolar depression in mood disorder diagnosis. Because the long-term monitoring is limited by the delayed detection of mood disorder, an accurate and one-time diagnosis is desirable to avoid delay in appropriate treatment due to misdiagnosis. In this paper, an elicitation-based approach is proposed for realizing a one-time diagnosis by using responses elicited from patients by having them watch six emotion-eliciting videos. After watching each video clip, the conversations, including patient facial expressions and speech responses, between the participant and the clinician conducting the interview were recorded. Next, the hierarchical spectral clustering algorithm was employed to adapt the facial expression and speech response features by using the extended Cohn-Kanade and eNTERFACE databases. A denoizing autoencoder was further applied to extract the bottleneck features of the adapted data. Then, the facial and speech bottleneck features were input into support vector machines to obtain speech emotion profiles (EPs) and the modulation spectrum (MS) of the facial action unit sequence for each elicited response. Finally, a cell-coupled long short-term memory (LSTM) network with an L-skip fusion mechanism was proposed to model the temporal information of all elicited responses and to loosely fuse the EPs and the MS for conducting mood disorder detection. The experimental results revealed that the cell-coupled LSTM with the L-skip fusion mechanism has promising advantages and efficacy for mood disorder detection.",4
Automatic Sleep Staging Employing Convolutional Neural Networks and Cortical Connectivity Images.,"Understanding of the neuroscientific sleep mechanisms is associated with mental/cognitive and physical well-being and pathological conditions. A prerequisite for further analysis is the identification of the sleep macroarchitecture through manual sleep staging. Several computer-based approaches have been proposed to extract time and/or frequency-domain features with accuracy ranging from 80% to 95% compared with the golden standard of manual staging. However, their acceptability by the medical community is still suboptimal. Recently, utilizing deep learning methodologies increased the research interest in computer-assisted recognition of sleep stages. Aiming to enhance the arsenal of automatic sleep staging, we propose a novel classification framework based on convolutional neural networks. These receive as input synchronizations features derived from cortical interactions within various electroencephalographic rhythms (delta, theta, alpha, and beta) for specific cortical regions which are critical for the sleep deepening. These functional connectivity metrics are then processed as multidimensional images. We also propose to augment the small portion of sleep onset (N1 stage) through the Synthetic Minority Oversampling Technique in order to deal with the great difference in its duration when compared with the remaining sleep stages. Our results (99.85%) indicate the flexibility of deep learning techniques to learn sleep-related neurophysiological patterns.",4
Augmenting Recurrent Neural Networks Resilience by Dropout.,"This brief discusses the simple idea that dropout regularization can be used to efficiently induce resiliency to missing inputs at prediction time in a generic neural network. We show how the approach can be effective on tasks where imputation strategies often fail, namely, involving recurrent neural networks and scenarios where whole sequences of input observations are missing. The experimental analysis provides an assessment of the accuracy-resiliency tradeoff in multiple recurrent models, including reservoir computing methods, and comprising real-world ambient intelligence and biomedical time series.",4
Reservoir Computing Universality With Stochastic Inputs.,"The universal approximation properties with respect to L p -type criteria of three important families of reservoir computers with stochastic discrete-time semi-infinite inputs are shown. First, it is proven that linear reservoir systems with either polynomial or neural network readout maps are universal. More importantly, it is proven that the same property holds for two families with linear readouts, namely, trigonometric state-affine systems and echo state networks, which are the most widely used reservoir systems in applications. The linearity in the readouts is a key feature in supervised machine learning applications. It guarantees that these systems can be used in high-dimensional situations and in the presence of large data sets. The L p criteria used in this paper allow the formulation of universality results that do not necessarily impose almost sure uniform boundedness in the inputs or the fading memory property in the filter that needs to be approximated.",4
3-D Learning-Enhanced Adaptive ILC for Iteration-Varying Formation Tasks.,"This paper explores the formation control problem of repetitive nonlinear homogeneous and asynchronous multiagent networks, where the early starting agent is designated as the parent, and the later starting agent with a small delayed time is designated as the child. Moreover, the desired formation reference is allowed to be different from iteration to iteration. A space-dimensional dynamic linearization method is presented to build the linear dynamic relationship between two parent-child agents in a networked system. Then, a 3-D learning-enhanced adaptive iterative learning control (3D-AILC) is proposed by utilizing the additional control information from previous time instants, iterative operations, and parent agents. In other words, the proposed method processes 3-D dynamics to strengthen its learnability, i.e., time dimension, iteration dimension, and space dimension. The desired formation signal is incorporated into the learning control law to compensate its iterative variation to achieve a fast and precise tracking performance. The proposed 3D-AILC is data based and does not use an explicit mechanistic model. The validity of the proposed approach is proven theoretically and tested through simulations as well. Moreover, the proposed method also works well with time-iteration-varying topologies and nonrepetitive uncertainties.",4
Event-Triggered Optimal Control With Performance Guarantees Using Adaptive Dynamic Programming.,"This paper studies the problem of event-triggered optimal control (ETOC) for continuous-time nonlinear systems and proposes a novel event-triggering condition that enables designing ETOC methods directly based on the solution of the Hamilton-Jacobi-Bellman (HJB) equation. We provide formal performance guarantees by proving a predetermined upper bound. Moreover, we also prove the existence of a lower bound for interexecution time. For implementation purposes, an adaptive dynamic programming (ADP) method is developed to realize the ETOC using a critic neural network (NN) to approximate the value function of the HJB equation. Subsequently, we prove that semiglobal uniform ultimate boundedness can be guaranteed for states and NN weight errors with the ADP-based ETOC. Simulation results demonstrate the effectiveness of the developed ADP-based ETOC method.",4
Adaptive Neural Network Learning Controller Design for a Class of Nonlinear Systems With Time-Varying State Constraints.,"This paper studies an adaptive neural network (NN) tracking control method for a class of uncertain nonlinear strict-feedback systems with time-varying full-state constraints. As we all know, the states are inevitably constrained in the actual systems because of the safety and performance factors. The main contributions of this paper are that: 1) in order to ensure that the states do not violate the asymmetric time-varying constraint regions, an adaptive NN controller is constructed by introducing the asymmetric time-varying barrier Lyapunov function (TVBLF) and 2) the amount of the learning parameters is reduced by introducing a TVBLF at each step of the backstepping. Based on the Lyapunov stability analysis, it can be proven that all the signals in the closed-loop system are the semiglobal ultimately uniformly bounded and the time-varying full-state constraints are never violated. Finally, a numerical simulation is given, and the effectiveness of this adaptive control method can be verified.",4
GeCo: Classification Restricted Boltzmann Machine Hardware for On-Chip Semisupervised Learning and Bayesian Inference.,"The probabilistic Bayesian inference of real-time input data is becoming more popular, and the importance of semisupervised learning is growing. We present a classification restricted Boltzmann machine (ClassRBM)-based hardware accelerator with on-chip semisupervised learning and Bayesian inference capability. ClassRBM is a specific type of Markov network that can perform classification tasks and reconstruct its input data. ClassRBM has several advantages in terms of hardware implementation compared to other backpropagation-based neural networks. However, its accuracy is relatively low compared to backpropagation-based learning. To improve the accuracy of ClassRBM, we propose the multi-neuron-per-class (multi-NPC) voting scheme. We also reveal that the contrastive divergence (CD) algorithm, which is commonly used to train RBM, shows poor performance in this multi-NPC ClassRBM. As an alternative, we propose an asymmetric contrastive divergence (ACD) training algorithm that improves the accuracy of multi-NPC ClassRBM. With the ACD learning algorithm, ClassRBM operates in the form of a combination of Markov Chain training and Bayesian inference. The experimental results on a field-programmable gate array (FPGA) board for a Modified National Institute of Standards and Technology data set confirm that the inference accuracy of the proposed ACD algorithm is 5.82% higher for a supervised learning case and 12.78% higher for a 1% labeled semisupervised learning case than the conventional CD algorithm. Also, the GeCo ver.2 hardware implemented on a Xilinx ZCU102 FPGA board was 349.04 times faster than the C simulation on CPU.",4
Spatially Arranged Sparse Recurrent Neural Networks for Energy Efficient Associative Memory.,"The development of hardware neural networks, including neuromorphic hardware, has been accelerated over the past few years. However, it is challenging to operate very large-scale neural networks with low-power hardware devices, partly due to signal transmissions through a massive number of interconnections. Our aim is to deal with the issue of communication cost from an algorithmic viewpoint and study learning algorithms for energy-efficient information processing. Here, we consider two approaches to finding spatially arranged sparse recurrent neural networks with the high cost-performance ratio for associative memory. In the first approach following classical methods, we focus on sparse modular network structures inspired by biological brain networks and examine their storage capacity under an iterative learning rule. We show that incorporating long-range intermodule connections into purely modular networks can enhance the cost-performance ratio. In the second approach, we formulate for the first time an optimization problem where the network sparsity is maximized under the constraints imposed by a pattern embedding condition. We show that there is a tradeoff between the interconnection cost and the computational performance in the optimized networks. We demonstrate that the optimized networks can achieve a better cost-performance ratio compared with those considered in the first approach. We show the effectiveness of the optimization approach mainly using binary patterns and apply it also to gray-scale image restoration. Our results suggest that the presented approaches are useful in seeking more sparse and less costly connectivity of neural networks for the enhancement of energy efficiency in hardware neural networks.",4
Neuromemristive Circuits for Edge Computing: A Review.,"The volume, veracity, variability, and velocity of data produced from the ever increasing network of sensors connected to Internet pose challenges for power management, scalability, and sustainability of cloud computing infrastructure. Increasing the data processing capability of edge computing devices at lower power requirements can reduce several overheads for cloud computing solutions. This paper provides the review of neuromorphic CMOS-memristive architectures that can be integrated into edge computing devices. We discuss why the neuromorphic architectures are useful for edge devices and show the advantages, drawbacks, and open problems in the field of neuromemristive circuits for edge computing.",4
On the Dynamics of Classification Measures for Imbalanced and Streaming Data.,"As each imbalanced classification problem comes with its own set of challenges, the measure used to evaluate classifiers must be individually selected. To help researchers make this decision in an informed manner, experimental and theoretical investigations compare general properties of measures. However, existing studies do not analyze changes in measure behavior imposed by different imbalance ratios. Moreover, several characteristics of imbalanced data streams, such as the effect of dynamically changing class proportions, have not been thoroughly investigated from the perspective of different metrics. In this paper, we study measure dynamics by analyzing changes of measure values, distributions, and gradients with diverging class proportions. For this purpose, we visualize measure probability mass functions and gradients. In addition, we put forward a histogram-based normalization method that provides a unified, probabilistic interpretation of any measure over data sets with different class distributions. The results of analyzing eight popular classification measures show that the effect class proportions have on each measure is different and should be taken into account when evaluating classifiers. Apart from highlighting imbalance-related properties of each measure, our study shows a direct connection between class ratio changes and certain types of concept drift, which could be influential in designing new types of classifiers and drift detectors for imbalanced data streams.",4
Beyond Majority Voting: A Coarse-to-Fine Label Filtration for Heavily Noisy Labels.,"Crowdsourcing has become the most appealing way to provide a plethora of labels at a low cost. Nevertheless, labels from amateur workers are often noisy, which inevitably degenerates the robustness of subsequent learning models. To improve the label quality for subsequent use, majority voting (MV) is widely leveraged to aggregate crowdsourced labels due to its simplicity and scalability. However, when crowdsourced labels are ``heavily'' noisy (e.g., 40% of noisy labels), MV may not work well because of the fact ``garbage (heavily noisy labels) in, garbage (full aggregated labels) out.'' This issue inspires us to think: if the ultimate target is to learn a robust model using noisy labels, why not provide partial aggregated labels and ensure that these labels are reliable enough for learning models? To solve this challenge by improving MV, we propose a coarse-to-fine label filtration model called double filter machine (DFM), which consists of a (majority) voting filter and a sparse filter serially. Specifically, the DFM refines crowdsourced labels from coarse filtering to fine filtering. In the stage of coarse filtering, the DFM aggregates crowdsourced labels by voting filter, which yields (quality-acceptable) full aggregated labels. In the stage of fine filtering, DFM further digs out a set of high-quality labels from full aggregated labels by sparse filter, since this filter can identify high-quality labels by the methodology of support selection. Based on the insight of compressed sensing, DFM recovers a ground-truth signal from heavily noisy data under a restricted isometry property. To sum up, the primary benefits of DFM are to keep the scalability by voting filter, while improve the robustness by sparse filter. We also derive theoretical guarantees for the convergence and recovery of DFM and reveal its complexity. We conduct comprehensive experiments on both the UCI simulated and the AMT crowdsourced datasets. Empirical results show that partial aggregated labels provided by DFM effectively improve the robustness of learning models.",4
Effects of Subsystem and Coupling on Synchronization of Multiple Neural Networks With Delays via Impulsive Coupling.,"This paper from new perspectives discusses the global synchronization of multiple recurrent neural networks (MNNs) with time delays via impulsive coupling. A new concept (coupling strength) is introduced, it is a variable parameter and plays a key role on synchronization. The selection of coupling strength can bring more convenience to the design of the impulsive coupling controller. Four results are presented for the synchronization of MNNs with time delays by using impulsive coupling with the coupling gain and variable topology, where two results are dependent on topology and other two results are independent on topological connectivity. In our results, the effects of each NN, coupling topology, and coupling strength can be positive or negative role on synchronization. In addition, three examples are presented to test our results in the theory analysis.",4
Approximation of Ensemble Boundary Using Spectral Coefficients.,"A spectral analysis of a Boolean function is proposed for approximating the decision boundary of an ensemble of classifiers, and an intuitive explanation of computing Walsh coefficients for the functional approximation is provided. It is shown that the difference between the first- and third-order coefficient approximations is a good indicator of optimal base classifier complexity. When combining neural networks, the experimental results on a variety of artificial and real two-class problems demonstrate under what circumstances ensemble performance can be improved. For tuned base classifiers, the first-order coefficients provide performance similar to the majority vote. However, for weak/fast base classifiers, higher order coefficient approximation may give better performance. It is also shown that higher order coefficient approximation is superior to the Adaboost logarithmic weighting rule when boosting weak decision tree base classifiers.",4
Nonlinear Dimensionality Reduction With Missing Data Using Parametric Multiple Imputations.,"Dimensionality reduction (DR) aims at faithfully and meaningfully representing high-dimensional (HD) data into a low-dimensional (LD) space. Recently developed neighbor embedding DR methods lead to outstanding performances, thanks to their ability to foil the curse of dimensionality. Unfortunately, they cannot be directly employed on incomplete data sets, which become ubiquitous in machine learning. Discarding samples with missing features prevents their LD coordinates computation and deteriorates the complete samples treatment. Common missing data imputation schemes are not appropriate in the nonlinear DR context either. Indeed, even if they model the data distribution in the feature space, they can, at best, enable the application of a DR scheme on the expected data set. In practice, one would, instead, like to obtain the LD embedding with the closest cost function value on average with respect to the complete data case. As the state-of-the-art DR techniques are nonlinear, the latter embedding results from minimizing the expected cost function on the incomplete database, not from considering the expected data set. This paper addresses these limitations by developing a general methodology for nonlinear DR with missing data, being directly applicable with any DR scheme optimizing some criterion. In order to model the feature dependences, an HD extension of Gaussian mixture models is first fitted on the incomplete data set. It is afterward employed under the multiple imputation paradigms to obtain a single relevant LD embedding, thus minimizing the cost function expectation. Extensive experiments demonstrate the superiority of the suggested framework over alternative approaches.",4
Fast Inference Predictive Coding: A Novel Model for Constructing Deep Neural Networks.,"As a biomimetic model of visual information processing, predictive coding (PC) has become increasingly popular for explaining a range of neural responses and many aspects of brain organization. While the development of PC model is encouraging in the neurobiology community, its practical applications in machine learning (e.g., image classification) have not been fully explored yet. In this paper, a novel image processing model called fast inference PC (FIPC) is presented for image representation and classification. Compared with the basic PC model, a regression procedure and a classification layer have been added to the proposed FIPC model. The regression procedure is used to learn regression mappings that achieve fast inference at test time, while the classification layer can instruct the model to extract more discriminative features. In addition, effective learning and fine-tuning algorithms are developed for the proposed model. Experimental results obtained on four image benchmark data sets show that our model is able to directly and fast infer representations and, simultaneously, produce lower error rates on image classification tasks.",4
Feature Aggregation With Reinforcement Learning for Video-Based Person Re-Identification.,"Video-based person re-identification (re-id) matches two tracks of persons from different cameras. Features are extracted from the images of a sequence and then aggregated as a track feature. Compared to existing works that aggregate frame features by simply averaging them or using temporal models such as recurrent neural networks, we propose an intelligent feature aggregate method based on reinforcement learning. Specifically, we train an agent to determine which frames in the sequence should be abandoned in the aggregation, which can be treated as a decision making process. By this way, the proposed method avoids introducing noisy information of the sequence and retains these valuable frames when generating a track feature. On benchmark data sets, experimental results show that our method can boost the re-id accuracy obviously based on the state-of-the-art models.",4
Comments and Corrections Comments on ``Fractional Extreme Value Adaptive Training Method: Fractional Steepest Descent Approach''.,"In this comment, we raise serious concerns over the derivation of the rate of convergence of fractional steepest descent algorithm in fractional adaptive learning approach presented in ``Fractional Extreme Value Adaptive Training Method: Fractional Steepest Descent Approach.'' We substantiate that the estimate of the rate of convergence is grandiloquent. We also draw attention toward a critical flaw in the design of the algorithm stymieing its applicability for broad adaptive learning problems. Our claims are based on analytical reasoning supported by experimental results.",4
Learning Accurate and Stable Dynamical System Under Manifold Immersion and Submersion.,"Learning from demonstration (LfD) has been increasingly used to encode robot tasks such that robots can achieve reproduction more flexibly in unstructured environments (e.g., households or factories). It is an effective alternative to preprogramming methods owing to its capacity of enabling robots to generalize to different situations. In this paper, we focus on LfD in the point-to-point movement case, where the dilemma of stability and accuracy exists. To avoid such a dilemma, we propose a learning approach that guarantees accuracy and stability simultaneously by means of constructed manifold immersion and submersion. We evaluate the proposed approach on two libraries of human handwriting motions (the LASA data set and a self-made GREEK data set) and on a set of experiments on the Barrett WAM robot.",4
Person Reidentification by Joint Local Distance Metric and Feature Transformation.,"Person reidentification is of great importance in visual surveillance and multiperson tracking across multiple camera views. Two fundamental problems are critical for person reidentification: 1) how to account for appearance variation or feature transformation caused by viewpoint changes and 2) how to learn a discriminative distance metric for reidentification. In this paper, we propose an algorithm in which both feature transformation and metric learning are exploited and jointly optimized. We learn local models from subsets of training samples with regularization imposed by the global model which is trained among the entire data set. The learned local models enhance the discriminative strength and generalization ability. Experimental results on the Viewpoint Invariant PEdestrian Eecognition, Queen Mary University of London ground reidentification, CUHK01, and CUHK03 benchmark data sets show that the proposed sample-specific view-invariant approach performs favorably against the state-of-the-art person reidentification methods.",4
Partial Diffusion Kalman Filtering for Distributed State Estimation in Multiagent Networks.,"Many problems in multiagent networks can be solved through distributed learning (state estimation) of linear dynamical systems. In this paper, we develop a partial-diffusion Kalman filtering (PDKF) algorithm, as a fully distributed solution for state estimation in the multiagent networks with limited communication resources. In the PDKF algorithm, every agent (node) is allowed to share only a subset of its intermediate estimate vectors with its neighbors at each iteration, reducing the amount of internode communications. We analyze the stability of the PDKF algorithm and show that the algorithm is stable and convergent in both mean and mean-square senses. We also derive a closed-form expression for the steady-state mean-square deviation criterion. Furthermore, we show theoretically and by numerical examples that the PDKF algorithm provides a trade-off between the estimation performance and the communication cost that is extremely profitable.",4
O(2)-Valued Hopfield Neural Networks.,"In complex-valued Hopfield neural networks (CHNNs), the neuron states are complex numbers whose amplitudes are: 1) they can also be described in special orthogonal matrices of order and 2) here, we propose a new Hopfield model, the O(2)-valued Hopfield neural network [O(2)-HNN], whose neuron states are extended to orthogonal matrices. Its neuron states are embedded in 4-D space, while those of CHNNs are embedded in 2-D space. Computer simulations were conducted to compare the noise tolerance (NT) and storage capacity (SC) of CHNNs, O(2)-HNNs, and rotor Hopfield neural networks. In terms of SC, O(2)-HNNs outperformed the others, while in NT, they outdid CHNNs.",4
Parallel Coordinate Descent Newton Method for Efficient $L_1$-Regularized Loss Minimization.,"The recent years have witnessed advances in parallel algorithms for large-scale optimization problems. Notwithstanding the demonstrated success, existing algorithms that parallelize over features are usually limited by divergence issues under high parallelism or require data preprocessing to alleviate these problems. In this paper, we propose a Parallel Coordinate Descent algorithm using approximate Newton steps (PCDN) that is guaranteed to converge globally without data preprocessing. The key component of the PCDN algorithm is the high-dimensional line search, which guarantees the global convergence with high parallelism. The PCDN algorithm randomly partitions the feature set into b subsets/bundles of size P, and sequentially processes each bundle by first computing the descent directions for each feature in parallel and then conducting P-dimensional line search to compute the step size. We show that: 1) the PCDN algorithm is guaranteed to converge globally despite increasing parallelism and 2) the PCDN algorithm converges to the specified accuracy epsilon within the limited iteration number of Tepsilon, and Tepsilon decreases with increasing parallelism. In addition, the data transfer and synchronization cost of the P-dimensional line search can be minimized by maintaining intermediate quantities. For concreteness, the proposed PCDN algorithm is applied to L(1)-regularized logistic regression and L(1)-regularized L(2)-loss support vector machine problems. Experimental evaluations on seven benchmark data sets show that the PCDN algorithm exploits parallelism well and outperforms the state-of-the-art methods.",4
Iterative Privileged Learning.,"While in the learning using privileged information paradigm, privileged information may not be as informative as example features in the context of making accurate label predictions, it may be able to provide some effective comments (e.g., the values of the auxiliary function) like a human teacher on the efficacy of the learned model. In a departure from conventional static manipulations of privileged information within the support vector machine framework, this paper investigates iterative privileged learning within the context of gradient boosted decision trees (GBDTs). As the learned model evolves, the comments learned from privileged information to assess the model should also be actively upgraded instead of remaining static and passive. During the learning phase of the GBDT method, new DTs are discovered to enhance the performance of the model, and iteratively update the comments generated from the privileged information to accurately assess and coach the up-to-date model. The resulting objective function can be efficiently solved within the gradient boosting framework. Experimental results on real-world data sets demonstrate the benefits of studying privileged information in an iterative manner, as well as the effectiveness of the proposed algorithm.",4
Admittance-Based Adaptive Cooperative Control for Multiple Manipulators With Output Constraints.,"This paper proposes a novel adaptive control methodology based on the admittance model for multiple manipulators transporting a rigid object cooperatively along a predefined desired trajectory. First, an admittance model is creatively applied to generate reference trajectory online for each manipulator according to the desired path of the rigid object, which is the reference input of the controller. Then, an innovative integral barrier Lyapunov function is utilized to tackle the constraints due to the physical and environmental limits. Adaptive neural networks (NNs) are also employed to approximate the uncertainties of the manipulator dynamics. Different from the conventional NN approximation method, which is usually semiglobally uniformly ultimately bounded, a switching function is presented to guarantee the global stability of the closed loop. Finally, the simulation studies are conducted on planar two-link robot manipulators to validate the efficacy of the proposed approach.",4
Data-Driven Robust Control of Discrete-Time Uncertain Linear Systems via Off-Policy Reinforcement Learning.,"This paper presents a model-free solution to the robust stabilization problem of discrete-time linear dynamical systems with bounded and mismatched uncertainty. An optimal controller design method is derived to solve the robust control problem, which results in solving an algebraic Riccati equation (ARE). It is shown that the optimal controller obtained by solving the ARE can robustly stabilize the uncertain system. To develop a model-free solution to the translated ARE, off-policy reinforcement learning (RL) is employed to solve the problem in hand without the requirement of system dynamics. In addition, the comparisons between on- and off-policy RL methods are presented regarding the robustness to probing noise and the dependence on system dynamics. Finally, a simulation example is carried out to validate the efficacy of the presented off-policy RL approach.",4
New Results on Stability Analysis for Delayed Markovian Generalized Neural Networks With Partly Unknown Transition Rates.,"The stability of delayed Markovian generalized neural networks is studied where the transition rates of the modes are partly unknown. The partly unknown transition rates generalize the traditional works that are with all known transition rates. Then, a Lyapunov-Krasovskii functional (LKF) with a delay-product-type (DPT) term is constructed. The DPT term is not only simple but also fully utilizes the information of time delay. Based on the new DPT LKF, stability criteria are presented, which are with lower computational complexity and less conservative. In the end, the validity and superiorities of the analytical results are verified by several examples.",4
Exponential Synchronization and L(2)-Gain Analysis of Delayed Chaotic Neural Networks Via Intermittent Control With Actuator Saturation.,"By using an intermittent control approach, this paper is concerned with the exponential synchronization and L(2)-gain analysis for a class of delayed master-slave chaotic neural networks subject to actuator saturation. Based on a switching strategy, the synchronization error system is modeled as a switched synchronization error system consisting of two subsystems, and each subsystem of the switched system satisfies a dwell time constraint due to the characteristics of intermittent control. A piecewise Lyapunov-Krasovskii functional depending on the control rate and control period is then introduced, under which sufficient conditions for the exponential stability of the constructed switched synchronization error system are developed. In addition, the influence of the exogenous perturbations on synchronization performance is constrained at a prescribed level. In the meantime, the intermittent linear state feedback controller can be derived by solving a set of linear matrix inequalities. More incisively, the proposed method is also proved to be valid in the case of aperiodically intermittent control. Finally, two simulation examples are employed to demonstrate the effectiveness and potential of the obtained results.",4
Supervised Discriminative Sparse PCA for Com-Characteristic Gene Selection and Tumor Classification on Multiview Biological Data.,"Principal component analysis (PCA) has been used to study the pathogenesis of diseases. To enhance the interpretability of classical PCA, various improved PCA methods have been proposed to date. Among these, a typical method is the so-called sparse PCA, which focuses on seeking sparse loadings. However, the performance of these methods is still far from satisfactory due to their limitation of using unsupervised learning methods; moreover, the class ambiguity within the sample is high. To overcome this problem, this paper developed a new PCA method, which is named the supervised discriminative sparse PCA (SDSPCA). The main innovation of this method is the incorporation of discriminative information and sparsity into the PCA model. Specifically, in contrast to the traditional sparse PCA, which imposes sparsity on the loadings, here, sparse components are obtained to represent the data. Furthermore, via the linear transformation, the sparse components approximate the given label information. On the one hand, sparse components improve interpretability over the traditional PCA, while on the other hand, they are have discriminative abilities suitable for classification purposes. A simple algorithm is developed, and its convergence proof is provided. SDSPCA has been applied to the common-characteristic gene selection and tumor classification on multiview biological data. The sparsity and classification performance of SDSPCA are empirically verified via abundant, reasonable, and effective experiments, and the obtained results demonstrate that SDSPCA outperforms other state-of-the-art methods.",4
Evaluate the Malignancy of Pulmonary Nodules Using the 3-D Deep Leaky Noisy-or Network.,"Automatic diagnosing lung cancer from computed tomography scans involves two steps: detect all suspicious lesions (pulmonary nodules) and evaluate the whole-lung/pulmonary malignancy. Currently, there are many studies about the first step, but few about the second step. Since the existence of nodule does not definitely indicate cancer, and the morphology of nodule has a complicated relationship with cancer, the diagnosis of lung cancer demands careful investigations on every suspicious nodule and integration of information of all nodules. We propose a 3-D deep neural network to solve this problem. The model consists of two modules. The first one is a 3-D region proposal network for nodule detection, which outputs all suspicious nodules for a subject. The second one selects the top five nodules based on the detection confidence, evaluates their cancer probabilities, and combines them with a leaky noisy-or gate to obtain the probability of lung cancer for the subject. The two modules share the same backbone network, a modified U-net. The overfitting caused by the shortage of the training data is alleviated by training the two modules alternately. The proposed model won the first place in the Data Science Bowl 2017 competition.",4
Cluster Synchronization for Neutral Stochastic Delay Networks via Intermittent Adaptive Control.,"This paper studies the problem of cluster synchronization at exponential rates in both the mean square and almost sure senses for neutral stochastic coupled neural networks with time-varying delay via a periodically intermittent pinning adaptive control strategy. The network topology can be symmetric or asymmetric, with each network node being described by neutral stochastic delayed neural networks. When considering the exponential stabilization in the mean square sense for neutral stochastic delay system, the delay integral inequality approach is used to circumvent the obstacle arising from the coexistence of random disturbance, neutral item, and time-varying delay. The almost surely exponential stabilization is also analyzed with the nonnegative semimartingale convergence theorem. Sufficient criteria on cluster synchronization at exponential rates in both the mean square and almost sure senses of the underlying networks under the designed control scheme are derived. The effectiveness of the obtained theoretical results is illustrated by two examples.",4
Adaptive Discrete-Time Flight Control Using Disturbance Observer and Neural Networks.,"This paper studies the adaptive neural control (ANC)-based tracking problem for discrete-time nonlinear dynamics of an unmanned aerial vehicle subject to system uncertainties, bounded time-varying disturbances, and input saturation by using a discrete-time disturbance observer (DTDO). Based on the approximation approach of neural network, system uncertainties are tackled approximately. To restrain the negative effects of bounded disturbances, a nonlinear DTDO is designed. Then, a backstepping technique-based ANC strategy is proposed by utilizing a constructed auxiliary system and a discrete-time tracking differentiator. The boundness of all signals is proven in the closed-loop system under the discrete-time Lyapunov analysis. Finally, the feasibility of the proposed ANC technique is further specified based on numerical simulation results.",4
Memristive Imitation of Synaptic Transmission and Plasticity.,"In this paper, a memristive artificial neural circuit imitating the excitatory chemical synaptic transmission of biological synapse is designed. The proposed memristor-based neural circuit exhibits synaptic plasticity, one of the important neurochemical foundations for learning and memory, which is demonstrated via the efficient imitation of short-term facilitation and long-term potentiation. Moreover, the memristive artificial circuit also mimics the distinct biological attributes of strong stimulation and deficient synthesis of neurotransmitters. The proposed artificial neural model is designed in SPICE, and the biological functionalities are demonstrated via various simulations. The simulation results obtained with the proposed artificial synapse are similar to the biological features of chemical synaptic transmission and synaptic plasticity.",4
A Novel Dual Successive Projection-Based Model-Free Adaptive Control Method and Application to an Autonomous Car.,"In this paper, a novel model-free adaptive control (MFAC) algorithm based on a dual successive projection (DuSP)-MFAC method is proposed, and it is analyzed using the introduced DuSP method and the symmetrically similar structures of the controller and its parameter estimator of MFAC. Then, the proposed DuSP-MFAC scheme is successfully implemented in an autonomous car ``Ruilong'' for the lateral tracking control problem via converting the trajectory tracking problem into a stabilization problem by using the proposed preview-deviation-yaw angle. This MFAC-based lateral tracking control method was tested and demonstrated satisfactory performance on real roads in Fengtai, Beijing, China, and through successful participation in the Chinese Smart Car Future Challenge Competition held in 2015 and 2016.",4
Semisupervised Discriminant Multimanifold Analysis for Action Recognition.,"Although recent semisupervised approaches have proven their effectiveness when there are limited training data, they assume that the samples from different actions lie on a single data manifold in the feature space and try to uncover a common subspace for all samples. However, this assumption ignores the intraclass compactness and the interclass separability simultaneously. We believe that human actions should occupy multimanifold subspace and, therefore, model the samples of the same action as the same manifold and those of different actions as different manifolds. In order to obtain the optimum subspace projection matrix, the current approaches may be mathematically imprecise owe to the badly scaled matrix and improper convergence. To address these issues in unconstrained convex optimization, we introduce a nontrivial spectral projected gradient method and Karush-Kuhn-Tucker conditions without matrix inversion. Through maximizing the separability between different classes by using labeled data points and estimating the intrinsic geometric structure of the data distributions by exploring unlabeled data points, the proposed algorithm can learn global and local consistency and boost the recognition performance. Extensive experiments conducted on the realistic video data sets, including JHMDB, HMDB51, UCF50, and UCF101, have demonstrated that our algorithm outperforms the compared algorithms, including deep learning approach when there are only a few labeled samples.",4
Large-Margin Label-Calibrated Support Vector Machines for Positive and Unlabeled Learning.,"Positive and unlabeled learning (PU learning) aims to train a binary classifier based on only PU data. Existing methods usually cast PU learning as a label noise learning problem or a cost-sensitive learning problem. However, none of them fully take the data distribution information into consideration when designing the model, which hinders them from acquiring more encouraging performance. In this paper, we argue that the clusters formed by positive examples and potential negative examples in the feature space should be critically utilized to establish the PU learning model, especially when the negative data are not explicitly available. To this end, we introduce a hat loss to discover the margin between data clusters, a label calibration regularizer to amend the biased decision boundary to the potentially correct one, and propose a novel discriminative PU classifier termed `` Large-margin Label-calibrated Support Vector Machines'' (LLSVM). Our LLSVM classifier can work properly in the absence of negative training examples and effectively achieve the max-margin effect between positive and negative classes. Theoretically, we derived the generalization error bound of LLSVM which reveals that the introduction of PU data does help to enhance the algorithm performance. Empirically, we compared LLSVM with state-of-the-art PU methods on various synthetic and practical data sets, and the results confirm that the proposed LLSVM is more effective than other compared methods on dealing with PU learning tasks.",4
A Greedy Assist-as-Needed Controller for Upper Limb Rehabilitation.,"Previous studies on robotic rehabilitation have shown that subjects' active participation and effort involved in rehabilitation training can promote the performance of therapies. In order to improve the voluntary effort of participants during the rehabilitation training, assist-as-needed (AAN) control strategies regulating the robotic assistance according to subjects' performance and conditions have been developed. Unfortunately, the heterogeneity of patients' motor function capability in task space is not taken into account during the implementation of these controllers. In this paper, a new scheme called greedy AAN (GAAN) controller is designed for the upper limb rehabilitation training of neurologically impaired subjects. The proposed GAAN control paradigm includes a baseline controller and a Gaussian RBF network that is utilized to model the functional capability of subjects and to provide corresponding a task challenge for them. In order to avoid subjects' slacking and encourage their active engagement, the weight vectors of RBF networks evaluating subjects' impairment level are updated based on a greedy strategy that makes the networks progressively learn the maximum forces over time provided by subjects. Simultaneously, a challenge level modification algorithm is employed to adjust the task challenge according to the task performance of subjects. Experiments on 12 subjects with neurological impairment are conducted to validate the performance and feasibility of the GAAN controller. The results show that the proposed GAAN controller has significant potential to promote the subjects' voluntary engagement during training exercises.",4
Objective Video Quality Assessment Combining Transfer Learning With CNN.,"Nowadays, video quality assessment (VQA) is essential to video compression technology applied to video transmission and storage. However, small-scale video quality databases with imbalanced samples and low-level feature representations for distorted videos impede the development of VQA methods. In this paper, we propose a full-reference (FR) VQA metric integrating transfer learning with a convolutional neural network (CNN). First, we imitate the feature-based transfer learning framework to transfer the distorted images as the related domain, which enriches the distorted samples. Second, to extract high-level spatiotemporal features of the distorted videos, a six-layer CNN with the acknowledged learning ability is pretrained and finetuned by the common features of the distorted image blocks (IBs) and video blocks (VBs), respectively. Notably, the labels of the distorted IBs and VBs are predicted by the classic FR metrics. Finally, based on saliency maps and the entropy function, we conduct a pooling stage to obtain the quality scores of the distorted videos by weighting the block-level scores predicted by the trained CNN. In particular, we introduce a preprocessing and a postprocessing to reduce the impact of inaccurate labels predicted by the FR-VQA metric. Due to feature learning in the proposed framework, two kinds of experimental schemes including train-test iterative procedures on one database and tests on one database with training other databases are carried out. The experimental results demonstrate that the proposed method has high expansibility and is on a par with some state-of-the-art VQA metrics on two widely used VQA databases with various compression distortions.",4
Short Sequence Classification Through Discriminable Linear Dynamical System.,"Linear dynamical system (LDS) offers a convenient way to reveal the unobservable structure behind the data. This makes it useful for data representation and explanatory analysis. An immediate limitation with this model is that most training algorithms train a model to best approximate a sequential instance. They do not consider its class or label which indicates the dissimilarity/similarity to other instances. As a result, LDS's trained in this way are inclined to be indistinguishable over classes, resulting in a poor performance in the model-based classification. In this paper, after revisiting this limitation, we propose to promote the diversity between the two models of different classes. The diversity, measured by determinantal point process (DPP) on LDS's, is utilized to remedy the greedy behavior of the electromagnetic algorithm. The training goal is a model that balances the goodness of fit and being distinguishable over classes. Experiments on synthetic data confirm its effectiveness in generating discriminative systems under supervisory information. The classification on short time-span data sets confirms that the models generated by our approach could generalize well to unseen data.",4
Computing Time-Varying Quadratic Optimization With Finite-Time Convergence and Noise Tolerance: A Unified Framework for Zeroing Neural Network.,"Zeroing neural network (ZNN), as a powerful calculating tool, is extensively applied in various computation and optimization fields. Convergence and noise-tolerance performance are always pursued and investigated in the ZNN field. Up to now, there are no unified ZNN models that simultaneously achieve the finite-time convergence and inherent noise tolerance for computing time-varying quadratic optimization problems, although this superior property is highly demanded in practical applications. In this paper, for computing time-varying quadratic optimization within finite-time convergence in the presence of various additive noises, a new framework for ZNN is designed to fill this gap in a unified manner. Specifically, different from the previous design formulas either possessing finite-time convergence or possessing noise-tolerance performance, a new design formula with finite-time convergence and noise tolerance is proposed in a unified framework (and thus called unified design formula). Then, on the basis of the unified design formula, a unified ZNN (UZNN) is, thus, proposed and investigated in the unified framework of ZNN for computing time-varying quadratic optimization problems in the presence of various additive noises. In addition, theoretical analyses of the unified design formula and the UZNN model are given to guarantee the finite-time convergence and inherent noise tolerance. Computer simulation results verify the superior property of the UZNN model for computing time-varying quadratic optimization problems, as compared with the previously proposed ZNN models.",4
3-D PersonVLAD: Learning Deep Global Representations for Video-Based Person Reidentification.,"We present the global deep video representation learning to video-based person reidentification (re-ID) that aggregates local 3-D features across the entire video extent. Existing methods typically extract frame-wise deep features from 2-D convolutional networks (ConvNets) which are pooled temporally to produce the video-level representations. However, 2-D ConvNets lose temporal priors immediately after the convolutions, and a separate temporal pooling is limited in capturing human motion in short sequences. In this paper, we present global video representation learning, to be complementary to 3-D ConvNets as a novel layer to capture the appearance and motion dynamics in full-length videos. Nevertheless, encoding each video frame in its entirety and computing aggregate global representations across all frames is tremendously challenging due to the occlusions and misalignments. To resolve this, our proposed network is further augmented with the 3-D part alignment to learn local features through the soft-attention module. These attended features are statistically aggregated to yield identity-discriminative representations. Our global 3-D features are demonstrated to achieve the state-of-the-art results on three benchmark data sets: MARS, Imagery Library for Intelligent Detection Systems-Video Re-identification, and PRID2011.",4
Balanced Decoupled Spatial Convolution for CNNs.,"In this paper, we are interested in designing lightweight CNNs by decoupling the convolution along the spatial and channel dimension. Most existing decoupling techniques focus on approximating the filter matrix through decomposition. In contrast, we provide a decoupled view of the standard convolution to separate the spatial information and the channel information. The resulting decoupled process is exactly equivalent to the standard convolution. Inspired from our decoupled view, we propose an effective structure, balanced decoupled spatial convolution (BDSC), to relax the sparsity of the filter in spatial aggregation by learning a spatial configuration and reduce the redundancy by reducing the number of intermediate channels. We also designed an adaptive spatial configuration, which is simply adding a nonlinear activation layer [rectified linear units (ReLU)] after the intermediate output. Our experiments verify that the adaptive spatial configuration can improve the classification performance without extra cost. In addition, our BDSC achieves comparable classification performance with the standard convolution but with a smaller model size on Canadian Institute for Advanced Research (CIFAR)-100, CIFAR-10, and ImageNet. To show the potential of further reducing the redundancy of across channel-domain convolution, we also show experiments of our models with a designed lightweight across channel-domain convolution. Finally, we show in our experiments that our models achieve superior performance than the state-of-the-art models.",4
Feature Control as Intrinsic Motivation for Hierarchical Reinforcement Learning.,"One of the main concerns of deep reinforcement learning (DRL) is the data inefficiency problem, which stems both from an inability to fully utilize data acquired and from naive exploration strategies. In order to alleviate these problems, we propose a DRL algorithm that aims to improve data efficiency via both the utilization of unrewarded experiences and the exploration strategy by combining ideas from unsupervised auxiliary tasks, intrinsic motivation, and hierarchical reinforcement learning (HRL). Our method is based on a simple HRL architecture with a metacontroller and a subcontroller. The subcontroller is intrinsically motivated by the metacontroller to learn to control aspects of the environment, with the intention of giving the agent: 1) a neural representation that is generically useful for tasks that involve manipulation of the environment and 2) the ability to explore the environment in a temporally extended manner through the control of the metacontroller. In this way, we reinterpret the notion of pixel- and feature-control auxiliary tasks as reusable skills that can be learned via an intrinsic reward. We evaluate our method on a number of Atari 2600 games. We found that it outperforms the baseline in several environments and significantly improves performance in one of the hardest games--Montezuma's revenge--for which the ability to utilize sparse data is key. We found that the inclusion of intrinsic reward is crucial for the improvement in the performance and that most of the benefit seems to be derived from the representations learned during training.",4
Multistep Prediction of Dynamic Systems With Recurrent Neural Networks.,"In this paper, we address the state initialization problem in recurrent neural networks (RNNs), which seeks proper values for the RNN initial states at the beginning of a prediction interval. The proposed methods employ various forms of neural networks (NNs) to generate proper initial state values for RNNs. A variety of RNNs are trained using the proposed NN initialization schemes for modeling two aerial vehicles, a helicopter and a quadrotor, from experimental data. It is shown that the RNN initialized by the NN-based initialization method outperforms the washout method which is commonly used to initialize RNNs. Furthermore, a comprehensive study of RNNs trained for multistep prediction of the two aerial vehicles is presented. The multistep prediction of the quadrotor is enhanced using a hybrid model, which combines a simplified physics-based motion model of the vehicle with RNNs. While the maximum translational and rotational velocities in the Quadrotor data set are about 4 m/s and 3.8 rad/s, respectively, the hybrid model produces predictions, over 1.9 s, which remain within 9 cm/s and 0.12 rad/s of the measured translational and rotational velocities, with 99% confidence on the test data set.",4
Utilizing Unlabeled Data to Detect Electricity Fraud in AMI: A Semisupervised Deep Learning Approach.,"As nontechnical losses in power systems have recently become a global concern, electricity fraud detection models attracted increasing academic interest. The wide application of smart meters has offered more possibility to detecting fraud from user's consumption patterns. However, the performances of existing consumption-based electricity fraud detection models are still not satisfactory enough for practice, partly due to their limited ability to handle high-dimensional data. In this paper, a deep-learning-based model is developed for detecting electricity fraud in the advanced metering infrastructure, namely, the multitask feature extracting fraud detector (MFEFD). The deep architecture has brought MFEFD a powerful ability to handle high-dimensional input, through which consumption patterns inside load profiles can be effectively extracted. Another challenge is that the insufficiency of labeled data has restricted the generalization of existing models since they are mostly based on supervised learning and labeled data. MFEFD is trained in a semisupervised manner, in which multitask training was implemented to combine the supervised and unsupervised training, so that both the knowledge from unlabeled and labeled data can be made use of. Real-world-data-based case studies have demonstrated MFEFD's high detection performance, robustness, privacy preservation, and practicability.",4
A Stochastic Sampling Mechanism for Time-Varying Formation of Multiagent Systems With Multiple Leaders and Communication Delays.,"The time-varying formation problem for multiagent systems (MASs) with stochastic sampling and multiple leaders is studied in this paper, in which communication delays are taken into account. All the agents are divided into the set of the follower group and the set of the leader group. Under the proposed stochastic sampling mechanism for time-varying formation of the MASs with communication delays, the followers are driven to achieve time-varying formation where the center of the formation is the convex combination of the states of the leaders. In the theoretical analysis, sufficient conditions for the MASs achieving time-varying formation in mean square under stochastic sampling with multiple leaders and communication delays are derived. Moreover, some corollaries are also given in this paper. Finally, the theoretical analysis is verified by a given simulation example.",4
An Accelerated Linearly Convergent Stochastic L-BFGS Algorithm.,"The limited memory version of the Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) algorithm is the most popular quasi-Newton algorithm in machine learning and optimization. Recently, it was shown that the stochastic L-BFGS (sL-BFGS) algorithm with the variance-reduced stochastic gradient converges linearly. In this paper, we propose a new sL-BFGS algorithm by importing a proper momentum. We prove an accelerated linear convergence rate under mild conditions. The experimental results on different data sets also verify this acceleration advantage.",4
Features Combined From Hundreds of Midlayers: Hierarchical Networks With Subnetwork Nodes.,"In this paper, we believe that the mixed selectivity of neuron in the top layer encodes distributed information produced from other neurons to offer a significant computational advantage over recognition accuracy. Thus, this paper proposes a hierarchical network framework that the learning behaviors of features combined from hundreds of midlayers. First, a subnetwork neuron, which itself could be constructed by other nodes, is functional as a subspace features extractor. The top layer of a hierarchical network needs subspace features produced by the subnetwork neurons to get rid of factors that are not relevant, but at the same time, to recast the subspace features into a mapping space so that the hierarchical network can be processed to generate more reliable cognition. Second, this paper shows that with noniterative learning strategy, the proposed method has a wider and shallower structure, providing a significant role in generalization performance improvements. Hence, compared with other state-of-the-art methods, multiple channel features with the proposed method could provide a comparable or even better performance, which dramatically boosts the learning speed. Our experimental results show that our platform can provide a much better generalization performance than 55 other state-of-the-art methods.",4
Neural Adaptive Event-Triggered Control for Nonlinear Uncertain Stochastic Systems With Unknown Hysteresis.,"In this paper, the uncertain direct of the hysteretic system component will be considered. Besides, the effect of stochastic disturbance inevitably exists in many practical systems, which would cause the instability. Simultaneously, it is significant to guarantee the perfect error tracking performance for the uncertain nonlinear hysteresis systems when operation suffers the failure. To ensure the maintaining acceptable system performance in reality, the new properties of the Nussbaum function are proposed, and an auxiliary virtual controller is designed through the neural network (NN) universal approximator. Furthermore, it is challenged to save the system-limited transmutation resource for nonlinear systems, especially for stochastic nonlinear systems, with unknown hysteresis input and actuator failures. The coupling effect of the system communication resource constrains has to arise the issue of the mutual coupling function, which makes that the tracking control design is more complicated. Using the proposed event-triggered controller and back-stepping technology, a new optimization algorithm is proposed to ensure that the states of the closed-loop system and the tracking error remain bounded in probability. Finally, to illustrate the effectiveness of our proposed adaptive NN control method with the event-triggered strategy, some numerical examples are provided.",4
Clone-Based Encoded Neural Networks to Design Efficient Associative Memories.,"In this paper, we introduce a neural network (NN) model named clone-based neural network (CbNN) to design associative memories. Neurons in CbNN can be cloned statically or dynamically which allows to increase the number of data that can be stored and retrieved. Thanks to their plasticity, CbNN can handle correlated information more robustly than existing models and thus provides better memory capacity. We experiment this model in encoded neural networks also known as Gripon-Berrou NNs. Numerical simulations demonstrate that memory and recall abilities of CbNN outperform state of the art for the same memory footprint.",4
Separability and Compactness Network for Image Recognition and Superresolution.,"Convolutional neural networks (CNNs) have wide applications in pattern recognition and image processing. Despite recent advances, much remains to be done for CNNs to learn a better representation of image samples. Therefore, constant optimizations should be provided on CNNs. To achieve a good performance on classification, intuitively, samples' interclass separability, or intraclass compactness should be simultaneously maximized. Accordingly, in this paper, we propose a new network, named separability and compactness network (SCNet) to rectify this problem. SCNet minimizes the softmax loss and the distance between features of samples from the same class under a jointly supervised framework, resulting in simultaneous maximization of interclass separability and intraclass compactness of samples. Furthermore, considering the convenience and the efficiency of the cosine similarity in face recognition tasks, we incorporate it into SCNet's distance metric to enable sample features from the same class to line up in the same direction and those from different classes to have a large angle of separation. We apply SCNet to three different tasks: visual classification, face recognition, and image superresolution. Experiments on both public data sets and real-world satellite images validate the effectiveness of our SCNet.",4
Variational Inference for 3-D Localization and Tracking of Multiple Targets Using Multiple Cameras.,"This paper proposes a novel unified framework to solve the 3-D localization and tracking problem that occurs multiple camera settings with overlapping views. The main challenge is to overcome the uncertainty of the back projection arising from the challenges of ground point detection in an environment that includes severe occlusions and the unknown heights of people. To tackle this challenge, we establish a Bayesian learning framework that maximizes a posterior over the trajectory assignments and 3-D positions for given detections from multiple cameras. To solve the Bayesian learning problem in a tractable form, we develop an expectation-maximization scheme based on the variation inference approximation, where the probability distributions are designed to follow Boltzmann distributions of seven terms that are induced from multicamera tracking settings. The experimental results show that the proposed method outperforms the state-of-the-art methods on the challenging multicamera data sets.",4
Crowdsourced Label Aggregation Using Bilayer Collaborative Clustering.,"With online crowdsourcing platforms, labels can be acquired at relatively low costs from massive nonexpert workers. To improve the quality of labels obtained from these imperfect crowdsourced workers, we usually let different workers provide labels for the same instance. Then, the true labels for all instances are estimated from these multiple noisy labels. This traditional general-purpose label aggregation process, solely relying on the collected noisy labels, cannot significantly improve the accuracy of integrated labels under a low labeling quality circumstance. This paper proposes a novel bilayer collaborative clustering (BLCC) method for the label aggregation in crowdsourcing. BLCC first generates the conceptual-level features for the instances from their multiple noisy labels and infers the initially integrated labels by performing clustering on the conceptual-level features. Then, it performs another clustering on the physical-level features to form the estimations of the true labels on the physical layer. The clustering results on both layers can facilitate in tracking the changes in the uncertainties of the instances. Finally, the initially integrated labels that are likely to be wrongly inferred on the conceptual layer can be addressed using the estimated labels on the physical layer. The clustering processes on both layers can keep providing guidance information for each other in the multiple label remedy rounds. The experimental results on 12 real-world crowdsourcing data sets show that the performance of the proposed method in terms of accuracy is better than that of the state-of-the-art methods.",4
Distributed Extremum Seeking for Optimal Resource Allocation and Its Application to Economic Dispatch in Smart Grids.,"This paper proposes a first-order extremum-seeking algorithm to solve the resource allocation problem, where the specific expression form and gradient information of the local cost functions are not required. Agents take advantage of measurements of local cost functions to minimize the sum of their cost functions while satisfying the resource constraint, where agents exchange the estimated decisions with their neighbors under an undirected and connected graph. Making use of the Lyapunov stability theory and the average analysis method, the convergence of the proposed algorithm to the neighborhood of the optimal solution is presented. In addition, it is obtained that the designed algorithm is semiglobally practically asymptotically stable. Then, the first-order algorithm is extended to the second-order algorithm with low-pass filters, which achieves better convergence performance than the first-order algorithm. Finally, the effectiveness of the proposed algorithm is illustrated by numerical examples and its application to economic dispatch in smart grids.",4
Synchronization Control for Network Systems With Communication Constraints.,"A novel control strategy for synchronization control for network systems with communication constraints is presented in this paper. The dynamics of nodes in the network are nonidentical. The communication topology of network is weakly connected with communication constraints. The designed distributed controller for each node has two parts: reference generator (RG) and regulator. All RGs adopt the communication channels to exchange local information and track the target trajectory. Meanwhile, regulator can ensure that nonidentical node achieves synchronization with its RG. In order to reduce the communication frequency between node and its regulator, a sampled-date control strategy is utilized. The upper bound of the aperiodic sampling instants is calculated through the small-gain theorem, where the closed-loop system is equivalently formulated as the feedback interconnection of a linear time-invariant system and an integral sampled-data operator. Finally, some simulation results are given to demonstrate the effectiveness of the controller design strategy.",4
Object Detection With Deep Learning: A Review.,"Due to object detection's close relationship with video analysis and image understanding, it has attracted much research attention in recent years. Traditional object detection methods are built on handcrafted features and shallow trainable architectures. Their performance easily stagnates by constructing complex ensembles that combine multiple low-level image features with high-level context from object detectors and scene classifiers. With the rapid development in deep learning, more powerful tools, which are able to learn semantic, high-level, deeper features, are introduced to address the problems existing in traditional architectures. These models behave differently in network architecture, training strategy, and optimization function. In this paper, we provide a review of deep learning-based object detection frameworks. Our review begins with a brief introduction on the history of deep learning and its representative tool, namely, the convolutional neural network. Then, we focus on typical generic object detection architectures along with some modifications and useful tricks to improve detection performance further. As distinct specific detection tasks exhibit different characteristics, we also briefly survey several specific tasks, including salient object detection, face detection, and pedestrian detection. Experimental analyses are also provided to compare various methods and draw some meaningful conclusions. Finally, several promising directions and tasks are provided to serve as guidelines for future work in both object detection and relevant neural network-based learning systems.",4
Morphological Convolutional Neural Network Architecture for Digit Recognition.,"Deep neural networks have proved promising results in many applications and fields, but they are still assimilated to a black box. Thus, it is very useful to introduce interpretability aspects to prevent the blind application of deep networks. This paper proposed an interpretable morphological convolutional neural network called Morph-CNN for pattern recognition, where morphological operations were incorporated using counter-harmonic mean into the convolutional layer in order to generate enhanced feature maps. Morph-CNN was extensively evaluated on MNIST and SVHN benchmarks for digit recognition. The different tested configurations showed that Morph-CNN outperforms the existing methods.",4
Event/Self-Triggered Control for Leader-Following Consensus Over Unreliable Network With DoS Attacks.,"This paper investigates the leader-following consensus issue with event/self-triggered schemes under an unreliable network environment. First, we characterize network communication and control protocol update in the presence of denial-of-service (DoS) attacks. In this situation, an event-triggered communication scheme is first proposed to effectively schedule information transmission over the network possibly subject to malicious attacks. In this communication framework, synchronous and asynchronous updated strategies of control protocols are constructed to achieve leader-following consensus in the presence of DoS attacks. Moreover, to further reduce the cost induced by event detection, a self-triggered communication scheme is proposed in which the next triggering instant can be determined by computing with the most updated information. Finally, a numerical example is provided to verify the effectiveness of the proposed communication schemes and updated strategies in the unreliable network environment.",4
Fast Matrix Factorization With Nonuniform Weights on Missing Data.,"Matrix factorization (MF) has been widely used to discover the low-rank structure and to predict the missing entries of data matrix. In many real-world learning systems, the data matrix can be very high dimensional but sparse. This poses an imbalanced learning problem since the scale of missing entries is usually much larger than that of the observed entries, but they cannot be ignored due to the valuable negative signal. For efficiency concern, existing work typically applies a uniform weight on missing entries to allow a fast learning algorithm. However, this simplification will decrease modeling fidelity, resulting in suboptimal performance for downstream applications. In this paper, we weight the missing data nonuniformly, and more generically, we allow any weighting strategy on the missing data. To address the efficiency challenge, we propose a fast learning method, for which the time complexity is determined by the number of observed entries in the data matrix rather than the matrix size. The key idea is twofold: 1) we apply truncated singular value decomposition on the weight matrix to get a more compact representation of the weights and 2) we learn MF parameters with elementwise alternating least squares (eALS) and memorize the key intermediate variables to avoid repeating computations that are unnecessary. We conduct extensive experiments on two recommendation benchmarks, demonstrating the correctness, efficiency, and effectiveness of our fast eALS method.",4
Nonparametric Dimension Reduction via Maximizing Pairwise Separation Probability.,"In this brief, we propose a novel nonparametric supervised linear dimension reduction (SLDR) algorithm that extracts the features by maximizing the pairwise separation probability. The separation probability, as a new class separability measure, describes the generalization accuracy when we use the obtained features to train a linear classifier. Obtaining high-quality features, the proposed method avoids the overlaps between classes that are close to each other in the input space and improves the subsequent classification performance. Experiments on benchmark data sets show the superiority of the proposed algorithm over some other state-of-the-art SLDR methods.",4
A Deep Collaborative Framework for Face Photo-Sketch Synthesis.,"Great breakthroughs have been made in the accuracy and speed of face photo-sketch synthesis in recent years. Regression-based methods have gained increasing attention, which benefit from deeper and faster end-to-end convolutional neural networks. However, most of these models typically formulate the mapping from photo domain X to sketch domain Y as a unidirectional feedforward mapping, G: X --> Y, and vice versa, F: Y --> X; thus, the utilization of mutual interaction between two opposite mappings is lacking. Therefore, we proposed a collaborative framework for face photo-sketch synthesis. The concept behind our model was that a middle latent domain Z between the photo domain X and the sketch domain Y can be learned during the learning procedure of G: X --> Y and F: Y --> X by introducing a collaborative loss that makes full use of two opposite mappings. This strategy can constrain the two opposite mappings and make them more symmetrical, thus making the network more suitable for the photo-sketch synthesis task and obtaining higher quality generated images. Qualitative and quantitative experiments demonstrated the superior performance of our model in comparison with the existing state-of-the-art solutions.",4
Deep Latent Low-Rank Representation for Face Sketch Synthesis.,"Face sketch synthesis is useful and profitable in digital entertainment. Most existing face sketch synthesis methods rely on the assumption that facial photographs/sketches form a low-dimensional manifold. Once the training data are insufficient, the manifold could not characterize the identity-specific information that is included in a test photograph but excluded in the training data. Thus, the synthesized sketch would lose this information, such as glasses, earrings, hairstyles, and hairpins. To provide the sufficient data and satisfy the assumption on manifold, we propose a novel face sketch synthesis framework based on deep latent low-rank representation (DLLRR) in this paper. The DLLRR induces the hidden training sketches with the identity-specific information as the hidden data to the insufficient original training sketches as the observed data. And it searches the lowest rank representation on the candidates of a test photograph from the both hidden and observed data. For the strong representational capability of the coupled autoencoder, we leverage it to reveal the hidden data. Experiment results on face photograph-sketch database illustrate that the proposed method can successfully provide the sufficient training data with the identity-specific information. And compared to the state of the arts, the proposed method synthesizes more clean and vivid face sketches.",4
Learning Time Series Associated Event Sequences With Recurrent Point Process Networks.,"Real-world sequential data are often generated based on complicated and latent mechanisms, which can be formulated as event sequences occurring in the continuous time domain. In addition, continuous signals may often be associated with event sequences and be formulated as time series with fixed time lags. Traditionally, event sequences are often modeled by parametric temporal point processes, which use explicitly defined conditional intensity functions to quantify the occurrence rates of events. However, these parametric models often merely take one-side information from event sequences into account while ignoring the information from concurrent time series, and their intensity functions are usually designed for specific tasks dependent on prior knowledge. To tackle the above-mentioned problems, we propose a model called recurrent point process networks which instantiates temporal point process models with temporal recurrent neural networks (RNNs). In particular, the intensity functions of the proposed model are modeled by two RNNs: one temporal RNN capturing the relationships among events and the other RNN updating intensity functions based on time series. Furthermore, an attention mechanism is introduced, which uncovers influence strengths among events with good interpretability. Focusing on challenging tasks such as temporal event prediction and underlying relational network mining, we demonstrate the superiority of our model on both synthetic and real-world data.",4
A Novel Neural Network for Remote Sensing Image Matching.,"Rapid development of remote sensing (RS) imaging technology makes the acquired images have larger size, higher resolution, and more complex structure, which goes beyond the reach of classical hand-crafted feature-based matching. In this paper, we propose a feature learning approach based on two-branch networks to transform the image matching task into a two-class classification problem. To match two key points, two image patches centered at the key points are entered into the proposed network. The network aims to learn discriminative feature representations for patch matching, so that more matching pairs can be obtained on the premise of maintaining higher subpixel matching accuracy. The proposed network adopts a two-stage training mode to deal with the complex characteristics of RS images. An adaptive sample selection strategy is proposed to determine the size of each patch by the scale of its central key point. Thus, each patch can preserve the texture structure around its key point rather than all patches have a predetermined size. In the matching prediction stage, two strategies, namely, superpixel-based sample graded strategy and superpixel-based ordered spatial matching, are designed to improve the matching efficiency and matching accuracy, respectively. The experimental results and theoretical analysis demonstrate the feasibility, robustness, and effectiveness of the proposed method.",4
Bayesian Weight Decay on Bounded Approximation for Deep Convolutional Neural Networks.,"This paper determines the weight decay parameter value of a deep convolutional neural network (CNN) that yields a good generalization. To obtain such a CNN in practice, numerical trials with different weight decay values are needed. However, the larger the CNN architecture is, the higher is the computational cost of the trials. To address this problem, this paper formulates an analytical solution for the decay parameter through a proposed objective function in conjunction with Bayesian probability distributions. For computational efficiency, a novel method to approximate this solution is suggested. This method uses a small amount of information in the Hessian matrix. Theoretically, the approximate solution is guaranteed by a provable bound and is obtained by a proposed algorithm, where its time complexity is linear in terms of both the depth and width of the CNN. The bound provides a consistent result for the proposed learning scheme. By reducing the computational cost of determining the decay value, the approximation allows for the fast investigation of a deep CNN (DCNN) which yields a small generalization error. Experimental results show that our assumption verified with different DCNNs is suitable for real-world image data sets. In addition, the proposed method significantly reduces the time cost of learning with setting the weight decay parameter while achieving good classification performances.",4
A Recursive Approach to Quantized Hinfinity State Estimation for Genetic Regulatory Networks Under Stochastic Communication Protocols.,"This paper deals with the finite-horizon quantized Hinfinity state estimation problem for a class of discrete time-varying genetic regulatory networks with quantization effects under stochastic communication protocols (SCPs). To better reflect the data-driven flavor of today's biological research, the network measurements (typically gigabytes in size by high-throughput sequencing technologies) are transmitted to a remote state estimator via two independent communication networks of limited bandwidths. To lighten the communication loads and avoid undesired data collisions, the measurement outputs are quantized and then transmitted under two SCPs introduced to schedule the large-scale data transmissions. The purpose of this paper is to design a time-varying state estimator such that the error dynamics of the state estimation satisfies a prescribed Hinfinity performance requirement over a finite horizon in the presence of nonlinearities, quantization effects, and SCPs. By utilizing the completing-the-square technique, sufficient conditions are derived to ensure the Hinfinity estimation performance and the parameters of the state estimator are designed by solving coupled backward recursive Riccati difference equations. A numerical example is given to illustrate the effectiveness of the design scheme of the proposed state estimator.",4
Scalable Proximal Jacobian Iteration Method With Global Convergence Analysis for Nonconvex Unconstrained Composite Optimizations.,"The recent studies have found that the nonconvex relaxation functions usually perform better than the convex counterparts in the l0 -norm and rank function minimization problems. However, due to the absence of convexity in these nonconvex problems, developing efficient algorithms with convergence guarantee becomes very challenging. Inspired by the basic ideas of both the Jacobian alternating direction method of multipliers (JADMMs) for solving linearly constrained problems with separable objectives and the proximal gradient methods (PGMs) for optimizing the unconstrained problems with one variable, this paper focuses on extending the PGMs to the proximal Jacobian iteration methods (PJIMs) for handling with a family of nonconvex composite optimization problems with two splitting variables. To reduce the total computational complexity by decreasing the number of iterations, we devise the accelerated version of PJIMs through the well-known Nesterov's acceleration strategy and further extend both to solve the multivariable cases. Most importantly, we provide a rigorous convergence analysis, in theory, to show that the generated variable sequence globally converges to a critical point by exploiting the Kurdyka-Lojasiewica (KL) property for a broad class of functions. Furthermore, we also establish the linear and sublinear convergence rates of the obtained variable sequence in the objective function. As the specific application to the nonconvex sparse and low-rank recovery problems, several numerical experiments can verify that the newly proposed algorithms not only keep fast convergence speed but also have high precision.",4
Kernel-Based Distance Metric Learning for Supervised k-Means Clustering.,"Finding an appropriate distance metric that accurately reflects the (dis)similarity between examples is a key to the success of k-means clustering. While it is not always an easy task to specify a good distance metric, we can try to learn one based on prior knowledge from some available clustered data sets, an approach that is referred to as supervised clustering. In this paper, a kernel-based distance metric learning method is developed to improve the practical use of k-means clustering. Given the corresponding optimization problem, we derive a meaningful Lagrange dual formulation and introduce an efficient algorithm in order to reduce the training complexity. Our formulation is simple to implement, allowing a large-scale distance metric learning problem to be solved in a computationally tractable way. Experimental results show that the proposed method yields more robust and better performances on synthetic as well as real-world data sets compared to other state-of-the-art distance metric learning methods.",4
Learning Algorithm for Boltzmann Machines With Additive Weight and Bias Noise.,"This brief presents analytical results on the effect of additive weight/bias noise on a Boltzmann machine (BM), in which the unit output is in {-1, 1} instead of {0,1}. With such noise, it is found that the state distribution is yet another Boltzmann distribution but the temperature factor is elevated. Thus, the desired gradient ascent learning algorithm is derived, and the corresponding learning procedure is developed. This learning procedure is compared with the learning procedure applied to train a BM with noise. It is found that these two procedures are identical. Therefore, the learning algorithm for noise-free BMs is suitable for implementing as an online learning algorithm for an analog circuit-implemented BM, even if the variances of the additive weight noise and bias noise are unknown.",4
Learning Discrete-Time Markov Chains Under Concept Drift.,"Learning under concept drift is a novel and promising research area aiming at designing learning algorithms able to deal with nonstationary data-generating processes. In this research field, most of the literature focuses on learning nonstationary probabilistic frameworks, while some extensions about learning graphs and signals under concept drift exist. For the first time in the literature, this paper addresses the problem of learning discrete-time Markov chains (DTMCs) under concept drift. More specifically, following a hybrid active/passive approach, this paper introduces both a family of change-detection mechanisms (CDMs), differing in the required assumptions and performance, for detecting changes in DTMCs and an adaptive learning algorithm able to deal with DTMCs under concept drift. The effectiveness of both the proposed CDMs and the adaptive learning algorithm has been extensively tested on synthetically generated experiments and real data sets.",4
Classification by Sparse Neural Networks.,"The choice of dictionaries of computational units suitable for efficient computation of binary classification tasks is investigated. To deal with exponentially growing sets of tasks with increasingly large domains, a probabilistic model is introduced. The relevance of tasks for a given application area is modeled by a product probability distribution on the set of all binary-valued functions. Approximate measures of network sparsity are studied in terms of variational norms tailored to dictionaries of computational units. Bounds on these norms are proven using the Chernoff-Hoeffding bound on sums of independent random variables that need not be identically distributed. Consequences of the probabilistic results for the choice of dictionaries of computational units are derived. It is shown that when a priori knowledge of a type of classification tasks is limited, then the sparsity may be achieved only at the expense of large sizes of dictionaries.",4
EEG-Based Spatio-Temporal Convolutional Neural Network for Driver Fatigue Evaluation.,"Driver fatigue evaluation is of great importance for traffic safety and many intricate factors would exacerbate the difficulty. In this paper, based on the spatial-temporal structure of multichannel electroencephalogram (EEG) signals, we develop a novel EEG-based spatial-temporal convolutional neural network (ESTCNN) to detect driver fatigue. First, we introduce the core block to extract temporal dependencies from EEG signals. Then, we employ dense layers to fuse spatial features and realize classification. The developed network could automatically learn valid features from EEG signals, which outperforms the classical two-step machine learning algorithms. Importantly, we carry out fatigue driving experiments to collect EEG signals from eight subjects being alert and fatigue states. Using 2800 samples under within-subject splitting, we compare the effectiveness of ESTCNN with eight competitive methods. The results indicate that ESTCNN fulfills a better classification accuracy of 97.37% than these compared methods. Furthermore, the spatial-temporal structure of this framework advantages in computational efficiency and reference time, which allows further implementations in the brain-computer interface online systems.",4
Simultaneously Learning Neighborship and Projection Matrix for Supervised Dimensionality Reduction.,"Explicitly or implicitly, most dimensionality reduction methods need to determine which samples are neighbors and the similarities between the neighbors in the original high-dimensional space. The projection matrix is then learnt on the assumption that the neighborhood information, e.g., the similarities, are known and fixed prior to learning. However, it is difficult to precisely measure the intrinsic similarities of samples in high-dimensional space because of the curse of dimensionality. Consequently, the neighbors selected according to such similarities and the projection matrix obtained according to such similarities and the corresponding neighbors might not be optimal in the sense of classification and generalization. To overcome this drawback, in this paper, we propose to let the similarities and neighbors be variables and model these in a low-dimensional space. Both the optimal similarity and projection matrix are obtained by minimizing a unified objective function. Nonnegative and sum-to-one constraints on the similarity are adopted. Instead of empirically setting the regularization parameter, we treat it as a variable to be optimized. It is interesting that the optimal regularization parameter is adaptive to the neighbors in a low-dimensional space and has an intuitive meaning. Experimental results on the YALE B, COIL-100, and MNIST data sets demonstrate the effectiveness of the proposed method.",4
Mining Top- k Useful Negative Sequential Patterns via Learning.,"As an important tool for behavior informatics, negative sequential patterns (NSPs) (such as missing a medical treatment) are sometimes much more informative than positive sequential patterns (PSPs) (e.g., attending a medical treatment) in many applications. However, NSP mining is at an early stage and faces many challenging problems, including 1) how to mine an expected number of NSPs; 2) how to select useful NSPs; and 3) how to reduce high time consumption. To solve the first problem, we propose an algorithm Topk-NSP to mine the k most frequent negative patterns. In Topk-NSP, we first mine the top- k PSPs using the existing methods, and then we use an idea which is similar to top- k PSPs mining to mine the top- k NSPs from these PSPs. To solve the remaining two problems, we propose three optimization strategies for Topk-NSP. The first optimization strategy is that, in order to consider the influence of PSPs when selecting useful top- k NSPs, we introduce two weights, wP and wN , to express the user preference degree for NSPs and PSPs, respectively, and select useful NSPs by a weighted support wsup. The second optimization strategy is to merge wsup and an interestingness metric to select more useful NSPs. The third optimization strategy is to introduce a pruning strategy to reduce the high computational costs of Topk-NSP. Finally, we propose an optimization algorithm Topk-NSP(+). To the best of our knowledge, Topk-NSP(+) is the first algorithm that can mine the top- k useful NSPs. The experimental results on four synthetic and two real-life data sets show that the Topk-NSP(+) is very efficient in mining the top- k NSPs in the sense of computational cost and scalability.",4
Adversarial Examples: Attacks and Defenses for Deep Learning.,"With rapid progress and significant successes in a wide spectrum of applications, deep learning is being applied in many safety-critical environments. However, deep neural networks (DNNs) have been recently found vulnerable to well-designed input samples called adversarial examples. Adversarial perturbations are imperceptible to human but can easily fool DNNs in the testing/deploying stage. The vulnerability to adversarial examples becomes one of the major risks for applying DNNs in safety-critical environments. Therefore, attacks and defenses on adversarial examples draw great attention. In this paper, we review recent findings on adversarial examples for DNNs, summarize the methods for generating adversarial examples, and propose a taxonomy of these methods. Under the taxonomy, applications for adversarial examples are investigated. We further elaborate on countermeasures for adversarial examples. In addition, three major challenges in adversarial examples and the potential solutions are discussed.",4
Learning With Annotation of Various Degrees.,"In this paper, we study a new problem in the scenario of sequences labeling. To be exact, we consider that the training data are with annotation of various degrees, namely, fully labeled, unlabeled, and partially labeled sequences. The learning with fully un/labeled sequence refers to the standard setting in traditional un/supervised learning, and the proposed partially labeling specifies the subject that the element does not belong to. The partially labeled data are cheaper to obtain compared with the fully labeled data though it is less informative, especially when the tasks require a lot of domain knowledge. To solve such a practical challenge, we propose a novel deep conditional random field (CRF) model which utilizes an end-to-end learning manner to smoothly handle fully/un/partially labeled sequences within a unified framework. To the best of our knowledge, this could be one of the first works to utilize the partially labeled instance for sequence labeling, and the proposed algorithm unifies the deep learning and CRF in an end-to-end framework. Extensive experiments show that our method achieves state-of-the-art performance in two sequence labeling tasks on some popular data sets.",4
Less Is More: A Comprehensive Framework for the Number of Components of Ensemble Classifiers.,"The number of component classifiers chosen for an ensemble greatly impacts the prediction ability. In this paper, we use a geometric framework for a priori determining the ensemble size, which is applicable to most of the existing batch and online ensemble classifiers. There are only a limited number of studies on the ensemble size examining majority voting (MV) and weighted MV (WMV). Almost all of them are designed for batch-mode, hardly addressing online environments. Big data dimensions and resource limitations, in terms of time and memory, make the determination of ensemble size crucial, especially for online environments. For the MV aggregation rule, our framework proves that the more strong components we add to the ensemble, the more accurate predictions we can achieve. For the WMV aggregation rule, our framework proves the existence of an ideal number of components, which is equal to the number of class labels, with the premise that components are completely independent of each other and strong enough. While giving the exact definition for a strong and independent classifier in the context of an ensemble is a challenging task, our proposed geometric framework provides a theoretical explanation of diversity and its impact on the accuracy of predictions. We conduct a series of experimental evaluations to show the practical value of our theorems and existing challenges.",4
Tractable Learning and Inference for Large-Scale Probabilistic Boolean Networks.,"Probabilistic Boolean networks (PBNs) have previously been proposed so as to gain insights into complex dynamical systems. However, identification of large networks and their underlying discrete Markov chain which describes their temporal evolution still remains a challenge. In this paper, we introduce an equivalent representation for PBNs, the stochastic conjunctive normal form network (SCNFN), which enables a scalable learning algorithm and helps predict long-run dynamic behavior of large-scale systems. State-of-the-art methods turn out to be 400 times slower for middle-sized networks (i.e., containing 100 nodes) and incapable of terminating for large networks (i.e., containing 1000 nodes) compared to the SCNFN-based learning, when attempting to achieve comparable accuracy. In addition, in contrast to the currently used methods which introduce strict restrictions on the structure of the learned PBNs, the hypothesis space of our training paradigm is the set of all possible PBNs. Moreover, SCNFNs enable efficient sampling so as to statistically infer multistep transition probabilities which can provide information on the activity levels of individual nodes in the long run. Extensive experimental results showcase the scalability of the proposed approach both in terms of sample and runtime complexity. In addition, we provide examples to study large and complex cell signaling networks to show the potential of our model. Finally, we suggest several directions for future research on model variations, theoretical analysis, and potential applications of SCNFNs.",4
Identification and Control of Nonlinear Systems Using Neural Networks: A Singularity-Free Approach.,"In this paper, identification and control for a class of nonlinear systems with unknown constant or variable control gains are investigated. By reformulating the original system dynamic equation into a new form with a unit control gain and introducing a set of filtered variables, a novel neural network (NN) estimator is constructed and a new estimation error is used to update the augmented weights. Based on the identification results, two singularity-free NN indirect adaptive controllers are developed for nonlinear systems with unknown constant control gains or variable control gains, respectively. Because the singularity problem is eradicated, the proposed methods remove limitations on parameter estimates that are used to guarantee the positiveness of the estimated control gain. Consequently, a more accurate estimation result can be achieved and the system state can track the given reference signal more precisely. The effectiveness of the proposed identification and control algorithms are tested and the superiority of the proposed singularity-free approach is demonstrated by simulation results.",4
Task-Oriented GAN for PolSAR Image Classification and Clustering.,"Based on a generative adversarial network (GAN), a novel version named Task-Oriented GAN is proposed to tackle difficulties in PolSAR image interpretation, including PolSAR data analysis and small sample problem. Besides two typical parts in GAN, i.e., generator (G-Net) and discriminator (D-Net), there is a third part named TaskNet (T-Net) in the Task-Oriented GAN, where T-Net is employed to accomplish a certain task. Two tasks, PolSAR image classification and clustering, are studied in this paper, where T-Net acts as a Classifier and a Clusterer, respectively. The learning procedure of Task-Oriented GAN consists of two main stages. In the first stage, G-Net and D-Net vie with each other like that in a general GAN; in the second stage, G-Net is adjusted and oriented by T-Net so that more samples, which are benefit for the task and called fake data, are generated. As a result, Task-Oriented GAN not only has the advantage of GAN (no-assumption data modeling) but also overcomes the disadvantage of GAN (task-free). After learning, fake data are employed to enrich training set and avoid overfitting; so Task-Oriented GAN performs well even if the manual-labeled data are small. To verify the effectiveness of T-Net, a visualized comparison is provided, where some fake digits generated from Task-Oriented GAN are illustrated along with that from GAN. What is more, considering that there is a great difference between PolSAR data and general data, in our PolSAR image classification and clustering tasks, the specific PolSAR information is inserted into the structure of the Task-Oriented GAN. This enables researchers to mine inherent information in PolSAR data without any data hypothesis and find ways for small sample problem at the same time. Experiment results tested on three PolSAR images show that the proposed method performs well in dealing with PolSAR image classification and clustering.",4
Neural Network Controller Design for a Class of Nonlinear Delayed Systems With Time-Varying Full-State Constraints.,"This paper proposes an adaptive neural control method for a class of nonlinear time-varying delayed systems with time-varying full-state constraints. To address the problems of the time-varying full-state constraints and time-varying delays in a unified framework, an adaptive neural control method is investigated for the first time. The problems of time delay and constraint are the main factors of limiting the system performance severely and even cause system instability. The effect of unknown time-varying delays is eliminated by using appropriate Lyapunov-Krasovskii functionals. In addition, the constant constraint is the only special case of time-varying constraint which leads to more complex and difficult tasks. To guarantee the full state always within the time-varying constrained interval, the time-varying asymmetric barrier Lyapunov function is employed. Finally, two simulation examples are given to confirm the effectiveness of the presented control scheme.",4
Regularizing Deep Neural Networks by Enhancing Diversity in Feature Extraction.,"This paper proposes a new and efficient technique to regularize the neural network in the context of deep learning using correlations among features. Previous studies have shown that oversized deep neural network models tend to produce a lot of redundant features that are either the shifted version of one another or are very similar and show little or no variations, thus resulting in redundant filtering. We propose a way to address this problem and show that such redundancy can be avoided using regularization and adaptive feature dropout mechanism. We show that regularizing both negative and positive correlated features according to their differentiation and based on their relative cosine distances yields network extracting dissimilar features with less overfitting and better generalization. This concept is illustrated with deep multilayer perceptron, convolutional neural network, sparse autoencoder, gated recurrent unit, and long short-term memory on MNIST digits recognition, CIFAR-10, ImageNet, and Stanford Natural Language Inference data sets.",4
A Lagrangian Relaxation Approach for Binary Multiple Instance Classification.,"In the standard classification problems, the objective is to categorize points into different classes. Multiple instance learning (MIL), instead, is aimed at classifying bags of points, each point being an instance. The main peculiarity of a MIL problem is that, in the learning phase, only the label of each bag is known whereas the labels of the instances are unknown. We discuss an instance-level learning approach for a binary MIL classification problem characterized by two classes of instances, positive and negative, respectively. In such a problem, a negative bag is constituted only by negative instances, while a bag is positive if it contains at least one positive instance. We start from a mixed integer nonlinear optimization model drawn from the literature and the main result we obtain is to prove that a Lagrangian relaxation approach, equipped with a dual ascent scheme, allows us to obtain an optimal solution of the original problem. The relaxed problem is tackled by means of a block coordinate descent (BCD) algorithm. We provide, finally, the results of our implementation on some benchmark data sets.",4
Recurrent Neural Network Model: A New Strategy to Solve Fuzzy Matrix Games.,"This paper aims to investigate the fuzzy constrained matrix game (MG) problems using the concepts of recurrent neural networks (RNNs). To the best of our knowledge, this paper is the first in attempting to find a solution for fuzzy game problems using RNN models. For this purpose, a fuzzy game problem is reformulated into a weighting problem. Then, the Karush-Kuhn-Tucker (KKT) optimality conditions are provided for the weighting problem. The KKT conditions are used to propose the RNN model. Moreover, the Lyapunov stability and the global convergence of the RNN model are also confirmed. Finally, three illustrative examples are presented to demonstrate the effectiveness of this approach. The obtained results are compared with the results obtained by the previous approaches for solving fuzzy constrained MG.",4
Learning a Low Tensor-Train Rank Representation for Hyperspectral Image Super-Resolution.,"Hyperspectral images (HSIs) with high spectral resolution only have the low spatial resolution. On the contrary, multispectral images (MSIs) with much lower spectral resolution can be obtained with higher spatial resolution. Therefore, fusing the high-spatial-resolution MSI (HR-MSI) with low-spatial-resolution HSI of the same scene has become the very popular HSI super-resolution scheme. In this paper, a novel low tensor-train (TT) rank (LTTR)-based HSI super-resolution method is proposed, where an LTTR prior is designed to learn the correlations among the spatial, spectral, and nonlocal modes of the nonlocal similar high-spatial-resolution HSI (HR-HSI) cubes. First, we cluster the HR-MSI cubes as many groups based on their similarities, and the HR-HSI cubes are also clustered according to the learned cluster structure in the HR-MSI cubes. The HR-HSI cubes in each group are much similar to each other and can constitute a 4-D tensor, whose four modes are highly correlated. Therefore, we impose the LTTR constraint on these 4-D tensors, which can effectively learn the correlations among the spatial, spectral, and nonlocal modes because of the well-balanced matricization scheme of TT rank. We formulate the super-resolution problem as TT rank regularized optimization problem, which is solved via the scheme of alternating direction method of multipliers. Experiments on HSI data sets indicate the effectiveness of the LTTR-based method.",4
Submodular Function Optimization for Motion Clustering and Image Segmentation.,"In this paper, we propose a framework of maximizing quadratic submodular energy with a knapsack constraint approximately, to solve certain computer vision problems. The proposed submodular maximization problem can be viewed as a generalization of the classic 0/1 knapsack problem. Importantly, maximization of our knapsack constrained submodular energy function can be solved via dynamic programing. We further introduce a range-reduction step prior to dynamic programing as a two-stage procedure for more efficient maximization. In order to demonstrate the effectiveness of the proposed energy function and its maximization algorithm, we apply it to two representative computer vision tasks: image segmentation and motion trajectory clustering. Experimental results of image segmentation demonstrate that our method outperforms the classic segmentation algorithms of graph cuts and random walks. Moreover, our framework achieves better performance than state-of-the-art methods on the motion trajectory clustering task.",4
A Multistage Game in Smart Grid Security: A Reinforcement Learning Solution.,"Existing smart grid security research investigates different attack techniques and cascading failures from the attackers' viewpoints, while the defenders' or the operators' protection strategies are somehow neglected. Game theoretic methods are applied for the attacker-defender games in the smart grid security area. Yet, most of the existing works only use the one-shot game and do not consider the dynamic process of the electric power grid. In this paper, we propose a new solution for a multistage game (also called a dynamic game) between the attacker and the defender based on reinforcement learning to identify the optimal attack sequences given certain objectives (e.g., transmission line outages or generation loss). Different from a one-shot game, the attacker here learns a sequence of attack actions applying for the transmission lines and the defender protects a set of selected lines. After each time step, the cascading failure will be measured, and the line outage (and/or generation loss) will be used as the feedback for the attacker to generate the next action. The performance is evaluated on W&W 6-bus and IEEE 39-bus systems. A comparison between a multistage attack and a one-shot attack is conducted to show the significance of the multistage attack. Furthermore, different protection strategies are evaluated in simulation, which shows that the proposed reinforcement learning solution can identify optimal attack sequences under several attack objectives. It also indicates that attacker's learned information helps the defender to enhance the security of the system.",4
Plume Tracing via Model-Free Reinforcement Learning Method.,"This paper studies the plume-tracing strategy for an autonomous underwater vehicle (AUV) in the deep-sea turbulent environment. The tracing problem is modeled as a partially observable Markov decision process with continuous state space and action space due to the spatio-temporal changes of environment. An long short-term memory-based reinforcement learning framework with full use of history information is proposed to generate a smooth strategy while the AUV interacting with the environment. Continuous temporal difference and deterministic policy gradient methods are employed to improve the strategy. To promote the performance of the algorithm, a supervised strategy generated by dynamic programming methods is utilized as transcendental knowledge of the agent. Historical searching trajectory's form and the exploration technology are specially designed to fit the algorithm. Simulation environments are established based on Reynolds-averaged Navier-Stokes equations and the effectiveness of the learned plume-tracing strategy is validated with simulation experiments.",4
A Novel Equivalent Model of Active Distribution Networks Based on LSTM.,"Dynamic behaviors of distribution networks are of great importance for the power system analysis. Nowadays, due to the integration of the renewable energy generation, energy storage, plug-in electric vehicles, and distribution networks turn from passive systems to active ones. Hence, the dynamic behaviors of active distribution networks (ADNs) are much more complex than the traditional ones. The research interests how to establish an accurate model of ADNs in modern power systems are drawing a great deal of attention. In this paper, motivated by the similarities between power system differential algebraic equations and the forward calculation flows of recurrent neural networks (RNNs), a long short-term memory (LSTM) RNN-based equivalent model is proposed to accurately represent the ADNs. First, the adoption reasons of the proposed LSTM RNN-based equivalent model are explained, and its advantages are analyzed from the mathematical point of view. Then, the accuracy and generalization performance of the proposed model is evaluated using the IEEE 39-Bus New England system integrated with ADNs in the study cases. It reveals that the proposed LSTM RNN-based equivalent model has a generalization capability to capture the dynamic behaviors of ADNs with high accuracy.",4
Extended Dissipativity Analysis for Markovian Jump Neural Networks With Time-Varying Delay via Delay-Product-Type Functionals.,"This paper investigates the problem of extended dissipativity for Markovian jump neural networks (MJNNs) with a time-varying delay. The objective is to derive less conservative extended dissipativity criteria for delayed MJNNs. Toward this aim, an appropriate Lyapunov-Krasovskii functional (LKF) with some improved delay-product-type terms is first constructed. Then, by employing the extended reciprocally convex matrix inequality (ERCMI) and the Wirtinger-based integral inequality to estimate the derivative of the constructed LKF, a delay-dependent extended dissipativity condition is derived for the delayed MJNNs. An improved extended dissipativity criterion is also given via the allowable delay sets method. Based on the above-mentioned results, the extended dissipativity condition of delayed NNs without Markovian jump parameters is directly derived. Finally, three numerical examples are employed to illustrate the advantages of the proposed method.",4
Rescaled Boosting in Classification.,"Boosting is a learning scheme that combines weak learners to produce a strong composite learner, with the underlying intuition that one can obtain accurate learner by combining ""rough"" ones. This paper aims at developing a new boosting strategy, called rescaled boosting (RBoosting), to accelerate the numerical convergence rate and, consequently, improve learning performances of the original boosting. Our studies show that RBoosting possesses the almost optimal numerical convergence rate in the sense that, up to a logarithmic factor, it can reach the minimax nonlinear approximation rate. We then use RBoosting to tackle classification problems and deduce corresponding statistical consistency and tight generalization error estimates. A series of theoretical and experimental results shows that RBoosting outperforms boosting in terms of generalization.",4
Unsupervised Feature Selection via Adaptive Multimeasure Fusion.,"Since multiple criteria can be adopted to estimate the similarity among the given data points, problem regarding diverse representations of pairwise relations is brought about. To address this issue, a novel self-adaptive multimeasure (SAMM) fusion problem is proposed, such that different measure functions can be adaptively merged into a unified similarity measure. Different from other approaches, we optimize similarity as a variable instead of presetting it as a priori, such that similarity can be adaptively evaluated based on integrating various measures. To further obtain the associated subspace representation, a graph-based dimensionality reduction problem is incorporated into the proposed SAMM problem, such that the related subspace can be achieved according to the unified similarity. In addition, sparsity-inducing l2,0 regularization is introduced, such that a sparse projection is obtained for efficient feature selection (FS). Consequently, the SAMM-FS method can be summarized correspondingly.",4
Covariance Matrix Adaptation for Multiobjective Multiarmed Bandits.,"Upper confidence bound (UCB) is a successful multiarmed bandit for regret minimization. The covariance matrix adaptation (CMA) for Pareto UCB (CMA-PUCB) algorithm considers stochastic reward vectors with correlated objectives. We upper bound the cumulative pseudoregret of pulling suboptimal arms for the CMA-PUCB algorithm to logarithmic number of arms K , objectives D , and samples n , O (ln(nDK) summation operatori (|| Sigmai ||(2)/i)) , using a variant of Berstein inequality for matrices, where i is the regret of pulling the suboptimal arm i . For unknown covariance matrices between objectives Sigmai , we upper bound the approximation of the covariance matrix using the number of samples to O (n ln(nDK) + ln(2)(nDK) summation operatori (1/i)) . Simulations on a three objective stochastic environment show the applicability of our method.",4
Multi Pseudo Q-Learning-Based Deterministic Policy Gradient for Tracking Control of Autonomous Underwater Vehicles.,"This paper investigates trajectory tracking problem for a class of underactuated autonomous underwater vehicles (AUVs) with unknown dynamics and constrained inputs. Different from existing policy gradient methods which employ single actor critic but cannot realize satisfactory tracking control accuracy and stable learning, our proposed algorithm can achieve high-level tracking control accuracy of AUVs and stable learning by applying a hybrid actors-critics architecture, where multiple actors and critics are trained to learn a deterministic policy and action-value function, respectively. Specifically, for the critics, the expected absolute Bellman error-based updating rule is used to choose the worst critic to be updated in each time step. Subsequently, to calculate the loss function with more accurate target value for the chosen critic, Pseudo Q-learning, which uses subgreedy policy to replace the greedy policy in Q-learning, is developed for continuous action spaces, and Multi Pseudo Q-learning (MPQ) is proposed to reduce the overestimation of action-value function and to stabilize the learning. As for the actors, deterministic policy gradient is applied to update the weights, and the final learned policy is defined as the average of all actors to avoid large but bad updates. Moreover, the stability analysis of the learning is given qualitatively. The effectiveness and generality of the proposed MPQ-based deterministic policy gradient (MPQ-DPG) algorithm are verified by the application on AUV with two different reference trajectories. In addition, the results demonstrate high-level tracking control accuracy and stable learning of MPQ-DPG. Besides, the results also validate that increasing the number of the actors and critics will further improve the performance.",4
Semiparametric Clustering: A Robust Alternative to Parametric Clustering.,"Clustering aims at naturally grouping the data according to the underlying data distribution. The data distribution is often estimated using a parametric or nonparametric model, e.g., Gaussian mixture or kernel density estimation. Compared with nonparametric models, parametric models are statistically stable, i.e., a small perturbation of data points leads to a small change in the estimated density. However, parametric models are highly sensitive to outliers because the data distribution is far away from the parametric assumptions in the presence of outliers. Given a parametric clustering algorithm, this paper shows how to turn this algorithm into a robust one. The idea is to modify the original parametric density into a semiparametric one. The high-density data that form the core of each cluster are modeled with the original parametric density. The low-density data are often far away from the cluster cores and may have an arbitrary shape, thus are modeled using a nonparametric density. A combination of parametric and nonparametric clustering algorithms is used to group the data modeled as a semiparametric density. From the robust statistical point of view, the proposed method has good robustness properties. We test the proposed algorithm on several synthetic and 70 UCI data sets. The results indicate that the semiparametric method could significantly improve the clustering performance.",4
A Two-Timescale Duplex Neurodynamic Approach to Biconvex Optimization.,"This paper presents a two-timescale duplex neurodynamic system for constrained biconvex optimization. The two-timescale duplex neurodynamic system consists of two recurrent neural networks (RNNs) operating collaboratively at two timescales. By operating on two timescales, RNNs are able to avoid instability. In addition, based on the convergent states of the two RNNs, particle swarm optimization is used to optimize initial states of the RNNs to avoid local minima. It is proven that the proposed system is globally convergent to the global optimum with probability one. The performance of the two-timescale duplex neurodynamic system is substantiated based on the benchmark problems. Furthermore, the proposed system is applied for L1 -constrained nonnegative matrix factorization.",4
Near-Nash Equilibrium Control Strategy for Discrete-Time Nonlinear Systems With Round-Robin Protocol.,"In this paper, the near-Nash equilibrium (NE) control strategies are investigated for a class of discrete-time nonlinear systems subjected to the round-robin protocol (RRP). In the studied systems, three types of complexities, namely, the additive nonlinearities, the RRP, and the output feedback form of controllers, are simultaneously taken into consideration. To tackle these complexities, an approximate dynamic programing (ADP) algorithm is first developed for NE control strategies by solving the coupled Bellman's equation. Then, a Luenberger-type observer is designed under the RRP scheduling to estimate the system states. The near-NE control strategies are implemented via the actor-critic neural networks. More importantly, the stability analysis of the closed-loop system is conducted to guarantee that the studied system with the proposed control strategies is bounded stable. Finally, simulation results are provided to demonstrate the validity of the proposed method.",4
"Power-Type Varying-Parameter RNN for Solving TVQP Problems: Design, Analysis, and Applications.","Many practical problems can be solved by being formulated as time-varying quadratic programing (TVQP) problems. In this paper, a novel power-type varying-parameter recurrent neural network (VPNN) is proposed and analyzed to effectively solve the resulting TVQP problems, as well as the original practical problems. For a clear understanding, we introduce this model from three aspects: design, analysis, and applications. Specifically, the reason why and the method we use to design this neural network model for solving online TVQP problems subject to time-varying linear equality/inequality are described in detail. The theoretical analysis confirms that when activated by six commonly used activation functions, VPNN achieves a superexponential convergence rate. In contrast to the traditional zeroing neural network with fixed design parameters, the proposed VPNN has better convergence performance. Comparative simulations with state-of-the-art methods confirm the advantages of VPNN. Furthermore, the application of VPNN to a robot motion planning problem verifies the feasibility, applicability, and efficiency of the proposed method.",4
Passivity and Synchronization of Coupled Uncertain Reaction-Diffusion Neural Networks With Multiple Time Delays.,"This paper presents a complex network model consisting of N uncertain reaction-diffusion neural networks with multiple time delays. We analyze the passivity and synchronization of the proposed network model and derive several passivity and synchronization criteria based on some inequality techniques. In addition, by considering the difficulty in achieving passivity (synchronization) in such a network, an adaptive control scheme is also developed to ensure that the proposed network achieves passivity (synchronization). Finally, we design two numerical examples to verify the effectiveness of the derived passivity and synchronization criteria.",4
Modified Gram-Schmidt Method-Based Variable Projection Algorithm for Separable Nonlinear Models.,"Separable nonlinear models are very common in various research fields, such as machine learning and system identification. The variable projection (VP) approach is efficient for the optimization of such models. In this paper, we study various VP algorithms based on different matrix decompositions. Compared with the previous method, we use the analytical expression of the Jacobian matrix instead of finite differences. This improves the efficiency of the VP algorithms. In particular, based on the modified Gram-Schmidt (MGS) method, a more robust implementation of the VP algorithm is introduced for separable nonlinear least-squares problems. In numerical experiments, we compare the performance of five different implementations of the VP algorithm. Numerical results show the efficiency and robustness of the proposed MGS method-based VP algorithm.",4
Finding Principal Paths in Data Space.,"In this paper, we introduce the concept of principal paths in data space; we show that this is a well-characterized problem from the point of view of cognition, and that it can lead to salient insights in the analyzed data enabling topological/holistic descriptions. These paths, interestingly, can be interpreted as local principal curves, and in this paper, we suggest that they are analogous to what, in the statistical mechanics realm, are called minimum free-energy paths. Here, we move that concept from physics to data space and compute them in both the original and the kernel space. The algorithm is a regularized version of the well-known k -means clustering algorithm. The regularization parameter is derived via an in-sample model selection process based on the Bayesian evidence maximization. Interestingly, we show that this choice for the regularization parameter consistently leads to the same manifold even when changing the number of clusters. We apply the method to common data sets, dynamical systems, and, in particular, to molecular dynamics trajectories showing the generality, the usefulness of the approach and its superiority with respect to other related approaches.",4
t -Exponential Memory Networks for Question-Answering Machines.,"Recent advances in deep learning have brought to the fore models that can make multiple computational steps in the service of completing a task; these are capable of describing long-term dependencies in sequential data. Novel recurrent attention models over possibly large external memory modules constitute the core mechanisms that enable these capabilities. Our work addresses learning subtler and more complex underlying temporal dynamics in language modeling tasks that deal with sparse sequential data. To this end, we improve upon these recent advances by adopting concepts from the field of Bayesian statistics, namely, variational inference. Our proposed approach consists in treating the network parameters as latent variables with a prior distribution imposed over them. Our statistical assumptions go beyond the standard practice of postulating Gaussian priors. Indeed, to allow for handling outliers, which are prevalent in long observed sequences of multivariate data, multivariate t -exponential distributions are imposed. On this basis, we proceed to infer corresponding posteriors; these can be used for inference and prediction at test time, in a way that accounts for the uncertainty in the available sparse training data. Specifically, to allow for our approach to best exploit the merits of the t -exponential family, our method considers a new t -divergence measure, which generalizes the concept of the Kullback-Leibler divergence. We perform an extensive experimental evaluation of our approach, using challenging language modeling benchmarks, and illustrate its superiority over existing state-of-the-art techniques.",4
Two Birds With One Stone: A Coupled Poisson Deconvolution for Detecting and Describing Topics From Multimodal Web Data.,"Organizing multimodal Web pages into hot topics is the core step to grasp trends on the Web. However, the less-constrained social media generate noisy user-generated content, which makes a detected topic be less coherent and less interpretable. In this paper, we address this problem by proposing a coupled Poisson deconvolution to jointly handle topic detection and topic description. For the topic detection, the interestingness of a topic is estimated from the similarities refined by the description of topics; for the topic description, the interestingness of topics is leveraged to describe topics. Two processes cyclically detect interesting topics and generate the multimodal description of topics. This is the innovation of this paper, which just likes killing two birds with one stone. Experiments not only show the significantly improved accuracies for the topic detection but also demonstrate the interpretable descriptions for the topic description on two public data sets.",4
Stochastic Graphlet Embedding.,"Graph-based methods are known to be successful in many machine learning and pattern classification tasks. These methods consider semistructured data as graphs where nodes correspond to primitives (parts, interest points, and segments) and edges characterize the relationships between these primitives. However, these nonvectorial graph data cannot be straightforwardly plugged into off-the-shelf machine learning algorithms without a preliminary step of-explicit/implicit-graph vectorization and embedding. This embedding process should be resilient to intraclass graph variations while being highly discriminant. In this paper, we propose a novel high-order stochastic graphlet embedding that maps graphs into vector spaces. Our main contribution includes a new stochastic search procedure that efficiently parses a given graph and extracts/samples unlimitedly high-order graphlets. We consider these graphlets, with increasing orders, to model local primitives as well as their increasingly complex interactions. In order to build our graph representation, we measure the distribution of these graphlets into a given graph, using particular hash functions that efficiently assign sampled graphlets into isomorphic sets with a very low probability of collision. When combined with maximum margin classifiers, these graphlet-based representations have a positive impact on the performance of pattern comparison and recognition as corroborated through extensive experiments using standard benchmark databases.",4
Global Synchronization of Coupled Fractional-Order Recurrent Neural Networks.,"This paper presents new theoretical results on the global synchronization of coupled fractional-order recurrent neural networks. Under the assumptions that the coupled fractional-order recurrent neural networks are sequentially connected in form of a single spanning tree or multiple spanning trees, two sets of sufficient conditions are derived for ascertaining the global synchronization by using the properties of Mittag-Leffler function and stochastic matrices. Compared with existing works, the results herein are applicable for fractional-order systems, which could be viewed as an extension of integer-order ones. Two numerical examples are presented to illustrate the effectiveness and characteristics of the theoretical results.",4
Zeroing Neural Network for Solving Time-Varying Linear Equation and Inequality Systems.,"A typical recurrent neural network called zeroing neural network (ZNN) was developed for time-varying problem-solving in a previous study. Many applications result in time-varying linear equation and inequality systems that should be solved in real time. This paper provides a ZNN model for determining the solution of time-varying linear equation and inequality systems. By introducing a nonnegative slack variable, the time-varying linear equation and inequality systems are transformed into a mixed nonlinear system. The ZNN model is established via the definition of an indefinite error function and the usage of an exponential decay formula. Theoretical results indicate the convergence property of the proposed ZNN model. Comparative simulation results prove the ZNN effectiveness and superiority for time-varying linear equation and inequality systems. Furthermore, the proposed ZNN model is employed to robot manipulators, thus showing the ZNN applicability.",4
Identification of the Structure of a Probabilistic Boolean Network From Samples Including Frequencies of Outcomes.,"We study the problem of identifying the structure of a probabilistic Boolean network (PBN), a probabilistic model of biological networks, from a given set of samples. This problem can be regarded as an identification of a set of Boolean functions from samples. Existing studies on the identification of the structure of a PBN only use information on the occurrences of samples. In this paper, we also make use of the frequencies of occurrences of subtuples, information that is obtainable from the samples. We show that under this model, it is possible to identify a PBN from among a class of PBNs, for much broader classes of PBNs. In particular, we prove that, under a reasonable assumption, the structure of a PBN can be identified from among the class of PBNs that have at most three functions assigned to each node, but that identification may be impossible if four or more functions are assigned to each node. We also analyze the sample complexity for exactly identifying the structure of a PBN, and present an efficient algorithm for the identification of a PBN consisting of threshold functions from samples.",4
Sparse Supervised Representation-Based Classifier for Uncontrolled and Imbalanced Classification.,"The sparse representation-based classification (SRC) has been utilized in many applications and is an effective algorithm in machine learning. However, the performance of SRC highly depends on the data distribution. Some existing works proved that SRC could not obtain satisfactory results on uncontrolled data sets. Except the uncontrolled data sets, SRC cannot deal with imbalanced classification either. In this paper, we proposed a model named sparse supervised representation classifier (SSRC) to solve the above-mentioned issues. The SSRC involves the class label information during the test sample representation phase to deal with the uncontrolled data sets. In SSRC, each class has the opportunity to linearly represent the test sample in its subspace, which can decrease the influences of the uncontrolled data distribution. In order to classify imbalanced data sets, a class weight learning model is proposed and added to SSRC. Each class weight is learned from its corresponding training samples. The experimental results based on the AR face database (uncontrolled) and 15 KEEL data sets (imbalanced) with an imbalanced rate ranging from 1.48 to 61.18 prove SSRC can effectively classify uncontrolled and imbalanced data sets.",4
Stability Analysis for Delayed Neural Networks via Improved Auxiliary Polynomial-Based Functions.,"This brief is concerned with stability analysis for delayed neural networks (DNNs). By establishing polynomials and introducing slack variables reasonably, some improved delay-product type of auxiliary polynomial-based functions (APFs) is developed to exploit additional degrees of freedom and more information on extra states. Then, by constructing Lyapunov-Krasovskii functional using APFs and integrals of quadratic forms with high order scalar functions, a novel stability criterion is derived for DNNs, in which the benefits of the improved inequalities are fully integrated and the information on delay and its derivative is well reflected. By virtue of the advantages of APFs, more desirable performance is achieved through the proposed approach, which is demonstrated by the numerical examples.",4
Asynchronous Multiplex Communication Channels in 2-D Neural Network With Fluctuating Characteristics.,"Neurons behave like transistors, but have fluctuating characteristics. In this paper, we show that several asynchronous multiplex communication channels can be established in a 2-D mesh neural network with randomly generated weights between eight neighbors. Neurons were simulated by integrate-and-fire neuron models without leakage and with fluctuating refractory period and output delay. If one of the transmitting neuron groups is stimulated, the signal is propagated in the form of spike waves. The corresponding receiving neuron group is able to identify the signal after having learned to form an asynchronous multiplex communication channel. The channel is composed of many intermediate/interstitial neurons working as relays. Each neuron can work as an I/O and as a relay element, i.e., as a multiuse unit. Grouping and synchronic firing is often seen in natural neuronal networks and seems to be effective for stable/robust communication in conjunction with spatial multiplex communication. This communication pattern corresponds to our wet lab experiments on cultured neuronal networks and is similar to sound identification by the ear and mobile adaptive communication systems.",4
Reconstructing Perceived Images From Human Brain Activities With Bayesian Deep Multiview Learning.,"Neural decoding, which aims to predict external visual stimuli information from evoked brain activities, plays an important role in understanding human visual system. Many existing methods are based on linear models, and most of them only focus on either the brain activity pattern classification or visual stimuli identification. Accurate reconstruction of the perceived images from the measured human brain activities still remains challenging. In this paper, we propose a novel deep generative multiview model for the accurate visual image reconstruction from the human brain activities measured by functional magnetic resonance imaging (fMRI). Specifically, we model the statistical relationships between the two views (i.e., the visual stimuli and the evoked fMRI) by using two view-specific generators with a shared latent space. On the one hand, we adopt a deep neural network architecture for visual image generation, which mimics the stages of human visual processing. On the other hand, we design a sparse Bayesian linear model for fMRI activity generation, which can effectively capture voxel correlations, suppress data noise, and avoid overfitting. Furthermore, we devise an efficient mean-field variational inference method to train the proposed model. The proposed method can accurately reconstruct visual images via Bayesian inference. In particular, we exploit a posterior regularization technique in the Bayesian inference to regularize the model posterior. The quantitative and qualitative evaluations conducted on multiple fMRI data sets demonstrate the proposed method can reconstruct visual images more accurately than the state of the art.",4
Visualization Methods for Image Transformation Convolutional Neural Networks.,"Convolutional neural networks (CNNs) are powerful machine learning models that have become the state of the art in several problems in the areas of computer vision and image processing. Nevertheless, the knowledge of why and how these models present an impressive performance is still limited. There are visualization techniques that can help us to understand the inner working of neural networks. However, they have mostly been applied to classification models. In this paper, we evaluate the application of visualization methods to networks where the input and output are images of proportional dimensions. The results show that visualization brings visual cues associated with how these systems work, helping in their understanding and improvement. We use the knowledge obtained from the visualization of an image restoration CNN to improve the architecture's efficiency with no significant degradation of its performance.",4
Integrated Sliding Mode Control and Neural Networks Based Packet Disordering Prediction for Nonlinear Networked Control Systems.,"In this paper, we propose a new scheme based on neural networks for predicting the packet disordering and sliding mode control (SMC) to stabilize the nonlinear networked control systems (NCSs). It is assumed that the packet disordering is unknown in the NCSs. The stochastic configuration networks (SCNs), which randomly assign the input weights and biases and analytically evaluate the output weights, are designed to solve the problem of unknown packet disordering. A new SMC scheme is developed by integrating the SCNs algorithm to learn and control the system in advance. Specifically, a novel measurement of packet disordering is constructed for the quantization of the packet disordering. In addition, the newest signal principle leads to the existence of stochastic parameters, thereby resulting in a Markovian jumping system. The effectiveness of the proposed approach is verified by some simulation results.",4
Fast-Time Stability of Temporal Boolean Networks.,"In real systems, most of the biological functionalities come from the fact that the connections are not active all the time. Based on the fact, temporal Boolean networks (TBNs) are proposed in this paper, and the fast-time stability is analyzed via semi-tensor product (STP) of matrices and incidence matrices. First, the algebraic form of a TBN is obtained based on the STP method, and one necessary and sufficient condition for global fast-time stability is presented. Moreover, incidence matrices are used to obtain several sufficient conditions, which reduce the computational complexity from O(n2(n)) (exponential type) to O(n(4)) (polynomial type) compared with the STP method. In addition, the global fast-time stabilization of TBNs is considered, and pinning controllers are designed based on the neighbors of controlled nodes rather than all the nodes. Finally, the local fast-time stability of TBNs is considered based on the incidence matrices as well. Several examples are provided to illustrate the effectiveness of the obtained results.",4
Self-Tuned Discrimination-Aware Method for Unsupervised Feature Selection.,"Unsupervised feature selection is fundamentally important for processing unlabeled high-dimensional data, and several methods have been proposed on this topic. Most existing embedded unsupervised methods just emphasize the data structure in the input space, which may contain large noise. Therefore, they are limited to perceive the discriminative information implied within the low-dimensional manifold. In addition, these methods always involve several parameters to be tuned, which is time-consuming. In this paper, we present a self-tuned discrimination-aware (STDA) approach for unsupervised feature selection. The main contributions of this paper are threefold: 1) it adopts the advantage of discriminant analysis technique to select the valuable features; 2) it learns the local data structure adaptively in the discriminative subspace to alleviate the effect of data noise; and 3) it performs feature selection and clustering simultaneously with an efficient optimization strategy, and saves the additional efforts to tune parameters. Experimental results on a toy data set and various real-world benchmarks justify the effectiveness of STDA on both feature selection and data clustering, and demonstrate its promising performance against the state of the arts.",4
Function Perturbation Impact on Feedback Stabilization of Boolean Control Networks.,"Function perturbation analysis of Boolean networks is an important topic in the study of gene regulation due to gene mutation or immeasurable variables. This brief studies the function perturbation impact on feedback stabilization of Boolean control networks (BCNs) by using the algebraic state space representation approach. First, the state feedback stabilization control design of BCNs is recalled and the function perturbation problem is formulated. Second, given a state feedback stabilizer, it is robust to the considered function perturbation if one of the following three cases happens: 1) the block where the function perturbation occurs is different from the block which is affected by the state feedback stabilizer (Case 1); 2) when Case 1 does not happen, the perturbed column converges to the equilibrium faster than the original column (Case 2); 3) when Cases 1 and 2 do not happen, the perturbed column does not belong to the reachable set of the original column (Case 3). Third, when the perturbed column belongs to the reachable set of the original column, a constructive procedure is proposed to modify the given state feedback stabilizer to be robust to the function perturbation. Finally, the obtained new results are applied to the function perturbation analysis of lactose operon in Escherichia coli. The main novelty of this brief is to develop a new theoretical framework for the robustness of feedback controllers of BCNs with respect to function perturbation, which is not solved in the existing literature.",4
Dynamic Feature Acquisition Using Denoising Autoencoders.,"In real-world scenarios, different features have different acquisition costs at test time which necessitates cost-aware methods to optimize the cost and performance tradeoff. This paper introduces a novel and scalable approach for cost-aware feature acquisition at test time. The method incrementally asks for features based on the available context that are known feature values. The proposed method is based on sensitivity analysis in neural networks and density estimation using denoising autoencoders with binary representation layers. In the proposed architecture, a denoising autoencoder is used to handle unknown features (i.e., features that are yet to be acquired), and the sensitivity of predictions with respect to each unknown feature is used as a context-dependent measure of informativeness. We evaluated the proposed method on eight different real-world data sets as well as one synthesized data set and compared its performance with several other approaches in the literature. According to the results, the suggested method is capable of efficiently acquiring features at test time in a cost- and context-aware fashion.",4
Set Stabilization of Probabilistic Boolean Networks Using Pinning Control.,"Probabilistic Boolean network (PBN) is a kind of stochastic logical system in which update functions are randomly selected from a set of candidate Boolean functions according to a prescribed probability distribution at each time step. In this brief, a pinning controller design algorithm is proposed to set stabilize any PBN with probability one. First, an algorithm is given to change the columns of its transition matrix. Then, according to the newly obtained transition matrix, a fraction of nodes can be selected as pinning nodes to inject control inputs to achieve set stabilization. The problem is challenging since the Boolean functions in a PBN are not deterministic but are randomly chosen among several Boolean functions. Furthermore, the structure matrices of the pinning controllers are given by solving some logical matrices equations based on which a pinning controller design algorithm is provided to set stabilize the PBN with probability one. Finally, the theoretical results are validated using several examples.",4
Prescribed Performance Model-Free Adaptive Integral Sliding Mode Control for Discrete-Time Nonlinear Systems.,"This paper studies the data-driven prescribed performance control (PPC) problem for a class of discrete-time nonlinear systems in the presence of tracking error constraints. By using the equivalent dynamic linearization technique and constructing a novel transformed error strategy, an adaptive integral sliding mode controller is designed such that the tracking error converges to a predefined neighborhood. Meanwhile, the presented control scheme can effectively ensure that the convergence rate is less than a predefined value and maximum overshoot is not smaller than a preselected constant. In addition, better tracking performance can be achieved by regulating the design parameters appropriately, which is more preferable in the practical application. Contrary to the existing PPC results, the new proposed control law does not use either the plant structure or any knowledge of system dynamics. The efficiency of the proposed control approach is shown with two simulated examples.",4
A Particle Swarm Optimization-Based Flexible Convolutional Autoencoder for Image Classification.,"Convolutional autoencoders (CAEs) have shown their remarkable performance in stacking to deep convolutional neural networks (CNNs) for classifying image data during the past several years. However, they are unable to construct the state-of-the-art CNNs due to their intrinsic architectures. In this regard, we propose a flexible CAE (FCAE) by eliminating the constraints on the numbers of convolutional layers and pooling layers from the traditional CAE. We also design an architecture discovery method by exploiting particle swarm optimization, which is capable of automatically searching for the optimal architectures of the proposed FCAE with much less computational resource and without any manual intervention. We test the proposed approach on four extensively used image classification data sets. Experimental results show that our proposed approach in this paper significantly outperforms the peer competitors including the state-of-the-art algorithms.",4
A Novel and Safe Two-Stage Screening Method for Support Vector Machine.,"To make support vector machine (SVM) applicable to large-scale data sets, safe screening rules are developed recently. The main idea is to reduce the scale of SVM by safely discarding the redundant training samples. Among existing safe screening rules, the dual screening method with variational inequalities (DVI) and the dynamic screening rule (DSR) based on duality gap are two representative strategies. DVI is efficient, while its safety may be affected by inaccurate solving algorithms. DSR is guaranteed to be safe; however, accurate feasible solutions are required for good efficiency. Based on the above-mentioned studies, in this paper, a two-stage screening (TSS) rule, which fully exploits the advantages of the above-mentioned two approaches and improves their shortcomings, is proposed. First, DVI is applied prior to training for sample screening. It reduces the scale of SVM and, meanwhile, produces a better initial feasible solution for DSR. Then, by embedding DSR into the solving algorithm, the solver becomes more accurate, and the safety of DVI can be strengthened. In the end, for safety guarantee, a postchecking step is added to search the wrongly identified samples and retrain them. To theoretically analyze the safety of DVI, an upper bound of the deviation in DVI is estimated, and a Safe-DVI is given based on it. To ensure the efficiency of TSS, the superiority of DVI over initial DSR is verified. In addition, kernel version of TSS is also given for nonlinear SVM. Numerical experiments on synthetic data sets and 12 real-world data sets verify the efficiency and safety of this TSS.",4
Effects of State-Dependent Impulses on Robust Exponential Stability of Quaternion-Valued Neural Networks Under Parametric Uncertainty.,"This paper addresses the state-dependent impulsive effects on robust exponential stability of quaternion-valued neural networks (QVNNs) with parametric uncertainties. In view of the noncommutativity of quaternion multiplication, we have to separate the concerned quaternion-valued models into four real-valued parts. Then, several assumptions ensuring every solution of the separated state-dependent impulsive neural networks intersects each of the discontinuous surface exactly once are proposed. In the meantime, by applying the B -equivalent method, the addressed state-dependent impulsive models are reduced to fixed-time ones, and the latter can be regarded as the comparative systems of the former. For the subsequent analysis, we proposed a novel norm inequality of block matrix, which can be utilized to analyze the same stability properties of the separated state-dependent impulsive models and the reduced ones efficaciously. Afterward, several sufficient conditions are well presented to guarantee the robust exponential stability of the origin of the considered models; it is worth mentioning that two cases of addressed models are analyzed concretely, that is, models with exponential stable continuous subsystems and destabilizing impulses, and models with unstable continuous subsystems and stabilizing impulses. In addition, an application case corresponding to the stability problem of models with unstable continuous subsystems and stabilizing impulses for state-dependent impulse control to robust exponential synchronization of QVNNs is considered summarily. Finally, some numerical examples are proffered to illustrate the effectiveness and correctness of the obtained results.",4
Data Subset Selection With Imperfect Multiple Labels.,"We study the problem of selecting a subset of weakly labeled data where the labels of each data instance are redundant and imperfect. In real applications, less-than-expert labels are obtained at low cost in order to acquire many labels for each instance and then used for estimating the ground truth. However, on one side, preparing and processing data itself sometimes can be even more expensive than labeling. On the other side, noisy labels also decrease the performance of supervised learning methods. Thus, we introduce a new quality control mechanism on labels for each instance and use it to select an optimal subset of data. Based on the quality control mechanism, in which the labeling quality of each instance is estimated, it provides a way to know which instance has enough reliable labels or how many labels still need to be collected for a data instance. In this paper, first, we consider the data subset selection problem under the probably approximately correct model. Then, we show how to find an -optimal labeled instance based on expected labeling quality. Furthermore, we propose new algorithms to select the best k quality instances that have high expected labeling quality. Using a reliable subset of data provides substantial benefit over using all data with imperfect multiple labels, and the expected labeling quality is a good indicator of where to allocate labeling effort. It shows how many labels should be acquired for an instance and which instances are qualified to be selected comparing with others. Both the theoretical guarantees and the comprehensive experiments demonstrate the effectiveness and efficiency of our algorithms.",4
Adaptive Leader-Following Consensus for Multiple Euler-Lagrange Systems With an Uncertain Leader System.,"In this paper, we study the leader-following consensus problem of multiple Euler-Lagrange (EL) systems subject to an uncertain leader system. We first establish an adaptive distributed observer for a neutrally stable linear leader system whose system matrix is not known exactly. Under standard assumptions, this adaptive distributed observer can estimate and pass the leader's state to each follower through the communication network of the system without knowing the leader's system matrix exactly. Under the additional assumption that the leader's state is persistently exciting, this adaptive distributed observer can also asymptotically learn the parameters of the leader's system matrix. On the basis of this adaptive distributed observer, we further synthesize an adaptive distributed control law to solve our problem via the certainty equivalence principle. Our result allows the leader-following consensus problem of multiple EL systems to be solved even if none of the followers knows the system matrix of the leader system exactly.",4
Biased Random Forest For Dealing With the Class Imbalance Problem.,"The class imbalance issue has been a persistent problem in machine learning that hinders the accurate predictive analysis of data in many real-world applications. The class imbalance problem exists when the number of instances present in a class (or classes) is significantly fewer than the number of instances belonging to another class (or classes). Sufficiently recognizing the minority class during classification is a problem as most algorithms employed to learn from data input are biased toward the majority class. The underlying issue is made more complex with the presence of data difficult factors embedded in such data input. This paper presents a novel and effective ensemble-based method for dealing with the class imbalance problem. This paper is motivated by the idea of moving the oversampling from the data level to the algorithm level, instead of increasing the minority instances in the data sets, the algorithms in this paper aims to ""oversample the classification ensemble"" by increasing the number of classifiers that represent the minority class in the ensemble, i.e., random forest. The proposed biased random forest algorithm employs the nearest neighbor algorithm to identify the critical areas in a given data set. The standard random forest is then fed with more random trees generated based on the critical areas. The results show that the proposed algorithm is very effective in dealing with the class imbalance problem.",4
"Fast and Accurate Sparse Coding of Visual Stimuli With a Simple, Ultralow-Energy Spiking Architecture.","Memristive crossbars have become a popular means for realizing unsupervised and supervised learning techniques. In previous neuromorphic architectures with leaky integrate-and-fire neurons, the crossbar itself has been separated from the neuron capacitors to preserve mathematical rigor. In this paper, we sought to design a simplified sparse coding circuit without this restriction, resulting in a fast circuit that approximated a sparse coding operation at a minimal loss in accuracy. We showed that connecting the neurons directly to the crossbar resulted in a more energy-efficient sparse coding architecture and alleviated the need to prenormalize receptive fields. This paper provides derivations for the design of such a network, named the simple spiking locally competitive algorithm, as well as CMOS designs and results on the CIFAR and MNIST data sets. Compared to a nonspiking, nonapproximate model which scored 33% on CIFAR-10 with a single-layer classifier, this hardware scored 32% accuracy. When used with a state-of-the-art deep learning classifier, the nonspiking model achieved 82% and our simplified, spiking model achieved 80% while compressing the input data by 92%. Compared to a previously proposed spiking model, our proposed hardware consumed 99% less energy to do the same work at 21 x the throughput. Accuracy held out with online learning to a write variance of 3%, suitable for the often reported 4-bit resolution required for neuromorphic algorithms, with offline learning to a write variance of 27%, and with read variance to 40%. The proposed architecture's excellent accuracy, throughput, and significantly lower energy usage demonstrate the utility of our innovations.",4
Extreme Learning Machine With Affine Transformation Inputs in an Activation Function.,"The extreme learning machine (ELM) has attracted much attention over the past decade due to its fast learning speed and convincing generalization performance. However, there still remains a practical issue to be approached when applying the ELM: the randomly generated hidden node parameters without tuning can lead to the hidden node outputs being nonuniformly distributed, thus giving rise to poor generalization performance. To address this deficiency, a novel activation function with an affine transformation (AT) on its input is introduced into the ELM, which leads to an improved ELM algorithm that is referred to as an AT-ELM in this paper. The scaling and translation parameters of the AT activation function are computed based on the maximum entropy principle in such a way that the hidden layer outputs approximately obey a uniform distribution. Application of the AT-ELM algorithm in nonlinear function regression shows its robustness to the range scaling of the network inputs. Experiments on nonlinear function regression, real-world data set classification, and benchmark image recognition demonstrate better performance for the AT-ELM compared with the original ELM, the regularized ELM, and the kernel ELM. Recognition results on benchmark image data sets also reveal that the AT-ELM outperforms several other state-of-the-art algorithms in general.",4
Low-Voltage Low-Power Integrable CMOS Circuit Implementation of Integer- and Fractional-Order FitzHugh-Nagumo Neuron Model.,"The low-voltage low-power sinh-domain (SD) implementations of integer- and fractional-order FitzHugh-Nagumo (FHN) neuron model have been introduced in this paper. Besides, the effect of fractional-orders on the external excitation current and dynamics of the neuron has been examined in this paper. The proposed SD designs of FHN neuron model have the benefits of: 1) low-voltage operation; 2) integrability, due to resistor-less design and the employment of only grounded components; 3) electronic tunability of performance parameters; and 4) low-power implementation due to the inherent properties of SD technique. HSPICE simulator tool and Taiwan Semiconductor Manufacturing Company, Hsinchu, Taiwan 130-nm CMOS process was used to evaluate and verify the correct functioning of the model. In addition, to experimentally verify the operation of the proposed fractional-order FHN neuron model, field-programmable analog array (FPAA) implementation of the model has been presented, and the proper functioning of the model has been verified. To the best of the authors' knowledge, this is the first paper that describes the electronic realization of the fractional-order FHN neuron model. In addition, it is the first time that the FPAA implementation of any fractional-order neuron model has been presented.",4
Tracking Sparse Linear Classifiers.,"In this paper, we investigate the problem of sparse online linear classification in changing environments. We first analyze the tracking performance of standard online linear classifiers, which use gradient descent for minimizing the regularized hinge loss. The derived shifting bounds highlight the importance of choosing appropriate step sizes in the presence of concept drifts. Notably, we show that a better adaptability to concept drifts can be achieved using constant step sizes rather than the state-of-the-art decreasing step sizes. Based on these observations, we then propose a novel sparse approximated linear classifier, called sparse approximated linear classification (SALC), which uses a constant step size. In essence, SALC simply rounds small weights to zero for achieving sparsity and controls the truncation error in a principled way for achieving a low tracking regret. The degree of sparsity obtained by SALC is continuous and can be controlled by a parameter which captures the tradeoff between the sparsity of the model and the regret performance of the algorithm. Experiments on nine stationary data sets show that SALC is superior to the state-of-the-art sparse online learning algorithms, especially when the solution is required to be sparse; on seven groups of nonstationary data sets with various total shifting amounts, SALC also presents a good ability to track drifts. When wrapped with a drift detector, SALC achieves a remarkable tracking performance regardless of the total shifting amount.",4
Global Nonfragile Synchronization in Finite Time for Fractional-Order Discontinuous Neural Networks With Nonlinear Growth Activations.,"This paper is concerned with the global nonfragile Mittag-Leffler synchronization and the global synchronization in finite time for fractional-order discontinuous neural networks, where activation functions are discontinuous at 0, or modeled as a local Holder functions with the nonlinear growth property in a neighborhood of 0. First, two lemmas concerned with the convergence with respect to an absolutely continuous function are developed. Second, a new property, which introduces an inequality of the fractional derivative for the variable upper limit integral with respect to the nonsmooth integrable function, is presented and applied in the synchronization results' analysis. In addition, under the fractional Filippov differential inclusion framework, by utilizing the Lur'e Postnikov-type Lyapunov functional, nonsmooth analysis method, and the convergence properties developed in this paper, the synchronization conditions are derived in the form of linear matrix inequalities. Moreover, the upper bound of the setting time for the global nonfragile synchronization in finite time is calculated accurately. Finally, two illustrations are presented to verify the correctness of the theoretical results.",4
Neural Network Filtering Control Design for Nontriangular Structure Switched Nonlinear Systems in Finite Time.,"This paper solves the finite-time switching control issue for the nonstrict-feedback nonlinear switched systems. The controlled plants contain immeasurable states, arbitrarily switchings, and the unknown functions which are constructed with the whole states. Neural network is used to simulate the uncertain systems and a filter-based state observer is designed to estimate the immeasurable states in this paper, respectively. Based on the backstepping recursive technique and the common Lyapunov function method, a finite-time switching control method is presented. Due to the developed finite-time control strategy, the closed-loop signals can be ensured to be bounded under arbitrarily switchings, and the outputs of systems can quickly track the desired reference signals in finite time. The effectiveness of the proposed method is given through its application to a mass-spring-damper system.",4
Topic-Based Algorithm for Multilabel Learning With Missing Labels.,"In multilabel learning (MLL), each instance can be assigned by several concepts simultaneously from a class dictionary. Usually, labels in the class dictionary have semantic correlations and semantic hierarchy. Instances can be categorized into different topics. Each topic has its own label candidates, and some topics have overlapped label candidates. In this paper, we propose a novel MLL method to deal with missing labels. The proposed algorithm can recover the label matrix according to local, topic-wise, and global semantic properties. Specifically, in the global level, label consistency, label-wise semantic correlations, and semantic hierarchy are exploited; in the local level, label importance and instance-wise semantic correlations in each topic are extracted; and in the topic level, label importance similarities and instance-wise semantic similarities between topics are mined. The experimental results on five image data sets in different applications demonstrate the effectiveness of the proposed approach.",4
Multistability of Switched Neural Networks With Piecewise Linear Activation Functions Under State-Dependent Switching.,"This paper is concerned with the multistability of switched neural networks with piecewise linear activation functions under state-dependent switching. Under some reasonable assumptions on the switching threshold and activation functions, by using the state-space decomposition method, contraction mapping theorem, and strictly diagonally dominant matrix theory, we can characterize the number of equilibria as well as analyze the stability/instability of the equilibria. More interesting, we can find that the switching threshold plays an important role for stable equilibria in the unsaturation regions of activation functions, and the number of stable equilibria of an n -neuron switched neural network with state-dependent parameters increases to 3(n) from 2(n) in the conventional one. Furthermore, for two-neuron switched neural networks, the precise attraction basin of each stable equilibrium point can be figured out, and its boundary is composed of the stable manifolds of unstable equilibrium points and the switching lines. Two simulation examples are discussed in detail to substantiate the effectiveness of the theoretical analysis.",4
Adaptive Neural Control of Underactuated Surface Vessels With Prescribed Performance Guarantees.,"This paper presents adaptive neural tracking control of underactuated surface vessels with modeling uncertainties and time-varying external disturbances, where the tracking errors consisting of position and orientation errors are required to keep inside their predefined feasible regions in which the controller singularity problem does not happen. To provide the preselected specifications on the transient and steady-state performances of the tracking errors, the boundary functions of the predefined regions are taken as exponentially decaying functions of time. The unknown external disturbances are estimated by disturbance observers and then are compensated in the feedforward control loop to improve the robustness against the disturbances. Based on the dynamic surface control technique, backstepping procedure, logarithmic barrier functions, and control Lyapunov synthesis, singularity-free controllers are presented to guarantee the satisfaction of predefined performance requirements. In addition to the nominal case when the accurate model of a marine vessel is known a priori, the modeling uncertainties in the form of unknown nonlinear functions are also discussed. Adaptive neural control with the compensations of modeling uncertainties and external disturbances is developed to achieve the boundedness of the signals in the closed-loop system with guaranteed transient and steady-state tracking performances. Simulation results show the performance of the vessel control systems.",4
Robust Subspace Clustering by Cauchy Loss Function.,"Subspace clustering is a problem of exploring the low-dimensional subspaces of high-dimensional data. State-of-the-art approaches are designed by following the model of spectral clustering-based method. These methods pay much attention to learn the representation matrix to construct a suitable similarity matrix and overlook the influence of the noise term on subspace clustering. However, the real data are always contaminated by the noise and the noise usually has a complicated statistical distribution. To alleviate this problem, in this paper, we propose a subspace clustering method based on Cauchy loss function (CLF). Particularly, it uses CLF to penalize the noise term for suppressing the large noise mixed in the real data. This is due to that the CLF's influence function has an upper bound that can alleviate the influence of a single sample, especially the sample with a large noise, on estimating the residuals. Furthermore, we theoretically prove the grouping effect of our proposed method, which means that highly correlated data can be grouped together. Finally, experimental results on five real data sets reveal that our proposed method outperforms several representative clustering methods.",4
L1 -Norm Batch Normalization for Efficient Training of Deep Neural Networks.,"Batch normalization (BN) has recently become a standard component for accelerating and improving the training of deep neural networks (DNNs). However, BN brings in additional calculations, consumes more memory, and significantly slows down the training iteration. Furthermore, the nonlinear square and sqrt operations in the normalization process impede low bit-width quantization techniques, which draw much attention to the deep learning hardware community. In this paper, we propose an L1 -norm BN (L1BN) with only linear operations in both forward and backward propagations during training. L1BN is approximately equivalent to the conventional L2 -norm BN (L2BN) by multiplying a scaling factor that equals (pi/2)(1/2) . Experiments on various convolutional neural networks and generative adversarial networks reveal that L1BN can maintain the same performance and convergence rate as L2BN but with higher computational efficiency. In real application-specified integrated circuit synthesis with reduced resources, L1BN achieves 25% speedup and 37% energy saving compared to the original L2BN. Our hardware-friendly normalization method not only surpasses L2BN in speed but also simplifies the design of deep learning accelerators. Last but not least, L1BN promises a fully quantized training of DNNs, which empowers future artificial intelligence applications on mobile devices with transfer and continual learning capability.",4
The Boundedness Conditions for Model-Free HDP( lambda ).,"This paper provides the stability analysis for a model-free action-dependent heuristic dynamic programing (HDP) approach with an eligibility trace long-term prediction parameter ( lambda ). HDP( lambda ) learns from more than one future reward. Eligibility traces have long been popular in Q-learning. This paper proves and demonstrates that they are worthwhile to use with HDP. In this paper, we prove its uniformly ultimately bounded (UUB) property under certain conditions. Previous works present a UUB proof for traditional HDP [HDP( lambda = 0 )], but we extend the proof with the lambda parameter. By using Lyapunov stability, we demonstrate the boundedness of the estimated error for the critic and actor neural networks as well as learning rate parameters. Three case studies demonstrate the effectiveness of HDP( lambda ). The trajectories of the internal reinforcement signal nonlinear system are considered as the first case. We compare the results with the performance of HDP and traditional temporal difference [TD( lambda )] with different lambda values. The second case study is a single-link inverted pendulum. We investigate the performance of the inverted pendulum by comparing HDP( lambda ) with regular HDP, with different levels of noise. The third case study is a 3-D maze navigation benchmark, which is compared with state action reward state action, Q( lambda ), HDP, and HDP( lambda ). All these simulation results illustrate that HDP( lambda ) has a competitive performance; thus this contribution is not only UUB but also useful in comparison with traditional HDP.",4
Efficient Multispike Learning for Spiking Neural Networks Using Probability-Modulated Timing Method.,"Error functions are normally based on the distance between output spikes and target spikes in supervised learning algorithms for spiking neural networks (SNNs). Due to the discontinuous nature of the internal state of spiking neuron, it is challenging to ensure that the number of output spikes and target spikes kept identical in multispike learning. This problem is conventionally dealt with by using the smaller of the number of desired spikes and that of actual output spikes in learning. However, if this approach is used, information is lost as some spikes are neglected. In this paper, a probability-modulated timing mechanism is built on the stochastic neurons, where the discontinuous spike patterns are converted to the likelihood of generating the desired output spike trains. By applying this mechanism to a probability-modulated spiking classifier, a probability-modulated SNN (PMSNN) is constructed. In its multilayer and multispike learning structure, more inputs are incorporated and mapped to the target spike trains. A clustering rule connection mechanism is also applied to a reservoir to improve the efficiency of information transmission among synapses, which can map the highly correlated inputs to the adjacent neurons. Results of comparisons between the proposed method and popular the SNN algorithms showed that the PMSNN yields higher efficiency and requires fewer parameters.",4
A Cross-Domain Recommender System With Kernel-Induced Knowledge Transfer for Overlapping Entities.,"The aim of recommender systems is to automatically identify user preferences within collected data, then use those preferences to make recommendations that help with decisions. However, recommender systems suffer from data sparsity problem, which is particularly prevalent in newly launched systems that have not yet had enough time to amass sufficient data. As a solution, cross-domain recommender systems transfer knowledge from a source domain with relatively rich data to assist recommendations in the target domain. These systems usually assume that the entities either fully overlap or do not overlap at all. In practice, it is more common for the entities in the two domains to partially overlap. Moreover, overlapping entities may have different expressions in each domain. Neglecting these two issues reduces prediction accuracy of cross-domain recommender systems in the target domain. To fully exploit partially overlapping entities and improve the accuracy of predictions, this paper presents a cross-domain recommender system based on kernel-induced knowledge transfer, called KerKT. Domain adaptation is used to adjust the feature spaces of overlapping entities, while diffusion kernel completion is used to correlate the non-overlapping entities between the two domains. With this approach, knowledge is effectively transferred through the overlapping entities, thus alleviating data sparsity issues. Experiments conducted on four data sets, each with three sparsity ratios, show that KerKT has 1.13%-20% better prediction accuracy compared with six benchmarks. In addition, the results indicate that transferring knowledge from the source domain to the target domain is both possible and beneficial with even small overlaps.",4
Shared Nearest-Neighbor Quantum Game-Based Attribute Reduction With Hierarchical Coevolutionary Spark and Its Application in Consistent Segmentation of Neonatal Cerebral Cortical Surfaces.,"The unprecedented increase in data volume has become a severe challenge for conventional patterns of data mining and learning systems tasked with handling big data. The recently introduced Spark platform is a new processing method for big data analysis and related learning systems, which has attracted increasing attention from both the scientific community and industry. In this paper, we propose a shared nearest-neighbor quantum game-based attribute reduction (SNNQGAR) algorithm that incorporates the hierarchical coevolutionary Spark model. We first present a shared coevolutionary nearest-neighbor hierarchy with self-evolving compensation that considers the features of nearest-neighborhood attribute subsets and calculates the similarity between attribute subsets according to the shared neighbor information of attribute sample points. We then present a novel attribute weight tensor model to generate ranking vectors of attributes and apply them to balance the relative contributions of different neighborhood attribute subsets. To optimize the model, we propose an embedded quantum equilibrium game paradigm (QEGP) to ensure that noisy attributes do not degrade the big data reduction results. A combination of the hierarchical coevolutionary Spark model and an improved MapReduce framework is then constructed that it can better parallelize the SNNQGAR to efficiently determine the preferred reduction solutions of the distributed attribute subsets. The experimental comparisons demonstrate the superior performance of the SNNQGAR, which outperforms most of the state-of-the-art attribute reduction algorithms. Moreover, the results indicate that the SNNQGAR can be successfully applied to segment overlapping and interdependent fuzzy cerebral tissues, and it exhibits a stable and consistent segmentation performance for neonatal cerebral cortical surfaces.",4
Two-Dimensional Quaternion PCA and Sparse PCA.,"Benefited from quaternion representation that is able to encode the cross-channel correlation of color images, quaternion principle component analysis (QPCA) was proposed to extract features from color images while reducing the feature dimension. A quaternion covariance matrix (QCM) of input samples was constructed, and its eigenvectors were derived to find the solution of QPCA. However, eigen-decomposition leads to the fixed solution for the same input. This solution is susceptible to outliers and cannot be further optimized. To solve this problem, this paper proposes a novel quaternion ridge regression (QRR) model for two-dimensional QPCA (2D-QPCA). We mathematically prove that this QRR model is equivalent to the QCM model of 2D-QPCA. The QRR model is a general framework and is flexible to combine 2D-QPCA with other technologies or constraints to adapt different requirements of real-world applications. Including sparsity constraints, we then propose a quaternion sparse regression model for 2D-QSPCA to improve its robustness for classification. An alternating minimization algorithm is developed to iteratively learn the solution of 2D-QSPCA in the equivalent complex domain. In addition, 2D-QPCA and 2D-QSPCA can preserve the spatial structure of color images and have a low computation cost. Experiments on several challenging databases demonstrate that 2D-QPCA and 2D-QSPCA are effective in color face recognition, and 2D-QSPCA outperforms the state of the arts.",4
Neuroadaptive Fault-Tolerant Control of Quadrotor UAVs: A More Affordable Solution.,"This paper investigates the position and attitude tracking control problem of a quadrotor unmanned aerial vehicle subject to modeling uncertainties and actuator failures. A comprehensive mathematical model reflecting the nonlinearity and state-space coupling of the dynamics as well as actuation faults and external disturbances is derived. By combining the radial basis function neural networks (NNs) with virtual parameter estimating algorithms, an indirect NN-based adaptive fault-tolerant control scheme is developed, which exhibits several attractive features as compared with most existing methods: 1) it is not only robust and adaptive to nonparametric uncertainties but also tolerant to unexpected actuation faults; 2) it ensures stable tracking without the need for precise information on system model; and 3) it only involves one lumped parameter adaptation, thus is structurally simpler and computationally less expensive, rendering the resultant scheme less demanding in programming and more affordable for onboard implementation. The effectiveness and benefits of the proposed method are confirmed via computer simulation.",4
Toward Resolution-Invariant Person Reidentification via Projective Dictionary Learning.,"Person reidentification (ReID) has recently been widely investigated for its vital role in surveillance and forensics applications. This paper addresses the low-resolution (LR) person ReID problem, which is of great practical meaning because pedestrians are often captured in LRs by surveillance cameras. Existing methods cope with this problem via some complicated and time-consuming strategies, making them less favorable, in practice, and meanwhile, their performances are far from satisfactory. Instead, we solve this problem by developing a discriminative semicoupled projective dictionary learning (DSPDL) model, which adopts the efficient projective dictionary learning strategy, and jointly learns a pair of dictionaries and a mapping function to model the correspondence of the cross-view data. A parameterless cross-view graph regularizer incorporating both positive and negative pair information is designed to enhance the discriminability of the dictionaries. Another weakness of existing approaches to this problem is that they are only applicable for the scenario where the cross-camera image sets have a globally uniform resolution gap. This fact undermines their practicality because the resolution gaps between cross-camera images often vary person by person in practice. To overcome this hurdle, we extend the proposed DSPDL model to the variational resolution gap scenario, basically by learning multiple pairs of dictionaries and multiple mapping functions. A novel technique is proposed to rerank and fuse the results obtained from all dictionary pairs. Experiments on five public data sets show the proposed method achieves superior performances to the state-of-the-art ones.",4
Seeing All From a Few: l1 -Norm-Induced Discriminative Prototype Selection.,"Prototype selection aims to remove redundancy and irrelevance from large-scale data by selecting an informative subset, which makes it possible to see all data from a few prototypes. However, due to the outliers and uncertain distribution of the data, the selected prototypes are generally less representative and diversified. To alleviate this issue, we develop, in this paper, a l1 -norm-induced discriminative prototype selection model ( l1 -ProSe). Inspired by the good performance of sparse representation, the sparsity property of data is rationally exploited in the formulated model. Meanwhile, to characterize the pairwise similarity in the learned sparse representation space, a more promising l1 -norm metric is applied for robust selection instead of the popularly used Euclidean metric in previous works. Considering the convexity of the model to be solved, a composite block coordinate descent solver is presented with rigorous theoretical analysis on its convergence. Furthermore, we extend our model to support online prototype selection by using already obtained prototypes and newly arrived data. Experimental results on synthetic data sets and some applications such as video summarization, motion segmentation, and scene categorization demonstrate that the proposed method is considerably superior to the state-of-the-art methods in the prototype selection.",4
Inverting the Generator of a Generative Adversarial Network.,"Generative adversarial networks (GANs) learn a deep generative model that is able to synthesize novel, high-dimensional data samples. New data samples are synthesized by passing latent samples, drawn from a chosen prior distribution, through the generative model. Once trained, the latent space exhibits interesting properties that may be useful for downstream tasks such as classification or retrieval. Unfortunately, GANs do not offer an ``inverse model,'' a mapping from data space back to latent space, making it difficult to infer a latent representation for a given data sample. In this paper, we introduce a technique, inversion, to project data samples, specifically images, to the latent space using a pretrained GAN. Using our proposed inversion technique, we are able to identify which attributes of a data set a trained GAN is able to model and quantify GAN performance, based on a reconstruction loss. We demonstrate how our proposed inversion technique may be used to quantitatively compare the performance of various GAN models trained on three image data sets. We provide codes for all of our experiments in the website (https://github.com/ToniCreswell/InvertingGAN).",4
Convergence Conditions for Solving Robust Iterative Learning Control Problems Under Nonrepetitive Model Uncertainties.,"Learning from saved measurement and control data to refine the performance of output tracking is the core feature of iterative learning control (ILC). Even though this implementation process of ILC does not need any model knowledge, ILC typically requires the strict repetitiveness of the control systems, especially on the plant models of them. The questions of interest in this paper are: 1) whether and how can robust ILC problems be solved with respect to the nonrepetitive (or iteration-dependent) model uncertainties and 2) can convergence conditions be developed with the effective contraction mapping (CM)-based approach to ILC? The answers to these questions are affirmative, and the CM-based approach is applicable to robust ILC that accommodates certain nonrepetitive uncertainties, especially in the plant models. In particular, an Hinfinity -norm condition is proposed to ensure the robust ILC convergence, which can be solved to determine learning gain matrices. Simulation tests are performed to illustrate the validity of our presented Hinfinity -based analysis results.",4
Deep FisherNet for Image Classification.,"Despite the great success of convolutional neural networks (CNNs) for the image classification task on data sets such as Cifar and ImageNet, CNN's representation power is still somewhat limited in dealing with images that have a large variation in size and clutter, where Fisher vector (FV) has shown to be an effective encoding strategy. FV encodes an image by aggregating local descriptors with a universal generative Gaussian mixture model (GMM). FV, however, has limited learning capability and its parameters are mostly fixed after constructing the codebook. To combine together the best of the two worlds, we propose in this brief a neural network structure with FV layer being part of an end-to-end trainable system that is differentiable; we name our network FisherNet that is learnable using back propagation. Our proposed FisherNet combines CNN training and FV encoding in a single end-to-end structure. We observe a clear advantage of FisherNet over plain CNN and standard FV in terms of both classification accuracy and computational efficiency on the challenging PASCAL visual object classes object classification and emotion image classification tasks.",4
Global Exponential Stability and Synchronization for Discrete-Time Inertial Neural Networks With Time Delays: A Timescale Approach.,"This paper considers generalized discrete-time inertial neural network (GDINN). By timescale theory, the original network is rewritten as a timescale-type inertial NN. Two different scenarios are considered. In a first scenario, several criteria guaranteeing the global exponential stability for the addressed GDINN are obtained based on the generalized matrix measure concept. In this case, Lyapunov function or functional is not necessary. In a second scenario, some inequality analytical and scaling techniques are used to achieve the global exponential stability for the considered GDINN. The obtained criteria are also applied to the global exponential synchronization of drive-response GDINNs. Several illustrative examples, including applications to the pseudorandom number generator and encrypted image transmission, are given to show the effectiveness of the theoretical results.",4
Training Passive Photonic Reservoirs With Integrated Optical Readout.,"As Moore's law comes to an end, neuromorphic approaches to computing are on the rise. One of these, passive photonic reservoir computing, is a strong candidate for computing at high bitrates (>10 Gb/s) and with low energy consumption. Currently though, both benefits are limited by the necessity to perform training and readout operations in the electrical domain. Thus, efforts are currently underway in the photonic community to design an integrated optical readout, which allows to perform all operations in the optical domain. In addition to the technological challenge of designing such a readout, new algorithms have to be designed in order to train it. Foremost, suitable algorithms need to be able to deal with the fact that the actual on-chip reservoir states are not directly observable. In this paper, we investigate several options for such a training algorithm and propose a solution in which the complex states of the reservoir can be observed by appropriately setting the readout weights, while iterating over a predefined input sequence. We perform numerical simulations in order to compare our method with an ideal baseline requiring full observability as well as with an established black-box optimization approach (CMA-ES).",4
Weighted p -Bits for FPGA Implementation of Probabilistic Circuits.,"Probabilistic spin logic is a recently proposed computing paradigm based on unstable stochastic units called probabilistic bits ( p -bits) that can be correlated to form probabilistic circuits (p-circuits). These p-circuits can be used to solve the problems of optimization, inference, and implement precise Boolean functions in an ""inverted"" mode, where a given Boolean circuit can operate in reverse to find the input combinations that are consistent with a given output. In this brief, we present a scalable field-programmable gate array implementation of such invertible p-circuits. We implement a ""weighted"" p -bit that combines stochastic units with localized memory structures. We also present a generalized tile of weighted p -bits to which a large class of problems beyond invertible Boolean logic can be mapped and how invertibility can be applied to interesting problems such as the NP-complete subset sum problem by solving a small instance of this problem in hardware.",4
Multidimensional Balance-Based Cluster Boundary Detection for High-Dimensional Data.,"The balance of neighborhood space around a central point is an important concept in cluster analysis. It can be used to effectively detect cluster boundary objects. The existing neighborhood analysis methods focus on the distribution of data, i.e., analyzing the characteristic of the neighborhood space from a single perspective, and could not obtain rich data characteristics. In this paper, we analyze the high-dimensional neighborhood space from multiple perspectives. By simulating each dimension of a data point's k nearest neighbors space ( k NNs) as a lever, we apply the lever principle to compute the balance fulcrum of each dimension after proving its inevitability and uniqueness. Then, we model the distance between the projected coordinate of the data point and the balance fulcrum on each dimension and construct the DHBlan coefficient to measure the balance of the neighborhood space. Based on this theoretical model, we propose a simple yet effective cluster boundary detection algorithm called Lever. Experiments on both low- and high-dimensional data sets validate the effectiveness and efficiency of our proposed algorithm.",4
Nonfragile Dissipative Synchronization for Markovian Memristive Neural Networks: A Gain-Scheduled Control Scheme.,"In this paper, the dissipative synchronization control problem for Markovian jump memristive neural networks (MNNs) is addressed with fully considering the time-varying delays and the fragility problem in the process of implementing the gain-scheduled controller. A Markov jump model is introduced to describe the stochastic changing among the connection of MNNs and it makes the networks under consideration suitable for some actual circumstances. By utilizing some improved integral inequalities and constructing a proper Lyapunov-Krasovskii functional, several delay-dependent synchronization criteria with less conservatism are established to ensure the dynamic error system is strictly stochastically dissipative. Based on these criteria, the procedure of designing the desired nonfragile gain-scheduled controller is established, which can well handle the fragility problem in the process of implementing the controller. Finally, an illustrated example is employed to explain that the developed method is efficient and available.",4
Model Order Reduction Based on Agglomerative Hierarchical Clustering.,"This paper presents an improved method for reducing high-order dynamical system models via clustering. Agglomerative hierarchical clustering based on performance evaluation (HC-PE) is introduced for model order reduction. This method computes the reduced order denominator of the transfer function model by clustering system poles in a hierarchical dendrogram. The base layer represents an nth order system, which is used to calculate each successive layer to reduce the model order until finally reaching a second-order system. HC-PE uses a mean-squared error (MSE) in every reduced order, which modifies the pole placement process. The coefficients for the numerator of the reduced model are calculated by using the Pade approximation (PA) or alternatively a genetic algorithm (GA). Several numerical examples of reducing techniques are taken from the literature to compare with HC-PE. Two classes of results are shown in this paper. The first sets are single-input single-output models that range from simple models to 48th order systems. The second sets of experiments are with a multi-input multioutput model. We demonstrate the best performance for HC-PE through minimum MSEs compared with other methods. Furthermore, the robustness of HC-PE combined with PA or GA is confirmed by evaluating the third-order reduced model for the triple-link inverted pendulum model by adding a disturbance impulse signal and by changing model parameters. The relevant stability proofs are provided in Appendixes A and B in the supplementary material. HC-PE with PA slightly outperforms its performance with GA, but both approaches are attractive alternatives to other published methods.",4
On the Universality of Memcomputing Machines.,"Universal memcomputing machines (UMMs) represent a novel computational model in which memory (time nonlocality) accomplishes both tasks of storing and processing of information. UMMs have been shown to be Turing-complete, namely, they can simulate any Turing machine. In this paper, we first introduce a novel set theory approach to compare different computational models and use it to recover the previous results on Turing-completeness of UMMs. We then relate UMMs directly to liquid-state machines (or ""reservoir-computing"") and quantum machines (""quantum computing""). We show that UMMs can simulate both types of machines, hence they are both ""liquid-"" or ""reservoir-complete"" and ""quantum-complete."" Of course, these statements pertain only to the type of problems these machines can solve and not to the amount of resources required for such simulations. Nonetheless, the set-theoretic method presented here provides a general framework which describes the relationship between any computational models.",4
Stable and Efficient Policy Evaluation.,"Policy evaluation algorithms are essential to reinforcement learning due to their ability to predict the performance of a policy. However, there are two long-standing issues lying in this prediction problem that need to be tackled: off-policy stability and on-policy efficiency. The conventional temporal difference (TD) algorithm is known to perform very well in the on-policy setting, yet is not off-policy stable. On the other hand, the gradient TD and emphatic TD algorithms are off-policy stable, but are not on-policy efficient. This paper introduces novel algorithms that are both off-policy stable and on-policy efficient by using the oblique projection method. The empirical experimental results on various domains validate the effectiveness of the proposed approach.",4
Deep Transfer Low-Rank Coding for Cross-Domain Learning.,"Transfer learning has attracted great attention to facilitate the sparsely labeled or unlabeled target learning by leveraging previously well-established source domain through knowledge transfer. Recent activities on transfer learning attempt to build deep architectures to better fight off cross-domain divergences by extracting more effective features. However, its generalizability would decrease greatly due to the domain mismatch enlarges, particularly at the top layers. In this paper, we develop a novel deep transfer low-rank coding based on deep convolutional neural networks, where we investigate multilayer low-rank coding at the top task-specific layers. Specifically, multilayer common dictionaries shared across two domains are obtained to bridge the domain gap such that more enriched domain-invariant knowledge can be captured through a layerwise fashion. With rank minimization on the new codings, our model manages to preserve the global structures across source and target, and thus, similar samples of two domains tend to gather together for effective knowledge transfer. Furthermore, domain/classwise adaption terms are integrated to guide the effective coding optimization in a semisupervised manner, so the marginal and conditional disparities of two domains will be alleviated. Experimental results on three visual domain adaptation benchmarks verify the effectiveness of our proposed approach on boosting the recognition performance for the target domain, by comparing it with other state-of-the-art deep transfer learning.",4
Maximum Likelihood Estimation-Based Joint Sparse Representation for the Classification of Hyperspectral Remote Sensing Images.,"A joint sparse representation (JSR) method has shown superior performance for the classification of hyperspectral images (HSIs). However, it is prone to be affected by outliers in the HSI spatial neighborhood. In order to improve the robustness of JSR, we propose a maximum likelihood estimation (MLE)-based JSR (MLEJSR) model, which replaces the traditional quadratic loss function with an MLE-like estimator for measuring the joint approximation error. The MLE-like estimator is actually a function of coding residuals. Given some priors on the coding residuals, the MLEJSR model can be easily converted to an iteratively reweighted JSR problem. Choosing a reasonable weight function, the effect of inhomogeneous neighboring pixels or outliers can be dramatically reduced. We provide a theoretical analysis of MLEJSR from the viewpoint of recovery error and evaluate its empirical performance on three public hyperspectral data sets. Both the theoretical and experimental results demonstrate the effectiveness of our proposed MLEJSR method, especially in the case of large noise.",4
Adaptive Neural Control for MIMO Pure-Feedback Nonlinear Systems With Periodic Disturbances.,"In this paper, an adaptive neural control design method is presented for a class of multiple-input-multiple-output (MIMO) pure-feedback nonlinear systems with periodically time-varying disturbances appearing nonlinearly in unknown nonaffine functions. The nonaffine functions do not need to be differentiable, and the bounded condition of unknown nonaffine functions is relaxed such that only a more general semibounded assumption is required as the controllability condition of the considered MIMO pure-feedback system. To facilitate the control design, the gain functions are designed to be continuous and positive with the bounds being unknown functions. Furthermore, for handling with the difficulty caused by these unknown bounds, several appropriate compact sets are defined to obtain the bounds of gain functions. By utilizing Lyapunov analysis, all the variables of the resulting closed-loop system are proven to be semiglobally uniformly ultimately bounded, and the tracking error can converge to an arbitrarily small neighborhood around zero by choosing design parameters appropriately. The effectiveness of the proposed control algorithm is demonstrated by two simulations.",4
Attention Inspiring Receptive-Fields Network for Learning Invariant Representations.,"In this paper, we describe a simple and highly efficient module for image classification, which we term the ""Attention Inspiring Receptive-fields"" (Air) module. We effectively convert the spatial attention mechanism into a plug-in module. In addition, we reveal the relationship between the spatial attention mechanism and the receptive fields, indicating that the proper use of the spatial attention mechanism can effectively increase the receptive fields of the module, which is able to enhance translation invariance and scale invariance of the network. By integrating the Air module into advanced convolutional neural networks (such as ResNet and ResNeXt), we can construct AirNet architectures for learning invariant representations and gain significant improvements on challenging data sets. We present extensive experiments on CIFAR and ImageNet data sets to verify the effectiveness and feature invariance of the Air module and explore more concise and efficient designs of the proposed module. On ImageNet classification, our AirNet-50 and AirNet-101 (ResNet-50/101 with Air module) achieve 1.69% and 1.50% top-1 accuracy improvement with a small amount of extra computation and parameters compared with the original ResNet. We make models and code public available https://github.com/soeaver/AirNet-PyTorch. We further demonstrate that AirNet has a good ability for transfer learning and measure the performance on Microsoft Common Objects in Context object detection, instance segmentation, and pose estimation.",4
Finite-Time Distributed Average Tracking for Second-Order Nonlinear Systems.,"This paper studies the distributed average tracking (DAT) problem for multiple reference signals described by the second-order nonlinear dynamical systems. Leveraging the state-dependent gain design and the adaptive control approaches, a couple of DAT algorithms are developed in this paper, which are named finite-time and adaptive-gain DAT algorithms. Based on the finite-time one, the states of the physical agents in this paper can track the average of the time-varying reference signals within a finite settling time. Furthermore, the finite settling time is also estimated by considering a well-designed Lyapunov function in this paper. Compared with asymptotical DAT algorithms, the proposed finite-time algorithm not only solve finite-time DAT problems but also ensure states of physical agents to achieve an accurate average of the multiple signals. Then, an adaptive-gain DAT algorithm is designed. Based on the adaptive-gain one, the DAT problem is solved without global information. Thus, it is fully distributed. Finally, numerical simulations show the effectiveness of the theoretical results.",4
Feature Extraction for Incomplete Data Via Low-Rank Tensor Decomposition With Feature Regularization.,"Multidimensional data (i.e., tensors) with missing entries are common in practice. Extracting features from incomplete tensors is an important yet challenging problem in many fields such as machine learning, pattern recognition, and computer vision. Although the missing entries can be recovered by tensor completion techniques, these completion methods focus only on missing data estimation instead of effective feature extraction. To the best of our knowledge, the problem of feature extraction from incomplete tensors has yet to be well explored in the literature. In this paper, we therefore tackle this problem within the unsupervised learning environment. Specifically, we incorporate low-rank tensor decomposition with feature variance maximization (TDVM) in a unified framework. Based on orthogonal Tucker and CP decompositions, we design two TDVM methods, TDVM-Tucker and TDVM-CP, to learn low-dimensional features viewing the core tensors of the Tucker model as features and viewing the weight vectors of the CP model as features. TDVM explores the relationship among data samples via maximizing feature variance and simultaneously estimates the missing entries via low-rank Tucker/CP approximation, leading to informative features extracted directly from observed entries. Furthermore, we generalize the proposed methods by formulating a general model that incorporates feature regularization into low-rank tensor approximation. In addition, we develop a joint optimization scheme to solve the proposed methods by integrating the alternating direction method of multipliers with the block coordinate descent method. Finally, we evaluate our methods on six real-world image and video data sets under a newly designed multiblock missing setting. The extracted features are evaluated in face recognition, object/action classification, and face/gait clustering. Experimental results demonstrate the superior performance of the proposed methods compared with the state-of-the-art approaches.",4
Eigenfunction-Based Multitask Learning in a Reproducing Kernel Hilbert Space.,"Multitask learning aims to improve the performance on related tasks by exploring the interdependence among them. Existing multitask learning methods explore the relatedness among tasks on the basis of the input features and the model parameters. In this paper, we focus on nonparametric multitask learning and propose to measure task relatedness from a novel perspective in a reproducing kernel Hilbert space (RKHS). Past works have shown that the objective function for a given task can be approximated using the top eigenvalues and corresponding eigenfunctions of a predefined integral operator on an RKHS. In our method, we formulate our objective for multitask learning as a linear combination of two sets of eigenfunctions, common eigenfunctions shared by different tasks and unique eigenfunctions in individual tasks, such that the eigenfunctions for one task can provide additional information on another and help to improve its performance. We present both theoretical and empirical validations of our proposed approach. The theoretical analysis demonstrates that our learning algorithm is uniformly argument stable and that the convergence rate of the generalization upper bound can be improved by learning multiple tasks. Experiments on several benchmark multitask learning data sets show that our method yields promising results.",4
Nonrigid Point Set Registration With Robust Transformation Learning Under Manifold Regularization.,"This paper solves the problem of nonrigid point set registration by designing a robust transformation learning scheme. The principle is to iteratively establish point correspondences and learn the nonrigid transformation between two given sets of points. In particular, the local feature descriptors are used to search the correspondences and some unknown outliers will be inevitably introduced. To precisely learn the underlying transformation from noisy correspondences, we cast the point set registration into a semisupervised learning problem, where a set of indicator variables is adopted to help distinguish outliers in a mixture model. To exploit the intrinsic structure of a point set, we constrain the transformation with manifold regularization which plays a role of prior knowledge. Moreover, the transformation is modeled in the reproducing kernel Hilbert space, and a sparsity-induced approximation is utilized to boost efficiency. We apply the proposed method to learning motion flows between image pairs of similar scenes for visual homing, which is a specific type of mobile robot navigation. Extensive experiments on several publicly available data sets reveal the superiority of the proposed method over state-of-the-art competitors, particularly in the context of the degenerated data.",4
Finite-Horizon l2-linfinity Synchronization for Time-Varying Markovian Jump Neural Networks Under Mixed-Type Attacks: Observer-Based Case.,"This paper studies the synchronization issue of time-varying Markovian jump neural networks (NNs). The denial-of-service (DoS) attack is considered in the communication channel connecting master NNs and slave NNs. An observer is designed based on the measurements of master NNs transmitted over this unreliable channel to estimate their states. The deception attack is used to destroy the controller by changing the sign of the control signal. Then, the mixed-type attacks are expressed uniformly, and a synchronization error system is established using this function. A finite-horizon l2-linfinity performance is proposed, and sufficient conditions are derived to ensure that the synchronization error system satisfies this performance. The controllers are then obtained by a recursive linear matrix inequality algorithm. At last, a simulation result to show the feasibility of the developed results is given.",4
Coupled Neural P Systems.,"Inspired by Eckhorn's neuron model that emulates a mammal's visual cortex, this paper proposes a new kind of neural-like P system, called a coupled neural P (CNP) system. The CNP system consists of some coupled neurons, each with three components: receptive field, modulation, and output module. CNP systems are a kind of distributed parallel-computing model with a directed graph structure like spiking neural P systems. Moreover, CNP systems have a nonlinear coupled-modulation characteristic and a dynamic threshold mechanism. The computational power of CNP systems is discussed. Specifically, it is proved that CNP systems as number-generating devices are Turing universal. Moreover, we provide a small universal CNP system for function-computing devices.",4
Training Lightweight Deep Convolutional Neural Networks Using Bag-of-Features Pooling.,"Convolutional neural networks (CNNs) are predominantly used for several challenging computer vision tasks achieving state-of-the-art performance. However, CNNs are complex models that require the use of powerful hardware, both for training and deploying them. To this end, a quantization-based pooling method is proposed in this paper. The proposed method is inspired from the bag-of-features model and can be used for learning more lightweight deep neural networks. Trainable radial basis function neurons are used to quantize the activations of the final convolutional layer, reducing the number of parameters in the network and allowing for natively classifying images of various sizes. The proposed method employs differentiable quantization and aggregation layers leading to an end-to-end trainable CNN architecture. Furthermore, a fast linear variant of the proposed method is introduced and discussed, providing new insight for understanding convolutional neural architectures. The ability of the proposed method to reduce the size of CNNs and increase the performance over other competitive methods is demonstrated using seven data sets and three different learning tasks (classification, regression, and retrieval).",4
Axially Symmetric Data Clustering Through Dirichlet Process Mixture Models of Watson Distributions.,"This paper proposes a Bayesian nonparametric framework for clustering axially symmetric data. Our approach is based on a Dirichlet processes mixture model with Watson distributions, which can also be considered as the infinite Watson mixture model. In this paper, first, we extend the finite Watson mixture model into its infinite counterpart based on the framework of truncated Dirichlet process mixture model with a stick-breaking representation. Second, we propose a coordinate ascent mean-field variational inference algorithm that can effectively learn the parameters of our model with closed-form solutions; Third, to cope with a massive data set, we develop a stochastic variational inference algorithm to learn the proposed model through the method of stochastic gradient ascent; Finally, the proposed nonparametric Bayesian model is evaluated through simulated axially symmetric data sets and a real-world application, namely, gene expression data clustering.",4
Data Augmentation-Based Joint Learning for Heterogeneous Face Recognition.,"Heterogeneous face recognition (HFR) is the process of matching face images captured from different sources. HFR plays an important role in security scenarios. However, HFR remains a challenging problem due to the considerable discrepancies (i.e., shape, style, and color) between cross-modality images. Conventional HFR methods utilize only the information involved in heterogeneous face images, which is not effective because of the substantial differences between heterogeneous face images. To better address this issue, this paper proposes a data augmentation-based joint learning (DA-JL) approach. The proposed method mutually transforms the cross-modality differences by incorporating synthesized images into the learning process. The aggregated data augments the intraclass scale, which provides more discriminative information. However, this method also reduces the interclass diversity (i.e., discriminative information). We develop the DA-JL model to balance this dilemma. Finally, we obtain the similarity score between heterogeneous face image pairs through the log-likelihood ratio. Extensive experiments on a viewed sketch database, forensic sketch database, near-infrared image database, thermal-infrared image database, low-resolution photo database, and image with occlusion database illustrate that the proposed method achieves superior performance in comparison with the state-of-the-art methods.",4
The State Following Approximation Method.,"A function approximation method is developed which aims to approximate a function in a small neighborhood of a state that travels within a compact set. The method provides a novel approximation strategy for the efficient approximation of nonlinear functions for real-time simulations and experiments. The development is based on the theory of universal reproducing kernel Hilbert spaces over the n -dimensional Euclidean space. Several theorems are introduced which support the development of this state following (StaF) method. In particular, it is shown that there is a bound on the number of kernel functions required for the maintenance of an accurate function approximation as a state moves through a compact set. In addition, a weight update law, based on gradient descent, is introduced where arbitrarily close accuracy can be achieved provided the weight update law is iterated at a sufficient frequency, as detailed in Theorem 4. An experience-based approximation method is presented which utilizes the samples of the estimations of the ideal weights to generate a global approximation of a function. The experience-based approximation interpolates the samples of the weight estimates using radial basis functions. To illustrate the StaF method, the method is utilized for derivative estimation, function approximation, and is applied to an adaptive dynamic programming problem where it is demonstrated that the stability is maintained with a reduced number of basis functions.",4
Time-Varying Formation Tracking for UAV Swarm Systems With Switching Directed Topologies.,"Time-varying formation tracking (TVFT) control problems for a team of unmanned aerial vehicles (UAVs) with switching and directed interaction topologies are investigated, where the follower UAVs realize a given time-varying formation while tracking the leader UAV. A TVFT control protocol is firstly constructed utilizing local neighboring information, where the information of the leader UAV is only available to partial followers and the neighborhood can be switching. An algorithm composed of four steps is provided to design the TVFT protocol. It is proved that the UAV swarm system can realize the TVFT using the designed protocol if the dwell time for the switching directed topologies is larger than a fixed threshold and the TVFT feasibility condition is satisfied. Based on the ultrawideband positioning technology, a quadrotor UAV formation control platform with four quadrotor UAVs is given. The obtained theoretical results are applied to solve the target enclosing problems of the UAV swarm systems. A flying experiment for three follower quadrotor UAVs to enclose a leader quadrotor UAV is carried out to verify the effectiveness of the presented results.",4
Adaptive Neural Control of a Kinematically Redundant Exoskeleton Robot Using Brain-Machine Interfaces.,"In this paper, a closed-loop control has been developed for the exoskeleton robot system based on brain-machine interface (BMI). Adaptive controllers in joint space, a redundancy resolution method at the velocity level, and commands that generated from BMI in task space have been integrated effectively to make the robot perform manipulation tasks controlled by human operator's electroencephalogram. By extracting the features from neural activity, the proposed intention decoding algorithm can generate the commands to control the exoskeleton robot. To achieve optimal motion, a redundancy resolution at the velocity level has been implemented through neural dynamics optimization. Considering human-robot interaction force as well as coupled dynamics during the exoskeleton operation, an adaptive controller with redundancy resolution has been designed to drive the exoskeleton tracking the planned trajectory in human brain and to offer a convenient method of dynamics compensation with minimal knowledge of the dynamics parameters of the exoskeleton robot. Extensive experiments which employed a few subjects have been carried out. In the experiments, subjects successfully fulfilled the given manipulation tasks with convergence of tracking errors, which verified that the proposed brain-controlled exoskeleton robot system is effective.",4
A Nonconvex Relaxation Approach to Low-Rank Tensor Completion.,"Low-rank tensor completion plays an important role in many applications such as image processing, computer vision, and machine learning. A widely used convex relaxation of this problem is to minimize the nuclear norm of the square deal matrix generated by reshaping a tensor. However, this approach can be substantially suboptimal. In order to seek a highly accurate solution, in this paper, we propose to use a family of nonconvex functions onto the singular values of the square deal matrix of the tensor to approximate the rank of the tensor. A proximal linearized minimization (PLM) algorithm is proposed to solve the resulting model. Furthermore, based on the Kurdyka-Lojasiewicz property, we show that the sequence generated by the PLM algorithm globally converges to a critical point of the objective function. Extensive numerical experiments including synthetic data, video data, and the extended Yale Face Database B show the effectiveness of the proposed model compared with several existing state-of-the-art models.",4
Adaptive Neural Network Tracking Control for Robotic Manipulators With Dead Zone.,"In this paper, the adaptive neural network (NN) tracking control problem is addressed for robot manipulators subject to dead-zone input. The control objective is to design an adaptive NN controller to guarantee the stability of the systems and obtain good performance. Different from the existing results, which used NN to approximate the nonlinearities directly, NNs are employed to identify the originally designed virtual control signals with unknown nonlinear items in this paper. Moreover, a sequence of virtual control signals and real controller are designed. The adaptive backstepping control method and Lyapunov stability theory are used to prove the proposed controller can ensure all the signals in the systems are semiglobally uniformly ultimately bounded, and the output of the systems can track the reference signal closely. Finally, the proposed adaptive control strategy is applied to the Puma 560 robot manipulator to demonstrate its effectiveness.",4
Event-Sampled Output Feedback Control of Robot Manipulators Using Neural Networks.,"In this paper, adaptive neural networks (NNs) are employed in the event-triggered feedback control framework to enable a robot manipulator to track a predefined trajectory. In the proposed output feedback control scheme, the joint velocities of the robot manipulator are reconstructed using a nonlinear NN observer by using the joint position measurements. Two different configurations are proposed for the implementation of the controller depending on whether the observer is co-located with the sensor or the controller in the feedback control loop. Besides the observer NN, a second NN is utilized to compensate the effects of nonlinearities in the robot dynamics via the feedback control. For both the configurations, by utilizing observer NN and the second NN, torque input is computed by the controller. The Lyapunov stability method is employed to determine the event-triggering condition, weight update rules for the controller, and the observer for both the configurations. The tracking performance of the robot manipulator with the two configurations is analyzed, wherein it is demonstrated that all the signals in the closed-loop system composed of the robotic system, the observer, the event-sampling mechanism, and the controller are locally uniformly ultimately bounded in the presence of bounded disturbance torque. To demonstrate the efficacy of the proposed design, simulation results are presented.",4
A Local and Global Discriminative Framework and Optimization for Balanced Clustering.,"For many specific applications in data mining and machine learning, we face explicit or latent size constraint for each cluster that leads to the ``balanced clustering'' problem. Many existing clustering algorithms perform well in partitioning but fail in producing balanced clusters and preserving the naturally balanced structure of some data. In this paper, we propose a novel balanced clustering framework that flexibly utilizes local and global information of data. First, we propose the global balanced clustering (GBC), in which a global discriminative partitioning model is combined with the minimization of the distribution entropy of data. Then, we show that the proposed GBC can be further used to globally regularize some widely used local clustering models, so as to transform them into balanced clustering that simultaneously capture local and global data. We apply our global balanced regularization to spectral clustering (SC) and local learning (LL)-based clustering, respectively, and propose another two novel balanced clustering models: the local and global balanced SC (LGB-SC) and LGB-LL. Finding the optimal balanced partition is nondeterministic polynomial-time (NP)-hard in general. We adopt the method of augmented Lagrange multipliers to help optimize our model. Comprehensive experiments on several real world benchmarks demonstrate the advantage of our framework to yield balanced clusters while preserving good clustering quality. Our proposed LGB-SC and LGB-LL also outperform SC and LL as well as other classical clustering methods.",4
A Robust AUC Maximization Framework With Simultaneous Outlier Detection and Feature Selection for Positive-Unlabeled Classification.,"The positive-unlabeled (PU) classification is a common scenario in real-world applications such as healthcare, text classification, and bioinformatics, in which we only observe a few samples labeled as ``positive'' together with a large volume of ``unlabeled'' samples that may contain both positive and negative samples. Building robust classifiers for the PU problem is very challenging, especially for complex data where the negative samples overwhelm and mislabeled samples or corrupted features exist. To address these three issues, we propose a robust learning framework that unifies area under the curve maximization (a robust metric for biased labels), outlier detection (for excluding wrong labels), and feature selection (for excluding corrupted features). The generalization error bounds are provided for the proposed model that give valuable insight into the theoretical performance of the method and lead to useful practical guidance, e.g., to train a model, we find that the included unlabeled samples are sufficient as long as the sample size is comparable to the number of positive samples in the training process. Empirical comparisons and two real-world applications on surgical site infection (SSI) and EEG seizure detection are also conducted to show the effectiveness of the proposed model.",4
A Deep Learning Approach to Competing Risks Representation in Peer-to-Peer Lending.,"Online peer-to-peer (P2P) lending is expected to benefit both investors and borrowers due to their low transaction cost and the elimination of expensive intermediaries. From the lenders' perspective, maximizing their return on investment is an ultimate goal during their decision-making procedure. In this paper, we explore and address a fundamental problem underlying such a goal: how to represent the two competing risks, charge-off and prepayment, in funded loans. We propose to model both potential risks simultaneously, which remains largely unexplored until now. We first develop a hierarchical grading framework to integrate two risks of loans both qualitatively and quantitatively. Afterward, we introduce an end-to-end deep learning approach to solve this problem by breaking it down into multiple binary classification subproblems that are amenable to both feature representation and risks learning. Particularly, we leverage deep neural networks to jointly solve these subtasks, which leads to the in-depth exploration of the interaction involved in these tasks. To the best of our knowledge, this is the first attempt to characterize competing risks for loans in P2P lending via deep neural networks. The comprehensive experiments on real-world loan data show that our methodology is able to achieve an appealing investment performance by modeling the competition within and between risks explicitly and properly. The feature analysis based on saliency maps provides useful insights into payment dynamics of loans for potential investors intuitively.",4
STRAINet: Spatially Varying sTochastic Residual AdversarIal Networks for MRI Pelvic Organ Segmentation.,"Accurate segmentation of pelvic organs is important for prostate radiation therapy. Modern radiation therapy starts to use a magnetic resonance image (MRI) as an alternative to computed tomography image because of its superior soft tissue contrast and also free of risk from radiation exposure. However, segmentation of pelvic organs from MRI is a challenging problem due to inconsistent organ appearance across patients and also large intrapatient anatomical variations across treatment days. To address such challenges, we propose a novel deep network architecture, called ""Spatially varying sTochastic Residual AdversarIal Network"" (STRAINet), to delineate pelvic organs from MRI in an end-to-end fashion. Compared to the traditional fully convolutional networks (FCN), the proposed architecture has two main contributions: 1) inspired by the recent success of residual learning, we propose an evolutionary version of the residual unit, i.e., stochastic residual unit, and use it to the plain convolutional layers in the FCN. We further propose long-range stochastic residual connections to pass features from shallow layers to deep layers; and 2) we propose to integrate three previously proposed network strategies to form a new network for better medical image segmentation: a) we apply dilated convolution in the smallest resolution feature maps, so that we can gain a larger receptive field without overly losing spatial information; b) we propose a spatially varying convolutional layer that adapts convolutional filters to different regions of interest; and c) an adversarial network is proposed to further correct the segmented organ structures. Finally, STRAINet is used to iteratively refine the segmentation probability maps in an autocontext manner. Experimental results show that our STRAINet achieved the state-of-the-art segmentation accuracy. Further analysis also indicates that our proposed network components contribute most to the performance.",4
Exploiting Generalization in the Subspaces for Faster Model-Based Reinforcement Learning.,"Due to the lack of enough generalization in the state space, common methods of reinforcement learning suffer from slow learning speed, especially in the early learning trials. This paper introduces a model-based method in discrete state spaces for increasing the learning speed in terms of required experiences (but not required computation time) by exploiting generalization in the experiences of the subspaces. A subspace is formed by choosing a subset of features in the original state representation. Generalization and faster learning in a subspace are due to many-to-one mapping of experiences from the state space to each state in the subspace. Nevertheless, due to inherent perceptual aliasing (PA) in the subspaces, the policy suggested by each subspace does not generally converge to the optimal policy. Our approach, called model-based learning with subspaces (MoBLeSs), calculates the confidence intervals of the estimated Q -values in the state space and in the subspaces. These confidence intervals are used in the decision-making, such that the agent benefits the most from the possible generalization while avoiding from the detriment of the PA in the subspaces. The convergence of MoBLeS to the optimal policy is theoretically investigated. In addition, we show through several experiments that MoBLeS improves the learning speed in the early trials.",4
Spatio-Temporal Interpolated Echo State Network for Meteorological Series Prediction.,"Spatio-temporal series prediction has attracted increasing attention in the field of meteorology in recent years. The spatial and temporal joint effect makes predictions challenging. Most of the existing spatio-temporal prediction models are computationally complicated. To develop an accurate but easy-to-implement spatio-temporal prediction model, this paper designs a novel spatio-temporal prediction model based on echo state networks. For real-world observed meteorological data with randomness and large changes, we use a cubic spline method to bridge the gaps between the neighboring points, which results in a pleasingly smooth series. The interpolated series is later input into the spatio-temporal echo state networks, in which the spatial coefficients are computed by the elastic-net algorithm. This approach offers automatic selection and continuous shrinkage of the spatial variables. The proposed model provides an intuitive but effective approach to address the interaction of spatial and temporal effects. To demonstrate the practicality of the proposed model, we apply it to predict two real-world datasets: monthly precipitation series and daily air quality index series. Experimental results demonstrate that the proposed model achieves a normalized root-mean-square error of approximately 0.250 on both datasets. Similar results are achieved on the long short-term memory model, but the computation time of our proposed model is considerably shorter. It can be inferred that our proposed neural network model has advantages on predicting meteorological series over other models.",4
Multistability of Delayed Hybrid Impulsive Neural Networks With Application to Associative Memories.,"The important topic of multistability of continuous-and discrete-time neural network (NN) models has been investigated rather extensively. Concerning the design of associative memories, multistability of delayed hybrid NNs is studied in this paper with an emphasis on the impulse effects. Arising from the spiking phenomenon in biological networks, impulsive NNs provide an efficient model for synaptic interconnections among neurons. Using state-space decomposition, the coexistence of multiple equilibria of hybrid impulsive NNs is analyzed. Multistability criteria are then established regrading delayed hybrid impulsive neurodynamics, for which both the impulse effects on the convergence rate and the basins of attraction of the equilibria are discussed. Illustrative examples are given to verify the theoretical results and demonstrate an application to the design of associative memories. It is shown by an experimental example that delayed hybrid impulsive NNs have the advantages of high storage capacity and high fault tolerance when used for associative memories.",4
Output Feedback Q-Learning Control for the Discrete-Time Linear Quadratic Regulator Problem.,"Approximate dynamic programming (ADP) and reinforcement learning (RL) have emerged as important tools in the design of optimal and adaptive control systems. Most of the existing RL and ADP methods make use of full-state feedback, a requirement that is often difficult to satisfy in practical applications. As a result, output feedback methods are more desirable as they relax this requirement. In this paper, we present a new output feedback-based Q-learning approach to solving the linear quadratic regulation (LQR) control problem for discrete-time systems. The proposed scheme is completely online in nature and works without requiring the system dynamics information. More specifically, a new representation of the LQR Q-function is developed in terms of the input-output data. Based on this new Q-function representation, output feedback LQR controllers are designed. We present two output feedback iterative Q-learning algorithms based on the policy iteration and the value iteration methods. This scheme has the advantage that it does not incur any excitation noise bias, and therefore, the need of using discounted cost functions is circumvented, which in turn ensures closed-loop stability. It is shown that the proposed algorithms converge to the solution of the LQR Riccati equation. A comprehensive simulation study is carried out, which illustrates the proposed scheme.",4
Approximate Optimal Distributed Control of Nonlinear Interconnected Systems Using Event-Triggered Nonzero-Sum Games.,"In this paper, approximate optimal distributed control schemes for a class of nonlinear interconnected systems with strong interconnections are presented using continuous and event-sampled feedback information. The optimal control design is formulated as an N -player nonzero-sum game where the control policies of the subsystems act as players. An approximate Nash equilibrium solution to the game, which is the solution to the coupled Hamilton-Jacobi equation, is obtained using the approximate dynamic programming-based approach. A critic neural network (NN) at each subsystem is utilized to approximate the Nash solution and novel event-sampling conditions, that are decentralized, are designed to asynchronously orchestrate the sampling and transmission of state vector at each subsystem. To ensure the local ultimate boundedness of the closed-loop system state and NN parameter estimation errors, a hybrid-learning scheme is introduced and the stability is guaranteed using Lyapunov-based stability analysis. Finally, implementation of the proposed event-based distributed control scheme for linear interconnected systems is discussed. For completeness, Zeno-free behavior of the event-sampled system is shown analytically and a numerical example is included to support the analytical results.",4
LTNN: A Layerwise Tensorized Compression of Multilayer Neural Network.,"An efficient deep learning requires a memory-efficient construction of a neural network. This paper introduces a layerwise tensorized formulation of a multilayer neural network, called LTNN, such that the weight matrix can be significantly compressed during training. By reshaping the multilayer neural network weight matrix into a high-dimensional tensor with a low-rank approximation, significant network compression can be achieved with maintained accuracy. An according layerwise training is developed by a modified alternating least-squares method with backward propagation for fine-tuning only. LTNN can provide the state-of-the-art results on various benchmarks with significant compression. For MNIST benchmark, LTNN shows 64 x compression rate without accuracy drop. For Imagenet12 benchmark, our proposed LTNN achieves 35.84 x compression of the neural network with around 2% accuracy drop. We have also shown 1.615 x faster on inference speed than the existing works due to the smaller tensor core ranks.",4
Early Expression Detection via Online Multi-Instance Learning With Nonlinear Extension.,"Video-based facial expression recognition has received substantial attention over the past decade, while early expression detection (EED) is still a relatively new and challenging problem. The goal of EED is to identify an expression as quickly as possible after the expression starts and before it ends. This timely ability has many potential applications, ranging from human-computer interaction to security. The max-margin early event detector (MMED) is a well-known ranking model for early event detection. It can achieve competitive EED performance but suffers from several critical limitations: 1) MMED lacks flexibility in extracting useful information for segment comparison, which leads to poor performance in exploring the ranking relation between segment pairs; 2) the training process is slow due to the large number of constraints, and the memory requirement is also usually hard to satisfy; and 3) MMED is linear in nature, and hence may not be appropriate for data in a nonlinear feature space. To overcome these limitations, we propose an online multi-instance learning (MIL) framework for EED. In particular, the MIL technique is first introduced to generalize MMED, resulting in the proposed MIL-based EED (MIED), which is more general and flexible than MMED, since various instance construction and combination strategies can be adopted. To accelerate the training process, we reformulate MIED in the online setting and develop online multi-instance learning framework for EED (OMIED). To further exploit the nonlinear structure of the data distribution, we incorporate the kernel methods in OMIED, which results in the proposed online kernel multi-instance learning for early expression detection. Experiments on two popular and one challenging video-based expression data sets demonstrate both the efficiency and effectiveness of the proposed methods.",4
Hypergraph-Induced Convolutional Networks for Visual Classification.,"At present, convolutional neural networks (CNNs) have become popular in visual classification tasks because of their superior performance. However, CNN-based methods do not consider the correlation of visual data to be classified. Recently, graph convolutional networks (GCNs) have mitigated this problem by modeling the pairwise relationship in visual data. Real-world tasks of visual classification typically must address numerous complex relationships in the data, which are not fit for the modeling of the graph structure using GCNs. Therefore, it is vital to explore the underlying correlation of visual data. Regarding this issue, we propose a framework called the hypergraph-induced convolutional network to explore the high-order correlation in visual data during deep neural networks. First, a hypergraph structure is constructed to formulate the relationship in visual data. Then, the high-order correlation is optimized by a learning process based on the constructed hypergraph. The classification tasks are performed by considering the high-order correlation in the data. Thus, the convolution of the hypergraph-induced convolutional network is based on the corresponding high-order relationship, and the optimization on the network uses each data and considers the high-order correlation of the data. To evaluate the proposed hypergraph-induced convolutional network framework, we have conducted experiments on three visual data sets: the National Taiwan University 3-D model data set, Princeton Shape Benchmark, and multiview RGB-depth object data set. The experimental results and comparison in all data sets demonstrate the effectiveness of our proposed hypergraph-induced convolutional network compared with the state-of-the-art methods.",4
Novel Finite-Time Synchronization Criteria for Inertial Neural Networks With Time Delays via Integral Inequality Method.,"In this paper, we are concerned with the finite-time synchronization of a class of inertial neural networks with time delays. Without applying some finite-time stability theorems, which are widely applied to studying the finite-time synchronization for neural networks, by constructing two Lyapunov functions and using integral inequality method, two sufficient conditions on the finite-time synchronization for a class of inertial neural networks with time delays are derived. Considering that the method and research results of the finite-time synchronization are different from some existing works, this paper extends the works on the finite-time synchronization of neural networks.",4
Nonuniformly Sampled Data Processing Using LSTM Networks.,"We investigate classification and regression for nonuniformly sampled variable length sequential data and introduce a novel long short-term memory (LSTM) architecture. In particular, we extend the classical LSTM network with additional time gates, which incorporate the time information as a nonlinear scaling factor on the conventional gates. We also provide forward-pass and backward-pass update equations for the proposed LSTM architecture. We show that our approach is superior to the classical LSTM architecture when there is correlation between time samples. In our experiments, we achieve significant performance gains with respect to the classical LSTM and phased-LSTM architectures. In this sense, the proposed LSTM architecture is highly appealing for the applications involving nonuniformly sampled sequential data.",4
Deep Neural Network Initialization With Decision Trees.,"In this paper, a novel, automated process for constructing and initializing deep feedforward neural networks based on decision trees is presented. The proposed algorithm maps a collection of decision trees trained on the data into a collection of initialized neural networks with the structures of the networks determined by the structures of the trees. The tree-informed initialization acts as a warm-start to the neural network training process, resulting in efficiently trained, accurate networks. These models, referred to as ""deep jointly informed neural networks"" (DJINN), demonstrate high predictive performance for a variety of regression and classification data sets and display comparable performance to Bayesian hyperparameter optimization at a lower computational cost. By combining the user-friendly features of decision tree models with the flexibility and scalability of deep neural networks, DJINN is an attractive algorithm for training predictive models on a wide range of complex data sets.",4
Distributed Adaptive Tracking Synchronization for Coupled Reaction-Diffusion Neural Network.,"This paper considers the tracking synchronization problem for a class of coupled reaction-diffusion neural networks (CRDNNs) with undirected topology. For the case where the tracking trajectory has identical individual dynamic as that of the network nodes, the edge-based and vertex-based adaptive strategies on coupling strengths as well as adaptive controllers, which demand merely the local neighbor information, are proposed to synchronize the CRDNNs to the tracking trajectory. To reduce the control costs, an adaptive pinning control technique is employed. For the case where the tracking trajectory has different individual dynamic from that of the network nodes, the vertex-based adaptive strategy is proposed to drive the synchronization error to a relatively small area, which is adjustable according to the parameters of the adaptive strategy. This kind of adaptive design can enhance the robustness of the network against the external disturbance posed on the tracking trajectory. The obtained theoretical results are verified by two representative examples.",4
Deep Semantic-Preserving Ordinal Hashing for Cross-Modal Similarity Search.,"Cross-modal hashing has attracted increasing research attention due to its efficiency for large-scale multimedia retrieval. With simultaneous feature representation and hash function learning, deep cross-modal hashing (DCMH) methods have shown superior performance. However, most existing methods on DCMH adopt binary quantization functions (e.g., [Formula: see text]) to generate hash codes, which limit the retrieval performance since binary quantization functions are sensitive to the variations of numeric values. Toward this end, we propose a novel end-to-end ranking-based hashing framework, in this paper, termed as deep semantic-preserving ordinal hashing (DSPOH), to learn hash functions with deep neural networks by exploring the ranking structure of feature dimensions. In DSPOH, the ordinal representation, which encodes the relative rank ordering of feature dimensions, is explored to generate hash codes. Such ordinal embedding benefits from the numeric stability of rank correlation measures. To make the hash codes discriminative, the ordinal representation is expected to well predict the class labels so that the ranking-based hash function learning is optimally compatible with the label predicting. Meanwhile, the intermodality similarity is preserved to guarantee that the hash codes of different modalities are consistent. Importantly, DSPOH can be effectively integrated with different types of network architectures, which demonstrates the flexibility and scalability of our proposed hashing framework. Extensive experiments on three widely used multimodal data sets show that DSPOH outperforms state of the art for cross-modal retrieval tasks.",4
Face Sketch Synthesis by Multidomain Adversarial Learning.,"Given a training set of face photo-sketch pairs, face sketch synthesis targets at learning a mapping from the photo domain to the sketch domain. Despite the exciting progresses made in the literature, it retains as an open problem to synthesize high-quality sketches against blurs and deformations. Recent advances in generative adversarial training provide a new insight into face sketch synthesis, from which perspective the existing synthesis pipelines can be fundamentally revisited. In this paper, we present a novel face sketch synthesis method by multidomain adversarial learning (termed MDAL), which overcomes the defects of blurs and deformations toward high-quality synthesis. The principle of our scheme relies on the concept of ""interpretation through synthesis."" In particular, we first interpret face photographs in the photodomain and face sketches in the sketch domain by reconstructing themselves respectively via adversarial learning. We define the intermediate products in the reconstruction process as latent variables, which form a latent domain. Second, via adversarial learning, we make the distributions of latent variables being indistinguishable between the reconstruction process of the face photograph and that of the face sketch. Finally, given an input face photograph, the latent variable obtained by reconstructing this face photograph is applied for synthesizing the corresponding sketch. Quantitative comparisons to the state-of-the-art methods demonstrate the superiority of the proposed MDAL method.",4
Multiobjective Support Vector Machines: Handling Class Imbalance With Pareto Optimality.,"Support vector machines (SVMs) seek to optimize three distinct objectives: maximization of margin, minimization of regularization from the positive class, and minimization of regularization from the negative class. The right choice of weightage for each of these objectives is critical to the quality of the classifier learned, especially in case of the class imbalanced data sets. Therefore, costly parameter tuning has to be undertaken to find a set of suitable relative weights. In this brief, we propose to train SVMs, on two-class as well as multiclass data sets, in a multiobjective optimization framework called radial boundary intersection to overcome this shortcoming. The experimental results suggest that the radial boundary intersection-based scheme is indeed effective in finding the best tradeoff among the objectives compared with parameter-tuning schemes.",4
Temporal Attention-Augmented Bilinear Network for Financial Time-Series Data Analysis.,"Financial time-series forecasting has long been a challenging problem because of the inherently noisy and stochastic nature of the market. In the high-frequency trading, forecasting for trading purposes is even a more challenging task, since an automated inference system is required to be both accurate and fast. In this paper, we propose a neural network layer architecture that incorporates the idea of bilinear projection as well as an attention mechanism that enables the layer to detect and focus on crucial temporal information. The resulting network is highly interpretable, given its ability to highlight the importance and contribution of each temporal instance, thus allowing further analysis on the time instances of interest. Our experiments in a large-scale limit order book data set show that a two-hidden-layer network utilizing our proposed layer outperforms by a large margin all existing state-of-the-art results coming from much deeper architectures while requiring far fewer computations.",4
Bag-Level Aggregation for Multiple-Instance Active Learning in Instance Classification Problems.,"A growing number of applications, e.g., video surveillance and medical image analysis, require training recognition systems from large amounts of weakly annotated data, while some targeted interactions with a domain expert are allowed to improve the training process. In such cases, active learning (AL) can reduce labeling costs for training a classifier by querying the expert to provide the labels of most informative instances. This paper focuses on AL methods for instance classification problems in multiple instance learning (MIL), where data are arranged into sets, called bags, which are weakly labeled. Most AL methods focus on single-instance learning problems. These methods are not suitable for MIL problems because they cannot account for the bag structure of data. In this paper, new methods for bag-level aggregation of instance informativeness are proposed for multiple instance AL (MIAL). The aggregated informativeness method identifies the most informative instances based on classifier uncertainty and queries bags incorporating the most information. The other proposed method, called cluster-based aggregative sampling, clusters data hierarchically in the instance space. The informativeness of instances is assessed by considering bag labels, inferred instance labels, and the proportion of labels that remain to be discovered in clusters. Both proposed methods significantly outperform reference methods in extensive experiments using benchmark data from several application domains. Results indicate that using an appropriate strategy to address MIAL problems yields a significant reduction in the number of queries needed to achieve the same level of performance as single-instance AL methods.",4
Generalization and Expressivity for Deep Nets.,"Along with the rapid development of deep learning in practice, theoretical explanations for its success become urgent. Generalization and expressivity are two widely used measurements to quantify theoretical behaviors of deep nets. The expressivity focuses on finding functions expressible by deep nets but cannot be approximated by shallow nets with similar number of neurons. It usually implies the large capacity. The generalization aims at deriving fast learning rate for deep nets. It usually requires small capacity to reduce the variance. Different from previous studies on deep nets, pursuing either expressivity or generalization, we consider both the factors to explore theoretical advantages of deep nets. For this purpose, we construct a deep net with two hidden layers possessing excellent expressivity in terms of localized and sparse approximation. Then, utilizing the well known covering number to measure the capacity, we find that deep nets possess excellent expressive power (measured by localized and sparse approximation) without essentially enlarging the capacity of shallow nets. As a consequence, we derive near-optimal learning rates for implementing empirical risk minimization on deep nets. These results theoretically exhibit advantages of deep nets from the learning theory viewpoint.",4
Bounded Neural Network Control for Target Tracking of Underactuated Autonomous Surface Vehicles in the Presence of Uncertain Target Dynamics.,"This paper is concerned with the target tracking of underactuated autonomous surface vehicles with unknown dynamics and limited control torques. The velocity of the target is unknown, and only the measurements of line-of-sight range and angle are obtained. First, a kinematic control law is designed based on an extended state observer, which is utilized to estimate the uncertain target dynamics due to the unknown velocities. Next, an estimation model based on a single-hidden-layer neural network is developed to approximate the unknown follower dynamics induced by uncertain model parameters, unmodeled dynamics, and environmental disturbances. A bounded control law is designed based on the neural estimation model and a saturated function. The salient feature of the proposed controller is twofold. First, only the measured line-of-sight range and angle are used, and the velocity information of the target is not required. Second, the control torques are bounded with the bounds known as a priori. The input-to-state stability of the closed-loop system is analyzed via cascade theory. Simulations illustrate the effectiveness of the proposed bounded controller for tracking a moving target.",4
Heterogeneous Domain Adaptation Through Progressive Alignment.,"In real-world transfer learning tasks, especially in cross-modal applications, the source domain and the target domain often have different features and distributions, which are well known as the heterogeneous domain adaptation (HDA) problem. Yet, existing HDA methods focus on either alleviating the feature discrepancy or mitigating the distribution divergence due to the challenges of HDA. In fact, optimizing one of them can reinforce the other. In this paper, we propose a novel HDA method that can optimize both feature discrepancy and distribution divergence in a unified objective function. Specifically, we present progressive alignment, which first learns a new transferable feature space by dictionary-sharing coding, and then aligns the distribution gaps on the new space. Different from previous HDA methods that are limited to specific scenarios, our approach can handle diverse features with arbitrary dimensions. Extensive experiments on various transfer learning tasks, such as image classification, text categorization, and text-to-image recognition, verify the superiority of our method against several state-of-the-art approaches.",4
Generalized Uncorrelated Regression with Adaptive Graph for Unsupervised Feature Selection.,"Unsupervised feature selection always occupies a key position as a preprocessing in the tasks of classification or clustering due to the existence of extra essential features within high-dimensional data. Although lots of efforts have been made, the existing methods neglect to consider the redundancy of features, and thus select redundant features. In this brief, by virtue of a generalized uncorrelated constraint, we present an improved sparse regression model [generalized uncorrelated regression model (GURM)] for seeking the uncorrelated yet discriminative features. Benefited from this, the structure of data is kept in the Stiefel manifold, which avoids the potential trivial solution triggered by a conventional ridge regression model. Besides that, the uncorrelated constraint equips the model with the closed-form solution. In addition, we also incorporate a graph regularization term based on the principle of maximum entropy into the GURM model (URAFS), so as to embed the local geometric structure of data into the manifold learning. An efficient algorithm is designed to perform URAFS by virtue of the existing generalized powered iteration method. Extensive experiments on eight benchmark data sets among seven state-of-the-art methods on the task of clustering are conducted to verify the effectiveness and superiority of the proposed method.",4
Hierarchical Feature Selection for Random Projection.,"Random projection is a popular machine learning algorithm, which can be implemented by neural networks and trained in a very efficient manner. However, the number of features should be large enough when applied to a rather large-scale data set, which results in slow speed in testing procedure and more storage space under some circumstances. Furthermore, some of the features are redundant and even noisy since they are randomly generated, so the performance may be affected by these features. To remedy these problems, an effective feature selection method is introduced to select useful features hierarchically. Specifically, a novel criterion is proposed to select useful neurons for neural networks, which establishes a new way for network architecture design. The testing time and accuracy of the proposed method are improved compared with traditional methods and some variations on both classification and regression tasks. Extensive experiments confirm the effectiveness of the proposed method.",4
Stochastic Conjugate Gradient Algorithm With Variance Reduction.,"Conjugate gradient (CG) methods are a class of important methods for solving linear equations and nonlinear optimization problems. In this paper, we propose a new stochastic CG algorithm with variance reduction(1) and we prove its linear convergence with the Fletcher and Reeves method for strongly convex and smooth functions. We experimentally demonstrate that the CG with variance reduction algorithm converges faster than its counterparts for four learning models, which may be convex, nonconvex or nonsmooth. In addition, its area under the curve performance on six large-scale data sets is comparable to that of the LIBLINEAR solver for the L2 -regularized L2 -loss but with a significant improvement in computational efficiency.(1)CGVR algorithm is available on github: https://github.com/xbjin/cgvr.",4
Quantized Minimum Error Entropy Criterion.,"Comparing with traditional learning criteria, such as mean square error, the minimum error entropy (MEE) criterion is superior in nonlinear and non-Gaussian signal processing and machine learning. The argument of the logarithm in Renyi's entropy estimator, called information potential (IP), is a popular MEE cost in information theoretic learning. The computational complexity of IP is, however, quadratic in terms of sample number due to double summation. This creates the computational bottlenecks, especially for large-scale data sets. To address this problem, in this paper, we propose an efficient quantization approach to reduce the computational burden of IP, which decreases the complexity from O(N(2)) to O(MN) with M << N . The new learning criterion is called the quantized MEE (QMEE). Some basic properties of QMEE are presented. Illustrative examples with linear-in-parameter models are provided to verify the excellent performance of QMEE.",4
On the Representational Power of Restricted Boltzmann Machines for Symmetric Functions and Boolean Functions.,"Restricted Boltzmann machines (RBMs) are used to build deep-belief networks that are widely thought to be one of the first effective deep learning neural networks. This paper studies the ability of RBMs to represent distributions over {0,1}(n) via softplus/hardplus RBM networks. It is shown that any distribution whose density depends on the number of 1's in their input can be approximated with arbitrarily high accuracy by an RBM of size 2n+1 , which improves the result of a previous study by reducing the size from n(2) to 2n+1 . A theorem for representing partially symmetric Boolean functions by softplus RBM networks is established. Accordingly, the representational power of RBMs for distributions whose mass represents the Boolean functions is investigated in comparison with that of threshold circuits and polynomial threshold functions. It is shown that a distribution over {0,1}(n) whose mass represents a Boolean function can be computed with a given margin delta by an RBM of size and parameters bounded by polynomials in n , if and only if it can be computed by a depth-2 threshold circuit with size and parameters bounded by polynomials in n .",4
Feature Analysis of Marginalized Stacked Denoising Autoenconder for Unsupervised Domain Adaptation.,"Marginalized stacked denoising autoencoder (mSDA), has recently emerged with demonstrated effectiveness in domain adaptation. In this paper, we investigate the rationale for why mSDA benefits domain adaptation tasks from the perspective of adaptive regularization. Our investigations focus on two types of feature corruption noise: Gaussian noise (mSDA g ) and Bernoulli dropout noise (mSDA bd ). Both theoretical and empirical results demonstrate that mSDA bd successfully boosts the adaptation performance but mSDA g fails to do so. We then propose a new mSDA with data-dependent multinomial dropout noise (mSDA md ) that overcomes the limitations of mSDA bd and further improves the adaptation performance. Our mSDA md is based on a more realistic assumption: different features are correlated and, thus, should be corrupted with different probabilities. Experimental results demonstrate the superiority of mSDA md to mSDA bd on the adaptation performance and the convergence speed. Finally, we propose a deep transferable feature coding (DTFC) framework for unsupervised domain adaptation. The motivation of DTFC is that mSDA fails to consider the distribution discrepancy across different domains in the feature learning process. We introduce a new element to mSDA: domain divergence minimization by maximum mean discrepancy. This element is essential for domain adaptation as it ensures the extracted deep features to have a small distribution discrepancy. The effectiveness of DTFC is verified by extensive experiments on three benchmark data sets for both Bernoulli dropout noise and multinomial dropout noise.",4
Pool-Based Sequential Active Learning for Regression.,"Active learning (AL) is a machine-learning approach for reducing the data labeling effort. Given a pool of unlabeled samples, it tries to select the most useful ones to label so that a model built from them can achieve the best possible performance. This paper focuses on pool-based sequential AL for regression (ALR). We first propose three essential criteria that an ALR approach should consider in selecting the most useful unlabeled samples: informativeness, representativeness, and diversity, and compare four existing ALR approaches against them. We then propose a new ALR approach using passive sampling, which considers both the representativeness and the diversity in both the initialization and subsequent iterations. Remarkably, this approach can also be integrated with other existing ALR approaches in the literature to further improve the performance. Extensive experiments on 11 University of California, Irvine, Carnegie Mellon University StatLib, and University of Florida Media Core data sets from various domains verified the effectiveness of our proposed ALR approaches.",4
Output-Feedback Adaptive Neural Controller for Uncertain Pure-Feedback Nonlinear Systems Using a High-Order Sliding Mode Observer.,"A novel adaptive neural output-feedback controller for SISO nonaffine pure-feedback nonlinear systems is proposed. The majority of the previously described adaptive neural controllers for pure-feedback nonlinear systems were based on the dynamic surface control (DSC) or backstepping schemes. This makes the control law as well as the stability analysis highly lengthy and complicated. Moreover, there has been very limited research till date on the output-feedback neural controller for this class of the systems. The proposed controller evades adopting adaptive backstepping or DSC scheme through reformulating the original system into the Brunovsky form, which considerably simplifies the control law. Combining a high-order sliding mode observer and single radial-basis function network with universal approximation property, it is shown that the controller guarantees closed-loop system stability in the Lyapunov sense.",4
Dynamical Behavior of Nonautonomous Stochastic Reaction-Diffusion Neural-Network Models.,"This brief investigates nonautonomous stochastic reaction-diffusion neural-network models with S-type distributed delays. First, the existence and uniqueness of mild solution are studied under the Lipschitz condition without the linear growth condition. Due to the existence of a nonautonomous reaction-diffusion term and the infinite dimensional Wiener process, the criteria for the well-posedness of the models are established based on the evolution system theory. Then, the S-type distributed delay, which is an infinite delay, is handled by the truncation method, and sufficient conditions for the global exponential stability are obtained by constructing a simple Lyapunov-Krasovskii functional candidate. Finally, neural-network examples and an illustrative example are given to show the applications of the obtained results.",4
Designing Fully Distributed Adaptive Event-Triggered Controllers for Networked Linear Systems With Matched Uncertainties.,"This paper considers the distributed event-triggered consensus control problem for a network of linear systems subject to bounded uncertainties satisfying the matching condition. Due to the existence of nonidentical uncertainties, the multiagent system studied in this paper is essentially heterogeneous, and the event-triggered consensus problem of which is much more challenging than that of homogeneous linear networks in the existing works. We propose a static nonsmooth event-triggered protocol that includes a nonlinear term to ensure that consensus is achieved and the Zeno behavior is excluded. To avoid the undesirable chattering effect caused by the nonsmooth protocol, we design a static continuous event-based protocol, which can guarantee that the consensus error is ultimately bounded and the upper bound of the consensus error can be made satisfactorily small by choosing properly the design parameters. We also design a continuous adaptive event-triggered protocol that includes time-varying weights into both the control law and the triggering function. Contrary to the event-triggered protocols in the previous related works, the adaptive event-based protocol is fully distributed and scalable, whose design does not require any global information of the network graph. Besides, all the event-triggered protocols in this paper do not need continuous communications among neighboring agents in either control laws' updating or triggering conditions' monitoring.",4
SEFRON: A New Spiking Neuron Model With Time-Varying Synaptic Efficacy Function for Pattern Classification.,"This paper presents a new time-varying long-term Synaptic Efficacy Function-based leaky-integrate-and-fire neuRON model, referred to as SEFRON and its supervised learning rule for pattern classification problems. The time-varying synaptic efficacy function is represented by a sum of amplitude modulated Gaussian distribution functions located at different times. For a given pattern, the SEFRON's learning rule determines the changes in the amplitudes of weights at selected presynaptic spike times by minimizing a new error function reflecting the differences between the desired and actual postsynaptic firing times. Similar to the gamma-aminobutyric acid-switch phenomenon observed in a biological neuron that switches between excitatory and inhibitory postsynaptic potentials based on the physiological needs, the time-varying synapse model proposed in this paper allows the synaptic efficacy (weight) to switch signs in a continuous manner. The computational power and the functioning of SEFRON are first illustrated using a binary pattern classification problem. The detailed performance comparisons of a single SEFRON classifier with other spiking neural networks (SNNs) are also presented using four benchmark data sets from the UCI machine learning repository. The results clearly indicate that a single SEFRON provides a similar generalization performance compared to other SNNs with multiple layers and multiple neurons.",4
Off-Policy Interleaved Q -Learning: Optimal Control for Affine Nonlinear Discrete-Time Systems.,"In this paper, a novel off-policy interleaved Q-learning algorithm is presented for solving optimal control problem of affine nonlinear discrete-time (DT) systems, using only the measured data along the system trajectories. Affine nonlinear feature of systems, unknown dynamics, and off-policy learning approach pose tremendous challenges on approximating optimal controllers. To this end, on-policy Q-learning method for optimal control of affine nonlinear DT systems is reviewed first, and its convergence is rigorously proven. The bias of solution to Q-function-based Bellman equation caused by adding probing noises to systems for satisfying persistent excitation is also analyzed when using on-policy Q-learning approach. Then, a behavior control policy is introduced followed by proposing an off-policy Q-learning algorithm. Meanwhile, the convergence of algorithm and no bias of solution to optimal control problem when adding probing noise to systems are investigated. Third, three neural networks run by the interleaved Q-learning approach in the actor-critic framework. Thus, a novel off-policy interleaved Q-learning algorithm is derived, and its convergence is proven. Simulation results are given to verify the effectiveness of the proposed method.",4
Dualityfree Methods for Stochastic Composition Optimization.,"In this paper, we consider the composition optimization with two expected-value functions in the form of (1/n) summation operatori = 1(n) Fi((1/m) summation operatorj = 1(m) Gj(x))+R(x) , which formulates many important problems in statistical learning and machine learning such as solving Bellman equations in reinforcement learning and nonlinear embedding. Full gradient- or classical stochastic gradient descent-based optimization algorithms are unsuitable or computationally expensive to solve this problem due to the inner expectation (1/m) summation operatorj = 1(m) Gj(x) . We propose a dualityfree-based stochastic composition method that combines the variance reduction methods to address the stochastic composition problem. We apply the stochastic variance reduction gradient- and stochastic average gradient algorithm-based methods to estimate the inner function and the dualityfree method to estimate the outer function. We prove the linear convergence rate not only for the convex composition problem but also for the case that the individual outer functions are nonconvex, while the objective function is strongly convex. We also provide the results of experiments that show the effectiveness of our proposed methods.",4
Neural Learning Control of Strict-Feedback Systems Using Disturbance Observer.,"This paper studies the compound learning control of disturbed uncertain strict-feedback systems. The design is using the dynamic surface control equipped with a novel learning scheme. This paper integrates the recently developed online recorded data-based neural learning with the nonlinear disturbance observer (DOB) to achieve good ""understanding"" of the system uncertainty including unknown dynamics and time-varying disturbance. With the proposed method to show how the neural networks and DOB are cooperating with each other, one indicator is constructed and included into the update law. The closed-loop system stability analysis is rigorously presented. Different kinds of disturbances are considered in a third-order system as simulation examples and the results confirm that the proposed method achieves higher tracking accuracy while the compound estimation is much more precise. The design is applied to the flexible hypersonic flight dynamics and a better tracking performance is obtained.",4
Event-Based Line Fitting and Segment Detection Using a Neuromorphic Visual Sensor.,"This paper introduces an event-based luminance-free algorithm for line and segment detection from the output of asynchronous event-based neuromorphic retinas. These recent biomimetic vision sensors are composed of autonomous pixels, each of them asynchronously generating visual events that encode relative changes in pixels' illumination at high temporal resolutions. This frame-free approach results in an increased energy efficiency and in real-time operation, making these sensors especially suitable for applications such as autonomous robotics. The proposed algorithm is based on an iterative event-based weighted least squares fitting, and it is consequently well suited to the high temporal resolution and asynchronous acquisition of neuromorphic cameras: parameters of a current line are updated for each event attributed (i.e., spatio-temporally close) to it, while implicitly forgetting the contribution of older events according to a speed-tuned exponentially decaying function. A detection occurs if a measure of activity, i.e., implicit measure of the number of contributing events and using the same decay function, exceeds a given threshold. The speed-tuned decreasing function is based on a measure of the apparent motion, i.e., the optical flow computed around each event. This latter ensures that the algorithm behaves independently of the edges' dynamics. Line segments are then extracted from the lines, allowing for the tracking of the corresponding endpoints. We provide experiments showing the accuracy of our algorithm and study the influence of the apparent velocity and relative orientation of the observed edges. Finally, evaluations of its computational efficiency show that this algorithm can be envisioned for high-speed applications, such as vision-based robotic navigation.",4
Universal Approximation Capability of Broad Learning System and Its Structural Variations.,"After a very fast and efficient discriminative broad learning system (BLS) that takes advantage of flatted structure and incremental learning has been developed, here, a mathematical proof of the universal approximation property of BLS is provided. In addition, the framework of several BLS variants with their mathematical modeling is given. The variations include cascade, recurrent, and broad-deep combination structures. From the experimental results, the BLS and its variations outperform several exist learning algorithms on regression performance over function approximation, time series prediction, and face recognition databases. In addition, experiments on the extremely challenging data set, such as MS-Celeb-1M, are given. Compared with other convolutional networks, the effectiveness and efficiency of the variants of BLS are demonstrated.",4
Multiview Multitask Gaze Estimation With Deep Convolutional Neural Networks.,"Gaze estimation, which aims to predict gaze points with given eye images, is an important task in computer vision because of its applications in human visual attention understanding. Many existing methods are based on a single camera, and most of them only focus on either the gaze point estimation or gaze direction estimation. In this paper, we propose a novel multitask method for the gaze point estimation using multiview cameras. Specifically, we analyze the close relationship between the gaze point estimation and gaze direction estimation, and we use a partially shared convolutional neural networks architecture to simultaneously estimate the gaze direction and gaze point. Furthermore, we also introduce a new multiview gaze tracking data set that consists of multiview eye images of different subjects. As far as we know, it is the largest multiview gaze tracking data set. Comprehensive experiments on our multiview gaze tracking data set and existing data sets demonstrate that our multiview multitask gaze point estimation solution consistently outperforms existing methods.",4
Neural Adaptive Backstepping Control of a Robotic Manipulator With Prescribed Performance Constraint.,"This paper presents an adaptive neural network (NN) control of a two-degree-of-freedom manipulator driven by an electrohydraulic actuator. To restrict the system output in a prescribed performance constraint, a weighted performance function is designed to guarantee the dynamic and steady tracking errors of joint angle in a required accuracy. Then, a radial-basis-function NN is constructed to train the unknown model dynamics of a manipulator by traditional backstepping control (TBC) and obtain the preliminary estimated model, which can replace the preknown dynamics in the backstepping iteration. Furthermore, an adaptive estimation law is adopted to self-tune every trained-node weight, and the estimated model is online optimized to enhance the robustness of the NN controller. The effectiveness of the proposed control is verified by comparative simulation and experimental results with Proportional-integral-derivative and TBC methods.",4
Developmental Resonance Network.,"Adaptive resonance theory (ART) networks deal with normalized input data only, which means that they need the normalization process for the raw input data, under the assumption that the upper and lower bounds of the input data are known in advance. Without such an assumption, ART networks cannot be utilized. To solve this problem and improve the learning performance, inspired by the ART networks, we propose a developmental resonance network (DRN) by employing new techniques of a global weight and node connection and grouping processes. The proposed DRN learns the global weight converging to the unknown range of the input data and properly clusters by grouping similar nodes into one. These techniques enable DRN to learn the raw input data without the normalization process while retaining the stability, plasticity, and memory usage efficiency without node proliferation. Simulation results verify that our DRN, applied to the unsupervised clustering problem, can cluster raw data properly without a prior normalization process.",4
l(1)-Norm Heteroscedastic Discriminant Analysis Under Mixture of Gaussian Distributions.,"Fisher's criterion is one of the most popular discriminant criteria for feature extraction. It is defined as the generalized Rayleigh quotient of the between-class scatter distance to the within-class scatter distance. Consequently, Fisher's criterion does not take advantage of the discriminant information in the class covariance differences, and hence, its discriminant ability largely depends on the class mean differences. If the class mean distances are relatively large compared with the within-class scatter distance, Fisher's criterion-based discriminant analysis methods may achieve a good discriminant performance. Otherwise, it may not deliver good results. Moreover, we observe that the between-class distance of Fisher's criterion is based on the l(2)-norm, which would be disadvantageous to separate the classes with smaller class mean distances. To overcome the drawback of Fisher's criterion, in this paper, we first derive a new discriminant criterion, expressed as a mixture of absolute generalized Rayleigh quotients, based on a Bayes error upper bound estimation, where mixture of Gaussians is adopted to approximate the real distribution of data samples. Then, the criterion is further modified by replacing l(2)-norm with l(1) one to better describe the between-class scatter distance, such that it would be more effective to separate the different classes. Moreover, we propose a novel l(1)-norm heteroscedastic discriminant analysis method based on the new discriminant analysis (L1-HDA/GM) for heteroscedastic feature extraction, in which the optimization problem of L1-HDA/GM can be efficiently solved by using the eigenvalue decomposition approach. Finally, we conduct extensive experiments on four real data sets and demonstrate that the proposed method achieves much competitive results compared with the state-of-the-art methods.",4
Domain Adaption via Feature Selection on Explicit Feature Map.,"In most domain adaption approaches, all features are used for domain adaption. However, often, not every feature is beneficial for domain adaption. In such cases, incorrectly involving all features might cause the performance to degrade. In other words, to make the model trained on the source domain work well on the target domain, it is desirable to find invariant features for domain adaption rather than using all features. However, invariant features across domains may lie in a higher order space, instead of in the original feature space. Moreover, the discriminative ability of some invariant features such as shared background information is weak, and needs to be further filtered. Therefore, in this paper, we propose a novel domain adaption algorithm based on an explicit feature map and feature selection. The data are first represented by a kernel-induced explicit feature map, such that high-order invariant features can be revealed. Then, by minimizing the marginal distribution difference, conditional distribution difference, and the model error, the invariant discriminative features are effectively selected. This problem is NP-hard to be solved, and we propose to relax it and solve it by a cutting plane algorithm. Experimental results on six real-world benchmarks have demonstrated the effectiveness and efficiency of the proposed algorithm, which outperforms many state-of-the-art domain adaption approaches.",4
Learning Aggregated Transmission Propagation Networks for Haze Removal and Beyond.,"Single-image dehazing is an important low-level vision task with many applications. Early studies have investigated different kinds of visual priors to address this problem. However, they may fail when their assumptions are not valid on specific images. Recent deep networks also achieve a relatively good performance in this task. But unfortunately, due to the disappreciation of rich physical rules in hazes, a large amount of data are required for their training. More importantly, they may still fail when there exist completely different haze distributions in testing images. By considering the collaborations of these two perspectives, this paper designs a novel residual architecture to aggregate both prior (i.e., domain knowledge) and data (i.e., haze distribution) information to propagate transmissions for scene radiance estimation. We further present a variational energy-based perspective to investigate the intrinsic propagation behavior of our aggregated deep model. In this way, we actually bridge the gap between prior-driven models and data-driven networks and leverage advantages but avoid limitations of previous dehazing approaches. A lightweight learning framework is proposed to train our propagation network. Finally, by introducing a task-aware image separation formulation with a flexible optimization scheme, we extend the proposed model for more challenging vision tasks, such as underwater image enhancement and single-image rain removal. Experiments on both synthetic and real-world images demonstrate the effectiveness and efficiency of the proposed framework.",4
Flexible Affinity Matrix Learning for Unsupervised and Semisupervised Classification.,"In this paper, we propose a unified model called flexible affinity matrix learning (FAML) for unsupervised and semisupervised classification by exploiting both the relationship among data and the clustering structure simultaneously. To capture the relationship among data, we exploit the self-expressiveness property of data to learn a structured matrix in which the structures are induced by different norms. A rank constraint is imposed on the Laplacian matrix of the desired affinity matrix, so that the connected components of data are exactly equal to the cluster number. Thus, the clustering structure is explicit in the learned affinity matrix. By making the estimated affinity matrix approximate the structured matrix during the learning procedure, FAML allows the affinity matrix itself to be adaptively adjusted such that the learned affinity matrix can well capture both the relationship among data and the clustering structure. Thus, FAML has the potential to perform better than other related methods. We derive optimization algorithms to solve the corresponding problems. Extensive unsupervised and semisupervised classification experiments on both synthetic data and real-world benchmark data sets show that the proposed FAML consistently outperforms the state-of-the-art methods.",4
Perception Coordination Network: A Neuro Framework for Multimodal Concept Acquisition and Binding.,"To simulate the concept acquisition and binding of different senses in the brain, a biologically inspired neural network model named perception coordination network (PCN) is proposed. It is a hierarchical structure, which is functionally divided into the primary sensory area (PSA), the primary sensory association area (SAA), and the higher order association area (HAA). The PSA contains feature neurons which respond to many elementary features, e.g., colors, shapes, syllables, and basic flavors. The SAA contains primary concept neurons which combine the elementary features in the PSA to represent unimodal concept of objects, e.g., the image of an apple, the Chinese word ""[ping guo]"" which names the apple, and the taste of the apple. The HAA contains associated neurons which connect the primary concept neurons of several PSA, e.g., connects the image, the taste, and the name of an apple. It means that the associated neurons have a multimodal response mode. Therefore, this area executes multisensory integration. PCN is an online incremental learning system, it is able to continuously acquire and bind multimodality concepts in an online way. The experimental results suggest that PCN is able to handle the multimodal concept acquisition and binding effectively.",4
Stepsize Range and Optimal Value for Taylor-Zhang Discretization Formula Applied to Zeroing Neurodynamics Illustrated via Future Equality-Constrained Quadratic Programming.,"In this brief, future equality-constrained quadratic programming (FECQP) is studied. Via a zeroing neurodynamics method, a continuous-time zeroing neurodynamics (CTZN) model is presented. By using Taylor-Zhang discretization formula to discretize the CTZN model, a Taylor-Zhang discrete-time zeroing neurodynamics (TZ-DTZN) model is presented to perform FECQP. Furthermore, we focus on the critical parameter of the TZ-DTZN model, i.e., stepsize. By theoretical analyses, we obtain an effective range of the stepsize, which guarantees the stability of the TZ-DTZN model. In addition, we further discuss the optimal value of the stepsize, which makes the TZ-DTZN model possess the optimal stability (i.e., the best stability with the fastest convergence). Finally, numerical experiments and application experiments for motion generation of a robot manipulator are conducted to verify the high precision of the TZ-DTZN model and the effective range and optimal value of the stepsize for FECQP.",4
Adaptive Learning Control for Nonlinear Systems With Randomly Varying Iteration Lengths.,"This paper proposes adaptive iterative learning control (ILC) schemes for continuous-time parametric nonlinear systems with iteration lengths that randomly vary. As opposed to the existing ILC works that feature nonuniform trial lengths, this paper is applicable to nonlinear systems that do not satisfy the globally Lipschitz continuous condition. In addition, this paper introduces a novel composite energy function based on newly defined virtual tracking error information for proving the asymptotical convergence. Both an original update algorithm and a projection-based update algorithm for estimating the unknown parameters are proposed. Extensions to cases with unknown input gains, iteration-varying tracking references, nonparametric uncertainty, high-order nonlinear systems, and multi-input-multi-output systems are all elaborated upon. Illustrative simulations are provided to verify the theoretical results.",4
Active Learning From Imbalanced Data: A Solution of Online Weighted Extreme Learning Machine.,"It is well known that active learning can simultaneously improve the quality of the classification model and decrease the complexity of training instances. However, several previous studies have indicated that the performance of active learning is easily disrupted by an imbalanced data distribution. Some existing imbalanced active learning approaches also suffer from either low performance or high time consumption. To address these problems, this paper describes an efficient solution based on the extreme learning machine (ELM) classification model, called active online-weighted ELM (AOW-ELM). The main contributions of this paper include: 1) the reasons why active learning can be disrupted by an imbalanced instance distribution and its influencing factors are discussed in detail; 2) the hierarchical clustering technique is adopted to select initially labeled instances in order to avoid the missed cluster effect and cold start phenomenon as much as possible; 3) the weighted ELM (WELM) is selected as the base classifier to guarantee the impartiality of instance selection in the procedure of active learning, and an efficient online updated mode of WELM is deduced in theory; and 4) an early stopping criterion that is similar to but more flexible than the margin exhaustion criterion is presented. The experimental results on 32 binary-class data sets with different imbalance ratios demonstrate that the proposed AOW-ELM algorithm is more effective and efficient than several state-of-the-art active learning algorithms that are specifically designed for the class imbalance scenario.",4
Markov Boundary-Based Outlier Mining.,"It is a grand challenge to identify the outliers existing in subspaces from a high-dimensional data set. A brute-force method is computationally prohibitive since it requires examining an exponential number of subspaces. Current state-of-the-art methods explore various heuristics to significantly prune subspaces, facing the tradeoff between the subspace completeness and search efficiency. In this brief, we discuss a principal type of subspace outliers whose behaviors are different from the others on individual attributes. We formulate such outliers by a novel notion of the Markov boundary-based (MBB) outliers. The central idea is that for each attribute T in a data set, we consider only the subspace representing the knowledge needed to predict the behavior on T , which is captured by the MB of T . Then, the outliers whose behavior is different from others on T can be detected in the subspace of the MB, and thus, our approach reduces the number of possible subspaces from exponential to linear with respect to dimensionality. Using both synthetic and real data sets, we validate the effectiveness and efficiency of our method.",4
Spectral Embedded Adaptive Neighbors Clustering.,"Spectral clustering has been widely used in various aspects, especially the machine learning fields. Clustering with similarity matrix and low-dimensional representation of data is the main reason of its promising performance shown in spectral clustering. However, such similarity matrix and low-dimensional representation directly derived from input data may not always hold when the data are high dimensional and has complex distribution. First, the similarity matrix simply based on the distance measurement might not be suitable for all kinds of data. Second, the low-dimensional representation might not be able to reflect the manifold structure of the original data. In this brief, we propose a novel linear space embedded clustering method, which uses adaptive neighbors to address the above-mentioned problems. Linearity regularization is used to make the data representation a linear embedded spectral. We also use adaptive neighbors to optimize the similarity matrix and clustering results simultaneously. Extensive experimental results show promising performance compared with the other state-of-the-art algorithms.",4
Online Robust Low-Rank Tensor Modeling for Streaming Data Analysis.,"Tensor data (i.e., the data having multiple dimensions) are quickly growing in scale in many practical applications, which poses new challenges for data modeling and analysis approaches, such as high-order relations of large complexity, gross noise, and varying data scale. Existing low-rank data analysis methods, which are effective at analyzing matrix data, may fail in the regime of tensor data due to these challenges. A robust and scalable low-rank tensor modeling method is heavily desired. In this paper, we develop an online robust low-rank tensor modeling (ORLTM) method to address these challenges. The ORLTM method leverages the high-order correlations among all tensor modes to model an intrinsic low-rank structure of streaming tensor data online and can effectively analyze data residing in a mixture of multiple subspaces by virtue of dictionary learning. ORLTM consumes a very limited memory space that remains constant regardless of the increase of tensor data size, which facilitates processing tensor data at a large scale. More concretely, it models each mode unfolding of streaming tensor data using the bilinear formulation of tensor nuclear norms. With this reformulation, ORLTM employs a stochastic optimization algorithm to learn the tensor low-rank structure alternatively for online updating. To capture the final tensors, ORLTM uses an average pooling operation on folded tensors in all modes. We also provide the analysis regarding computational complexity, memory cost, and convergence. Moreover, we extend ORLTM to the image alignment scenario by incorporating the geometrical transformations and linearizing the constraints. Extensive empirical studies on synthetic database and three practical vision tasks, including video background subtraction, image alignment, and visual tracking, have demonstrated the superiority of the proposed method.",4
Adaptive Neural State-Feedback Tracking Control of Stochastic Nonlinear Switched Systems: An Average Dwell-Time Method.,"In this paper, the problem of adaptive neural state-feedback tracking control is considered for a class of stochastic nonstrict-feedback nonlinear switched systems with completely unknown nonlinearities. In the design procedure, the universal approximation capability of radial basis function neural networks is used for identifying the unknown compounded nonlinear functions, and a variable separation technique is employed to overcome the design difficulty caused by the nonstrict-feedback structure. The most outstanding novelty of this paper is that individual Lyapunov function of each subsystem is constructed by flexibly adopting the upper and lower bounds of the control gain functions of each subsystem. Furthermore, by combining the average dwell-time scheme and the adaptive backstepping design, a valid adaptive neural state-feedback controller design algorithm is presented such that all the signals of the switched closed-loop system are in probability semiglobally uniformly ultimately bounded, and the tracking error eventually converges to a small neighborhood of the origin in probability. Finally, the availability of the developed control scheme is verified by two simulation examples.",4
Denoising Adversarial Autoencoders.,"Unsupervised learning is of growing interest because it unlocks the potential held in vast amounts of unlabeled data to learn useful representations for inference. Autoencoders, a form of generative model, may be trained by learning to reconstruct unlabeled input data from a latent representation space. More robust representations may be produced by an autoencoder if it learns to recover clean input samples from corrupted ones. Representations may be further improved by introducing regularization during training to shape the distribution of the encoded data in the latent space. We suggest denoising adversarial autoencoders (AAEs), which combine denoising and regularization, shaping the distribution of latent space using adversarial training. We introduce a novel analysis that shows how denoising may be incorporated into the training and sampling of AAEs. Experiments are performed to assess the contributions that denoising makes to the learning of representations for classification and sample synthesis. Our results suggest that autoencoders trained using a denoising criterion achieve higher classification performance and can synthesize samples that are more consistent with the input data than those trained without a corruption process.",4
From Deterministic to Generative: Multimodal Stochastic RNNs for Video Captioning.,"Video captioning, in essential, is a complex natural process, which is affected by various uncertainties stemming from video content, subjective judgment, and so on. In this paper, we build on the recent progress in using encoder-decoder framework for video captioning and address what we find to be a critical deficiency of the existing methods that most of the decoders propagate deterministic hidden states. Such complex uncertainty cannot be modeled efficiently by the deterministic models. In this paper, we propose a generative approach, referred to as multimodal stochastic recurrent neural networks (MS-RNNs), which models the uncertainty observed in the data using latent stochastic variables. Therefore, MS-RNN can improve the performance of video captioning and generate multiple sentences to describe a video considering different random factors. Specifically, a multimodal long short-term memory (LSTM) is first proposed to interact with both visual and textual features to capture a high-level representation. Then, a backward stochastic LSTM is proposed to support uncertainty propagation by introducing latent variables. Experimental results on the challenging data sets, microsoft video description and microsoft research video-to-text, show that our proposed MS-RNN approach outperforms the state-of-the-art video captioning benchmarks.",4
Category-Based Deep CCA for Fine-Grained Venue Discovery From Multimodal Data.,"In this work, travel destinations and business locations are taken as venues. Discovering a venue by a photograph is very important for visual context-aware applications. Unfortunately, few efforts paid attention to complicated real images such as venue photographs generated by users. Our goal is fine-grained venue discovery from heterogeneous social multimodal data. To this end, we propose a novel deep learning model, category-based deep canonical correlation analysis. Given a photograph as input, this model performs: 1) exact venue search (find the venue where the photograph was taken) and 2) group venue search (find relevant venues that have the same category as the photograph), by the cross-modal correlation between the input photograph and textual description of venues. In this model, data in different modalities are projected to a same space via deep networks. Pairwise correlation (between different modality data from the same venue) for exact venue search and category-based correlation (between different modality data from different venues with the same category) for group venue search are jointly optimized. Because a photograph cannot fully reflect rich text description of a venue, the number of photographs per venue in the training phase is increased to capture more aspects of a venue. We build a new venue-aware multimodal data set by integrating Wikipedia featured articles and Foursquare venue photographs. Experimental results on this data set confirm the feasibility of the proposed method. Moreover, the evaluation over another publicly available data set confirms that the proposed method outperforms state of the arts for cross-modal retrieval between image and text.",4
Self-Organizing Neuroevolution for Solving Carpool Service Problem With Dynamic Capacity to Alternate Matches.,"Traffic congestion often incurs environmental problems. One of the most effective ways to mitigate this is carpooling transportation, which substantially reduces automobile demands. Due to the popularization of smartphones and mobile applications, a carpool service can be conveniently accessed via the intelligent carpool system. In this system, the service optimization required to intelligently and adaptively distribute the carpool participant resources is called the carpool service problem (CSP). Several previous studies have examined viable and preliminary solutions to the CSP by using exact and metaheuristic optimization approaches. For CSP-solving, evolutionary computation (e.g., metaheuristics) is a more promising option in comparison to exact-type approaches. However, all the previous state-of-the-art approaches use pure optimization to solve the CSP. In this paper, we employ the framework of neuroevolution to propose the self-organizing map-based neuroevolution (SOMNE) solver by which the SOM-like network represents the abstract CSP solution and is well-trained by using neural learning and evolutionary mechanism. The experimental section of this paper investigates the comparisons and analyses of two objective functions of the CSP and demonstrates that the proposed SOMNE solver achieves superior results when compared against those the other approaches produce, especially in regard to the optimization of the primary objective functions of the CSP. Finally, the visual results of the SOM are illustrated to show the effectiveness and efficiency of the evolutionary neural learning process.",4
Semantically Modeling of Object and Context for Categorization.,"Object-centric-based categorization methods have been proven more effective than hard partitions of images (e.g., spatial pyramid matching). However, how to determine the locations of objects is still an open problem. Besides, modeling of context areas is often mixed with the background. Moreover, the semantic information is often ignored by these methods that only use visual representations for classification. In this paper, we propose an object categorization method by semantically modeling the object and context information (SOC). We first select a number of candidate regions with high confidence scores and semantically represent these regions by measuring correlations of each region with prelearned classifiers (e.g., local feature-based classifiers and deep convolutional-neural-network-based classifiers). These regions are clustered for object selections. The other selected areas are then viewed as context areas. We treat other areas beyond the object and context areas within one image as the background. The visually and semantically represented objects and contexts are then used along with the background area for object representations and categorizations. Experimental results on several public data sets well demonstrate the effectiveness of the proposed object categorization method by semantically modeling the object and context information.",4
Variational Bayesian Learning of Generalized Dirichlet-Based Hidden Markov Models Applied to Unusual Events Detection.,"Learning a hidden Markov model (HMM) is typically based on the computation of a likelihood which is intractable due to a summation over all possible combinations of states and mixture components. This estimation is often tackled by a maximization strategy, which is known as the Baum-Welch algorithm. However, some drawbacks of this approach have led to the consideration of Bayesian methods that add a prior over the parameters in order to work with the posterior probability and the marginal likelihood. These approaches can lead to good models but to the cost of extremely long computations (e.g., Markov Chain Monte Carlo). More recently, variational Bayesian frameworks have been proposed as a Bayesian alternative that keeps the computation tractable and the approximation tight. It relies on the introduction of a prior over the parameters to be learned and on an approximation of the true posterior distribution. After proving good standing in the case of finite mixture models and discrete and Gaussian HMMs, we propose here to derive the equations of the variational learning of the Dirichlet mixture-based HMM, and to extend it to the generalized Dirichlet. The latter case presents several properties that make the estimation more accurate. We prove the validity of this approach within the context of unusual event detection in public areas using the University of California San Diego data sets. HMMs are trained over normal video sequences using the typical Baum-Welch approach versus the variational one. The variational learning leads to more accurate models for the detection and localization of anomaly, and the general HMM approach is shown to be versatile enough to handle the detection of various synthetically generated tampering events.",4
Spatially Regularized Structural Support Vector Machine for Robust Visual Tracking.,"Structural support vector machine (SSVM) is popular in the visual tracking field as it provides a consistent target representation for both learning and detection. However, the spatial distribution of feature is not considered in standard SSVM-based trackers, therefore leading to limited performance. To obtain a robust discriminative classifier, this paper proposes a novel tracking framework that spatially regularizes SSVM, which yields a new spatially regularized SSVM (SRSSVM). We utilize the spatial regularization prior to penalize the learning classifier with the same size as the target region. The location of classifier spatially located far from the center of region is assigned large weight and vice versa. Then, it is introduced into the SSVM model as a regularization factor to learn the robust discriminative model. Furthermore, an optimizing algorithm with dual coordination descent is presented to efficiently solve the SRSSVM tracking model. Our proposed SRSSVM tracking method has low computational cost like the traditional linear SSVM tracker while can significantly improve the robustness of the discriminative classifier. The experimental results on three popular tracking benchmark data sets show that the proposed SRSSVM tracking method performs favorably against the state-of-the-art trackers.",4
Exponential Synchronization for Delayed Dynamical Networks via Intermittent Control: Dealing With Actuator Saturations.,"Over the past two decades, the synchronization problem for dynamical networks has drawn significant attention due to its clear practical insight in biological systems, social networks, and neuroscience. In the case where a dynamical network cannot achieve the synchronization by itself, the feedback controller should be added to drive the network toward a desired orbit. On the other hand, the time delays may often occur in the nodes or the couplings of a dynamical network, and the existence of time delays may induce some undesirable dynamics or even instability. Moreover, in the course of implementing a feedback controller, the inevitable actuator limitations could downgrade the system performance and, in the worst case, destabilize the closed-loop dynamics. The main purpose of this paper is to consider the synchronization problem for a class of delayed dynamical networks with actuator saturations. Each node of the dynamical network is described by a nonlinear system with a time-varying delay and the intermittent control strategy is proposed. By using a combination of novel sector conditions, piecewise Lyapunov-like functionals and the switched system approach, delay-dependent sufficient conditions are first obtained under which the dynamical network is locally exponentially synchronized. Then, the explicit characterization of the controller gains is established by means of the feasibility of certain matrix inequalities. Furthermore, optimization problems are formulated in order to acquire a larger estimate of the set of initial conditions for the evolution of the error dynamics when designing the intermittent controller. Finally, two examples are given to show the benefits and effectiveness of the developed theoretical results.",4
Exponential Synchronizationlike Criterion for State-Dependent Impulsive Dynamical Networks.,"This paper focuses on the problem of the exponential synchronizationlike criteria for state-dependent impulsive dynamical networks (SIDNs). Two types of sufficient conditions, which are applied to ensure every solution intersecting each impulsive surface exactly once, are derived. For each type of collision conditions, combining with comparison principle and inequality techniques, some sufficient conditions are obtained to ensure local exponential synchronizationlike for SIDN. Moreover, a quiet different impulsive strategy concerning the trigger rules of impulsive instants is proposed. Finally, an example is given to demonstrate the effectiveness of our results.",4
Asymptotically Optimal Contextual Bandit Algorithm Using Hierarchical Structures.,"We propose an online algorithm for sequential learning in the contextual multiarmed bandit setting. Our approach is to partition the context space and, then, optimally combine all of the possible mappings between the partition regions and the set of bandit arms in a data-driven manner. We show that in our approach, the best mapping is able to approximate the best arm selection policy to any desired degree under mild Lipschitz conditions. Therefore, we design our algorithm based on the optimal adaptive combination and asymptotically achieve the performance of the best mapping as well as the best arm selection policy. This optimality is also guaranteed to hold even in adversarial environments since we do not rely on any statistical assumptions regarding the contexts or the loss of the bandit arms. Moreover, we design an efficient implementation for our algorithm using various hierarchical partitioning structures, such as lexicographical or arbitrary position splitting and binary trees (BTs) (and several other partitioning examples). For instance, in the case of BT partitioning, the computational complexity is only log-linear in the number of regions in the finest partition. In conclusion, we provide significant performance improvements by introducing upper bounds (with respect to the best arm selection policy) that are mathematically proven to vanish in the average loss per round sense at a faster rate compared to the state of the art. Our experimental work extensively covers various scenarios ranging from bandit settings to multiclass classification with real and synthetic data. In these experiments, we show that our algorithm is highly superior to the state-of-the-art techniques while maintaining the introduced mathematical guarantees and a computationally decent scalability.",4
Exploring Self-Repair in a Coupled Spiking Astrocyte Neural Network.,"It is now known that astrocytes modulate the activity at the tripartite synapses where indirect signaling via the retrograde messengers, endocannabinoids, leads to a localized self-repairing capability. In this paper, a self-repairing spiking astrocyte neural network (SANN) is proposed to demonstrate a distributed self-repairing capability at the network level. The SANN uses a novel learning rule that combines the spike-timing-dependent plasticity (STDP) and Bienenstock, Cooper, and Munro (BCM) learning rules (hereafter referred to as the BSTDP rule). In this learning rule, the synaptic weight potentiation is not only driven by the temporal difference between the presynaptic and postsynaptic neuron firing times but also by the postsynaptic neuron activity. We will show in this paper that the BSTDP modulates the height of the plasticity window to establish an input-output mapping (in the learning phase) and also maintains this mapping (via self-repair) if synaptic pathways become dysfunctional. It is the functional dependence of postsynaptic neuron firing activity on the height of the plasticity window that underpins how the proposed SANN self-repairs on the fly. The SANN also uses the coupling between the tripartite synapses and gamma -GABAergic interneurons. This interaction gives rise to a presynaptic neuron frequency filtering capability that serves to route information, represented as spike trains, to different neurons in the subsequent layers of the SANN. The proposed SANN follows a feedforward architecture with multiple interneuron pathways and astrocytes modulate synaptic activity at the hidden and output neuronal layers. The self-repairing capability will be demonstrated in a robotic obstacle avoidance application, and the simulation results will show that the SANN can maintain learned maneuvers at synaptic fault densities of up to 80% regardless of the fault locations.",4
General Square-Pattern Discretization Formulas via Second-Order Derivative Elimination for Zeroing Neural Network Illustrated by Future Optimization.,"Previous works provide a few effective discretization formulas for zeroing neural network (ZNN), of which the precision is a square pattern. However, those formulas are separately developed via many relatively blind attempts. In this paper, general square-pattern discretization (SPD) formulas are proposed for ZNN via the idea of the second-order derivative elimination. All existing SPD formulas in previous works are included in the framework of the general SPD formulas. The connections and differences of various general formulas are also discussed. Furthermore, the general SPD formulas are used to solve future optimization under linear equality constraints, and the corresponding general discrete ZNN models are proposed. General discrete ZNN models have at least one parameter to adjust, thereby determining their zero stability. Thus, the parameter domains are obtained by restricting zero stability. Finally, numerous comparative numerical experiments, including the motion control of a PUMA560 robot manipulator, are provided to substantiate theoretical results and their superiority to conventional Euler formula.",4
A Novel Cluster Validity Index Based on Local Cores.,"It is critical to evaluate the quality of clusters for most cluster analysis. A number of cluster validity indexes have been proposed, such as the Silhouette and Davies-Bouldin indexes. However, these validity indexes cannot be used to process clusters with arbitrary shapes. Some researchers employ graph-based distance to cluster nonspherical data sets, but the computation of graph-based distances between all pairs of points in a data set is time-consuming. A potential solution is to select some representative points. Inspired by this idea, we propose a novel Local Cores-based Cluster Validity (LCCV) index to improve the performance of Silhouette index. Local cores, with local maximum density, are selected as representative points. Since graph-based distance is used to evaluate the dissimilarity between local cores, the LCCV index is effective for obtaining the optimal cluster number for data sets containing clusters with arbitrary shapes. Moreover, a hierarchical clustering algorithm based on the LCCV index is proposed. The experimental results on synthetic and real data sets indicate that the new index outperforms existing ones.",4
Hierarchical Stability Conditions for a Class of Generalized Neural Networks With Multiple Discrete and Distributed Delays.,"This brief investigates the analysis issue for global asymptotic stability of a class of generalized neural networks with multiple discrete and distributed delays. To tackle delays arising in different neuron activation functions, we employ a generalized model with multiple discrete and distributed delays which covers various existing neural networks. We then generalize the Bessel-Legendre inequalities to deal with integral terms with any linearly independent functions and nonlinear function of states. Based on these inequalities, we design the Lyapunov-Krasovskii functional and derive hierarchical linear matrix inequality stability conditions. Finally, three numerical examples are provided to demonstrate that the proposed method is less conservative with a reasonable numerical burden than the existing results.",4
Synchronization of Coupled Markovian Reaction-Diffusion Neural Networks With Proportional Delays Via Quantized Control.,"The asymptotic synchronization of coupled reaction-diffusion neural networks with proportional delay and Markovian switching topologies is considered in this brief where the diffusion space does not need to contain the origin. The main objectives of this brief are to save communication resources and to reduce the conservativeness of the obtained synchronization criteria, which are carried out from the following two aspects: 1) mode-dependent quantized control technique is designed to reduce control cost and save communication channels and 2) Wirtinger inequality is utilized to deal with the reaction-diffusion terms in a matrix form and reciprocally convex technique combined with new Lyapunov-Krasovskii functional is used to derive delay-dependent synchronization criteria. The obtained results are general and formulated by linear matrix inequalities. Moreover, combined with an optimal algorithm, control gains with the least magnitude are designed.",4
Fast and Accurate Hierarchical Clustering Based on Growing Multilayer Topology Training.,"Hierarchical clustering has been extensively applied for data analysis and knowledge discovery. However, the scalability of hierarchical clustering methods is generally limited due to their time complexity of O(n(2)) , where n is the size of the input data. To address this issue, we present a fast and accurate hierarchical clustering algorithm based on topology training. Specifically, a trained multilayer topological structure that fits the spatial distribution of the data is utilized to accelerate the similarity measurement, which dominates the computational cost in hierarchical clustering. Moreover, the topological structure also guides the merging steps in hierarchical clustering to form a meaningful and accurate clustering result. In addition, an incremental version of the proposed algorithm is further designed so that the proposed approach is applicable to the streaming data as well. Promising experimental results on various data sets demonstrate the efficiency and effectiveness of the proposed algorithms.",4
Optimal Control of Propagating Fronts by Using Level Set Methods and Neural Approximations.,"We address the optimal control of level sets associated with the solution of the normal flow equation. The problem consists in finding the normal velocity to the front described by a certain level set in such a way to minimize a given cost functional. First, the considered problem is shown to admit a solution on a suitable space of functions. Then, since in general it is difficult to solve it analytically, an approximation scheme that relies on the extended Ritz method is proposed to find suboptimal solutions. Specifically, the control law is forced to take on a neural structure depending nonlinearly on a finite number of parameters to be tuned, i.e., the neural weights. The selection of the optimal weights is performed with two different approaches. The first one employs classical line-search descent methods, while the second one is based on a quasi-Newton optimization that can be regarded as neural learning based on the extended Kalman filter. Compared with line-search methods, such an approach reveals to be successful with a reduced computational effort and an increased robustness with respect to the trapping into local minima, as confirmed by simulations in both two and three dimensions.",4
Robust Stabilization of Delayed Neural Networks: Dissipativity-Learning Approach.,"This paper examines the robust stabilization problem of continuous-time delayed neural networks via the dissipativity-learning approach. A new learning algorithm is established to guarantee the asymptotic stability as well as the (Q,S,R) - alpha -dissipativity of the considered neural networks. The developed result encompasses some existing results, such as Hinfinity and passivity performances, in a unified framework. With the introduction of a Lyapunov-Krasovskii functional together with the Legendre polynomial, a novel delay-dependent linear matrix inequality (LMI) condition and a learning algorithm for robust stabilization are presented. Demonstrative examples are given to show the usefulness of the established learning algorithm.",4
Cost-Effective Object Detection: Active Sample Mining With Switchable Selection Criteria.,"Though quite challenging, leveraging large-scale unlabeled or partially labeled data in learning systems (e.g., model/classifier training) has attracted increasing attentions due to its fundamental importance. To address this problem, many active learning (AL) methods have been proposed that employ up-to-date detectors to retrieve representative minority samples according to predefined confidence or uncertainty thresholds. However, these AL methods cause the detectors to ignore the remaining majority samples (i.e., those with low uncertainty or high prediction confidence). In this paper, by developing a principled active sample mining (ASM) framework, we demonstrate that cost-effective mining samples from these unlabeled majority data are a key to train more powerful object detectors while minimizing user effort. Specifically, our ASM framework involves a switchable sample selection mechanism for determining whether an unlabeled sample should be manually annotated via AL or automatically pseudolabeled via a novel self-learning process. The proposed process can be compatible with mini-batch-based training (i.e., using a batch of unlabeled or partially labeled data as a one-time input) for object detection. In this process, the detector, such as a deep neural network, is first applied to the unlabeled samples (i.e., object proposals) to estimate their labels and output the corresponding prediction confidences. Then, our ASM framework is used to select a number of samples and assign pseudolabels to them. These labels are specific to each learning batch based on the confidence levels and additional constraints introduced by the AL process and will be discarded afterward. Then, these temporarily labeled samples are employed for network fine-tuning. In addition, a few samples with low-confidence predictions are selected and annotated via AL. Notably, our method is suitable for object categories that are not seen in the unlabeled data during the learning process. Extensive experiments on two public benchmarks (i.e., the PASCAL VOC 2007/2012 data sets) clearly demonstrate that our ASM framework can achieve performance comparable to that of the alternative methods but with significantly fewer annotations.",4
Multiview Subspace Clustering via Tensorial t-Product Representation.,"The ubiquitous information from multiple-view data, as well as the complementary information among different views, is usually beneficial for various tasks, for example, clustering, classification, denoising, and so on. Multiview subspace clustering is based on the fact that multiview data are generated from a latent subspace. To recover the underlying subspace structure, a successful approach adopted recently has been sparse and/or low-rank subspace clustering. Despite the fact that existing subspace clustering approaches may numerically handle multiview data, by exploring all possible pairwise correlation within views, high-order statistics that can only be captured by simultaneously utilizing all views are often overlooked. As a consequence, the clustering performance of the multiview data is compromised. To address this issue, in this paper, a novel multiview clustering method is proposed by using t-product in the third-order tensor space. First, we propose a novel tensor construction method to organize multiview tensorial data, to which the tensor-tensor product can be applied. Second, based on the circular convolution operation, multiview data can be effectively represented by a t-linear combination with sparse and low-rank penalty using ""self-expressiveness."" Our extensive experimental results on face, object, digital image, and text data demonstrate that the proposed method outperforms the state-of-the-art methods for a range of criteria.",4
Local Restricted Convolutional Neural Network for Change Detection in Polarimetric SAR Images.,"To detect changed areas in multitemporal polarimetric synthetic aperture radar (SAR) images, this paper presents a novel version of convolutional neural network (CNN), which is named local restricted CNN (LRCNN). CNN with only convolutional layers is employed for change detection first, and then LRCNN is formed by imposing a spatial constraint called local restriction on the output layer of CNN. In the training of CNN/LRCNN, the polarimetric property of SAR image is fully used instead of manual labeled pixels. As a preparation, a similarity measure for polarimetric SAR data is proposed, and several layered difference images (LDIs) of polarimetric SAR images are produced. Next, the LDIs are transformed into discriminative enhanced LDIs (DELDIs). CNN/LRCNN is trained to model these DELDIs by a regression pretraining, and then a classification fine-tuning is conducted with some pseudolabeled pixels obtained from DELDIs. Finally, the change detection result showing changed areas is directly generated from the output of the trained CNN/LRCNN. The relation of LRCNN to the traditional way for change detection is also discussed to illustrate our method from an overall point of view. Tested on one simulated data set and two real data sets, the effectiveness of LRCNN is certified and it outperforms various traditional algorithms. In fact, the experimental results demonstrate that the proposed LRCNN for change detection not only recognizes different types of changed/unchanged data, but also ensures noise insensitivity without losing details in changed areas.",4
Fine-Grained Image Classification Using Modified DCNNs Trained by Cascaded Softmax and Generalized Large-Margin Losses.,"We develop a fine-grained image classifier using a general deep convolutional neural network (DCNN). We improve the fine-grained image classification accuracy of a DCNN model from the following two aspects. First, to better model the h -level hierarchical label structure of the fine-grained image classes contained in the given training data set, we introduce h fully connected (fc) layers to replace the top fc layer of a given DCNN model and train them with the cascaded softmax loss. Second, we propose a novel loss function, namely, generalized large-margin (GLM) loss, to make the given DCNN model explicitly explore the hierarchical label structure and the similarity regularities of the fine-grained image classes. The GLM loss explicitly not only reduces between-class similarity and within-class variance of the learned features by DCNN models but also makes the subclasses belonging to the same coarse class be more similar to each other than those belonging to different coarse classes in the feature space. Moreover, the proposed fine-grained image classification framework is independent and can be applied to any DCNN structures. Comprehensive experimental evaluations of several general DCNN models (AlexNet, GoogLeNet, and VGG) using three benchmark data sets (Stanford car, fine-grained visual classification-aircraft, and CUB-200-2011) for the fine-grained image classification task demonstrate the effectiveness of our method.",4
Robot Learning System Based on Adaptive Neural Control and Dynamic Movement Primitives.,"This paper proposes an enhanced robot skill learning system considering both motion generation and trajectory tracking. During robot learning demonstrations, dynamic movement primitives (DMPs) are used to model robotic motion. Each DMP consists of a set of dynamic systems that enhances the stability of the generated motion toward the goal. A Gaussian mixture model and Gaussian mixture regression are integrated to improve the learning performance of the DMP, such that more features of the skill can be extracted from multiple demonstrations. The motion generated from the learned model can be scaled in space and time. Besides, a neural-network-based controller is designed for the robot to track the trajectories generated from the motion model. In this controller, a radial basis function neural network is used to compensate for the effect caused by the dynamic environments. The experiments have been performed using a Baxter robot and the results have confirmed the validity of the proposed methods.",4
Exponential Stabilization of Fuzzy Memristive Neural Networks With Hybrid Unbounded Time-Varying Delays.,"This paper is concerned with exponential stabilization for a class of Takagi-Sugeno fuzzy memristive neural networks (FMNNs) with unbounded discrete and distributed time-varying delays. Under the framework of Filippov solutions, algebraic criteria are established to guarantee exponential stabilization of the addressed FMNNs with hybrid unbounded time delays via designing a fuzzy state feedback controller by exploiting inequality techniques, calculus theorems, and theories of fuzzy sets. The obtained results in this paper enhance and generalize some existing ones. Meanwhile, a general theoretical framework is proposed to investigate the dynamical behaviors of various neural networks with mixed infinite time delays. Finally, two simulation examples are performed to illustrate the validity of the derived outcomes.",4
NullHop: A Flexible Convolutional Neural Network Accelerator Based on Sparse Representations of Feature Maps.,"Convolutional neural networks (CNNs) have become the dominant neural network architecture for solving many state-of-the-art (SOA) visual processing tasks. Even though graphical processing units are most often used in training and deploying CNNs, their power efficiency is less than 10 GOp/s/W for single-frame runtime inference. We propose a flexible and efficient CNN accelerator architecture called NullHop that implements SOA CNNs useful for low-power and low-latency application scenarios. NullHop exploits the sparsity of neuron activations in CNNs to accelerate the computation and reduce memory requirements. The flexible architecture allows high utilization of available computing resources across kernel sizes ranging from 1x1 to 7x7 . NullHop can process up to 128 input and 128 output feature maps per layer in a single pass. We implemented the proposed architecture on a Xilinx Zynq field-programmable gate array (FPGA) platform and presented the results showing how our implementation reduces external memory transfers and compute time in five different CNNs ranging from small ones up to the widely known large VGG16 and VGG19 CNNs. Postsynthesis simulations using Mentor Modelsim in a 28-nm process with a clock frequency of 500 MHz show that the VGG19 network achieves over 450 GOp/s. By exploiting sparsity, NullHop achieves an efficiency of 368%, maintains over 98% utilization of the multiply-accumulate units, and achieves a power efficiency of over 3 TOp/s/W in a core area of 6.3 mm(2). As further proof of NullHop's usability, we interfaced its FPGA implementation with a neuromorphic event camera for real-time interactive demonstrations.",4
Discriminative Feature Selection via Employing Smooth and Robust Hinge Loss.,"A wide variety of sparsity-inducing feature selection methods have been developed in recent years. Most of the loss functions of these approaches are built upon regression since it is general and easy to optimize, but regression is not well suitable for classification. In contrast, the hinge loss (HL) of support vector machines has proved to be powerful to handle classification tasks, but a model with existing multiclass HL and sparsity regularization is difficult to optimize. In view of that, we propose a new loss, called smooth and robust HL, which gathers the merits of regression and HL but overcome their drawbacks, and apply it to our sparsity regularized feature selection model. To optimize the model, we present a new variant of accelerated proximal gradient (APG) algorithm, which boosts the discriminative margins among different classes, compared with standard APG algorithms. We further propose an efficient optimization technique to solve the proximal projection problem at each iteration step, which is a key component of the new APG algorithm. We theoretically prove that the new APG algorithm converges at rate O(1/k(2)) if it is convex ( k is the iteration counter), which is the optimal convergence rate for smooth problems. Experimental results on nine publicly available data sets demonstrate the effectiveness of our method.",4
ICFS Clustering With Multiple Representatives for Large Data.,"With the prevailing development of Cyber-physical-social systems and Internet of Things, large-scale data have been collected consistently. Mining large data effectively and efficiently becomes increasingly important to promote the development and improve the service quality of these applications. Clustering, a popular data mining technique, aims to identify underlying patterns hidden in the data. Most clustering methods assume the static data, thus they are unfavorable for analyzing large, unbalanced dynamic data. In this paper, to address this concern, we focus on incremental clustering by extending the novel [clustering by fast search (CFS) and find of density peaks] method to incrementally handle large-scale dynamic data. Specifically, we first discuss two challenges, i.e., assignment of new arriving objects and dynamic adjustment of clusters, in incremental CFS (ICFS) clustering. We then propose two ICFS clustering algorithms, ICFS with multiple representatives (ICFSMR) and the enhanced ICFSMR (E_ICFSMR) to tackle the two challenges. In ICFSMR, we explore the convex hull theory to modify the representatives identified for each cluster. E_ICFSMR improves the generality and effectiveness of ICFSMR by exploring one-time cluster adjustment strategy after integration of each data chunk. We evaluate the proposed methods with extensive experiments on four benchmark data sets, as well as the air quality and traffic monitoring time series, with comparisons to CFS and other three state-of-the-art incremental clustering methods. Experimental results demonstrate that the proposed methods outperform the compared methods in terms of both effectiveness and efficiency.",4
"A Fast and Accurate Matrix Completion Method Based on QR Decomposition and L2,1 -Norm Minimization.","Low-rank matrix completion aims to recover matrices with missing entries and has attracted considerable attention from machine learning researchers. Most of the existing methods, such as weighted nuclear-norm-minimization-based methods and Qatar Riyal (QR)-decomposition-based methods, cannot provide both convergence accuracy and convergence speed. To investigate a fast and accurate completion method, an iterative QR-decomposition-based method is proposed for computing an approximate singular value decomposition. This method can compute the largest singular values of a matrix by iterative QR decomposition. Then, under the framework of matrix trifactorization, a method for computing an approximate SVD based on QR decomposition (CSVD-QR)-based L2,1 -norm minimization method (LNM-QR) is proposed for fast matrix completion. Theoretical analysis shows that this QR-decomposition-based method can obtain the same optimal solution as a nuclear norm minimization method, i.e., the L2,1 -norm of a submatrix can converge to its nuclear norm. Consequently, an LNM-QR-based iteratively reweighted L2,1 -norm minimization method (IRLNM-QR) is proposed to improve the accuracy of LNM-QR. Theoretical analysis shows that IRLNM-QR is as accurate as an iteratively reweighted nuclear norm minimization method, which is much more accurate than the traditional QR-decomposition-based matrix completion methods. Experimental results obtained on both synthetic and real-world visual data sets show that our methods are much faster and more accurate than the state-of-the-art methods.",4
Unsupervised Knowledge Transfer Using Similarity Embeddings.,"With the advent of deep neural networks, there is a growing interest in transferring the knowledge from a large and complex model to a smaller and faster one. In this brief, a method for unsupervised knowledge transfer (KT) between neural networks is proposed. To the best of our knowledge, the proposed method is the first method that utilizes similarity-induced embeddings to transfer the knowledge between any two layers of neural networks, regardless of the number of neurons in each of them. By this way, the knowledge is transferred without using any lossy dimensionality reduction transformations or requiring any information about the complex model, except for the activations of the layer used for KT. This is in contrast with most existing approaches that only generate soft-targets for training the smaller neural network or directly use the weights of the larger model. The proposed method is evaluated using six image data sets and it is demonstrated, through extensive experiments, that the knowledge of a neural network can be successfully transferred using different kinds of (synthetic or not) data, ranging from cross-domain data to just randomly generated data.",4
A Fused CP Factorization Method for Incomplete Tensors.,"Low-rank tensor completion methods have been advanced recently for modeling sparsely observed data with a multimode structure. However, low-rank priors may fail to interpret the model factors of general tensor objects. The most common method to address this drawback is to use regularizations together with the low-rank priors. However, due to the complex nature and diverse characteristics of real-world multiway data, the use of a single or a few regularizations remains far from efficient, and there are limited systematic experimental reports on the advantages of these regularizations for tensor completion. To fill these gaps, we propose a modified CP tensor factorization framework that fuses the l2 norm constraint, sparseness ( l1 norm), manifold, and smooth information simultaneously. The factorization problem is addressed through a combination of Nesterov's optimal gradient descent method and block coordinate descent. Here, we construct a smooth approximation to the l1 norm and TV norm regularizations, and then, the tensor factor is updated using the projected gradient method, where the step size is determined by the Lipschitz constant. Extensive experiments on simulation data, visual data completion, intelligent transportation systems, and GPS data of user involvement are conducted, and the efficiency of our method is confirmed by the results. Moreover, the obtained results reveal the characteristics of these commonly used regularizations for tensor completion in a certain sense and give experimental guidance concerning how to use them.",4
Indefinite Kernel Logistic Regression With Concave-Inexact-Convex Procedure.,"In kernel methods, the kernels are often required to be positive definitethat restricts the use of many indefinite kernels. To consider those nonpositive definite kernels, in this paper, we aim to build an indefinite kernel learning framework for kernel logistic regression (KLR). The proposed indefinite KLR (IKLR) model is analyzed in the reproducing kernel Krein spaces and then becomes nonconvex. Using the positive decomposition of a nonpositive definite kernel, the derived IKLR model can be decomposed into the difference of two convex functions. Accordingly, a concave-convex procedure (CCCP) is introduced to solve the nonconvex optimization problem. Since the CCCP has to solve a subproblem in each iteration, we propose a concave-inexact-convex procedure (CCICP) algorithm with an inexact solving scheme to accelerate the solving process. Besides, we propose a stochastic variant of CCICP to efficiently obtain a proximal solution, which achieves the similar purpose with the inexact solving scheme in CCICP. The convergence analyses of the above-mentioned two variants of CCCP are conducted. By doing so, our method works effectively not only in a deterministic setting but also in a stochastic setting. Experimental results on several benchmarks suggest that the proposed IKLR model performs favorably against the standard (positive definite) KLR and other competitive indefinite learning-based algorithms.",4
Distributed Generalized Nash Equilibrium Seeking Algorithm Design for Aggregative Games Over Weight-Balanced Digraphs.,"In this paper, two aggregative games over weight-balanced digraphs are studied, where the cost functions of all players depend on not only their own decisions but also the aggregate of all decisions. In the first problem, the cost functions of players are differentiable with Lipschitz gradients, and the decisions of all players are coupled by linear coupling constraints. In the second problem, the cost functions are nonsmooth, and the decisions of all players are constrained by local feasibility constraints as well as linear coupling constraints. In order to seek the variational generalized Nash equilibrium (GNE) of the differentiable aggregative games, a continuous-time distributed algorithm is developed via gradient descent and dynamic average consensus, and its exponential convergence to the variational GNE is proven with the help of Lyapunov stability theory. Then, another continuous-time distributed projection-based algorithm is proposed for the nonsmooth aggregative games based on differential inclusions and differentiated projection operations. Moreover, the convergence of the algorithm to the variational GNE is analyzed by utilizing singular perturbation analysis. Finally, simulation examples are presented to illustrate the effectiveness of our methods.",4
Modulation Classification Based on Signal Constellation Diagrams and Deep Learning.,"Deep learning (DL) is a new machine learning (ML) methodology that has found successful implementations in many application domains. However, its usage in communications systems has not been well explored. This paper investigates the use of the DL in modulation classification, which is a major task in many communications systems. The DL relies on a massive amount of data and, for research and applications, this can be easily available in communications systems. Furthermore, unlike the ML, the DL has the advantage of not requiring manual feature selections, which significantly reduces the task complexity in modulation classification. In this paper, we use two convolutional neural network (CNN)-based DL models, AlexNet and GoogLeNet. Specifically, we develop several methods to represent modulated signals in data formats with gridlike topologies for the CNN. The impacts of representation on classification performance are also analyzed. In addition, comparisons with traditional cumulant and ML-based algorithms are presented. Experimental results demonstrate the significant performance advantage and application feasibility of the DL-based approach for modulation classification.",4
Adaptive Optimal Output Regulation of Time-Delay Systems via Measurement Feedback.,"This brief proposes a novel solution to problems related to the measurement feedback adaptive optimal output regulation of discrete-time linear systems with input time-delay. Based on reinforcement learning and adaptive dynamic programming, an approximate optimal control policy is obtained via recursive numerical algorithms using online information. Convergence proofs for the proposed algorithms are given. Notably, the exact knowledge of the plant and the exosystem is not needed. The learned control policy is only a function of retrospective input and measurement output data. Theoretical analysis and an application to a grid-connected inverter show that the proposed methodologies serve as effective tools for solving adaptive and optimal output regulation problems.",4
Learning of a Decision-Maker's Preference Zone With an Evolutionary Approach.,"A new evolutionary-learning algorithm is proposed to learn a decision maker (DM)'s best solution on a conflicting multiobjective space. Given the exemplary pairwise comparisons of solutions by a DM, we learn an ideal point (for the DM) that is used to evolve toward a better set of solutions. The process is repeated to get the DM's best solution. The comparison of solutions in pairs facilitates the process of eliciting training information for the proposed learning model. Experimental study on standard multiobjective data sets shows that the proposed method accurately identifies a DM's preferred zone in relatively a few generations and with a small number of preferences. Besides, it is found to be robust to inconsistencies in the preference statements. The results obtained are validated through a variant of the established NSGA-2 algorithm.",4
DBSDA : Lowering the Bound of Misclassification Rate for Sparse Linear Discriminant Analysis via Model Debiasing.,"Linear discriminant analysis (LDA) is a well-known technique for linear classification, feature extraction, and dimension reduction. To improve the accuracy of LDA under the high dimension low sample size (HDLSS) settings, shrunken estimators, such as Graphical Lasso, can be used to strike a balance between biases and variances. Although the estimator with induced sparsity obtains a faster convergence rate, however, the introduced bias may also degrade the performance. In this paper, we theoretically analyze how the sparsity and the convergence rate of the precision matrix (also known as inverse covariance matrix) estimator would affect the classification accuracy by proposing an analytic model on the upper bound of an LDA misclassification rate. Guided by the model, we propose a novel classifier, DBSDA , which improves classification accuracy through debiasing. Theoretical analysis shows that DBSDA possesses a reduced upper bound of misclassification rate and better asymptotic properties than sparse LDA (SDA). We conduct experiments on both synthetic datasets and real application datasets to confirm the correctness of our theoretical analysis and demonstrate the superiority of DBSDA over LDA, SDA, and other downstream competitors under HDLSS settings.",4
Robust Dimension Reduction for Clustering With Local Adaptive Learning.,"In pattern recognition and data mining, clustering is a classical technique to group matters of interest and has been widely employed to numerous applications. Among various clustering algorithms, K-means (KM) clustering is most popular for its simplicity and efficiency. However, with the rapid development of the social network, high-dimensional data are frequently generated, which poses a considerable challenge to the traditional KM clustering as the curse of dimensionality. In such scenarios, it is difficult to directly cluster such high-dimensional data that always contain redundant features and noises. Although the existing approaches try to solve this problem using joint subspace learning and KM clustering, there are still the following limitations: 1) the discriminative information in low-dimensional subspace is not well captured; 2) the intrinsic geometric information is seldom considered; and 3) the optimizing procedure of a discrete cluster indicator matrix is vulnerable to noises. In this paper, we propose a novel clustering model to cope with the above-mentioned challenges. Within the proposed model, discriminative information is adaptively explored by unifying local adaptive subspace learning and KM clustering. We extend the proposed model using a robust l2,1 -norm loss function, where the robust cluster centroid can be calculated in a weighted iterative procedure. We also explore and discuss the relationships between the proposed algorithm and several related studies. Extensive experiments on kinds of benchmark data sets demonstrate the advantage of the proposed model compared with the state-of-the-art clustering approaches.",4
Multiclass Nonnegative Matrix Factorization for Comprehensive Feature Pattern Discovery.,"In this big data era, interpretable machine learning models are strongly demanded for the comprehensive analytics of large-scale multiclass data. Characterizing all features from such data is a key but challenging step to understand the complexity. However, existing feature selection methods do not meet this need. In this paper, to address this problem, we propose a Bayesian multiclass nonnegative matrix factorization (MC-NMF) model with structured sparsity that is able to discover ubiquitous and class-specific features. Variational update rules were derived for efficient decomposition. In order to relieve the need of model selection and stably describe feature patterns, we further propose MC-NMF with stability selection, an ensemble method that collectively detects feature patterns from many runs of MC-NMF using different hyperparameter values and training subsets. We assessed our models on both simulated count data and multitumor ribonucleic acid-seq data. The experiments revealed that our models were able to recover predefined feature patterns from the simulated data and identify biologically meaningful patterns from the pan-cancer data.",4
"Dendritic Neuron Model With Effective Learning Algorithms for Classification, Approximation, and Prediction.","An artificial neural network (ANN) that mimics the information processing mechanisms and procedures of neurons in human brains has achieved a great success in many fields, e.g., classification, prediction, and control. However, traditional ANNs suffer from many problems, such as the hard understanding problem, the slow and difficult training problems, and the difficulty to scale them up. These problems motivate us to develop a new dendritic neuron model (DNM) by considering the nonlinearity of synapses, not only for a better understanding of a biological neuronal system, but also for providing a more useful method for solving practical problems. To achieve its better performance for solving problems, six learning algorithms including biogeography-based optimization, particle swarm optimization, genetic algorithm, ant colony optimization, evolutionary strategy, and population-based incremental learning are for the first time used to train it. The best combination of its user-defined parameters has been systemically investigated by using the Taguchi's experimental design method. The experiments on 14 different problems involving classification, approximation, and prediction are conducted by using a multilayer perceptron and the proposed DNM. The results suggest that the proposed learning algorithms are effective and promising for training DNM and thus make DNM more powerful in solving classification, approximation, and prediction problems.",4
Admissible Delay Upper Bounds for Global Asymptotic Stability of Neural Networks With Time-Varying Delays.,"This paper is concerned with global asymptotic stability of a neural network with a time-varying delay, where the delay function is differentiable uniformly bounded with delay-derivative bounded from above. First, a general reciprocally convex inequality is presented by introducing some slack vectors with flexible dimensions. This inequality provides a tighter bound in the form of a convex combination than some existing ones. Second, by constructing proper Lyapunov-Krasovskii functional, global asymptotic stability of the neural network is analyzed for two types of the time-varying delays depending on whether or not the lower bound of the delay derivative is known. Third, noticing that sufficient conditions on stability from estimation on the derivative of some Lyapunov-Krasovskii functional are affine both on the delay function and its derivative, allowable delay sets can be refined to produce less conservative stability criteria for the neural network under study. Finally, two numerical examples are given to substantiate the effectiveness of the proposed method.",4
"Feature Selection With $\ell_{2,1-2}$ Regularization.","Feature selection aims to select a subset of features from high-dimensional data according to a predefined selecting criterion. Sparse learning has been proven to be a powerful technique in feature selection. Sparse regularizer, as a key component of sparse learning, has been studied for several years. Although convex regularizers have been used in many works, there are some cases where nonconvex regularizers outperform convex regularizers. To make the process of selecting relevant features more effective, we propose a novel nonconvex sparse metric on matrices as the sparsity regularization in this paper. The new nonconvex regularizer could be written as the difference of the $\ell _{2,1}$ norm and the Frobenius ( $\ell _{2,2}$ ) norm, which is named the $\ell _{2,1-2}$ . To find the solution of the resulting nonconvex formula, we design an iterative algorithm in the framework of ConCave-Convex Procedure (CCCP) and prove its strong global convergence. An adopted alternating direction method of multipliers is embedded to solve the sequence of convex subproblems in CCCP efficiently. Using the scaled cluster indictors of data points as pseudolabels, we also apply $\ell _{2,1-2}$ to the unsupervised case. To the best of our knowledge, it is the first work considering nonconvex regularization for matrices in the unsupervised learning scenario. Numerical experiments are performed on real-world data sets to demonstrate the effectiveness of the proposed method.",4
Stochastic Training of Neural Networks via Successive Convex Approximations.,"This paper proposes a new family of algorithms for training neural networks (NNs). These are based on recent developments in the field of nonconvex optimization, going under the general name of successive convex approximation techniques. The basic idea is to iteratively replace the original (nonconvex, highly dimensional) learning problem with a sequence of (strongly convex) approximations, which are both accurate and simple to optimize. Different from similar ideas (e.g., quasi-Newton algorithms), the approximations can be constructed using only first-order information of the NN function, in a stochastic fashion, while exploiting the overall structure of the learning problem for a faster convergence. We discuss several use cases, based on different choices for the loss function (e.g., squared loss and cross-entropy loss), and for the regularization of the NN's weights. We experiment on several medium-sized benchmark problems and on a large-scale data set involving simulated physical data. The results show how the algorithm outperforms the state-of-the-art techniques, providing faster convergence to a better minimum. Additionally, we show how the algorithm can be easily parallelized over multiple computational units without hindering its performance. In particular, each computational unit can optimize a tailored surrogate function defined on a randomly assigned subset of the input variables, whose dimension can be selected depending entirely on the available computational power.",4
"Matrix-Regularized Multiple Kernel Learning via (r,p) Norms.","This paper examines a matrix-regularized multiple kernel learning (MKL) technique based on a notion of (r,p) norms. For the problem of learning a linear combination in the support vector machine-based framework, model complexity is typically controlled using various regularization strategies on the combined kernel weights. Recent research has developed a generalized lp-norm MKL framework with tunable variable p(p>/=1) to support controlled intrinsic sparsity. Unfortunately, this ``1-D'' vector lp-norm hardly exploits potentially useful information on how the base kernels ``interact.'' To allow for higher order kernel-pair relationships, we extend the ``1-D'' vector lp-MKL to the ``2-D'' matrix (r,p) norms (1 </= r,p < infinity). We develop a new formulation and an efficient optimization strategy for (r,p)-MKL with guaranteed convergence. A theoretical analysis and experiments on seven UCI data sets shed light on the superiority of (r,p)-MKL over lp-MKL in various scenarios.",4
Modified Sparse Linear-Discriminant Analysis via Nonconvex Penalties.,"This paper considers the linear-discriminant analysis (LDA) problem in the undersampled situation, in which the number of features is very large and the number of observations is limited. Sparsity is often incorporated in the solution of LDA to make a well interpretation of the results. However, most of the existing sparse LDA algorithms pursue sparsity by means of the $\ell _{1}$ -norm. In this paper, we give elaborate analysis for nonconvex penalties, including the $\ell _{0}$ -based and the sorted $\ell _{1}$ -based LDA methods. The latter one can be regarded as a bridge between the $\ell _{0}$ and $\ell _{1}$ penalties. These nonconvex penalty-based LDA algorithms are evaluated on the gene expression array and face database, showing high classification accuracy on real-world problems.",4
Frame-Based Variational Bayesian Learning for Independent or Dependent Source Separation.,"Variational Bayesian (VB) learning has been successfully applied to instantaneous blind source separation. However, the traditional VB learning is restricted to the separation of independent source signals. Moreover, it has the difficulty to recover source signals with a sizable number of samples because of its rapidly increasing computational requirement. To overcome such shortcomings, frame-based VB (FVB) learning is proposed to address both independent and dependent source separation with a large number of samples in this paper. Specifically, a Gaussian process (GP) is employed to model independent or dependent source signals. To our knowledge, GP has been only used to model each of independent source signals. For dependent source signals, this paper proposes a novel modeling process: initial source signals are zigzag concatenated into a long serial and GP is then used to model it. In order to obtain a reliable covariance function for GP, first, we apply singular value decomposition to give initial estimated source signals and then we select an appropriate covariance function with which GP can perfectly fit them. In order to alleviate the computational burden of VB learning, we split observed signals into frames, and then model and infer source signals for each frame. Compared with the state-of-the-art algorithms, the experimental results show that the FVB learning has potential to provide improvement in separation performance not only for independent source signals but also for dependent ones, especially for long data records.",4
Spatial and Temporal Downsampling in Event-Based Visual Classification.,"As the interest in event-based vision sensors for mobile and aerial applications grows, there is an increasing need for high-speed and highly robust algorithms for performing visual tasks using event-based data. As event rate and network structure have a direct impact on the power consumed by such systems, it is important to explore the efficiency of the event-based encoding used by these sensors. The work presented in this paper represents the first study solely focused on the effects of both spatial and temporal downsampling on event-based vision data and makes use of a variety of data sets chosen to fully explore and characterize the nature of downsampling operations. The results show that both spatial downsampling and temporal downsampling produce improved classification accuracy and, additionally, a lower overall data rate. A finding is particularly relevant for bandwidth and power constrained systems. For a given network containing 1000 hidden layer neurons, the spatially downsampled systems achieved a best case accuracy of 89.38% on N-MNIST as opposed to 81.03% with no downsampling at the same hidden layer size. On the N-Caltech101 data set, the downsampled system achieved a best case accuracy of 18.25%, compared with 7.43% achieved with no downsampling. The results show that downsampling is an important preprocessing technique in event-based visual processing, especially for applications sensitive to power consumption and transmission bandwidth.",4
Containment Control of Linear Multiagent Systems With Aperiodic Sampling and Measurement Size Reduction.,"The containment control problem for generally linear multiagent systems with aperiodic sampling intervals and measurement size reduction is considered in this paper. Under the assumption that the sampling interval changes from a finite set, an improved protocol is proposed, such that a larger sampling interval can be obtained to achieve containment. By using the properties of Laplacian matrix and the newly developed protocol, the containment control problem is transformed into the stability problem of a discrete-time switched linear system. A sufficient condition is obtained that ensures all the followers converge to the convex hull formed by the state of leaders, and such a sufficient condition is presented in terms of linear matrix inequalities, which are independent of the node of network. To further reduce the communication among agents, a switching-type measurement size reduction scheme is introduced. An optimization problem is proposed for the corresponding controller design. Finally, two simulation studies are conducted to show the effectiveness and advantage of the proposed control algorithms.",4
On the Generalization Ability of Online Gradient Descent Algorithm Under the Quadratic Growth Condition.,"Online learning has been successfully applied in various machine learning problems. Conventional analysis of online learning achieves a sharp generalization bound with a strongly convex assumption. In this paper, we study the generalization ability of the classic online gradient descent algorithm under the quadratic growth condition (QGC), a strictly weaker condition than strong convexity. Under some mild assumptions, we prove that the excess risk converges no worse than $O(\log T/T)$ when the data are independently and identically distributed (i.i.d.). When the data are generated from a $\phi $ -mixing process, we achieve the excess risk bound $O(\log T /T+\phi (\tau))$ , where $\phi (\tau)$ is the mixing coefficient capturing the non-i.i.d. attribute. Our key technique is based on the combination of the QGC and the martingale concentrations. Our results indicate that the strong convexity is not necessary to achieve the sharp $O(\log {T}/T)$ convergence rate in online learning. We verify our theories on both synthetic and real-world data.",4
A Neural Controller for Image-Based Visual Servoing of Manipulators With Physical Constraints.,"Main issues in visual servoing of manipulators mainly include rapid convergence of feature errors to zero and the safety of joints regarding joint physical limits. To address the two issues, in this paper, an image-based visual servoing scheme is proposed for manipulators with an eye-in-hand configuration. Compared with existing schemes, the proposed one does not require performing pseudoinversion for the image Jacobian matrix or inversion for the Jacobian matrix associated with the forward kinematics of the manipulators. Theoretical analysis shows that the proposed scheme not only guarantees the asymptotic convergence of feature errors to zero but also the compliance with joint angle and velocity limits of the manipulators. Besides, simulation results based on a PUMA560 manipulator with a camera mounted on the end effector verify the theoretical conclusions and the efficacy of the proposed scheme.",4
Learning Rates of Regularized Regression With Multiple Gaussian Kernels for Multi-Task Learning.,"This paper considers a least square regularized regression algorithm for multi-task learning in a union of reproducing kernel Hilbert spaces (RKHSs) with Gaussian kernels. It is assumed that the optimal prediction function of the target task and those of related tasks are in an RKHS with the same but with unknown Gaussian kernel width. The samples for related tasks are used to select the Gaussian kernel width, and the sample for the target task is used to obtain the prediction function in the RKHS with this selected width. With an error decomposition result, a fast learning rate is obtained for the target task. The key step is to estimate the sample errors of related tasks in the union of RKHSs with Gaussian kernels. The utility of this algorithm is illustrated with one simulated data set and four real data sets. The experiment results illustrate that the underlying algorithm can result in significant improvements in prediction error when few samples of the target task and more samples of related tasks are available.",4
Multistability Analysis of Quaternion-Valued Neural Networks With Time Delays.,"This paper addresses the multistability issue for quaternion-valued neural networks (QVNNs) with time delays. By using the inequality technique, sufficient conditions are proposed for the boundedness and the global attractivity of delayed QVNNs. Based on the geometrical properties of the activation functions, several criteria are obtained to ensure the existence of equilibrium points, of which are locally stable. Two numerical examples are provided to illustrate the effectiveness of the obtained results.",4
A Generalized Model for Robust Tensor Factorization With Noise Modeling by Mixture of Gaussians.,"The low-rank tensor factorization (LRTF) technique has received increasing attention in many computer vision applications. Compared with the traditional matrix factorization technique, it can better preserve the intrinsic structure information and thus has a better low-dimensional subspace recovery performance. Basically, the desired low-rank tensor is recovered by minimizing the least square loss between the input data and its factorized representation. Since the least square loss is most optimal when the noise follows a Gaussian distribution, -norm-based methods are designed to deal with outliers. Unfortunately, they may lose their effectiveness when dealing with real data, which are often contaminated by complex noise. In this paper, we consider integrating the noise modeling technique into a generalized weighted LRTF (GWLRTF) procedure. This procedure treats the original issue as an LRTF problem and models the noise using a mixture of Gaussians (MoG), a procedure called MoG GWLRTF. To extend the applicability of the model, two typical tensor factorization operations, i.e., CANDECOMP/PARAFAC factorization and Tucker factorization, are incorporated into the LRTF procedure. Its parameters are updated under the expectation-maximization framework. Extensive experiments indicate the respective advantages of these two versions of MoG GWLRTF in various applications and also demonstrate their effectiveness compared with other competing methods.",4
Semisupervised Negative Correlation Learning.,"Negative correlation learning (NCL) is an ensemble learning algorithm that introduces a correlation penalty term to the cost function of each individual ensemble member. Each ensemble member minimizes its mean square error and its error correlation with the rest of the ensemble. This paper analyzes NCL and reveals that adopting a negative correlation term for unlabeled data is beneficial to improving the model performance in the semisupervised learning (SSL) setting. We then propose a novel SSL algorithm, Semisupervised NCL (SemiNCL) algorithm. The algorithm considers the negative correlation terms for both labeled and unlabeled data for the semisupervised problems. In order to reduce the computational and memory complexity, an accelerated SemiNCL is derived from the distributed least square algorithm. In addition, we have derived a bound for two parameters in SemiNCL based on an analysis of the Hessian matrix of the error function. The new algorithm is evaluated by extensive experiments with various ratios of labeled and unlabeled training data. Comparisons with other state-of-the-art supervised and semisupervised algorithms confirm that SemiNCL achieves the best overall performance.",4
Optimization of Distributions Differences for Classification.,"In this paper, we introduce a new classification algorithm called the optimization of distribution differences (ODD). The algorithm aims to find a transformation from the feature space to a new space where the instances in the same class are as close as possible to one another, whereas the gravity centers of these classes are as far as possible from one another. This aim is formulated as a multiobjective optimization problem that is solved by a hybrid of an evolutionary strategy and the quasi-Newton method. The choice of the transformation function is flexible and could be any continuous space function. We experiment with a linear and a nonlinear transformation in this paper. We show that the algorithm can outperform eight other classification methods, namely naive Bayes, support vector machines, linear discriminant analysis, multilayer perceptrons, decision trees, and k -nearest neighbors, and two recently proposed classification methods, in 12 standard classification data sets. Our results show that the method is less sensitive to the imbalanced number of instances compared with these methods. We also show that ODD maintains its performance better than other classification methods in these data sets and hence offers a better generalization ability.",4
Hierarchical Decision and Control for Continuous Multitarget Problem: Policy Evaluation With Action Delay.,"This paper proposes a hierarchical decision-making and control algorithm for the shepherd game, the seventh mission in the International Aerial Robotics Competition (IARC). In this game, the agent (a multirotor aerial robot) is required to contact targets (ground vehicles) sequentially and drive them to a certain boundary to earn score. During the game of 10 min, the agent should be fully autonomous without any human interference. Regarding the lower-level controller and dynamics of the agent, each action takes a duration of time to accomplish. Denoted as an action delay, in this paper, this action duration is nonconstant and is related to the final reward. Therefore, the challenging point is making the agent ""aware of time"" when applying a certain action. We solve this problem by two approaches: deep Q-networks and lookup table. The action delay predictor in the decision-level is fitted by a lower-level controller. Through simulations by the example of the shepherd game, the effectiveness and efficiency of this approach are validated. This paper helps our team winning the first prize in IARC 2017, and keeps the best record of this mission since it was released in 2013.",4
Variational Bayesian Learning for Dirichlet Process Mixture of Inverted Dirichlet Distributions in Non-Gaussian Image Feature Modeling.,"In this paper, we develop a novel variational Bayesian learning method for the Dirichlet process (DP) mixture of the inverted Dirichlet distributions, which has been shown to be very flexible for modeling vectors with positive elements. The recently proposed extended variational inference (EVI) framework is adopted to derive an analytically tractable solution. The convergency of the proposed algorithm is theoretically guaranteed by introducing single lower bound approximation to the original objective function in the EVI framework. In principle, the proposed model can be viewed as an infinite inverted Dirichlet mixture model that allows the automatic determination of the number of mixture components from data. Therefore, the problem of predetermining the optimal number of mixing components has been overcome. Moreover, the problems of overfitting and underfitting are avoided by the Bayesian estimation approach. Compared with several recently proposed DP-related methods and conventional applied methods, the good performance and effectiveness of the proposed method have been demonstrated with both synthesized data and real data evaluations.",4
Online Active Learning Ensemble Framework for Drifted Data Streams.,"In practical applications, data stream classification faces significant challenges, such as high cost of labeling instances and potential concept drifting. We present a new online active learning ensemble framework for drifting data streams based on a hybrid labeling strategy that includes the following: 1) an ensemble classifier, which consists of a long-term stable classifier and multiple dynamic classifiers (a multilevel sliding window model is used to create and update the dynamic classifiers to effectively process both the gradual drift type and sudden drift type data stream) and 2) active learning, which takes a nonfixed labeling budget, supports on-demand request labeling, and adopts an uncertainty strategy and random strategy to label instances. The decision threshold of the uncertainty strategy is adjusted dynamically, i.e., when concept drift occurs, the threshold is gradually reduced to query the most uncertain instances in priority to reduce the request expense as much as possible. Experiments on synthetic and real data sets show that precise prediction accuracy can be obtained by the proposed method without increasing the total cost of labeling, and that the labeling cost can be dynamically allocated according to the concept drift.",4
Temporal Self-Organization: A Reaction-Diffusion Framework for Spatiotemporal Memories.,"Self-organizing maps (SOMs) find numerous applications in learning, clustering, and recalling spatial input patterns. The traditional approach in learning spatiotemporal patterns is to incorporate time on the output space of a SOM along with heuristic update rules that work well in practice. Inspired by the pioneering work of Alan Turing, who used reaction-diffusion equations to explain spatial pattern formation, we develop an analogous theoretical model for a spatiotemporal memory to learn and recall temporal patterns. The contribution of the paper is threefold: 1) using coupled reaction-diffusion equations, we develop a theory from first principles for constructing a spatiotemporal SOM and derive an update rule for learning based on the gradient of a potential function; 2) we analyze the dynamics of our algorithm and derive conditions for optimally setting the model parameters; and 3) we mathematically quantify the temporal plasticity effect observed during recall in response to the input dynamics. The simulation results show that the proposed algorithm outperforms the SOM with temporal activity diffusion, neural gas with temporal activity diffusion and spatiotemporal map formation based on a potential function in the presence of correlated noise for the same data set and similar training conditions.",4
Unified Low-Rank Matrix Estimate via Penalized Matrix Least Squares Approximation.,"Low-rank matrix estimation arises in a number of statistical and machine learning tasks. In particular, the coefficient matrix is considered to have a low-rank structure in multivariate linear regression and multivariate quantile regression. In this paper, we propose a method called penalized matrix least squares approximation (PMLSA) toward a unified yet simple low-rank matrix estimate. Specifically, PMLSA can transform many different types of low-rank matrix estimation problems into their asymptotically equivalent least-squares forms, which can be efficiently solved by a popular matrix fast iterative shrinkage-thresholding algorithm. Furthermore, we derive analytic degrees of freedom for PMLSA, with which a Bayesian information criterion (BIC)-type criterion is developed to select the tuning parameters. The estimated rank based on the BIC-type criterion is verified to be asymptotically consistent with the true rank under mild conditions. Extensive experimental studies are performed to confirm our assertion.",4
Deep Convolutional Identifier for Dynamic Modeling and Adaptive Control of Unmanned Helicopter.,"Helicopters are complex high-order and time-varying nonlinear systems, strongly coupling with aerodynamic forces, engine dynamics, and other phenomena. Therefore, it is a great challenge to investigate system identification for dynamic modeling and adaptive control for helicopters. In this paper, we address the system identification problem as dynamic regression and propose to represent the uncertainties and the hidden states in the system dynamic model with a deep convolutional neural network. Particularly, the parameters of the network are directly learned from the real flight data of aerobatic helicopter. Since the deep convolutional model has a good performance for describing the dynamic behavior of the hidden states and uncertainties in the flight process, the proposed identifier manifests strong robustness and high accuracy, even for untrained aerobatic maneuvers. The effectiveness of the proposed method is verified by various experiments with the real-world flight data from the Stanford Autonomous Helicopter Project. Consequently, an adaptive flight control scheme including a deep convolutional identifier and a backstepping-based controller is presented. The stability of the flight control scheme is rigorously proved by the Lyapunov theory. It reveals that the tracking errors for both the position and attitude of unmanned helicopter asymptotic converge to a small neighborhood of the origin.",4
Adaptive Reinforcement Learning Control Based on Neural Approximation for Nonlinear Discrete-Time Systems With Unknown Nonaffine Dead-Zone Input.,"In this paper, an optimal control algorithm is designed for uncertain nonlinear systems in discrete-time, which are in nonaffine form and with unknown dead-zone. The main contributions of this paper are that an optimal control algorithm is for the first time framed in this paper for nonlinear systems with nonaffine dead-zone, and the adaptive parameter law for dead-zone is calculated by using the gradient rules. The mean value theory is employed to deal with the nonaffine dead-zone input and the implicit function theory based on reinforcement learning is appropriately introduced to find an unknown ideal controller which is approximated by using the action network. Other neural networks are taken as the critic networks to approximate the strategic utility functions. Based on the Lyapunov stability analysis theory, we can prove the stability of systems, i.e., the optimal control laws can guarantee that all the signals in the closed-loop system are bounded and the tracking errors are converged to a small compact set. Finally, two simulation examples demonstrate the effectiveness of the design algorithm.",4
fpgaConvNet: Mapping Regular and Irregular Convolutional Neural Networks on FPGAs.,"Since neural networks renaissance, convolutional neural networks (ConvNets) have demonstrated a state-of-the-art performance in several emerging artificial intelligence tasks. The deployment of ConvNets in real-life applications requires power-efficient designs that meet the application-level performance needs. In this context, field-programmable gate arrays (FPGAs) can provide a potential platform that can be tailored to application-specific requirements. However, with the complexity of ConvNet models increasing rapidly, the ConvNet-to-FPGA design space becomes prohibitively large. This paper presents fpgaConvNet, an end-to-end framework for the optimized mapping of ConvNets on FPGAs. The proposed framework comprises an automated design methodology based on the synchronous dataflow (SDF) paradigm and defines a set of SDF transformations in order to efficiently navigate the architectural design space. By proposing a systematic multiobjective optimization formulation, the presented framework is able to generate hardware designs that are cooptimized for the ConvNet workload, the target device, and the application's performance metric of interest. Quantitative evaluation shows that the proposed methodology yields hardware designs that improve the performance by up to 6.65x over highly optimized graphics processing unit designs for the same power constraints and achieve up to 2.94x higher performance density compared with the state-of-the-art FPGA-based ConvNet architectures.",4
Online Identification of Nonlinear Stochastic Spatiotemporal System With Multiplicative Noise by Robust Optimal Control-Based Kernel Learning Method.,"In this paper, we propose a novel kernel method for the online identification of stochastic nonlinear spatiotemporal dynamical systems using the robust control approach. By the difference method, the stochastic spatiotemporal (SST) systems driven by multiplicative noise are first transformed into a class of multi-input-multi-output-partially linear kernel models (PLKMs) with heterogeneous random terms. With the help of techniques established for reproducing kernel Hilbert space, the online learning problem is reasonably considered as an output feedback control problem for a group of time varying linear dynamical systems. We develop an effective algorithm to address the learning problem of PLKM and SST systems by employing the model predictive control theory. Compared with the existing learning methods, the new one can achieve adaptive, robust, and fast convergent online modeling performance for the spatiotemporal dynamics with multiplicative noise, which greatly facilitates the characterization of physical characteristics of the system. Moreover, this investigation for the first time addresses the learning problems for SST systems with novel robust control techniques, which can provide some novel insights into the design of kernel machine learning methods from the perspective of optimal control theory. Numerical studies for benchmark systems are presented to illustrate the effectiveness and efficiency of our new method.",4
Semisupervised Learning With Parameter-Free Similarity of Label and Side Information.,"As for semisupervised learning, both label information and side information serve as pivotal indicators for the classification. Nonetheless, most of related research works utilize either label information or side information instead of exploiting both of them simultaneously. To address the referred defect, we propose a graph-based semisupervised learning (GSL) problem according to both given label information and side information. To solve the GSL problem efficiently, two novel self-weighted strategies are proposed based on solving associated equivalent counterparts of a GSL problem, which can be widely applied to a spectrum of biobjective optimizations. Different from a conventional technique to amalgamate must-link and cannot-link into a single similarity for convenient optimization, we derive a new parameter-free similarity, upon which intrinsic graph and penalty graph can be separately developed. Consequently, a novel semisupervised classification algorithm can be summarized correspondingly with a theoretical analysis.",4
A New Approach to Stochastic Stability of Markovian Neural Networks With Generalized Transition Rates.,"This paper investigates the stability problem of Markovian neural networks (MNNs) with time delay. First, to reflect more realistic behaviors, more generalized transition rates are considered for MNNs, where all transition rates of some jumping modes are completely unknown. Second, a new approach, namely time-delay-dependent-matrix (TDDM) approach, is proposed for the first time. The TDDM approach is associated with both time delay and its time derivative. Thus, the TDDM approach can fully capture the information of time delay and would play a key role in deriving less conservative results. Third, based on the TDDM approach and applying Wirtinger's inequality and improved reciprocally convex inequality, stability criteria are derived. In comparison with some existing results, our results are not only less conservative but also involve lower calculation complexity. Finally, numerical examples are provided to show the effectiveness and advantages of the proposed results.",4
Hinfinity State Estimation for Discrete-Time Nonlinear Singularly Perturbed Complex Networks Under the Round-Robin Protocol.,"This paper investigates the Hinfinity state estimation problem for a class of discrete-time nonlinear singularly perturbed complex networks (SPCNs) under the Round-Robin (RR) protocol. A discrete-time nonlinear SPCN model is first devised on two time scales with their discrepancies reflected by a singular perturbation parameter (SPP). The network measurement outputs are transmitted via a communication network where the data transmissions are scheduled by the RR protocol with hope to avoid the undesired data collision. The error dynamics of the state estimation is governed by a switched system with a periodic switching parameter. A novel Lyapunov function is constructed that is dependent on both the transmission order and the SPP. By establishing a key lemma specifically tackling the SPP, sufficient conditions are obtained such that, for any SPP less than or equal to a predefined upper bound, the error dynamics of the state estimation is asymptotically stable and satisfies a prescribed Hinfinity performance requirement. Furthermore, the explicit parameterization of the desired state estimator is given by means of the solution to a set of matrix inequalities, and the upper bound of the SPP is then evaluated in the feasibility of these matrix inequalities. Moreover, the corresponding results for linear discrete-time SPCNs are derived as corollaries. A numerical example is given to illustrate the effectiveness of the proposed state estimator design scheme.",4
Exploring Auxiliary Context: Discrete Semantic Transfer Hashing for Scalable Image Retrieval.,"Unsupervised hashing can desirably support scalable content-based image retrieval for its appealing advantages of semantic label independence, memory, and search efficiency. However, the learned hash codes are embedded with limited discriminative semantics due to the intrinsic limitation of image representation. To address the problem, in this paper, we propose a novel hashing approach, dubbed as discrete semantic transfer hashing (DSTH). The key idea is to directly augment the semantics of discrete image hash codes by exploring auxiliary contextual modalities. To this end, a unified hashing framework is formulated to simultaneously preserve visual similarities of images and perform semantic transfer from contextual modalities. Furthermore, to guarantee direct semantic transfer and avoid information loss, we explicitly impose the discrete constraint, bit-uncorrelation constraint, and bit-balance constraint on hash codes. A novel and effective discrete optimization method based on augmented Lagrangian multiplier is developed to iteratively solve the optimization problem. The whole learning process has linear computation complexity and desirable scalability. Experiments on three benchmark data sets demonstrate the superiority of DSTH compared with several state-of-the-art approaches.",4
Tree2Vector: Learning a Vectorial Representation for Tree-Structured Data.,"The tree structure is one of the most powerful structures for data organization. An efficient learning framework for transforming tree-structured data into vectorial representations is presented. First, in attempting to uncover the global discriminative information of child nodes hidden at the same level of all of the trees, a clustering technique can be adopted for allocating children into different clusters, which are used to formulate the components of a vector. Moreover, a locality-sensitive reconstruction method is introduced to model a process, in which each parent node is assumed to be reconstructed by its children. The resulting reconstruction coefficients are reversely transformed into complementary coefficients, which are utilized for locally weighting the components of the vector. A new vector is formulated by concatenating the original parent node vector and the learned vector from its children. This new vector for each parent node is inputted into the learning process of formulating vectorial representation at the upper level of the tree. This recursive process concludes when a vectorial representation is achieved for the entire tree. Our method is examined in two applications: book author recommendations and content-based image retrieval. Extensive experimental results demonstrate the effectiveness of the proposed method for transforming tree-structured data into vectors.",4
"Integrating Space, Time, and Orientation in Spiking Neural Networks: A Case Study on Multimodal Brain Data Modeling.","Recent progress in a noninvasive brain data sampling technology has facilitated simultaneous sampling of multiple modalities of brain data, such as functional magnetic resonance imaging, electroencephalography, diffusion tensor imaging, and so on. In spite of the potential benefits from integrating predictive modeling of multiple modality brain data, this area of research remains mostly unexplored due to a lack of methodological advancements. The difficulty in fusing multiple modalities of brain data within a single model lies in the heterogeneous temporal and spatial characteristics of the data sources. Recent advances in spiking neural network systems, however, provide the flexibility to incorporate multidimensional information within the model. This paper proposes a novel, unsupervised learning algorithm for fusing temporal, spatial, and orientation information in a spiking neural network architecture that could potentially be used to understand and perform predictive modeling using multimodal data. The proposed algorithm is evaluated both qualitatively and quantitatively using synthetically generated data to characterize its behavior and its ability to utilize spatial, temporal, and orientation information within the model. This leads to improved pattern recognition capabilities and performance along with robust interpretability of the brain data. Furthermore, a case study is presented, which aims to build a computational model that discriminates between people with schizophrenia who respond or do not respond to monotherapy with the antipsychotic clozapine.",4
Sequential Outlier Criterion for Sparsification of Online Adaptive Filtering.,"In this paper, we deal with the learning problem when using an adaptive filtering method. For the learning system in filtering, the knowledge is obtained and updated based on the newly acquired information that is extracted and learned from the sequential samples over time. Effective measurement on the informativeness of a sample and reasonable subsequent treatment on the sample will improve the learning performance. This paper proposes a sequential outlier criterion for sparsification of online adaptive filtering. The method is proposed to achieve effective informativeness measurement of online filtering to obtain a more accurate and more compact network in the learning process. In the proposed method, the measurement on the samples' informativeness is established based on the historical sequentially adjacent samples, and then the informative-measured samples are treated individually by the learning system based on whether the sample is informative, redundant, or abnormal. With our method, a more sensible learning process can be achieved with valid knowledge extracted, and the optimal network in the learning system can be obtained. Simulations based on static function estimation, Mackey-Glass time series prediction, and Lorenz chaotic time series prediction demonstrate that the proposed method can provide more effective classification on samples and more accurate networks in online adaptive filtering.",4
Shared Predictive Cross-Modal Deep Quantization.,"With explosive growth of data volume and ever-increasing diversity of data modalities, cross-modal similarity search, which conducts nearest neighbor search across different modalities, has been attracting increasing interest. This paper presents a deep compact code learning solution for efficient cross-modal similarity search. Many recent studies have proven that quantization-based approaches perform generally better than hashing-based approaches on single-modal similarity search. In this paper, we propose a deep quantization approach, which is among the early attempts of leveraging deep neural networks into quantization-based cross-modal similarity search. Our approach, dubbed shared predictive deep quantization (SPDQ), explicitly formulates a shared subspace across different modalities and two private subspaces for individual modalities, and representations in the shared subspace and the private subspaces are learned simultaneously by embedding them to a reproducing kernel Hilbert space, where the mean embedding of different modality distributions can be explicitly compared. In addition, in the shared subspace, a quantizer is learned to produce the semantics preserving compact codes with the help of label alignment. Thanks to this novel network architecture in cooperation with supervised quantization training, SPDQ can preserve intramodal and intermodal similarities as much as possible and greatly reduce quantization error. Experiments on two popular benchmarks corroborate that our approach outperforms state-of-the-art methods.",4
Neural Network Training With Levenberg-Marquardt and Adaptable Weight Compression.,"Difficult experiments in training neural networks often fail to converge due to what is known as the flat-spot problem, where the gradient of hidden neurons in the network diminishes in value, rending the weight update process ineffective. Whereas a first-order algorithm can address this issue by learning parameters to normalize neuron activations, the second-order algorithms cannot afford additional parameters given that they include a large Jacobian matrix calculation. This paper proposes Levenberg-Marquardt with weight compression (LM-WC), which combats the flat-spot problem by compressing neuron weights to push neuron activation out of the saturated region and close to the linear region. The presented algorithm requires no additional learned parameters and contains an adaptable compression parameter, which is adjusted to avoid training failure and increase the probability of neural network convergence. Several experiments are presented and discussed to demonstrate the success of LM-WC against standard LM and LM with random restarts on benchmark data sets for varying network architectures. Our results suggest that the LM-WC algorithm can improve training success by 10 times or more compared with other methods.",4
Multiple psi -Type Stability of Cohen-Grossberg Neural Networks With Both Time-Varying Discrete Delays and Distributed Delays.,"In this paper, multiple psi -type stability of Cohen-Grossberg neural networks (CGNNs) with both time-varying discrete delays and distributed delays is investigated. By utilizing psi -type functions combined with a new psi -type integral inequality for treating distributed delay terms, some sufficient conditions are obtained to ensure that multiple equilibrium points are psi -type stable for CGNNs with discrete and distributed delays, where the distributed delays include bounded and unbounded delays. These conditions of CGNNs with different output functions are less restrictive. More specifically, the algebraic criteria of the generalized model are applicable to several well-known neural network models by taking special parameters, and multiple different output functions are introduced to replace some of the same output functions, which improves the diversity of output results for the design of neural networks. In addition, the estimation of relative convergence rate of psi -type stability is determined by the parameters of CGNNs and the selection of psi -type functions. As a result, the existing results on multistability and monostability can be improved and extended. Finally, some numerical simulations are presented to illustrate the effectiveness of the obtained results.",4
Solving Partial Least Squares Regression via Manifold Optimization Approaches.,"Partial least squares regression (PLSR) has been a popular technique to explore the linear relationship between two data sets. However, all existing approaches often optimize a PLSR model in Euclidean space and take a successive strategy to calculate all the factors one by one for keeping the mutually orthogonal PLSR factors. Thus, a suboptimal solution is often generated. To overcome the shortcoming, this paper takes statistically inspired modification of PLSR (SIMPLSR) as a representative of PLSR, proposes a novel approach to transform SIMPLSR into optimization problems on Riemannian manifolds, and develops corresponding optimization algorithms. These algorithms can calculate all the PLSR factors simultaneously to avoid any suboptimal solutions. Moreover, we propose sparse SIMPLSR on Riemannian manifolds, which is simple and intuitive. A number of experiments on classification problems have demonstrated that the proposed models and algorithms can get lower classification error rates compared with other linear regression methods in Euclidean space. We have made the experimental code public at https://github.com/Haoran2014.",4
Efficient Unsupervised Parameter Estimation for One-Class Support Vector Machines.,"One-class support vector machines (OCSVMs) are very effective for semisupervised anomaly detection. However, their performance strongly depends on the settings of their hyperparameters, which has not been well studied. Moreover, unavailability of a clean training set that only comprises normal data in many real-life problems has given rise to the application of OCSVMs in an unsupervised manner. However, it has been shown that if the training set includes anomalies, the normal boundary created by OCSVMs is prone to skew toward the anomalies. This problem decreases the detection rate of anomalies and results in poor performance of the classifier. In this paper, we propose a new technique to set the hyperparameters and clean suspected anomalies from unlabelled training sets. The proposed method removes suspected anomalies based on a $K$ -nearest neighbors technique, which is then used to directly estimate the hyperparameters. We examine several benchmark data sets with diverse distributions and dimensionality. Our findings suggest that on the examined data sets, the proposed technique is roughly 70 times faster than supervised parameter estimation via grid-search and cross validation, and one to three orders of magnitude faster than broadly used semisupervised and unsupervised parameter estimation methods for OCSVMs. Moreover, our method statistically outperforms those semisupervised and unsupervised methods and its accuracy is comparable to supervised grid-search and cross validation.",4
Generative Kernels for Tree-Structured Data.,"This paper presents a family of methods for the design of adaptive kernels for tree-structured data that exploits the summarization properties of hidden states of hidden Markov models for trees. We introduce a compact and discriminative feature space based on the concept of hidden states multisets and we discuss different approaches to estimate such hidden state encoding. We show how it can be used to build an efficient and general tree kernel based on Jaccard similarity. Furthermore, we derive an unsupervised convolutional generative kernel using a topology induced on the Markov states by a tree topographic mapping. This paper provides an extensive empirical assessment on a variety of structured data learning tasks, comparing the predictive accuracy and computational efficiency of state-of-the-art generative, adaptive, and syntactical tree kernels. The results show that the proposed generative approach has a good tradeoff between computational complexity and predictive performance, in particular when considering the soft matching introduced by the topographic mapping.",4
SGD-Based Adaptive NN Control Design for Uncertain Nonlinear Systems.,"In this paper, a stochastic gradient descent (SGD)-based adaptive neural network (NN) control scheme is presented for a class of uncertain nonlinear systems. The introduction of the SGD algorithm results in a better tracking performance compared with some other adaptive NN methods without using SGD. This is because the proposed SGD-based adaptive NN control strategy provides optimization algorithms for the weights, the widths, and the centers of the NNs, which can achieve a good function approximation performance. In order to implement the proposed method, extended differentiators are introduced to get the differential estimations of error signals, such that the loss function of the optimization algorithm can be constructed approximatively. Moreover, adaptive laws are designed to reduce the overall approximation errors, such that the tracking performance is further improved. By using the Lyapunov stability theory, it can be proved that the target signal is tracked by the system output within a small error. Finally, simulation and comparison results are given to show the effectiveness and advantages of the proposed method.",4
Exponential Stability Analysis for Delayed Semi-Markovian Recurrent Neural Networks: A Homogeneous Polynomial Approach.,"This paper investigates the exponential stability analysis issue for a class of delayed recurrent neural networks (RNNs) with semi-Markovian parameters. By constructing a stochastic Lyapunov functional and using some zoom techniques to estimate its weak infinitesimal operator, the exponential mean square stability criteria have been proposed for the Markovian neural networks with certain transition probabilities. We then generalize the homogeneous polynomial approach for the delayed Markovian RNNs with uncertain transition probabilities during the stability analysis. Theoretical results have obtained by introducing an appropriate technique for dealing with a large number of complex homogeneous polynomial matrix inequalities. Finally, numerical examples are provided to demonstrate the effectiveness of the proposed technique.",4
Pairwise Constraint Propagation-Induced Symmetric Nonnegative Matrix Factorization.,"As a variant of nonnegative matrix factorization (NMF), symmetric NMF (SNMF) has shown to be effective for capturing the cluster structure embedded in the graph representation. In contrast to the existing SNMF-based clustering methods that empirically construct the similarity matrix and rigidly introduce the supervisory information to the assignment matrix, in this paper, we propose a novel SNMF-based semisupervised clustering method, namely, pairwise constraint propagation-induced SNMF (PCPSNMF). By formulating a single-constrained optimization problem, PCPSNMF is capable of learning the similarity and assignment matrices adaptively and simultaneously, in which a small amount of supervisory information in the form of pairwise constraints is introduced in a flexible way to guide the construction of the similarity matrix, and the two matrices communicate with each other to achieve mutual refinement until convergence. In addition, we propose an efficient alternating iterative algorithm to solve the optimization problem, whose convergence is theoretically proven. Experimental results over several benchmark image data sets demonstrate that PCPSNMF is less sensitive to initialization and produces higher clustering performance, compared with the state-of-the-art methods.",4
Feature Selection Based on the Neighborhood Entropy.,"In feature selection, a measure that captures nonlinear relationships between features and class is the mutual information (MI), which is based on how information in the features reduces the uncertainty in the output. In this paper, we propose a new measure that is related to MI, called neighborhood entropy, and a novel filter method based on its minimization in a greedy procedure. Our algorithm integrates sequential forward selection with approximated nearest-neighbors techniques and locality-sensitive hashing. Experiments show that the classification accuracy is usually higher than that of other state-of-the-art algorithms, with the best results obtained with problems that are highly unbalanced and nonlinearly separable. The order by which the features are selected is also better, leading to a higher accuracy for fewer features. The experimental results indicate that our technique can be employed effectively in offline scenarios when one can dedicate more CPU time to achieve superior results and more robustness to noise and to class imbalance.",4
Dynamic Affinity Graph Construction for Spectral Clustering Using Multiple Features.,"Spectral clustering (SC) has been widely applied to various computer vision tasks, where the key is to construct a robust affinity matrix for data partitioning. With the increase in visual features, conventional SC methods are facing two challenges: 1) how to effectively generate an affinity matrix based on multiple features? and 2) how to deal with high-dimensional visual features which could be redundant? To address these issues mentioned earlier, we present a new approach to: 1) learn a robust affinity matrix using multiple features, allowing us to simultaneously determine optimal weights for each feature; and 2) decide a set of optimal projection matrixes, one for each feature, that decide the lower dimensional space, as well as the optimal affinity weight of each data pair in the lower dimensional space. There are two major advantages of our new approach over the existing clustering techniques. First, our approach assigns affinity weights for data points on a per-data-pair basis. The learning procedure avoids the explicit specification of the size of the neighborhood in the affinity matrix, and the bandwidth parameter required to compute the Gaussian kernel, both of which are sensitive and yet difficult to determine beforehand. Second, the affinity weights are based on the distances in a lower dimensional space, while the low-dimensional space is inferred according to the optimized affinity weights. Both variables are jointly optimized so as to leverage mutual benefits. The experimental results outperform the compared alternatives, which indicate that the proposed method is effective in simultaneously learning the affinity graph and feature fusion, resulting in better clustering results.",4
Adaptive Human-Machine Interactive Behavior Analysis With Wrist-Worn Devices for Password Inference.,"The pervasiveness of wearable devices furnished with state-of-the-art sensors has shown the powerful capability in context-aware applications. However, embedded sensors also become targets for adversaries to launch potential side-channel attacks. In this paper, we present a self-adaptive and pretraining-independent pattern attack that infers a graphical password by recovering the victim's hand movement trajectory via motion sensors of a wrist-worn smart device. With the adaptive pattern inference algorithm, the discovered attack can be launched remotely without requiring previous training data from victims or the prior knowledge about the keyboard input settings. Toward the proposed attack, we create a method to detect the sliding behavior that draws a graphical password on the screen. We also propose an inference algorithm to generate password candidates from hand movement trajectories for different keypad input settings. We implement the discovered attack on a smartwatch and conduct experiments to evaluate the impact of this attack. The evaluation results show that for complex graphical patterns, with a single try, the attack can infer the passwords at a success rate as high as 80%, and the success rate can be further boosted to over 90% within five attempts, which reveals the overlooked privacy information threat caused by sensor data leakage.",4
Stability of Singular Discrete-Time Neural Networks With State-Dependent Coefficients and Run-to-Run Control Strategies.,"In this brief, sustaining and intermittent run-to-run controllers are designed to achieve the stability of singular discrete-time neural networks with state-dependent coefficients. The controllers are designed for two reasons: 1) it is very difficult and almost impossible to only measure the in situ feedback information for the controllers and 2) the controllers may not always exist at any time. The stability is then established for singular discrete-time neural networks with state-dependent coefficients. Finally, numerical simulations are shown to illustrate the usefulness of the obtained criteria.",4
Incomplete-Data Oriented Multiview Dimension Reduction via Sparse Low-Rank Representation.,"For dimension reduction on multiview data, most of the previous studies implicitly take an assumption that all samples are completed in all views. Nevertheless, this assumption could often be violated in real applications due to the presence of noise, limited access to data, equipment malfunction, and so on. Most of the previous methods will cease to work when missing values in one or multiple views occur, thus an incomplete-data oriented dimension reduction becomes an important issue. To this end, we mathematically formulate the above-mentioned issue as sparse low-rank representation through multiview subspace (SRRS) learning to impute missing values, by jointly measuring intraview relations (via sparse low-rank representation) and interview relations (through common subspace representation). Moreover, by exploiting various subspace priors in the proposed SRRS formulation, we develop three novel dimension reduction methods for incomplete multiview data: 1) multiview subspace learning via graph embedding; 2) multiview subspace learning via structured sparsity; and 3) sparse multiview feature selection via rank minimization. For each of them, the objective function and the algorithm to solve the resulting optimization problem are elaborated, respectively. We perform extensive experiments to investigate their performance on three types of tasks including data recovery, clustering, and classification. Both two toy examples (i.e., Swiss roll and -curve) and four real-world data sets (i.e., face images, multisource news, multicamera activity, and multimodality neuroimaging data) are systematically tested. As demonstrated, our methods achieve the performance superior to that of the state-of-the-art comparable methods. Also, the results clearly show the advantage of integrating the sparsity and low-rankness over using each of them separately.",4
Adaptive Asymptotic Neural Network Control of Nonlinear Systems With Unknown Actuator Quantization.,"In this paper, we propose an adaptive neural-network-based asymptotic control algorithm for a class of nonlinear systems subject to unknown actuator quantization. To this end, we exploit the sector property of the quantization nonlinearity and transform actuator quantization control problem into analyzing its upper bounds, which are then handled by a dynamic loop gain function-based approach. In our adaptive control scheme, there is only one parameter required to be estimated online for updating weights of neural networks. Within the framework of Lyapunov theory, it is shown that the proposed algorithm ensures that all the signals in the closed-loop system are ultimately bounded. Moreover, an asymptotic tracking error is obtained by means of introducing Barbalat's lemma to the proposed adaptive law.",4
Estimation of Graphlet Counts in Massive Networks.,"Graphlets are induced subgraphs of a large network and are important for understanding and modeling complex networks. Despite their practical importance, graphlets have been severely limited to applications and domains with relatively small graphs. Most previous work has focused on exact algorithms; however, it is often too expensive to compute graphlets exactly in massive networks with billions of edges, and finding an approximate count is usually sufficient for many applications. In this paper, we propose an unbiased graphlet estimation framework that is: (a) fast with large speedups compared to the state of the art; (b) parallel with nearly linear speedups; (c) accurate with less than 1% relative error; (d) scalable and space efficient for massive networks with billions of edges; and (e) effective for a variety of real-world settings as well as estimating global and local graphlet statistics (e.g., counts). On 300 networks from 20 domains, we obtain <1% relative error for all graphlets. This is vastly more accurate than the existing methods while using less data. Moreover, it takes a few seconds on billion edge graphs (as opposed to days/weeks). These are by far the largest graphlet computations to date.",4
Optimizing Top- Multiclass SVM via Semismooth Newton Algorithm.,"Top- performance has recently received increasing attention in large data categories. Advances, like a top- multiclass support vector machine (SVM), have consistently improved the top- accuracy. However, the key ingredient in the state-of-the-art optimization scheme based upon stochastic dual coordinate ascent relies on the sorting method, which yields complexity. In this paper, we leverage the semismoothness of the problem and propose an optimized top- multiclass SVM algorithm, which employs semismooth Newton algorithm for the key building block to improve the training speed. Our method enjoys a local superlinear convergence rate in theory. In practice, experimental results confirm the validity. Our algorithm is four times faster than the existing method in large synthetic problems; Moreover, on real-world data sets it also shows significant improvement in training time.",4
Adaptive Neural Dynamic Surface Control for Nonstrict-Feedback Systems With Output Dead Zone.,"This paper focuses on the problem of adaptive output-constrained neural tracking control for uncertain nonstrict-feedback systems in the presence of unknown symmetric output dead zone and input saturation. A Nussbaum-type function-based dead-zone model is introduced such that the dynamic surface control approach can be used for controller design. The variable separation technique is employed to decompose the unknown function of entire states in each subsystem into a series of smooth functions. Radial basis function neural networks are utilized to approximate the unknown black-box functions derived from Young's inequality. With the help of auxiliary first-order filters, the dimensions of neural network input are reduced in each recursive design. A main advantage of the proposed method is that for an -order nonlinear system, only one adaptation parameter needs to be tuned online. It is rigorously shown that the proposed output-constrained controller guarantees that all the closed-loop signals are semiglobal uniformly ultimately bounded and the tracking error never violates the output constraint.",4
Self-Paced Learning-Based Probability Subspace Projection for Hyperspectral Image Classification.,"In this paper a self-paced learning-based probability subspace projection (SL-PSP) method is proposed for hyperspectral image classification. First, a probability label is assigned for each pixel, and a risk is assigned for each labeled pixel. Then, two regularizers are developed from a self-paced maximum margin and a probability label graph, respectively. The first regularizer can increase the discriminant ability of features by gradually involving the most confident pixels into the projection to simultaneously push away heterogeneous neighbors and pull inhomogeneous neighbors. The second regularizer adopts a relaxed clustering assumption to make avail of unlabeled samples, thus accurately revealing the affinity between mixed pixels and achieving accurate classification with very few labeled samples. Several hyperspectral data sets are used to verify the effectiveness of SL-PSP, and the experimental results show that it can achieve the state-of-the-art results in terms of accuracy and stability.",4
Deep Hyperspectral Image Sharpening.,"Hyperspectral image (HSI) sharpening, which aims at fusing an observable low spatial resolution (LR) HSI (LR-HSI) with a high spatial resolution (HR) multispectral image (HR-MSI) of the same scene to acquire an HR-HSI, has recently attracted much attention. Most of the recent HSI sharpening approaches are based on image priors modeling, which are usually sensitive to the parameters selection and time-consuming. This paper presents a deep HSI sharpening method (named DHSIS) for the fusion of an LR-HSI with an HR-MSI, which directly learns the image priors via deep convolutional neural network-based residual learning. The DHSIS method incorporates the learned deep priors into the LR-HSI and HR-MSI fusion framework. Specifically, we first initialize the HR-HSI from the fusion framework via solving a Sylvester equation. Then, we map the initialized HR-HSI to the reference HR-HSI via deep residual learning to learn the image priors. Finally, the learned image priors are returned to the fusion framework to reconstruct the final HR-HSI. Experimental results demonstrate the superiority of the DHSIS approach over existing state-of-the-art HSI sharpening approaches in terms of reconstruction accuracy and running time.",4
Biologically Inspired Intensity and Depth Image Edge Extraction.,"In recent years, artificial vision research has moved from focusing on the use of only intensity images to include using depth images, or RGB-D combinations due to the recent development of low-cost depth cameras. However, depth images require a lot of storage and processing requirements. In addition, it is challenging to extract relevant features from depth images in real time. Researchers have sought inspiration from biology in order to overcome these challenges resulting in biologically inspired feature extraction methods. By taking inspiration from nature, it may be possible to reduce redundancy, extract relevant features, and process an image efficiently by emulating biological visual processes. In this paper, we present a depth and intensity image feature extraction approach that has been inspired by biological vision systems. Through the use of biologically inspired spiking neural networks, we emulate functional computational aspects of biological visual systems. The results demonstrate that the proposed bioinspired artificial vision system has increased performance over existing computer vision feature extraction approaches.",4
Nonparametric Bayesian Correlated Group Regression With Applications to Image Classification.,"Sparse Bayesian learning has emerged as a powerful tool to tackle various image classification tasks. The existing sparse Bayesian models usually use independent Gaussian distribution as the prior knowledge for the noise. However, this assumption often contradicts to the practical observations in which the noise is long tail and pixels containing noise are spatially correlated. To handle the practical noise, this paper proposes to partition the noise image into several 2-D groups and adopt the long-tail distribution, i.e., the scale mixture of the matrix Gaussian distribution, to model each group to capture the intragroup correlation of the noise. Under the nonparametric Bayesian estimation, the low-rank-induced prior and the matrix Gamma distribution prior are imposed on the covariance matrix of each group, respectively, to induce two Bayesian correlated group regression (BCGR) methods. Moreover, the proposed methods are extended to the case with unknown group structure. Our BCGR method provides an effective way to automatically fit the noise distribution and integrates the long-tail attribute and structure information of the practical noise into model. Therefore, the estimated coefficients are better for reconstructing the desired data. We apply BCGR to address image classification task and utilize the learned covariance matrices to construct a grouped Mahalanobis distance to measure the reconstruction residual of each class in the design of a classifier. Experimental results demonstrate the effectiveness of our new BCGR model.",4
Progressive Stochastic Learning for Noisy Labels.,"Large-scale learning problems require a plethora of labels that can be efficiently collected from crowdsourcing services at low cost. However, labels annotated by crowdsourced workers are often noisy, which inevitably degrades the performance of large-scale optimizations including the prevalent stochastic gradient descent (SGD). Specifically, these noisy labels adversely affect updates of the primal variable in conventional SGD. To solve this challenge, we propose a robust SGD mechanism called progressive stochastic learning (POSTAL), which naturally integrates the learning regime of curriculum learning (CL) with the update process of vanilla SGD. Our inspiration comes from the progressive learning process of CL, namely learning from ""easy"" tasks to ""complex"" tasks. Through the robust learning process of CL, POSTAL aims to yield robust updates of the primal variable on an ordered label sequence, namely, from ""reliable"" labels to ""noisy"" labels. To realize POSTAL mechanism, we design a cluster of ""screening losses,"" which sorts all labels from the reliable region to the noisy region. To sum up, POSTAL using screening losses ensures robust updates of the primal variable on reliable labels first, then on noisy labels incrementally until convergence. In theory, we derive the convergence rate of POSTAL realized by screening losses. Meanwhile, we provide the robustness analysis of representative screening losses. Experimental results on UCI1 simulated and Amazon Mechanical Turk crowdsourcing data sets show that the POSTAL using screening losses is more effective and robust than several existing baselines.1UCI is the abbreviation of University of California Irvine.",4
Learning From Multiple Imperfect Instructors in Sensor Networks.,"This paper presents a sequential learning framework for sensors in a network, where a few sensors assume the role of an instructor to train other sensors in the network. The instructors provide estimated labels for measurements of new sensors. These labels are possibly noisy, because a classifier of the instructor may not be perfect. A recursive density estimator is proposed to obtain the true measurement model (i.e., the observation density conditioned on the label) in spite of the training with noisy labels. Specifically, this paper answers the question ""Can a sensor train other sensors?"", provides necessary conditions for sensors to act as instructors, presents a sequential learning framework using recursive nonparametric kernel density estimation, and provides a convergence rate for the expected error in an observation density. The underlying concepts are illustrated and validated with simulation results.",4
Permutation Jaccard Distance-Based Hierarchical Clustering to Estimate EEG Network Density Modifications in MCI Subjects.,"In this paper, a novel electroencephalographic (EEG)-based method is introduced for the quantification of brain-electrical connectivity changes over a longitudinal evaluation of mild cognitive impaired (MCI) subjects. In the proposed method, a dissimilarity matrix is constructed by estimating the coupling strength between every pair of EEG signals, Hierarchical clustering is then applied to group the related electrodes according to the dissimilarity estimated on pairs of EEG recordings. Subsequently, the connectivity density of the electrodes network is calculated. The technique was tested over two different coupling strength descriptors: wavelet coherence (WC) and permutation Jaccard distance (PJD), a novel metric of coupling strength between time series introduced in this paper. Twenty-five MCI patients were enrolled within a follow-up program that consisted of two successive evaluations, at time T0 and at time T1, three months later. At T1, four subjects were diagnosed to have converted to Alzheimer's Disease (AD). When applying the PJD-based method, the converted patients exhibited a significantly increased PJD (p < 0.05), i.e., a reduced overall coupling strength, specifically in delta and theta bands and in the overall range (0.5-32 Hz). In addition, in contrast to stable MCI patients, converted patients exhibited a network density reduction in every subband (delta, theta, alpha, and beta). When WC was used as coupling strength descriptor, the method resulted in a less sensitive and specific outcome. The proposed method, mixing nonlinear analysis to a machine learning approach, appears to provide an objective evaluation of the connectivity density modifications associated to the MCI-AD conversion, just processing noninvasive EEG signals.",4
F-SVM: Combination of Feature Transformation and SVM Learning via Convex Relaxation.,"The generalization error bound of the support vector machine (SVM) depends on the ratio of the radius and margin. However, conventional SVM only considers the maximization of the margin but ignores the minimization of the radius, which restricts its performance when applied to joint learning of feature transformation and the SVM classifier. Although several approaches have been proposed to integrate the radius and margin information, most of them either require the form of the transformation matrix to be diagonal, or are nonconvex and computationally expensive. In this paper, we suggest a novel approximation for the radius of the minimum enclosing ball in feature space, and then propose a convex radius-margin-based SVM model for joint learning of feature transformation and the SVM classifier, i.e., F-SVM. A generalized block coordinate descent method is adopted to solve the F-SVM model, where the feature transformation is updated via the gradient descent and the classifier is updated by employing the existing SVM solver. By incorporating with kernel principal component analysis, F-SVM is further extended for joint learning of nonlinear transformation and the classifier. F-SVM can also be incorporated with deep convolutional networks to improve image classification performance. Experiments on the UCI, LFW, MNIST, CIFAR-10, CIFAR-100, and Caltech101 data sets demonstrate the effectiveness of F-SVM.",4
Experimental Study of Artificial Neural Networks Using a Digital Memristor Simulator.,"This paper presents a fully digital implementation of a memristor hardware (HW) simulator, as the core of an emulator, based on a behavioral model of voltage-controlled threshold-type bipolar memristors. Compared to other analog solutions, the proposed digital design is compact, easily reconfigurable, demonstrates very good matching with the mathematical model on which it is based, and complies with all the required features for memristor emulators. We validated its functionality using Altera Quartus II and ModelSim tools targeting low-cost yet powerful field-programmable gate array families. We tested its suitability for complex memristive circuits as well as its synapse functioning in artificial neural networks, implementing examples of associative memory and unsupervised learning of spatiotemporal correlations in parallel input streams using a simplified spike-timing-dependent plasticity. We provide the full circuit schematics of all our digital circuit designs and comment on the required HW resources and their scaling trends, thus presenting a design framework for applications based on our HW simulator.",4
Sequential Independent Component Analysis Density Estimation.,"A problem of multivariate probability density function estimation by exploiting linear independent components analysis (ICA) is addressed. Historically, ICA density estimation was initially proposed under the name projection pursuit density estimation (PPDE) and two basic methods, named forward and backward, were published. We derive a modification of the forward PPDE method, which avoids a computationally demanding optimization involving Monte Carlo sampling of the original method. The results of the experiments show that the proposed method presents an attractive choice for density estimation, which is pronounced for a small number of training observations. Under such conditions, our method usually outperforms model-based Gaussian mixture model. We also found that our method obtained better results than the backward PPDE methods in the situation of nonfactorizable underlying density functions. The proposed method has demonstrated a competitive performance compared with the support vector machine and the extreme learning machine in some real classification tasks.",4
Nonfragile State Estimation of Quantized Complex Networks With Switching Topologies.,"This paper considers the nonfragile $H_\infty $ estimation problem for a class of complex networks with switching topologies and quantization effects. The network architecture is assumed to be dynamic and evolves with time according to a random process subject to a sojourn probability. The coupled signal is to be quantized before transmission due to power and bandwidth constraints, and the quantization errors are transformed into sector-bounded uncertainties. The concept of nonfragility is introduced by inserting randomly occurred uncertainties into the estimator parameters to cope with the unavoidable small gain variations emerging from the implementations of estimators. Both the quantizers and the estimators have several operation modes depending on the switching signal of the underlying network structure. A sufficient condition is provided via a linear matrix inequality approach to ensure the estimation error dynamic to be stochastically stable in the absence of external disturbances, and the $H_\infty $ performance with a prescribed index is also satisfied. Finally, a numerical example is presented to clarify the validity of the proposed method.",4
Neural-Response-Based Extreme Learning Machine for Image Classification.,"This paper proposes a novel and simple multilayer feature learning method for image classification by employing the extreme learning machine (ELM). The proposed algorithm is composed of two stages: the multilayer ELM (ML-ELM) feature mapping stage and the ELM learning stage. The ML-ELM feature mapping stage is recursively built by alternating between feature map construction and maximum pooling operation. In particular, the input weights for constructing feature maps are randomly generated and hence need not be trained or tuned, which makes the algorithm highly efficient. Moreover, the maximum pooling operation enables the algorithm to be invariant to certain transformations. During the ELM learning stage, elastic-net regularization is proposed to learn the output weight. Elastic-net regularization helps to learn more compact and meaningful output weight. In addition, we preprocess the input data with the dense scale-invariant feature transform operation to improve both the robustness and invariance of the algorithm. To evaluate the effectiveness of the proposed method, several experiments are conducted on three challenging databases. Compared with the conventional deep learning methods and other related ones, the proposed method achieves the best classification results with high computational efficiency.",4
Deep Ensemble Machine for Video Classification.,"Video classification has been extensively researched in computer vision due to its wide spread applications. However, it remains an outstanding task because of the great challenges in effective spatial-temporal feature extraction and efficient classification with high-dimensional video representations. To address these challenges, in this paper, we propose an end-to-end learning framework called deep ensemble machine (DEM) for video classification. Specifically, to establish effective spatio-temporal features, we propose using two deep convolutional neural networks (CNNs), i.e., vision and graphics group and C3-D to extract heterogeneous spatial and temporal features for complementary representations. To achieve efficient classification, we propose ensemble learning based on random projections aiming to transform high-dimensional features into a set of lower dimensional compact features in subspaces; an ensemble of classifiers is trained on the subspaces and combined with a weighting layer during the backpropagation. To further enhance the performance, we introduce rectified linear encoding (RLE) inspired from error-correcting output coding to encode the initial outputs of classifiers, followed by a softmax layer to produce the final classification results. DEM combines the strengths of deep CNNs and ensemble learning, which establishes a new end-to-end learning architecture for more accurate and efficient video classification. We show the great effectiveness of DEM by extensive experiments on four data sets for diverse video classification tasks including action recognition and dynamic scene classification. Results have shown that DEM achieves high performance on all tasks with an improvement of up to 13% on CIFAR10 data set over the baseline model.",4
Approximate Low-Rank Projection Learning for Feature Extraction.,"Feature extraction plays a significant role in pattern recognition. Recently, many representation-based feature extraction methods have been proposed and achieved successes in many applications. As an excellent unsupervised feature extraction method, latent low-rank representation (LatLRR) has shown its power in extracting salient features. However, LatLRR has the following three disadvantages: 1) the dimension of features obtained using LatLRR cannot be reduced, which is not preferred in feature extraction; 2) two low-rank matrices are separately learned so that the overall optimality may not be guaranteed; and 3) LatLRR is an unsupervised method, which by far has not been extended to the supervised scenario. To this end, in this paper, we first propose to use two different matrices to approximate the low-rank projection in LatLRR so that the dimension of obtained features can be reduced, which is more flexible than original LatLRR. Then, we treat the two low-rank matrices in LatLRR as a whole in the process of learning. In this way, they can be boosted mutually so that the obtained projection can extract more discriminative features. Finally, we extend LatLRR to the supervised scenario by integrating feature extraction with the ridge regression. Thus, the process of feature extraction is closely related to the classification so that the extracted features are discriminative. Extensive experiments are conducted on different databases for unsupervised and supervised feature extraction, and very encouraging results are achieved in comparison with many state-of-the-arts methods.",4
Matrix Factorization From a Few Dominators.,"The Pareto principle states that most effects are the result of a few dominating causes. This principle also fits most matrix completion problems. In practice, most real-world data sets exhibit nonuniformly distributed observations. Unfortunately, most existing algorithms are designed based on uniformly distributed observations. In this brief, we propose a matrix factorization approach to recover a large-scale matrix from a dominating submatrix that is composed of a few most important rows and columns from the original matrix. The method for evaluating the importance of a row or column is inspired by the term frequency-inverse document frequency in natural language processing. The selected submatrix is recovered using an existing base matrix factorization algorithm. Then, factors of the completed submatrix are used to retrieve the factors of the whole matrix via a linear regression model. Numerical experiments demonstrate the effectiveness of our approach for recovering the matrix from nonuniformly distributed observations. In addition, our framework is naturally applicable for parallel and distributed computing, which is very encouraging for massive-sized data sets.",4
Improved Stability Criterion for Recurrent Neural Networks With Time-Varying Delays.,"In this brief, the problem of delay-dependent stability of recurrent neural networks with time-varying delays is studied. A newly augmented Lyapunov-Krasovskii functional (LKF) that considers the information of the nonzero lower bound of time-varying delays is developed. Moreover, the information of the delayed state terms is not considered as elements of augmented vectors when constructing the LKF. An improved stability criterion with the framework of linear matrix inequalities is derived by employing the integral inequality and reciprocally convex combination. With the comparison to the existing ones, the developed stability criterion for neural networks has less conservatism and complexity. Finally, two widely used numerical examples are given to show the effectiveness and superiority of the obtained stability criterion.",4
Theoretical Study of Oscillator Neurons in Recurrent Neural Networks.,"Neurons in a network can be both active or inactive. Given a subset of neurons in a network, is it possible for the subset of neurons to evolve to form an active oscillator by applying some external periodic stimulus? Furthermore, can these oscillator neurons be observable, that is, is it a stable oscillator? This paper explores such possibility, finding that an important property: any subset of neurons can be intermittently co-activated to form a stable oscillator by applying some external periodic input without any condition. Thus, the existing of intermittently active oscillator neurons is an essential property possessed by the networks. Moreover, this paper shows that, under some conditions, a subset of neurons can be fully co-activated to form a stable oscillator. Such neurons are called selectable oscillator neurons. Necessary and sufficient conditions are established for a subset of neurons to be selectable oscillator neurons in linear threshold recurrent neuron networks. It is proved that a subset of neurons forms selectable oscillator neurons if and only if the real part of each eigenvalue of the associated synaptic connection weight submatrix of the network is not larger than one. This simple condition makes the concept of selectable oscillator neurons tractable. The selectable oscillator neurons can be regarded as memories stored in the synaptic connections of networks, which enables to find a new perspective of memories in neural networks, different from the equilibrium-type attractors.",4
Remote Estimator Design for Time-Delay Neural Networks Using Communication State Information.,"This paper investigates the estimator design for the neural networks, where distributed delays and imperfect measurements are included. A randomly occurred neuron-dependent nonlinearity is used to describe the uncertain measurements disturbed by neurons. The measurements are transmitted over multiple transmission channels, and Markov chains are introduced to model packet dropouts of these channels. A one-to-one map is constructed to transform $m$ independent Markov chains to an augmented one to facilitate system analysis. A new variable called channel state is defined based on the cases of packet dropouts, and the channel-state-dependent estimator is designed to trade off between the number and the performance of the estimator. Sufficient conditions are established to guarantee that the augmented system is stochastically stable and satisfies the strict $(Q, S, R)-\gamma -$ dissipativity. The estimator gains are derived using linear matrix methods. Finally, an example is applied to illustrate the effectiveness of the developed methods.",4
Fuzzy Neural Network Control of a Flexible Robotic Manipulator Using Assumed Mode Method.,"In this paper, in order to analyze the single-link flexible structure, the assumed mode method is employed to develop the dynamic model. Based on the discrete dynamic model, fuzzy neural network (NN) control is investigated to track the desired trajectory accurately and to suppress the flexible vibration maximally. To ensure the stability rigorously as the goal, the system is proved to be uniform ultimate boundedness by Lyapunov's stability method. Eventually, simulations verify that the proposed control strategy is effective, and the control performance is compared with the proportion derivative control. The experiments are implemented on the Quanser platform to further demonstrate the feasibility of the proposed fuzzy NN control.",4
Domain-Weighted Majority Voting for Crowdsourcing.,"Crowdsourcing labeling systems provide an efficient way to generate multiple inaccurate labels for given observations. If the competence level or the ""reputation,"" which can be explained as the probabilities of annotating the right label, for each crowdsourcing annotators is equal and biased to annotate the right label, majority voting (MV) is the optimal decision rule for merging the multiple labels into a single reliable one. However, in practice, the competence levels of annotators employed by the crowdsourcing labeling systems are often diverse very much. In these cases, weighted MV is more preferred. The weights should be determined by the competence levels. However, since the annotators are anonymous and the ground-truth labels are usually unknown, it is hard to compute the competence levels of the annotators directly. In this paper, we propose to learn the weights for weighted MV by exploiting the expertise of annotators. Specifically, we model the domain knowledge of different annotators with different distributions and treat the crowdsourcing problem as a domain adaptation problem. The annotators provide labels to the source domains and the target domain is assumed to be associated with the ground-truth labels. The weights are obtained by matching the source domains with the target domain. Although the target-domain labels are unknown, we prove that they could be estimated under mild conditions. Both theoretical and empirical analyses verify the effectiveness of the proposed method. Large performance gains are shown for specific data sets.",4
A Discrete-Time Projection Neural Network for Sparse Signal Reconstruction With Application to Face Recognition.,"This paper deals with sparse signal reconstruction by designing a discrete-time projection neural network. Sparse signal reconstruction can be converted into an L1 -minimization problem, which can also be changed into the unconstrained basis pursuit denoising problem. To solve the L1 -minimization problem, an iterative algorithm is proposed based on the discrete-time projection neural network, and the global convergence of the algorithm is analyzed by using Lyapunov method. Experiments on sparse signal reconstruction and several popular face data sets are organized to illustrate the effectiveness and performance of the proposed algorithm. The experimental results show that the proposed algorithm is not only robust to different levels of sparsity and amplitude of signals and the noise pixels but also insensitive to the diverse values of scalar weight. Moreover, the value of the step size of the proposed algorithm is close to 1/2, thus a fast convergence rate is potentially possible. Furthermore, the proposed algorithm achieves better classification performance compared with some other algorithms for face recognition.",4
Reconstructible Nonlinear Dimensionality Reduction via Joint Dictionary Learning.,"This paper presents a parametric low-dimensional (LD) representation learning method that allows to reconstruct high-dimensional (HD) input vectors in an unsupervised manner. Under the assumption that the HD data and its LD representation share the same or similar local sparse structure, the proposed method achieves reconstructible dimensionality reduction via jointly learning dictionaries in both the original HD data space and its LD representation space. By regarding the sparse representation as a smooth function with respect to a specific dictionary, we construct an encoding-decoding block for learning LD representations from sparse coefficients of HD data. It is expected that this learning process preserves the desirable structure of HD data in the LD representation space, and simultaneously allows a reliable reconstruction from the LD space back to the original HD space. In addition, the proposed single layer encoding-decoding block can be easily extended to deep learning structures. Numerical experiments on both synthetic data sets and real images show that the proposed method achieves strongly competitive and robust performance in data DR, reconstruction, and synthesis, even on heavily corrupted data. The proposed method can be used as an alternative approach to compressive sensing (CS); however, it can outperform the traditional CS methods in: 1) task-driven learning problems, such as 2-D/3-D data visualization, and 2) data reconstruction at a lower dimensional space.",4
Quantized Sampled-Data Control for Synchronization of Inertial Neural Networks With Heterogeneous Time-Varying Delays.,"This paper is concerned with the problem of synchronization for inertial neural networks (INNs) with heterogeneous time-varying delays (HTVDs) through quantized sampled-data control. The control scheme, which takes the communication limitations of quantization and variable sampling into account, is first employed for tackling the synchronization of INNs. A novel Lyapunov-Krasovskii functional (LKF) is constructed for synchronizing an error system. Compared with existing LKFs by the largest upper bound of all HTVDs, the proposed LKF is superior, since it can make full use of the information on the lower and upper bounds of each HTVD. Based on the LKF and a new integral inequality technique, less conservative synchronization criteria are derived. The desired quantized sampled-data controller is designed by solving a set of linear matrix inequalities. Finally, a numerical example is given to illustrate the effectiveness and conservatism reduction of the proposed results.",4
Metric Learning-Guided Least Squares Classifier Learning.,"For a multicategory classification problem, discriminative least squares regression (DLSR) explicitly introduces an -dragging technique to enlarge the margin between the categories, yielding superior classification performance from a margin perspective. In this brief, we reconsider this classification problem from a metric learning perspective and propose a framework of metric learning-guided least squares classifier (MLG-LSC) learning. The core idea is to learn a unified metric matrix for the error of LSR, such that such a metric matrix can yield small distances for the same category, while large ones for the different categories. As opposed to the -dragging in DLSR, we call this the error-dragging (e-dragging). Different from DLSR and its related variants, our MLG-LSC implicitly carries out the e-dragging and can naturally reflect the roughly relative distance relationships among the categories from a metric learning perspective. Furthermore, our optimization objective functions are strictly (geodesically) convex and thus can obtain their corresponding closed-form solutions, resulting in higher computational performance. Experimental results on a set of benchmark data sets indicate the validity of our learning framework.",4
Finite-Time Passivity-Based Stability Criteria for Delayed Discrete-Time Neural Networks via New Weighted Summation Inequalities.,"In this paper, we study the problem of finite-time stability and passivity criteria for discrete-time neural networks (DNNs) with variable delays. The main objective is how to effectively evaluate the finite-time passivity conditions for NNs. To achieve this, some new weighted summation inequalities are proposed for application to a finite-sum term appearing in the forward difference of a novel Lyapunov-Krasovskii functional, which helps to ensure that the considered delayed DNN is passive. The derived passivity criteria are presented in terms of linear matrix inequalities. A numerical example is given to illustrate the effectiveness of the proposed results.",4
Mining Markov Blankets Without Causal Sufficiency.,"Markov blankets (MBs) in Bayesian networks (BNs) play an important role in both local causal discovery and large-scale BN structure learning. Almost all existing MB discovery algorithms are designed under the assumption of causal sufficiency, which states that there are no latent common causes for two or more of the observed variables in data. However, latent common causes are ubiquitous in many applications, and hence, this assumption is often violated in practice. Thus, developing algorithms for discovering MBs without assuming causal sufficiency is of practical significance, and it is crucial for causal structure learning in real-world data. In this paper, we focus on addressing this problem. Specifically, we adopt a maximal ancestral graph (MAG) model to represent latent common causes and the concept of MBs without assuming causal sufficiency. Then, we propose an effective and efficient algorithm to discover the MB of a target variable in an MAG. Using benchmark and real-world data sets, the experiments validate the algorithm proposed in this paper.",4
A Comprehensive Look at Coding Techniques on Riemannian Manifolds.,"Core to many learning pipelines is visual recognition such as image and video classification. In such applications, having a compact yet rich and informative representation plays a pivotal role. An underlying assumption in traditional coding schemes [e.g., sparse coding (SC)] is that the data geometrically comply with the Euclidean space. In other words, the data are presented to the algorithm in vector form and Euclidean axioms are fulfilled. This is of course restrictive in machine learning, computer vision, and signal processing, as shown by a large number of recent studies. This paper takes a further step and provides a comprehensive mathematical framework to perform coding in curved and non-Euclidean spaces, i.e., Riemannian manifolds. To this end, we start by the simplest form of coding, namely, bag of words. Then, inspired by the success of vector of locally aggregated descriptors in addressing computer vision problems, we will introduce its Riemannian extensions. Finally, we study Riemannian form of SC, locality-constrained linear coding, and collaborative coding. Through rigorous tests, we demonstrate the superior performance of our Riemannian coding schemes against the state-of-the-art methods on several visual classification tasks, including head pose classification, video-based face recognition, and dynamic scene recognition.",4
Neurons With Paraboloid Decision Boundaries for Improved Neural Network Classification Performance.,"In mathematical terms, an artificial neuron computes the inner product of a d -dimensional input vector x with its weight vector w , compares it with a bias value w0 and fires based on the result of this comparison. Therefore, its decision boundary is given by the equation w(T)x+w0=0 . In this paper, we propose replacing the linear hyperplane decision boundary of a neuron with a curved, paraboloid decision boundary. Thus, the decision boundary of the proposed paraboloid neuron is given by the equation (h(T)x+h0)(2)-||x-p||2(2)=0 , where h and h0 denote the parameters of the directrix and p denotes the coordinates of the focus. Such paraboloid neural networks are proven to have superior recognition accuracy in a number of applications.",4
Blind Denoising Autoencoder.,"The term ``blind denoising'' refers to the fact that the basis used for denoising is learned from the noisy sample itself during denoising. Dictionary learning- and transform learning-based formulations for blind denoising are well known. But there has been no autoencoder-based solution for the said blind denoising approach. So far, autoencoder-based denoising formulations have learned the model on a separate training data and have used the learned model to denoise test samples. Such a methodology fails when the test image (to denoise) is not of the same kind as the models learned with. This will be the first work, where we learn the autoencoder from the noisy sample while denoising. Experimental results show that our proposed method performs better than dictionary learning (K-singular value decomposition), transform learning, sparse stacked denoising autoencoder, and the gold standard BM3D algorithm.",4
Augmented Real-Valued Time-Delay Neural Network for Compensation of Distortions and Impairments in Wireless Transmitters.,"A digital predistorter, modeled by an augmented real-valued time-delay neural network (ARVTDNN), has been proposed and found suitable to mitigate the nonlinear distortions of the power amplifier (PA) along with modulator imperfections for a wideband direct-conversion transmitter. The input signal of the proposed ARVTDNN consists of Cartesian in-phase and quadrature phase ( I/Q ) components, as well as envelope-dependent terms. Theoretical analysis shows that the proposed model is able to produce a richer basis function containing both the desired odd- and even-order terms, resulting in improved modeling capability and distortion mitigation. Its actual performance has been validated through extensive simulations and experiments. The results show that the compensation and hardware impairment mitigation capabilities of the ARVTDNN are superior to the existing state-of-the-art real-valued focused time-delay neural network (RVFTDNN) by 3-4 dB for the adjacent channel power ratio and by 2-3 dB in terms of the normalized mean square error. Other important features of the proposed model are its reduced complexity, in terms of the number of parameters and floating-point operations, and its improved numerical stability compared to the RVFTDNN model.",4
Variational Random Function Model for Network Modeling.,"Link prediction is a fundamental problem in network modeling. A family of link prediction approaches is to treat network data as an exchangeable array whose entries can be explained by random functions (e.g., block models and Gaussian processes) over latent node factors. Despite their powerful ability in modeling missing links, these models tend to have a large computational complexity and thus are hard to deal with large networks. To address this problem, we develop a novel variational random function model by defining latent Gaussian processes on exchangeable arrays. This model not only inherits the ability of Gaussian process to describe the nonlinear interactions between nodes, but also enjoys significant reduction on computational complexity. To further make the model scalable to large network data, we develop an efficient key-value-free strategy under the map-reduce framework to tremendously reduce the inference time. Experimental results on large network data have demonstrated both the efficacy and efficiency of the proposed method over state-of-the-arts methods in network modeling.",4
A Semisupervised Classification Approach for Multidomain Networks With Domain Selection.,"Multidomain network classification has attracted significant attention in data integration and machine learning, which can enhance network classification or prediction performance by integrating information from different sources. Despite the previous success, existing multidomain network learning methods usually assume that different views are available for the same set of instances, and thus, they seek a consistent classification result for all domains. However, in many real-world problems, each domain has its specific instance set, and one instance in one domain may correspond to multiple instances in another domain. Moreover, due to the rapid growth of data sources, different domains may not be relevant to each other, which asks for selecting domains relevant to the target/focused domain. A key challenge under this setting is how to achieve accurate prediction by integrating different data representations without losing data information. In this paper, we propose a semisupervised classification approach for a multidomain network based on label propagation, i.e., multidomain classification with domain selection (MCS), which can deal with the cross-domain information and different instance sets in domains. In particular, with sparse weight properties, the proposed MCS can automatically identify those domains relevant to our target domain by assigning them higher weights than the other irrelevant domains. This not only significantly improves a classification accuracy but also helps to obtain optimal network partition for the target domain. From the theoretical viewpoint, we equivalently decompose MCS into two simpler subproblems with analytical solutions, which can be efficiently solved by their computational procedures. Extensive experimental results on both synthetic and real-world data sets empirically demonstrate the advantages of the proposed approach in terms of both prediction performance and domain selection ability.",4
UCFTS: A Unilateral Coupling Finite-Time Synchronization Scheme for Complex Networks.,"Improving universality and robustness of the control method is one of the most challenging problems in the field of complex networks (CNs) synchronization. In this paper, a special unilateral coupling finite-time synchronization (UCFTS) method for uncertain CNs is proposed for this challenging problem. Multiple influencing factors are considered, so that the proposed method can be applied to a variety of situations. First, two kinds of drive-response CNs with different sizes are introduced, each of which contains two types of nonidentical nodes and time-varying coupling delay. In addition, the node parameters and topological structure are unknown in drive network. Then, an effective UCFTS control technique is proposed to realize the synchronization of drive-response CNs and identify the unknown parameters and topological structure. Second, the UCFTS of uncertain CNs with four types of nonidentical nodes is further studied. Moreover, both the networks are of unknown parameters, time-varying coupling delay and uncertain topological structure. Through designing corresponding adaptive updating laws, the unknown parameters are estimated successfully and the weight of uncertain topology can be automatically adapted to the appropriate value with the proposed UCFTS. Finally, two experimental examples show the correctness of the proposed scheme. Furthermore, the method is compared with the other three synchronization methods, which shows that our method has a better control performance.",4
Local Adaptive Projection Framework for Feature Selection of Labeled and Unlabeled Data.,"Most feature selection methods first compute a similarity matrix by assigning a fixed value to pairs of objects in the whole data or to pairs of objects in a class or by computing the similarity between two objects from the original data. The similarity matrix is fixed as a constant in the subsequent feature selection process. However, the similarities computed from the original data may be unreliable, because they are affected by noise features. Moreover, the local structure within classes cannot be recovered if the similarities between the pairs of objects in a class are equal. In this paper, we propose a novel local adaptive projection (LAP) framework. Instead of computing fixed similarities before performing feature selection, LAP simultaneously learns an adaptive similarity matrix and a projection matrix with an iterative method. In each iteration, is computed from the projected distance with the learned and W is computed with the learned . Therefore, LAP can learn better projection matrix by weakening the effect of noise features with the adaptive similarity matrix. A supervised feature selection with LAP (SLAP) method and an unsupervised feature selection with LAP (ULAP) method are proposed. Experimental results on eight data sets show the superiority of SLAP compared with seven supervised feature selection methods and the superiority of ULAP compared with five unsupervised feature selection methods.",4
Deep CNN-Based Blind Image Quality Predictor.,"Image recognition based on convolutional neural networks (CNNs) has recently been shown to deliver the state-of-the-art performance in various areas of computer vision and image processing. Nevertheless, applying a deep CNN to no-reference image quality assessment (NR-IQA) remains a challenging task due to critical obstacles, i.e., the lack of a training database. In this paper, we propose a CNN-based NR-IQA framework that can effectively solve this problem. The proposed method-deep image quality assessor (DIQA)-separates the training of NR-IQA into two stages: 1) an objective distortion part and 2) a human visual system-related part. In the first stage, the CNN learns to predict the objective error map, and then the model learns to predict subjective score in the second stage. To complement the inaccuracy of the objective error map prediction on the homogeneous region, we also propose a reliability map. Two simple handcrafted features were additionally employed to further enhance the accuracy. In addition, we propose a way to visualize perceptual error maps to analyze what was learned by the deep CNN model. In the experiments, the DIQA yielded the state-of-the-art accuracy on the various databases.",4
A Novel Neural Networks Ensemble Approach for Modeling Electrochemical Cells.,"Accurate modeling of electrochemical cells is nowadays mandatory for achieving effective upgrades in the fields of energetic efficiency and sustainable mobility. Indeed, these models are often used for performing accurate State-of-Charge (SoC) estimations in energy storage systems used in microgrids or powering pure electric and hybrid cars. To this aim, a novel neural networks ensemble approach for modeling electrochemical cells is proposed in this paper. Herein, the system identification has been faced by means of a gray box technique, in which different and specialized neural networks are used for identifying the unknown internal behaviors of the cell. In particular, the a priori knowledge on the system dynamic is used for defining the network architecture. Specifically, each nonlinear function appearing in the system equations is approximated by a distinct neural network. The proposed model has been validated upon three different data sets both in terms of model accuracy and effectiveness in the SoC estimation task. The achieved performances have been compared with those of other computational intelligence approaches proposed in the literature. The results prove the effectiveness of the gray box scheme, achieving very promising performances in both the system identification accuracy and the SoC estimation task.",4
"Exploiting Combination Effect for Unsupervised Feature Selection by l2,0 Norm.","In learning applications, exploring the cluster structures of the high dimensional data is an important task. It requires projecting or visualizing the cluster structures into a low dimensional space. The challenges are: 1) how to perform the projection or visualization with less information loss and 2) how to preserve the interpretability of the original data. Recent methods address these challenges simultaneously by unsupervised feature selection. They learn the cluster indicators based on the k nearest neighbor similarity graph, then select the features highly correlated with these indicators. Under this direction, many techniques, such as local discriminative analysis, nonnegative spectral analysis, nonnegative matrix factorization, etc., have been successfully introduced to make the selection more accurate. In this paper, we focus on enhancing the unsupervised feature selection in another perspective, namely, making the selection exploit the combination effect of the features. Given the expected feature amount, previous works operate on the whole features then select those of high coefficients one by one as the output. Our proposed method, instead, operates on a group of features initially then update the selection when a better group appears. Compared to the previous methods, the proposed method exploits the combination effect of the features by l2,0 norm. It improves the selection accuracy where the cluster structures are strongly related to a group of features. We conduct the experiments on six open access data sets from different domains. The experimental results show that our proposed method is more accurate than the recent methods which do not specially consider the combination effect of the features.",4
On the Duality Between Belief Networks and Feed-Forward Neural Networks.,"This paper addresses the duality between the deterministic feed-forward neural networks (FF-NNs) and linear Bayesian networks (LBNs), which are the generative stochastic models representing probability distributions over the visible data based on a linear function of a set of latent (hidden) variables. The maximum entropy principle is used to define a unique generative model corresponding to each FF-NN, called projected belief network (PBN). The FF-NN exactly recovers the hidden variables of the dual PBN. The large- N asymptotic approximation to the PBN has the familiar structure of an LBN, with the addition of an invertible nonlinear transformation operating on the latent variables. It is shown that the exact nature of the PBN depends on the range of the input (visible) data details for the three cases of input data range are provided. The likelihood function of the PBN is straightforward to calculate, allowing it to be used as a generative classifier. An example is provided in which a generative classifier based on the PBN has comparable performance to a deep belief network in classifying handwritten characters. In addition, several examples are provided that demonstrate the duality relationship, for example, by training networks from either side of the duality.",4
Filippov Hindmarsh-Rose Neuronal Model With Threshold Policy Control.,"A Filippov system of Hindmarsh-Rose (HR) neuronal model with threshold policy control is proposed, membrane potential has been taken as the threshold and the corresponding switching function is also established. We first discuss the existence and stability of the equilibria for the two Filippov subsystems based on the 2-D HR model. Subsequently, the sliding dynamics of HR model including the sliding segments, sliding regions, and various equilibria under the Filippov framework are studied. Then, we further consider the equilibria and the sliding bifurcation set of the Filippov system, and find there exist the bistable equilibria and several sliding bifurcation phenomena, such as boundary-node bifurcation, pseudosaddle-node bifurcation, the emergence and disappearance of limit cycles on the sliding line, and so on. Finally, we study the Filippov system of the 3-D HR model, and provide a phase diagram of the system that generates the sliding spiking and the sliding bursting, which lie on the sliding line.",4
Leader-Following Practical Cluster Synchronization for Networks of Generic Linear Systems: An Event-Based Approach.,"In network systems, a group of nodes may evolve into several subgroups and coordinate with each other in the same subgroup, i.e., reach cluster synchronization, to cope with the unanticipated situations. To this end, the leader-following practical cluster synchronization problem of networks of generic linear systems is studied in this paper. An event-based control algorithm that can largely reduce the amount of communication is first proposed over directed communication topologies. In the proposed algorithm, each node decides itself when to transmit its current state to its neighbors and how to update its controller according to the estimations of the states of it and its neighbors. Then, the Lyapunov method is utilized to perform the convergence analysis. It shows that the practical cluster synchronization can be ensured by choosing appropriate parameters no matter what kind of estimation for the state is applied. Furthermore, the Zeno behavior is also excluded for each node under some mild assumptions. Besides, three kinds of common estimations for the states including zero-order hold model, first-order approximate model, and high-order model-based estimations are, respectively, analyzed from the perspective of the exclusion of Zeno behavior. Finally, the validity of the proposed algorithm is demonstrated, the effects of the concerned parameters are simply presented, and the effects of the three estimations are also compared through several simulations.",4
Semisupervised Learning Based on a Novel Iterative Optimization Model for Saliency Detection.,"In this paper, we propose a novel iterative optimization model for bottom-up saliency detection. By exploring bottom-up saliency principles and semisupervised learning approaches, we design a high-performance saliency analysis method for wide ranging scenes. The proposed algorithm consists of two stages: 1) we develop a boundary homogeneity model to characterize the general position and the contour of the salient objects and 2) we propose a novel iterative optimization model, termed gradual saliency optimization, for further performance improvement. Our main contribution falls on the second stage, where we propose an iterative framework with self-repairing mechanisms for refining saliency maps. In this framework, we further develop a more comprehensive optimization function applying a novel semisupervised learning scheme to enhance the traditional saliency measure. More elaborately, the iterative method can gradually improve the output in each iteration and finally converge to high-quality saliency maps. Based on our experiments on four different public data sets, it can be demonstrated that our approach significantly outperforms the state-of-the-art methods.",4
Event-Triggered Stabilization of Neural Networks With Time-Varying Switching Gains and Input Saturation.,"This paper investigates the event-triggered stabilization of neural networks (NNs) subject to input saturation. The main core lies in the design of a novel controller with time-varying switching gains and the associated switching event-triggered condition (ETC). The ETC is essentially a switching between the aperiodic sampling and continuous event trigger. The control gains of the designed controller are composed of an exponentially decaying term and two gain matrices. The two gain matrices are required to be switched when the switching between the aperiodic sampling and continuous event trigger is met. By employing the generalized sector condition and switching Lyapunov function, several sufficient conditions that ensure the local exponential stability of the NNs are formulated in terms of linear matrix inequalities (LMIs). Both the exponentially decaying term and switching gains improve the feasible region of LMIs, and then they are helpful to enlarge the set of admissible initial conditions, the threshold in ETC, and the average waiting time. Together with several optimization problems, two numerical examples are employed to validate the effectiveness of our results.",4
Motivated Optimal Developmental Learning for Sequential Tasks Without Using Rigid Time-Discounts.,"Many methods for reinforcement learning use symbolic representations-nonemergent-such as Q-learning. We use emergent representations here, without human handcrafted symbolic states (i.e., each state corresponds to a different location). This paper models reinforcement learning for hidden neurons in emergent networks for sequential tasks. In this paper, their influences on sequential tasks (e.g., robot navigation in different scenarios) are investigated where the learned value and results of a behavior rely on not only the current experience just like in a pattern recognition (episodic) but also the prediction of future experiences (e.g., delayed rewards) and environments (e.g., previously learned navigational trajectories). We show that this new model of motivated learning amounts to the computation of the maximum-likelihood estimate through ""life"" where punishment and reward have increased weights. This new formulation avoids the greediness of time-discount in Q-learning. Its complex nonlinear sequential optimization has been solved in a closed-form procedure under the condition of the limited computational resources and limited learning experience so far, because we convert it into a simpler problem of incremental and linear estimation. The experimental results showed that the serotonin and dopamine systems speed up learning for sequential tasks, because not all events are equally important. As far as we know, this is the first work that studies the influences of reinforcers (via serotonin and dopamine) on hidden neurons (Y neurons) for sequential tasks in dynamic scenarios using emergent representations.",4
Efficient Cluster-Based Boosting for Semisupervised Classification.,"Semisupervised classification (SSC) consists of using both labeled and unlabeled data to classify unseen instances. Due to the large number of unlabeled data typically available, SSC algorithms must be able to handle large-scale data sets. Recently, various ensemble algorithms have been introduced with improved generalization performance when compared to single classifiers. However, existing ensemble methods are not able to handle typical large-scale data sets. We propose efficient cluster-based boosting (ECB), a multiclass SSC algorithm with cluster-based regularization that avoids generating decision boundaries in high-density regions. A semisupervised selection procedure reduces time and space complexities by selecting only the most informative unlabeled instances for the training of each base learner. We provide evidences to demonstrate that ECB is able to achieve good performance with small amounts of selected data and a relatively small number of base learners. Our experiments confirmed that ECB scales to large data sets while delivering comparable generalization to state-of-the-art methods.",4
Collaborative Deconvolutional Neural Networks for Joint Depth Estimation and Semantic Segmentation.,"Semantic segmentation and single-view depth estimation are two fundamental problems in computer vision. They exploit the semantic and geometric properties of images, respectively, and are thus complementary in scene understanding. In this paper, we propose a collaborative deconvolutional neural network (C-DCNN) to jointly model these two problems for mutual promotion. The C-DCNN consists of two DCNNs, of which each is for one task. The DCNNs provide a finer resolution reconstruction method and are pretrained with hierarchical supervision. The feature maps from these two DCNNs are integrated via a pointwise bilinear layer, which fuses the semantic and depth information and produces higher order features. Then, the integrated features are fed into two sibling classification layers to simultaneously learn for semantic segmentation and depth estimation. In this way, we combine the semantic and depth features in a unified deep network and jointly train them to benefit each other. Specifically, during network training, we process depth estimation as a classification problem where a soft mapping strategy is proposed to map the continuous depth values into discrete probability distributions and the cross entropy loss is used. Besides, a fully connected conditional random field is also used as postprocessing to further improve the performance of semantic segmentation, where the proximity relations of pixels on position, intensity, and depth are jointly considered. We evaluate our approach on two challenging benchmarks: NYU Depth V2 and SUN RGB-D. It is demonstrated that our approach effectively utilizes these two kinds of information and achieves state-of-the-art results on both the semantic segmentation and depth estimation tasks.",4
"Exploring Correlations Among Tasks, Clusters, and Features for Multitask Clustering.","Multitask clustering methods are proposed to improve performances of related tasks concurrently, because they explore the relationship among tasks via exploiting the coefficient matrix or the shared feature matrix. However, divergent effects of features in learning this relationship are seldom considered. To further improve performances, we propose a new multitask clustering approach through exploring correlations among tasks, clusters, and features based on effects of features on clusters. First, a Feature-Cluster (FeaCluster) matrix is introduced to capture the similarity and the distinct task-feature information simultaneously for each task. With the FeaCluster matrix, two affinities are calculated to constitute the interdependencies among tasks: the former is the graphical affinity based on feature-task and task-cluster correlations, while the latter is the reconstructive affinity. Here, the feature-task correlation considers effects of features on tasks, and the task-cluster correlation considers the overall effects of features on clusters. The reconstructive affinity is obtained by minimizing the reconstruction error when representing the FeaCluster matrix for a given task with a linear combination of others. The interdependencies among tasks allow transferring asymmetric shared information, exploring significant features and preserving key information when mapping data into the subspace. The experimental results on multiple data sets reveal that the proposed approach outperforms the state-of-the-art clustering methods in terms of accuracy and normal mutual information.",4
Optimized Neural Network Parameters Using Stochastic Fractal Technique to Compensate Kalman Filter for Power System-Tracking-State Estimation.,"Tracking-state estimation uses previous state vector and recent measurement data to give real-time update on the state of the power system noniteratively during the subsequent time sampling. This paper discusses Kalman filtering enhanced by optimized neural network parameters-based stochastic fractals search technique (KF-MLP-based SFS). Both KF gain (mismodeling error) and measurement noise were replaced by optimized multilayer perceptron (MLP-SFS). This optimized MLP-based SFS could suppress filter divergence and improve the accuracy. The proposed method was used to detect and identify anomalies exhibited in normal operation where loads fluctuate linearly, bad data condition, sudden loss of loads, generators, and transmission lines. The application of the proposed technique (KF-MLP-based SFS) is illustrated on the IEEE 57-bus system. Results of the presented approach are compared to the true state vector (load flow), KF standalone, and KF compensated by radial basis function.",4
Scaling Up Kernel SVM on Limited Resources: A Low-Rank Linearization Approach.,"Kernel support vector machines (SVMs) deliver state-of-the-art results in many real-world nonlinear classification problems, but the computational cost can be quite demanding in order to maintain a large number of support vectors. Linear SVM, on the other hand, is highly scalable to large data but only suited for linearly separable problems. In this paper, we propose a novel approach called low-rank linearized SVM to scale up kernel SVM on limited resources. Our approach transforms a nonlinear SVM to a linear one via an approximate empirical kernel map computed from efficient kernel low-rank decompositions. We theoretically analyze the gap between the solutions of the approximate and optimal rank- k kernel map, which in turn provides guidance on the sampling scheme of the Nystrom approximation. Furthermore, we extend it to a semisupervised metric learning scenario in which partially labeled samples can be exploited to further improve the quality of the low-rank embedding. Our approach inherits rich representability of kernel SVM and high efficiency of linear SVM. Experimental results demonstrate that our approach is more robust and achieves a better tradeoff between model representability and scalability against state-of-the-art algorithms for large-scale SVMs.",4
Sparse Temporal Encoding of Visual Features for Robust Object Recognition by Spiking Neurons.,"Robust object recognition in spiking neural systems remains a challenging in neuromorphic computing area as it needs to solve both the effective encoding of sensory information and also its integration with downstream learning neurons. We target this problem by developing a spiking neural system consisting of sparse temporal encoding and temporal classifier. We propose a sparse temporal encoding algorithm which exploits both spatial and temporal information derived from an spike-timing-dependent plasticity-based HMAX feature extraction process. The temporal feature representation, thus, becomes more appropriate to be integrated with a temporal classifier based on spiking neurons rather than with nontemporal classifier. The algorithm has been validated on two benchmark data sets and the results show the temporal feature encoding and learning-based method achieves high recognition accuracy. The proposed model provides an efficient approach to perform feature representation and recognition in a consistent temporal learning framework, which is easily adapted to neuromorphic implementations.",4
An Event-Triggered Pinning Control Approach to Synchronization of Discrete-Time Stochastic Complex Dynamical Networks.,"This paper is concerned with the synchronization analysis and control problems for a class of nonlinear discrete-time stochastic complex dynamical networks (CDNs) consisting of identical nodes. The discrete-time stochastic dynamical networks under consideration are quite general that account for asymmetric coupling configuration, nonlinear inner coupling structures as well as nonidentical exogenous disturbances. By resorting to both the error bound and the synchronization probability, a notion of quasi-synchronization in probability is first introduced to assess the synchronization performance of the addressed CDNs. An event-triggered pinning feedback control strategy is adopted to control a small fraction of the network nodes with hope to reduce the frequency of updating and communication in the control process while preserving the desired dynamical behaviors of the controlled networks. By using the Lyapunov function method and the stochastic analysis techniques, a general framework is established within which the problems of dynamics analysis and controller synthesis are solved for the closed-loop stochastic dynamical networks. Two numerical examples and their simulations are presented to illustrate the effectiveness and the usefulness of our theoretical results.",4
Swarming Behavior of Multiple Euler-Lagrange Systems With Cooperation-Competition Interactions: An Auxiliary System Approach.,"In this paper, the swarming behavior of multiple Euler-Lagrange systems with cooperation-competition interactions is investigated, where the agents can cooperate or compete with each other and the parameters of the systems are uncertain. The distributed stabilization problem is first studied, by introducing an auxiliary system to each agent, where the common assumption that the cooperation-competition network satisfies the digon sign-symmetry condition is removed. Based on the input-output property of the auxiliary system, it is found that distributed stabilization can be achieved provided that the cooperation subnetwork is strongly connected and the parameters of the auxiliary system are chosen appropriately. Furthermore, as an extension, a distributed consensus tracking problem of the considered multiagent systems is discussed, where the concept of equi-competition is introduced and a new pinning control strategy is proposed based on the designed auxiliary system. Finally, illustrative examples are provided to show the effectiveness of the theoretical analysis.",4
A Collaborative Neurodynamic Approach to Multiobjective Optimization.,"There are two ultimate goals in multiobjective optimization. The primary goal is to obtain a set of Pareto-optimal solutions while the secondary goal is to obtain evenly distributed solutions to characterize the efficient frontier. In this paper, a collaborative neurodynamic approach to multiobjective optimization is presented to attain both goals of Pareto optimality and solution diversity. The multiple objectives are first scalarized using a weighted Chebyshev function. Multiple projection neural networks are employed to search for Pareto-optimal solutions with the help of a particle swarm optimization (PSO) algorithm in reintialization. To diversify the Pareto-optimal solutions, a holistic approach is proposed by maximizing the hypervolume (HV) using again a PSO algorithm. The experimental results show that the proposed approach outperforms three other state-of-the-art multiobjective algorithms (i.e., HMOEA/D, MOEA/DD, and NSGAIII) most of times on 37 benchmark datasets in terms of HV and inverted generational distance.",4
Reduced-Order Filtering of Delayed Static Neural Networks With Markovian Jumping Parameters.,"The reduced-order filtering problems are investigated in this paper for static neural networks with Markovian jumping parameters and mode-dependent time-varying delays. By fully making use of integral inequalities, the designs of reduced-order and filters are discussed. The proper gain matrices of filters and the optimal performance indices are efficiently obtained by resolving corresponding convex optimization problems with the constraints of linear matrix inequalities. It is verified that the computational complexity for the reduced-order filter design is significantly reduced when compared with the full-order one. Furthermore, the nonfragile reduced-order filtering problems are also resolved in this paper. Two examples with simulation results are presented to demonstrate the feasibility and application of the established results.",4
An Online Minimax Optimal Algorithm for Adversarial Multiarmed Bandit Problem.,"We investigate the adversarial multiarmed bandit problem and introduce an online algorithm that asymptotically achieves the performance of the best switching bandit arm selection strategy. Our algorithms are truly online such that we do not use the game length or the number of switches of the best arm selection strategy in their constructions. Our results are guaranteed to hold in an individual sequence manner, since we have no statistical assumptions on the bandit arm losses. Our regret bounds, i.e., our performance bounds with respect to the best bandit arm selection strategy, are minimax optimal up to logarithmic terms. We achieve the minimax optimal regret with computational complexity only log-linear in the game length. Thus, our algorithms can be efficiently used in applications involving big data. Through an extensive set of experiments involving synthetic and real data, we demonstrate significant performance gains achieved by the proposed algorithm with respect to the state-of-the-art switching bandit algorithms. We also introduce a general efficiently implementable bandit arm selection framework, which can be adapted to various applications.",4
Unification of MAP Estimation and Marginal Inference in Recurrent Neural Networks.,"Numerous experimental data show that human brain can represent probability distributions and perform Bayesian inference. However, it remains unclear how the brain implements probabilistic inference in the form of neural circuits. Several models have been proposed that aim at explaining how the network of neurons carry out maximum a posterior inference (MAP) estimation and marginal inference, but they are all task specific in that they treat MAP estimation and marginal inference separately. In this brief, we propose that human brain could implement MAP estimation and marginal inference in the same network of neurons. We illustrate our result in hidden Markov models and prove that a recurrent neural network (RNN) implementation of belief propagation can be tuned to perform approximate Bayesian inference (to provide posterior or conditional distribution over the latent causes of observations) or identify the MAP or peak of the joint distribution. The key tuning parameter is a temperature parameter that controls the precision of probability distributions that are optimized. Theoretical analyses and experimental results demonstrate that RNNs can carry out near-optimal MAP estimation and marginal inference.",4
Hierarchical Deep Reinforcement Learning for Continuous Action Control.,"Robotic control in a continuous action space has long been a challenging topic. This is especially true when controlling robots to solve compound tasks, as both basic skills and compound skills need to be learned. In this paper, we propose a hierarchical deep reinforcement learning algorithm to learn basic skills and compound skills simultaneously. In the proposed algorithm, compound skills and basic skills are learned by two levels of hierarchy. In the first level of hierarchy, each basic skill is handled by its own actor, overseen by a shared basic critic. Then, in the second level of hierarchy, compound skills are learned by a meta critic by reusing basic skills. The proposed algorithm was evaluated on a Pioneer 3AT robot in three different navigation scenarios with fully observable tasks. The simulations were built in Gazebo 2 in a robot operating system Indigo environment. The results show that the proposed algorithm can learn both high performance basic skills and compound skills through the same learning process. The compound skills learned outperform those learned by a discrete action space deep reinforcement learning algorithm.",4
Concept Drift and Anomaly Detection in Graph Streams.,"Graph representations offer powerful and intuitive ways to describe data in a multitude of application domains. Here, we consider stochastic processes generating graphs and propose a methodology for detecting changes in stationarity of such processes. The methodology is general and considers a process generating attributed graphs with a variable number of vertices/edges, without the need to assume a one-to-one correspondence between vertices at different time steps. The methodology acts by embedding every graph of the stream into a vector domain, where a conventional multivariate change detection procedure can be easily applied. We ground the soundness of our proposal by proving several theoretical results. In addition, we provide a specific implementation of the methodology and evaluate its effectiveness on several detection problems involving attributed graphs representing biological molecules and drawings. Experimental results are contrasted with respect to suitable baseline methods, demonstrating the effectiveness of our approach.",4
Adaptive Neural Control for Robotic Manipulators With Output Constraints and Uncertainties.,"This paper investigates adaptive neural control methods for robotic manipulators, subject to uncertain plant dynamics and constraints on the joint position. The barrier Lyapunov function is employed to guarantee that the joint constraints are not violated, in which the Moore-Penrose pseudo-inverse term is used in the control design. To handle the unmodeled dynamics, the neural network (NN) is adopted to approximate the uncertain dynamics. The NN control based on full-state feedback for robots is proposed when all states of the closed loop are known. Subsequently, only the robot joint is measurable in practice; output feedback control is designed with a high-gain observer to estimate unmeasurable states. Through the Lyapunov stability analysis, system stability is achieved with the proposed control, and the system output achieves convergence without violation of the joint constraints. Simulation is conducted to approve the feasibility and superiority of the proposed NN control.",4
Learning Temporal Information for Brain-Computer Interface Using Convolutional Neural Networks.,"Deep learning (DL) methods and architectures have been the state-of-the-art classification algorithms for computer vision and natural language processing problems. However, the successful application of these methods in motor imagery (MI) brain-computer interfaces (BCIs), in order to boost classification performance, is still limited. In this paper, we propose a classification framework for MI data by introducing a new temporal representation of the data and also utilizing a convolutional neural network (CNN) architecture for classification. The new representation is generated from modifying the filter-bank common spatial patterns method, and the CNN is designed and optimized accordingly for the representation. Our framework outperforms the best classification method in the literature on the BCI competition IV-2a 4-class MI data set by 7% increase in average subject accuracy. Furthermore, by studying the convolutional weights of the trained networks, we gain an insight into the temporal characteristics of EEG.",4
Kurtosis-Based CRTRL Algorithms for Fully Connected Recurrent Neural Networks.,"In this paper, kurtosis-based complex-valued real-time recurrent learning (KCRTRL) and kurtosis-based augmented CRTRL (KACRTRL) algorithms are proposed for training fully connected recurrent neural networks (FCRNNs) in the complex domain. These algorithms are designed by minimizing the cost functions based on the kurtosis of a complex-valued error signal. The KCRTRL algorithm exploits the circularity properties of the complex-valued signals, and this algorithm not only provides a faster convergence rate but also results in a lower steady-state error. However, the KCRTRL algorithm is suboptimal in the processing of noncircular (NC) complex-valued signals. On the other hand, the KACRTRL algorithm contains a complete second-order information due to the augmented statistics, thus considerably improves the performance of the FCRNN in the processing of NC complex-valued signals. Simulation results on the one-step-ahead prediction problems show that the proposed KCRTRL algorithm significantly enhances the performance for only circular complex-valued signals, whereas the proposed KACRTRL algorithm provides more superior performance than existing algorithms for NC complex-valued signals in terms of the convergence rate and the steady-state error.",4
Neuro-Adaptive Control With Given Performance Specifications for Strict Feedback Systems Under Full-State Constraints.,"In this paper, we investigate the tracking control problem for a class of strict feedback systems with pregiven performance specifications as well as full-state constraints. Our focus is on developing a feasible neural network (NN)-based control method that is able to, under full-state constraints, force the tracking error to converge into a prescribed region within preset finite time and further reduce the error to a smaller and adjustable residual set, while confining the overshoot within predefined small level. Based on two consecutive error transformations governed by two auxiliary functions, named with behavior-shaping function and asymmetric scaling function, respectively, a novel approach to achieve given performance specifications is developed under certain bound condition on the transformed error, such condition, along with the full-stated constraints, is guaranteed by imbedding barrier Lyapunov function (BLF) into the back-stepping design. Furthermore, asymmetric output constraints are maintained with a single symmetric BLF, simplifying the procedure of stability analysis. All internal signals including the stimulating inputs to the NN unit are ensured to be bounded. Both theoretical analysis and numerical simulation verify the effectiveness and the benefits of the design.",4
Exclusive Sparsity Norm Minimization With Random Groups via Cone Projection.,"Many practical applications such as gene expression analysis, multitask learning, image recognition, signal processing, and medical data analysis pursue a sparse solution for the feature selection purpose and particularly favor the nonzeros evenly distributed in different groups. The exclusive sparsity norm has been widely used to serve to this purpose. However, it still lacks systematical studies for exclusive sparsity norm optimization. This paper offers two main contributions from the optimization perspective: 1) we provide several efficient algorithms to solve exclusive sparsity norm minimization with either smooth loss or hinge loss (nonsmooth loss). All algorithms achieve the optimal convergence rate . ( is the iteration number.) To the best of our knowledge, this is the first time to guarantee such convergence rate for the general exclusive sparsity norm minimization and 2) when the group information is unavailable to define the exclusive sparsity norm, we propose to use the random grouping scheme to construct groups and prove that if the number of groups is appropriately chosen, the nonzeros (true features) would be grouped in the ideal way with high probability. Empirical studies validate the efficiency of the proposed algorithms, and the effectiveness of random grouping scheme on the proposed exclusive support vector machine formulation.",4
Discriminative Deep Quantization Hashing for Face Image Retrieval.,"This paper proposes a new discriminative deep quantization hashing (DDQH) approach for large-scale face image retrieval by learning discriminative and compact binary codes. It jointly explores the discrete code learning, batch normalization quantization (BNQ) module, and end-to-end learning in one unified framework, which can guarantee the optimal compatibility of hash coding and feature learning. To learn multiscale and robust facial features, a deep network properly stacking several convolution-pooling layers and pooling layers is designed, and the facial features are obtained by fusing the outputs of the last convolutional layer and the last pooling layer. Besides, the prediction errors of the learned binary codes are minimized to learn discriminative binary codes of images. To obtain higher retrieval accuracies, a BNQ module is utilized to control quantization at a moderate level. Experiments are conducted on two widely used data sets, and the proposed DDQH method achieves encouraging improvements over some state-of-the-art hashing approaches.",4
Behavioral Learning in a Cognitive Neuromorphic Robot: An Integrative Approach.,"We present here a learning system using the iCub humanoid robot and the SpiNNaker neuromorphic chip to solve the real-world task of object-specific attention. Integrating spiking neural networks with robots introduces considerable complexity for questionable benefit if the objective is simply task performance. But, we suggest, in a cognitive robotics context, where the goal is understanding how to compute, such an approach may yield useful insights to neural architecture as well as learned behavior, especially if dedicated neural hardware is available. Recent advances in cognitive robotics and neuromorphic processing now make such systems possible. Using a scalable, structured, modular approach, we build a spiking neural network where the effects and impact of learning can be predicted and tested, and the network can be scaled or extended to new tasks automatically. We introduce several enhancements to a basic network and show how they can be used to direct performance toward behaviorally relevant goals. Results show that using a simple classical spike-timing-dependent plasticity (STDP) rule on selected connections, we can get the robot (and network) to progress from poor task-specific performance to good performance. Behaviorally relevant STDP appears to contribute strongly to positive learning: ""do this"" but less to negative learning: ""don't do that."" In addition, we observe that the effect of structural enhancements tends to be cumulative. The overall system suggests that it is by being able to exploit combinations of effects, rather than any one effect or property in isolation, that spiking networks can achieve compelling, task-relevant behavior.",4
Weakly Supervised Object Detection via Object-Specific Pixel Gradient.,"Most existing object detection algorithms are trained based upon a set of fully annotated object regions or bounding boxes, which are typically labor-intensive. On the contrary, nowadays there is a significant amount of image-level annotations cheaply available on the Internet. It is hence a natural thought to explore such ""weak"" supervision to benefit the training of object detectors. In this paper, we propose a novel scheme to perform weakly supervised object localization, termed object-specific pixel gradient (OPG). The OPG is trained by using image-level annotations alone, which performs in an iterative manner to localize potential objects in a given image robustly and efficiently. In particular, we first extract an OPG map to reveal the contributions of individual pixels to a given object category, upon which an iterative mining scheme is further introduced to extract instances or components of this object. Moreover, a novel average and max pooling layer is introduced to improve the localization accuracy. In the task of weakly supervised object localization, the OPG achieves a state-of-the-art 44.5% top-5 error on ILSVRC 2013, which outperforms competing methods, including Oquab et al. and region-based convolutional neural networks on the Pascal VOC 2012, with gains of 2.6% and 2.3%, respectively. In the task of object detection, OPG achieves a comparable performance of 27.0% mean average precision on Pascal VOC 2007. In all experiments, the OPG only adopts the off-the-shelf pretrained CNN model, without using any object proposals. Therefore, it also significantly improves the detection speed, i.e., achieving three times faster compared with the state-of-the-art method.",4
Runtime Programmable and Memory Bandwidth Optimized FPGA-Based Coprocessor for Deep Convolutional Neural Network.,"The deep convolutional neural network (DCNN) is a class of machine learning algorithms based on feed-forward artificial neural network and is widely used for image processing applications. Implementation of DCNN in real-world problems needs high computational power and high memory bandwidth, in a power-constrained environment. A general purpose CPU cannot exploit different parallelisms offered by these algorithms and hence is slow and energy inefficient for practical use. We propose a field-programmable gate array (FPGA)-based runtime programmable coprocessor to accelerate feed-forward computation of DCNNs. The coprocessor can be programmed for a new network architecture at runtime without resynthesizing the FPGA hardware. Hence, it acts as a plug-and-use peripheral for the host computer. Caching is implemented for input features and filter weights using on-chip memory to reduce the external memory bandwidth requirement. Data are prefetched at several stages to avoid stalling of computational units and different optimization techniques are used to efficiently reuse the fetched data. Dataflow is dynamically adjusted in runtime for each DCNN layer to achieve consistent computational throughput across a wide range of input feature sizes and filter sizes. The coprocessor is prototyped using Xilinx Virtex-7 XC7VX485T FPGA-based VC707 board and operates at 150 MHz. Experimental results show that our implementation is energy efficient than highly optimized CPU implementation and achieves consistent computational throughput of more than 140 G operations/s for a wide range of input feature sizes and filter sizes. Off-chip memory transactions decrease by due to the use of the on-chip cache.",4
Computationally Efficient Data-Driven Higher Order Optimal Iterative Learning Control.,"Based on a nonlifted iterative dynamic linearization formulation, a novel data-driven higher order optimal iterative learning control (DDHOILC) is proposed for a class of nonlinear repetitive discrete-time systems. By using the historical data, additional tracking errors and control inputs in previous iterations are used to enhance the online control performance. From the online data, additional control inputs of previous time instants within the current iteration are utilized to improve transient response. The data-driven property of the proposed method implies that no model information except for the I/O data is utilized. The computational complexity is reduced by avoiding matrix inverse operation in the proposed DDHOILC approach due to the nonlifted linear formulation of the original model. The asymptotic convergence is proved rigorously. Furthermore, the convergence property is analyzed and evaluated via three performance indexes. By elaborately selecting the higher order factors, the higher order learning control law outperforms the lower order one in terms of convergence performance. Simulation results verify the effectiveness of the proposed approach.",4
Local Regression and Global Information-Embedded Dimension Reduction.,"A large family of algorithms for unsupervised dimension reduction is based on both the local and global structures of the data. A fundamental step in these methods is to model the local geometrical structure of the data. However, the previous methods mainly ignore two facts in this step: 1) the dimensionality of the data is usually far larger than the number of local data, which is a typical ill-posed problem and 2) the data might be polluted by noise. These facts normally may lead to an inaccurate learned local structure and may degrade the final performance. In this paper, we propose a novel unsupervised dimension reduction method with the ability to address these problems effectively while also preserving the global information of the input data. Specifically, we first denoise the local data by preserving their principal components and we then apply a regularization term to the local modeling function to solve the illposed problem. Then, we use a linear regression model to capture the local geometrical structure, which is demonstrated to be insensitive to the parameters. Finally, we propose two criteria to simultaneously model both the local and the global information. Theoretical analyses for the relations between the proposed methods and some classical dimension-reduction methods are presented. The experimental results from various databases demonstrate the effectiveness of our methods.",4
An Adaptive Self-Stabilizing Algorithm for Minor Generalized Eigenvector Extraction and Its Convergence Analysis.,"Generalized eigendecomposition, which extracts the generalized eigenvector from a matrix pencil, is a powerful tool and has been widely used in many fields, such as data classification and blind source separation. First, to extract the minor generalized eigenvector (MGE), we propose a deterministic discrete-time (DDT) system. Unlike some existing systems, the proposed DDT system does not need to normalize the weight vector in each iteration, since the weight vectors in the proposed DDT system are self-stabilizing. Second, we propose an adaptive algorithm corresponding to the proposed DDT system. Moreover, we study the dynamic behavior and convergence properties of the proposed DDT system and prove that the weight vector must converge to the direction of the MGE of a matrix pencil under some mild conditions. Numerical simulations show that the proposed algorithm has a better performance in terms of convergence speed and estimation accuracy than some existing algorithms. Finally, we conduct two experiments on real data sets to demonstrate its practicability.",4
A Two-Layer Mixture Model of Gaussian Process Functional Regressions and Its MCMC EM Algorithm.,"The mixture of Gaussian processes (GPs) is capable of learning any general stochastic process based on a given set of (sample) curves for the regression and prediction problems. However, it is ineffective for curve clustering and prediction, when the sample curves are derived from different stochastic processes as independent sources linearly mixed together. In this paper, we propose a two-layer mixture model of GP functional regressions (GPFRs) to describe such a mixture of general stochastic processes or independent sources, especially for curve clustering and prediction. Specifically, in the lower layer, the mixture of GPFRs (MGPFRs) is developed for a cluster (or class) of curves within the input space. In the higher layer, the mixture of MGPFRs is further established to divide the curves into clusters according to its components in the output space. For the parameter estimation of the two-layer mixture of GPFRs, we develop a Monte Carlo EM algorithm based on a Monte Carlo Markov chain (MCMC) method, in short, the MCMC EM algorithm. We validate the hierarchical mixture of GPFRs and MCMC EM algorithm using synthetic and real-world data sets. Our results show that our new model outperforms the conventional mixture models in curve clustering and prediction.",4
Modeling of Agent Cognition in Extensive Games via Artificial Neural Networks.,"The decision-making process, which is regarded as cognitive and ubiquitous, has been exploited in diverse fields, such as psychology, economics, and artificial intelligence. This paper considers the problem of modeling agent cognition in a class of game-theoretic decision-making scenarios called extensive games. We present a novel framework in which artificial neural networks are incorporated to simulate agent cognition regarding the structure of the underlying game and the goodness of the game situations therein. An algorithmic procedure is investigated to describe the process for solving games with cognition, and then, a new equilibrium concept is proposed as a refinement of the classical one-subgame perfect equilibrium-by involving players' cognitive reasoning. Moreover, a series of results concerning the computational complexity, soundness, and completeness of the algorithm, as well as the existence of an equilibrium solution, is obtained. This framework, which is shown to be general enough to model the way in which AlphaGo plays Go, may offer a means for bridging the gap between theoretical models and practical problem-solving.",4
Multiview Spectral Clustering via Structured Low-Rank Matrix Factorization.,"Multiview data clustering attracts more attention than their single-view counterparts due to the fact that leveraging multiple independent and complementary information from multiview feature spaces outperforms the single one. Multiview spectral clustering aims at yielding the data partition agreement over their local manifold structures by seeking eigenvalue-eigenvector decompositions. Among all the methods, low-rank representation (LRR) is effective, by exploring the multiview consensus structures beyond the low rankness to boost the clustering performance. However, as we observed, such classical paradigm still suffers from the following stand-out limitations for multiview spectral clustering of overlooking the flexible local manifold structure, caused by aggressively enforcing the low-rank data correlation agreement among all views, and such a strategy, therefore, cannot achieve the satisfied between-views agreement; worse still, LRR is not intuitively flexible to capture the latent data clustering structures. In this paper, first, we present the structured LRR by factorizing into the latent low-dimensional data-cluster representations, which characterize the data clustering structure for each view. Upon such representation, second, the Laplacian regularizer is imposed to be capable of preserving the flexible local manifold structure for each view. Third, we present an iterative multiview agreement strategy by minimizing the divergence objective among all factorized latent data-cluster representations during each iteration of optimization process, where such latent representation from each view serves to regulate those from other views, and such an intuitive process iteratively coordinates all views to be agreeable. Fourth, we remark that such data-cluster representation can flexibly encode the data clustering structure from any view with an adaptive input cluster number. To this end, finally, a novel nonconvex objective function is proposed via the efficient alternating minimization strategy. The complexity analysis is also presented. The extensive experiments conducted against the real-world multiview data sets demonstrate the superiority over the state of the arts.",4
Sparse Simultaneous Recurrent Deep Learning for Robust Facial Expression Recognition.,"Facial expression recognition is a challenging task that involves detection and interpretation of complex and subtle changes in facial muscles. Recent advances in feed-forward deep neural networks (DNNs) have offered improved object recognition performance. Sparse feature learning in feed-forward DNN models offers further improvement in performance when compared to the earlier handcrafted techniques. However, the depth of the feed-forward DNNs and the computational complexity of the models increase proportional to the challenges posed by the facial expression recognition problem. The feed-forward DNN architectures do not exploit another important learning paradigm, known as recurrency, which is ubiquitous in the human visual system. Consequently, this paper proposes a novel biologically relevant sparse-deep simultaneous recurrent network (S-DSRN) for robust facial expression recognition. The feature sparsity is obtained by adopting dropout learning in the proposed DSRN as opposed to usual handcrafting of additional penalty terms for the sparse representation of data. Theoretical analysis of S-DSRN shows that the dropout learning offers desirable properties such as sparsity, and prevents the model from overfitting. Experimental results also suggest that the proposed method yields better performance accuracy, requires reduced number of parameters, and offers reduced computational complexity than that of the previously reported state-of-the-art feed-forward DNNs using two of the most widely used publicly available facial expression data sets. Furthermore, we show that by combining the proposed neural architecture with a state-of-the-art metric learning technique significantly improves the overall recognition performance. Finally, a graphical processing unit (GPU)-based implementation of S-DSRN is obtained for real-time applications.",4
Concept Drift Adaptation by Exploiting Historical Knowledge.,"Incremental learning with concept drift has often been tackled by ensemble methods, where models built in the past can be retrained to attain new models for the current data. Two design questions need to be addressed in developing ensemble methods for incremental learning with concept drift, i.e., which historical (i.e., previously trained) models should be preserved and how to utilize them. A novel ensemble learning method, namely, Diversity and Transfer-based Ensemble Learning (DTEL), is proposed in this paper. Given newly arrived data, DTEL uses each preserved historical model as an initial model and further trains it with the new data via transfer learning. Furthermore, DTEL preserves a diverse set of historical models, rather than a set of historical models that are merely accurate in terms of classification accuracy. Empirical studies on 15 synthetic data streams and 5 real-world data streams (all with concept drifts) demonstrate that DTEL can handle concept drift more effectively than 4 other state-of-the-art methods.",4
A Systematic Study of Online Class Imbalance Learning With Concept Drift.,"As an emerging research topic, online class imbalance learning often combines the challenges of both class imbalance and concept drift. It deals with data streams having very skewed class distributions, where concept drift may occur. It has recently received increased research attention; however, very little work addresses the combined problem where both class imbalance and concept drift coexist. As the first systematic study of handling concept drift in class-imbalanced data streams, this paper first provides a comprehensive review of current research progress in this field, including current research focuses and open challenges. Then, an in-depth experimental study is performed, with the goal of understanding how to best overcome concept drift in online learning with class imbalance.",4
Cross-Modal Metric Learning for AUC Optimization.,"Cross-modal metric learning (CML) deals with learning distance functions for cross-modal data matching. The existing methods mostly focus on minimizing a loss defined on sample pairs. However, the numbers of intraclass and interclass sample pairs can be highly imbalanced in many applications, and this can lead to deteriorating or unsatisfactory performances. The area under the receiver operating characteristic curve (AUC) is a more meaningful performance measure for the imbalanced distribution problem. To tackle the problem as well as to make samples from different modalities directly comparable, a CML method is presented by directly maximizing AUC. The method can be further extended to focus on optimizing partial AUC (pAUC), which is the AUC between two specific false positive rates (FPRs). This is particularly useful in certain applications where only the performances assessed within predefined false positive ranges are critical. The proposed method is formulated as a log-determinant regularized semidefinite optimization problem. For efficient optimization, a minibatch proximal point algorithm is developed. The algorithm is experimentally verified stable with the size of sampled pairs that form a minibatch at each iteration. Several data sets have been used in evaluation, including three cross-modal data sets on face recognition under various scenarios and a single modal data set, the Labeled Faces in the Wild. Results demonstrate the effectiveness of the proposed methods and marked improvements over the existing methods. Specifically, pAUC-optimized CML proves to be more competitive for performance measures such as Rank-1 and verification rate at FPR = 0.1%.",4
Global Bandits.,"Multiarmed bandits (MABs) model sequential decision-making problems, in which a learner sequentially chooses arms with unknown reward distributions in order to maximize its cumulative reward. Most of the prior works on MAB assume that the reward distributions of each arm are independent. But in a wide variety of decision problems-from drug dosage to dynamic pricing-the expected rewards of different arms are correlated, so that selecting one arm provides information about the expected rewards of other arms as well. We propose and analyze a class of models of such decision problems, which we call global bandits (GB). In the case in which rewards of all arms are deterministic functions of a single unknown parameter, we construct a greedy policy that achieves bounded regret, with a bound that depends on the single true parameter of the problem. Hence, this policy selects suboptimal arms only finitely many times with probability one. For this case, we also obtain a bound on regret that is independent of the true parameter; this bound is sublinear, with an exponent that depends on the informativeness of the arms. We also propose a variant of the greedy policy that achieves worst case and parameter-dependent regret. Finally, we perform experiments on dynamic pricing and show that the proposed algorithms achieve significant gains with respect to the well-known benchmarks.",4
Practical Time-Varying Formation Tracking for Second-Order Nonlinear Multiagent Systems With Multiple Leaders Using Adaptive Neural Networks.,"Practical time-varying formation tracking problems for second-order nonlinear multiagent systems with multiple leaders are investigated using adaptive neural networks (NNs), where the time-varying formation tracking error caused by time-varying external disturbances can be arbitrarily small. Different from the previous work, there exists a predefined time-varying formation formed by the states of the followers and the formation tracks the convex combination of the states of the leaders with unknown control inputs. Besides, the dynamics of each agent has both matched/mismatched heterogeneous nonlinearities and disturbances simultaneously. First, a practical time-varying formation tracking protocol using adaptive NNs is proposed, which is constructed using only local neighboring information. The proposed control protocol can process not only the matched/mismatched heterogeneous nonlinearities and disturbances, but also the unknown control inputs of the leaders. Second, an algorithm with three steps is introduced to design the practical formation tracking protocol, where the parameters of the protocol are determined, and the practical time-varying formation tracking feasibility condition is given. Third, the stability of the closed-loop multiagent system is proven by using the Lyapunov theory. Finally, a simulation example is showed to illustrate the effectiveness of the obtained theoretical results.",4
Contrast-Oriented Deep Neural Networks for Salient Object Detection.,"Deep convolutional neural networks (CNNs) have become a key element in the recent breakthrough of salient object detection. However, existing CNN-based methods are based on either patchwise (regionwise) training and inference or fully convolutional networks. Methods in the former category are generally time-consuming due to severe storage and computational redundancies among overlapping patches. To overcome this deficiency, methods in the second category attempt to directly map a raw input image to a predicted dense saliency map in a single network forward pass. Though being very efficient, it is arduous for these methods to detect salient objects of different scales or salient regions with weak semantic information. In this paper, we develop hybrid contrast-oriented deep neural networks to overcome the aforementioned limitations. Each of our deep networks is composed of two complementary components, including a fully convolutional stream for dense prediction and a segment-level spatial pooling stream for sparse saliency inference. We further propose an attentional module that learns weight maps for fusing the two saliency predictions from these two streams. A tailored alternate scheme is designed to train these deep networks by fine-tuning pretrained baseline models. Finally, a customized fully connected conditional random field model incorporating a salient contour feature embedding can be optionally applied as a postprocessing step to improve spatial coherence and contour positioning in the fused result from these two streams. Extensive experiments on six benchmark data sets demonstrate that our proposed model can significantly outperform the state of the art in terms of all popular evaluation metrics.",4
A Three-Layered Mutually Reinforced Model for Personalized Citation Recommendation.,"Fast-growing scientific papers pose the problem of rapidly and accurately finding a list of reference papers for a given manuscript. Citation recommendation is an indispensable technique to overcome this obstacle. In this paper, we propose a citation recommendation approach via mutual reinforcement on a three-layered graph, in which each paper, author or venue is represented as a vertex in the paper layer, author layer, and venue layer, respectively. For personalized recommendation, we initiate the random walk separately for each query researcher. However, this has a high computational complexity due to the large graph size. To solve this problem, we apply a three-layered interactive clustering approach to cluster related vertices in the graph. Personalized citation recommendations are then made on the subgraph, generated by the clusters associated with each researcher's needs. When evaluated on the ACL anthology network, DBLP, and CiteSeer ML data sets, the performance of our proposed model-based citation recommendation approach is comparable with that of other state-of-the-art citation recommendation approaches. The results also demonstrate that the personalized recommendation approach is more effective than the nonpersonalized recommendation approach.",4
Robust Regression Estimation Based on Low-Dimensional Recurrent Neural Networks.,"The robust Huber's M-estimator is widely used in signal and image processing, classification, and regression. From an optimization point of view, Huber's M-estimation problem is often formulated as a large-sized quadratic programming (QP) problem in view of its nonsmooth cost function. This paper presents a generalized regression estimator which minimizes a reduced-sized QP problem. The generalized regression estimator may be viewed as a significant generalization of several robust regression estimators including Huber's M-estimator. The performance of the generalized regression estimator is analyzed in terms of robustness and approximation accuracy. Furthermore, two low-dimensional recurrent neural networks (RNNs) are introduced for robust estimation. The two RNNs have low model complexity and enhanced computational efficiency. Finally, the experimental results of two examples and an application to image restoration are presented to substantiate superior performance of the proposed method over conventional algorithms for robust regression estimation in terms of approximation accuracy and convergence rate.",4
Unified Simultaneous Clustering and Feature Selection for Unlabeled and Labeled Data.,"This paper proposes a novel feature selection method, namely, unified simultaneous clustering feature selection (USCFS). A regularized regression with a new type of target matrix is formulated to select the most discriminative features among the original features from labeled or unlabeled data. The regression with -norm regularization allows the projection matrix to represent an effective selection of discriminative features. For unsupervised feature selection, the target matrix discovers label-like information not from the original data points but rather from projected data points, which are of a reduced dimensionality. Without the aid of an affinity graph-based local structure learning method, USCFS allows the target matrix to capture latent cluster centers via orthogonal basis clustering and to simultaneously select discriminative features guided by latent cluster centers. When class labels are available, the target matrix is also able to find latent class labels by regarding the ground-truth class labels as an approximate guide. Hence, supervised feature selection is realized using these latent class labels, which may differ from the ground-truth class labels. Experimental results demonstrate the effectiveness of the proposed method. Specifically, the proposed method outperforms the state-of-the-art methods on diverse real-world data sets for both the supervised and the unsupervised feature selection.",4
Rank-Constrained Spectral Clustering With Flexible Embedding.,"Spectral clustering (SC) has been proven to be effective in various applications. However, the learning scheme of SC is suboptimal in that it learns the cluster indicator from a fixed graph structure, which usually requires a rounding procedure to further partition the data. Also, the obtained cluster number cannot reflect the ground truth number of connected components in the graph. To alleviate these drawbacks, we propose a rank-constrained SC with flexible embedding framework. Specifically, an adaptive probabilistic neighborhood learning process is employed to recover the block-diagonal affinity matrix of an ideal graph. Meanwhile, a flexible embedding scheme is learned to unravel the intrinsic cluster structure in low-dimensional subspace, where the irrelevant information and noise in high-dimensional data have been effectively suppressed. The proposed method is superior to previous SC methods in that: 1) the block-diagonal affinity matrix learned simultaneously with the adaptive graph construction process, more explicitly induces the cluster membership without further discretization; 2) the number of clusters is guaranteed to converge to the ground truth via a rank constraint on the Laplacian matrix; and 3) the mismatch between the embedded feature and the projected feature allows more freedom for finding the proper cluster structure in the low-dimensional subspace as well as learning the corresponding projection matrix. Experimental results on both synthetic and real-world data sets demonstrate the promising performance of the proposed algorithm.",4
Dynamical and Static Multisynchronization of Coupled Multistable Neural Networks via Impulsive Control.,"This paper investigates the dynamical multisynchronization and static multisynchronization problem for delayed coupled multistable neural networks with fixed and switching topologies. To begin with, a class of activation functions as well as several sufficient conditions are introduced to ensure that every subnetwork has multiple equilibrium states. By constructing an appropriate Lyapunov function and by employing impulsive control theory and the average impulsive interval method, several sufficient conditions for multisynchronization in terms of linear matrix inequalities (LMIs) are obtained. Moreover, a unified impulsive controller is designed by means of the established LMIs. Finally, a numerical example is presented to demonstrate the effectiveness of the presented impulsive control strategy.",4
Transfer Hashing: From Shallow to Deep.,"One major assumption used in most existing hashing approaches is that the domain of interest (i.e., the target domain) could provide sufficient training data, either labeled or unlabeled. However, this assumption may be violated in practice. To address this so-called data sparsity issue in hashing, a new framework termed transfer hashing with privileged information (THPI) is proposed, which marriages hashing and transfer learning (TL). To show the efficacy of THPI, we propose three variants of the well-known iterative quantization (ITQ) as a showcase. The proposed methods, ITQ+, LapITQ+, and deep transfer hashing (DTH), solve the aforementioned data sparsity issue from different aspects. Specifically, ITQ+ is a shallow model, which makes ITQ achieve hashing in a TL manner. ITQ+ learns a new slack function from the source domain to approximate the quantization error on the target domain given by ITQ. To further improve the performance of ITQ+, LapITQ+ is proposed by embedding the geometric relationship of the source domain into the target domain. Moreover, DTH is proposed to show the generality of our framework by utilizing the powerful representative capacity of deep learning. To the best of our knowledge, this could be one of the first DTH works. Extensive experiments on several popular data sets demonstrate the effectiveness of our shallow and DTH approaches comparing with several state-of-the-art hashing approaches.",4
Consensus Problems Over Cooperation-Competition Random Switching Networks With Noisy Channels.,"In this paper, distributed iterative algorithms for consensus problems are considered for multiagent networks. Each agent randomly contacts with other agents at each instant and receives corrupted information due to the noisy channel from its neighborhood. Neighbors of each agent are cooperative or competitive, i.e., the elements in the adjacent weight matrix may be positive or negative. In such a framework, asymptotic consensus and mean square consensus problems are investigated, based on random graph theory and stochastic stability theory. The control gains have been designed such that cooperation-competition random multiagent networks can reach almost sure consensus and mean square consensus. Simulation examples are finally given to illustrate the effectiveness of the obtained results.",4
First-Spike-Based Visual Categorization Using Reward-Modulated STDP.,"Reinforcement learning (RL) has recently regained popularity with major achievements such as beating the European game of Go champion. Here, for the first time, we show that RL can be used efficiently to train a spiking neural network (SNN) to perform object recognition in natural images without using an external classifier. We used a feedforward convolutional SNN and a temporal coding scheme where the most strongly activated neurons fire first, while less activated ones fire later, or not at all. In the highest layers, each neuron was assigned to an object category, and it was assumed that the stimulus category was the category of the first neuron to fire. If this assumption was correct, the neuron was rewarded, i.e., spike-timing-dependent plasticity (STDP) was applied, which reinforced the neuron's selectivity. Otherwise, anti-STDP was applied, which encouraged the neuron to learn something else. As demonstrated on various image data sets (Caltech, ETH-80, and NORB), this reward-modulated STDP (R-STDP) approach has extracted particularly discriminative visual features, whereas classic unsupervised STDP extracts any feature that consistently repeats. As a result, R-STDP has outperformed STDP on these data sets. Furthermore, R-STDP is suitable for online learning and can adapt to drastic changes such as label permutations. Finally, it is worth mentioning that both feature extraction and classification were done with spikes, using at most one spike per neuron. Thus, the network is hardware friendly and energy efficient.",4
Postboosting Using Extended G-Mean for Online Sequential Multiclass Imbalance Learning.,"In this paper, a novel learning method called postboosting using extended G-mean (PBG) is proposed for online sequential multiclass imbalance learning (OS-MIL) in neural networks. PBG is effective due to three reasons. 1) Through postadjusting a classification boundary under extended G-mean, the challenging issue of imbalanced class distribution for sequentially arriving multiclass data can be effectively resolved. 2) A newly derived update rule for online sequential learning is proposed, which produces a high G-mean for current model and simultaneously possesses almost the same information of its previous models. 3) A dynamic adjustment mechanism provided by extended G-mean is valid to deal with the unresolved challenging dense-majority problem and two dynamic changing issues, namely, dynamic changing data scarcity (DCDS) and dynamic changing data diversity (DCDD). Compared to other OS-MIL methods, PBG is highly effective on resolving DCDS, while PBG is the only method to resolve dense-majority and DCDD. Furthermore, PBG can directly and effectively handle unscaled data stream. Experiments have been conducted for PBG and two popular OS-MIL methods for neural networks under massive binary and multiclass data sets. Through the analyses of experimental results, PBG is shown to outperform the other compared methods on all data sets in various aspects including the issues of data scarcity, dense-majority, DCDS, DCDD, and unscaled data.",4
Observability of Boolean Control Networks Using Parallel Extension and Set Reachability.,"This brief reviews various definitions of observability for Boolean control networks (BCNs) and proposes a new one: output-feedback observability. This new definition applies to all BCNs whose initial states can be identified from the history of output measurements. A technique called parallel extension is then proposed to facilitate observability analysis. Furthermore, a technique called state transition graph reconstruction is proposed for analyzing the set reachability of BCNs, based on which new criteria for observability, single-input sequence observability, and arbitrary-input observability, are obtained. Using the proposed techniques, this brief proves that the problem of output-feedback observability can be recast as that of stabilizing a logic dynamical system with output feedback. Then, a necessary and sufficient condition for static output feedback observability is proposed. The relationships between the different definitions of observability are discussed, and the main results are illustrated with examples.",4
Editorial Special Issue on Deep Reinforcement Learning and Adaptive Dynamic Programming.,"The sixteen papers in this special section focus on deep reinforcement learning and adaptive dynamic programming (deep RL/ADP). Deep RL is able to output control signal directly based on input images, which incorporates both the advantages of the perception of deep learning (DL) and the decision making of RL or adaptive dynamic programming (ADP). This mechanism makes the artificial intelligence much closer to human thinking modes. Deep RL/ADP has achieved remarkable success in terms of theory and applications since it was proposed. Successful applications cover video games, Go, robotics, smart driving, healthcare, and so on. However, it is still an open problem to perform the theoretical analysis on deep RL/ADP, e.g., the convergence, stability, and optimality analyses. The learning efficiency needs to be improved by proposing new algorithms or combined with other methods. More practical demonstrations are encouraged to be presented. Therefore, the aim of this special issue is to call for the most advanced research and state-of-the-art works in the field of deep RL/ADP.",4
A Unifying Objective Function of Independent Component Analysis for Ordering Sources by Non-Gaussianity.,"The independent component analysis (ICA) is a widely used method for solving blind separation problems. The ICA assumes that the sources are independent of each other and extracts them by maximizing their non-Gaussianity as the objective function. There are the two types of non-Gaussianity of the sources (the super-Gaussian type with the positive kurtosis and the sub-Gaussian one with the negative kurtosis). In this paper, we propose a new objective function unifying the two types of non-Gaussianity naturally, which is derived by applying the Gaussian approximation to the distribution of sources in the second-order polynomial feature space. The proposed objective function [called the adaptive ICA function (AIF)] is a simple form given as a summation of weighted fourth-order statistics, where the weights are adaptively estimated by the current kurtoses. The first practical advantage of the AIF is that it can extract the sources one by one in the descending order of the criterion of non-Gaussianity. It can solve the permutation ambiguity problem. The second and more important advantage is that it can estimate the number of non-Gaussian sources by the Akaike information criterion irrespective of the specific form of their distributions. In order to utilize the above-mentioned advantages of the AIF, we construct a new algorithm named the ordering ICA by extending the fast ICA. Experimental results verify that the ordering ICA can estimate the number of non-Gaussian sources correctly in both artificial and real data sets.",4
New Discrete-Time ZNN Models for Least-Squares Solution of Dynamic Linear Equation System With Time-Varying Rank-Deficient Coefficient.,"In this brief, a new one-step-ahead numerical differentiation rule called six-instant -cube finite difference (6I CFD) formula is proposed for the first-order derivative approximation with higher precision than existing finite difference formulas (i.e., Euler and Taylor types). Subsequently, by exploiting the proposed 6I CFD formula to discretize the continuous-time Zhang neural network model, two new-type discrete-time ZNN (DTZNN) models, namely, new-type DTZNNK and DTZNNU models, are designed and generalized to compute the least-squares solution of dynamic linear equation system with time-varying rank-deficient coefficient in real time, which is quite different from the existing ZNN-related studies on solving continuous-time and discrete-time (dynamic or static) linear equation systems in the context of full-rank coefficients. Specifically, the corresponding dynamic normal equation system, of which the solution exactly corresponds to the least-squares solution of dynamic linear equation system, is elegantly introduced to solve such a rank-deficient least-squares problem efficiently and accurately. Theoretical analyses show that the maximal steady-state residual errors of the two new-type DTZNN models have an pattern, where denotes the sampling gap. Comparative numerical experimental results further substantiate the superior computational performance of the new-type DTZNN models to solve the rank-deficient least-squares problem of dynamic linear equation systems.",4
A Block EM Algorithm for Multivariate Skew Normal and Skew -Mixture Models.,"Finite mixtures of skew distributions provide a flexible tool for modeling heterogeneous data with asymmetric distributional features. However, parameter estimation via the Expectation-Maximization (EM) algorithm can become very time consuming due to the complicated expressions involved in the E-step that are numerically expensive to evaluate. While parallelizing the EM algorithm can offer considerable speedup in time performance, current implementations focus almost exclusively on distributed platforms. In this paper, we consider instead the most typical operating environment for users of mixture models-a standalone multicore machine and the R programming environment. We develop a block implementation of the EM algorithm that facilitates the calculations on the E- and M-steps to be spread across a number of threads. We focus on the fitting of finite mixtures of multivariate skew normal and skew distributions, and show that both the E- and M-steps in the EM algorithm can be modified to allow the data to be split into blocks. Our approach is easy to implement and provides immediate benefits to users of multicore machines. Experiments were conducted on two real data sets to demonstrate the effectiveness of the proposed approach.",4
Beyond Bilinear: Generalized Multimodal Factorized High-Order Pooling for Visual Question Answering.,"Visual question answering (VQA) is challenging, because it requires a simultaneous understanding of both visual content of images and textual content of questions. To support the VQA task, we need to find good solutions for the following three issues: 1) fine-grained feature representations for both the image and the question; 2) multimodal feature fusion that is able to capture the complex interactions between multimodal features; and 3) automatic answer prediction that is able to consider the complex correlations between multiple diverse answers for the same question. For fine-grained image and question representations, a ""coattention"" mechanism is developed using a deep neural network (DNN) architecture to jointly learn the attentions for both the image and the question, which can allow us to reduce the irrelevant features effectively and obtain more discriminative features for image and question representations. For multimodal feature fusion, a generalized multimodal factorized high-order pooling approach (MFH) is developed to achieve more effective fusion of multimodal features by exploiting their correlations sufficiently, which can further result in superior VQA performance as compared with the state-of-the-art approaches. For answer prediction, the Kullback-Leibler divergence is used as the loss function to achieve precise characterization of the complex correlations between multiple diverse answers with the same or similar meaning, which can allow us to achieve faster convergence rate and obtain slightly better accuracy on answer prediction. A DNN architecture is designed to integrate all these aforementioned modules into a unified model for achieving superior VQA performance. With an ensemble of our MFH models, we achieve the state-of-the-art performance on the large-scale VQA data sets and win the runner-up in VQA Challenge 2017.",4
Learning and Guaranteed Cost Control With Event-Based Adaptive Critic Implementation.,"This paper focuses on the event-triggered guaranteed cost control design of nonlinear systems via a self-learning technique. In brief, an event-based guaranteed cost control strategy of nonlinear systems subjects to matched uncertainties is developed, thereby balancing the performance of guaranteed cost and the actuality of limited communication resource. The original control design is transformed into an optimal control problem with an event-based mechanism, where the relationship of guaranteed cost performance compared to the time-based formulation is discussed. A critic neural network is constructed for implementing the event-based optimal control design with stability guarantee. Simulation experiments are carried out to verify the theoretical results in detail.",4
A Weightedly Uniform Detectability for Sensor Networks.,"In this brief, we study the detectability issues in the context of distributed state estimation problems for a class of locally undetectable sensor networks. First, we introduce a novel detectability condition, i.e., weightedly uniform detectability (WUD), which is a sufficient condition to prove that the error covariances of the consensus filtering are uniformly bounded even though the local sensor nodes are undetectable. Different from the existing detectability (or observability) conditions, our condition includes the interacting weights which could further optimize the lower detectability Gramian bound. Hence, a new weights selection method is derived in term of the criterion of WUD. This new rule of selecting weights provides a new framework for distributed state estimation. The advantages of this approach lead to a better performance in estimation without extra computational burden to the filtering process. Finally, an example shows the effectiveness of the proposed method.",4
Simultaneous Spectral Data Embedding and Clustering.,"Spectral clustering is often carried out by combining spectral data embedding and -means clustering. However, the aims, dimensionality reduction and clustering, are usually not performed jointly. In this brief, we propose a novel approach to finding an optimal spectral embedding for identifying a partition of the set of objects; it iteratively alternates spectral embedding and clustering. In doing so, we show that our model can learn a low-dimensional representation more suited to clustering. Compared with classical spectral clustering methods, the proposed algorithm is not costly and outperforms not only these methods but also other nonnegative matrix factorization variants.",4
Low-Complexity Approximate Convolutional Neural Networks.,"In this paper, we present an approach for minimizing the computational complexity of the trained convolutional neural networks (ConvNets). The idea is to approximate all elements of a given ConvNet and replace the original convolutional filters and parameters (pooling and bias coefficients; and activation function) with an efficient approximations capable of extreme reductions in computational complexity. Low-complexity convolution filters are obtained through a binary (zero and one) linear programming scheme based on the Frobenius norm over sets of dyadic rationals. The resulting matrices allow for multiplication-free computations requiring only addition and bit-shifting operations. Such low-complexity structures pave the way for low power, efficient hardware designs. We applied our approach on three use cases of different complexities: 1) a ""light"" but efficient ConvNet for face detection (with around 1000 parameters); 2) another one for hand-written digit classification (with more than 180 000 parameters); and 3) a significantly larger ConvNet: AlexNet with million matrices. We evaluated the overall performance on the respective tasks for different levels of approximations. In all considered applications, very low-complexity approximations have been derived maintaining an almost equal classification performance.",4
Neural-Learning-Based Control for a Constrained Robotic Manipulator With Flexible Joints.,"Nowadays, the control technology of the robotic manipulator with flexible joints (RMFJ) is not mature enough. The flexible-joint manipulator dynamic system possesses many uncertainties, which brings a great challenge to the controller design. This paper is motivated by this problem. In order to deal with this and enhance the system robustness, the full-state feedback neural network (NN) control is proposed. Moreover, output constraints of the RMFJ are achieved, which improve the security of the robot. Through the Lyapunov stability analysis, we identify that the proposed controller can guarantee not only the stability of flexible-joint manipulator system but also the boundedness of system state variables by choosing appropriate control gains. Then, we make some necessary simulation experiments to verify the rationality of our controllers. Finally, a series of control experiments are conducted on the Baxter. By comparing with the proportional-derivative control and the NN control with the rigid manipulator model, the feasibility and the effectiveness of NN control based on flexible-joint manipulator model are verified.",4
Output Reachable Set Estimation and Verification for Multilayer Neural Networks.,"In this brief, the output reachable estimation and safety verification problems for multilayer perceptron (MLP) neural networks are addressed. First, a conception called maximum sensitivity is introduced, and for a class of MLPs whose activation functions are monotonic functions, the maximum sensitivity can be computed via solving convex optimization problems. Then, using a simulation-based method, the output reachable set estimation problem for neural networks is formulated into a chain of optimization problems. Finally, an automated safety verification is developed based on the output reachable set estimation result. An application to the safety verification for a robotic arm model with two joints is presented to show the effectiveness of the proposed approaches.",4
Latent Topic Text Representation Learning on Statistical Manifolds.,"The explosive growth of text data requires effective methods to represent and classify these texts. Many text learning methods have been proposed, like statistics-based methods, semantic similarity methods, and deep learning methods. The statistics-based methods focus on comparing the substructure of text, which ignores the semantic similarity between different words. Semantic similarity methods learn a text representation by training word embedding and representing text as the average vector of all words. However, these methods cannot capture the topic diversity of words and texts clearly. Recently, deep learning methods such as CNNs and RNNs have been studied. However, the vanishing gradient problem and time complexity for parameter selection limit their applications. In this paper, we propose a novel and efficient text learning framework, named Latent Topic Text Representation Learning. Our method aims to provide an effective text representation and text measurement with latent topics. With the assumption that words on the same topic follow a Gaussian distribution, texts are represented as a mixture of topics, i.e., a Gaussian mixture model. Our framework is able to effectively measure text distance to perform text categorization tasks by leveraging statistical manifolds. Experimental results on text representation and classification, and topic coherence demonstrate the effectiveness of the proposed method.",4
Ristretto: A Framework for Empirical Study of Resource-Efficient Inference in Convolutional Neural Networks.,"Convolutional neural networks (CNNs) have led to remarkable progress in a number of key pattern recognition tasks, such as visual scene understanding and speech recognition, that potentially enable numerous applications. Consequently, there is a significant need to deploy trained CNNs to resource-constrained embedded systems. Inference using pretrained modern deep CNNs, however, requires significant system resources, including computation, energy, and memory space. To enable efficient implementation of trained CNNs, a viable approach is to approximate the network with an implementation-friendly model with only negligible degradation in classification accuracy. We present Ristretto, a CNN approximation framework that enables empirical investigation of the tradeoff between various number representation and word width choices and the classification accuracy of the model. Specifically, Ristretto analyzes a given CNN with respect to numerical range required to represent weights, activations, and intermediate results of convolutional and fully connected layers, and subsequently, it simulates the impact of reduced word width or lower precision arithmetic operators on the model accuracy. Moreover, Ristretto can fine-tune a quantized network to further improve its classification accuracy under a given number representation and word width configuration. Given a maximum classification accuracy degradation tolerance of 1%, we use Ristretto to demonstrate that three ImageNet networks can be condensed to use 8-bit dynamic fixed point for network weights and activations. Ristretto is available as a popular open-source software project and has already been viewed over 1,000 times on Github as of the submission of this brief.",4
Synchronization of Nonlinearly and Stochastically Coupled Markovian Switching Networks via Event-Triggered Sampling.,"This paper studies the exponential synchronization problem for a new array of nonlinearly and stochastically coupled networks via events-triggered sampling (ETS) by self-adaptive learning. The networks include the following features: 1) a Bernoulli stochastic variable is introduced to describe the random structural coupling; 2) a stochastic variable with positive mean is used to model the coupling strength; and 3) a continuous time homogeneous Markov chain is employed to characterize the dynamical switching of the coupling structure and pinned node sets. The proposed network model is capable to capture various stochastic effect of an external environment during the network operations. In order to reduce networks' workload, different ETS strategies for network self-adaptive learning are proposed under continuous and discrete monitoring, respectively. Based on these ETS approaches, several sufficient conditions for synchronization are derived by employing stochastic Lyapunov-Krasovskii functions, the properties of stochastic processes, and some linear matrix inequalities. Numerical simulations are provided to demonstrate the effectiveness of the theoretical results and the superiority of the proposed ETS approach.",4
Adaptive Critic Design for Pure-Feedback Discrete-Time MIMO Systems Preceded by Unknown Backlashlike Hysteresis.,"This paper concentrates on the adaptive critic design (ACD) issue for a class of uncertain multi-input multioutput (MIMO) nonlinear discrete-time systems preceded by unknown backlashlike hysteresis. The considered systems are in a block-triangular pure-feedback form, in which there exist nonaffine functions and couplings between states and inputs. This makes that the ACD-based optimal control becomes very difficult and complicated. To this end, the mean value theorem is employed to transform the original systems into input-output models. Based on the reinforcement learning algorithm, the optimal control strategy is established with an actor-critic structure. Not only the stability of the systems is ensured but also the performance index is minimized. In contrast to the previous results, the main contributions are: 1) it is the first time to build an ACD framework for such MIMO systems with unknown hysteresis and 2) an adaptive auxiliary signal is developed to compensate the influence of hysteresis. In the end, a numerical study is provided to demonstrate the effectiveness of the present method.",4
Adaptive Neural Control of Pure-Feedback Nonlinear Systems With Event-Triggered Communications.,"This paper is concerned with the adaptive event-triggered control problem for a class of pure-feedback nonlinear systems. Unlike the existing results where the control execution is periodic, the new proposed scheme updates the controller and the neural network weights only when desired control specifications cannot be guaranteed. Clearly, this can largely reduce the amount of transmission data. Besides, since the event-trigger error is discontinuous because of the event-triggering mechanism, the stability analysis in the classical sense may not be guaranteed. To solve this problem, we formulate the event-triggered network control systems as a nonlinear impulsive dynamical system, and a novel Lyapunov theorem is used to show the stability properties of the closed-loop systems. Finally, two simulation examples are given to illustrate the effectiveness of the theoretical results.",4
Neural Network-Based Model-Free Adaptive Near-Optimal Tracking Control for a Class of Nonlinear Systems.,"In this paper, the receding horizon near-optimal tracking control problem about a class of continuous-time nonlinear systems with fully unknown dynamics is considered. The main challenges of this problem lie in two aspects: 1) most existing systems only restrict their considerations to the state feedback part while the input channel parameters are assumed to be known. This paper considers fully unknown system dynamics in both the state feedback channel and the input channel and 2) the optimal control of nonlinear systems requires the solution of nonlinear Hamilton-Jacobi-Bellman equations. Up to date, there are no systematic approaches in the existing literature to solve it accurately. A novel model-free adaptive near-optimal control method is proposed to solve this problem via utilizing the Taylor expansion-based problem relaxation, the universal approximation property of sigmoid neural networks, and the concept of sliding mode control. By making approximation for the performance index, it is first relaxed to a quadratic program, and then, a linear algebraic equation with unknown terms. An auxiliary system is designed to reconstruct the input-to-output property of the control systems with unknown dynamics, so as to tackle the difficulty caused by the unknown terms. Then, by considering the property of the sliding-mode surface, an explicit adaptive near-optimal control law is derived from the linear algebraic equation. Theoretical analysis shows that the auxiliary system is convergent, the resultant closed-loop system is asymptotically stable, and the performance index asymptomatically converges to optimal. An illustrative example and experimental results are presented, which substantiate the efficacy of the proposed method and verify the theoretical results.",4
Radial Basis Functions With Adaptive Input and Composite Trend Representation for Portfolio Selection.,"We propose a set of novel radial basis functions with adaptive input and composite trend representation (AICTR) for portfolio selection (PS). Trend representation of asset price is one of the main information to be exploited in PS. However, most state-of-the-art trend representation-based systems exploit only one kind of trend information and lack effective mechanisms to construct a composite trend representation. The proposed system exploits a set of RBFs with multiple trend representations, which improves the effectiveness and robustness in price prediction. Moreover, the input of the RBFs automatically switches to the best trend representation according to the recent investing performance of different price predictions. We also propose a novel objective to combine these RBFs and select the portfolio. Extensive experiments on six benchmark data sets (including a new challenging data set that we propose) from different real-world stock markets indicate that the proposed RBFs effectively combine different trend representations and AICTR achieves state-of-the-art investing performance and risk control. Besides, AICTR withstands the reasonable transaction costs and runs fast; hence, it is applicable to real-world financial environments.",4
A New Correntropy-Based Conjugate Gradient Backpropagation Algorithm for Improving Training in Neural Networks.,"Mean square error (MSE) is the most prominent criterion in training neural networks and has been employed in numerous learning problems. In this paper, we suggest a group of novel robust information theoretic backpropagation (BP) methods, as correntropy-based conjugate gradient BP (CCG-BP). CCG-BP algorithms converge faster than the common correntropy-based BP algorithms and have better performance than the common CG-BP algorithms based on MSE, especially in nonGaussian environments and in cases with impulsive noise or heavy-tailed distributions noise. In addition, a convergence analysis of this new type of method is particularly considered. Numerical results for several samples of function approximation, synthetic function estimation, and chaotic time series prediction illustrate that our new BP method is more robust than the MSE-based method in the sense of impulsive noise, especially when SNR is low.",4
Learning-Based Predictive Control for Discrete-Time Nonlinear Systems With Stochastic Disturbances.,"In this paper, a learning-based predictive control (LPC) scheme is proposed for adaptive optimal control of discrete-time nonlinear systems under stochastic disturbances. The proposed LPC scheme is different from conventional model predictive control (MPC), which uses open-loop optimization or simplified closed-loop optimal control techniques in each horizon. In LPC, the control task in each horizon is formulated as a closed-loop nonlinear optimal control problem and a finite-horizon iterative reinforcement learning (RL) algorithm is developed to obtain the closed-loop optimal/suboptimal solutions. Therefore, in LPC, RL and adaptive dynamic programming (ADP) are used as a new class of closed-loop learning-based optimization techniques for nonlinear predictive control with stochastic disturbances. Moreover, LPC also decomposes the infinite-horizon optimal control problem in previous RL and ADP methods into a series of finite horizon problems, so that the computational costs are reduced and the learning efficiency can be improved. Convergence of the finite-horizon iterative RL algorithm in each prediction horizon and the Lyapunov stability of the closed-loop control system are proved. Moreover, by using successive policy updates between adjoint time horizons, LPC also has lower computational costs than conventional MPC which has independent optimization procedures between two different prediction horizons. Simulation results illustrate that compared with conventional nonlinear MPC as well as ADP, the proposed LPC scheme can obtain a better performance both in terms of policy optimality and computational efficiency.",4
Optimal Synchronization Control of Multiagent Systems With Input Saturation via Off-Policy Reinforcement Learning.,"In this paper, we aim to investigate the optimal synchronization problem for a group of generic linear systems with input saturation. To seek the optimal controller, Hamilton-Jacobi-Bellman (HJB) equations involving nonquadratic input energy terms in coupled forms are established. The solutions to these coupled HJB equations are further proven to be optimal and the induced controllers constitute interactive Nash equilibrium. Due to the difficulty to analytically solve HJB equations, especially in coupled forms, and the possible lack of model information of the systems, we apply the data-based off-policy reinforcement learning algorithm to learn the optimal control policies. A byproduct of this off-policy algorithm is shown that it is insensitive to probing noise that is exerted to the system to maintain persistence of excitation condition. In order to implement this off-policy algorithm, we employ actor and critic neural networks to approximate the controllers and the cost functions. Furthermore, the estimated control policies obtained by this presented implementation are proven to converge to the optimal ones under certain conditions. Finally, an illustrative example is provided to verify the effectiveness of the proposed algorithm.",4
Multiple-Model Adaptive Estimation for 3-D and 4-D Signals: A Widely Linear Quaternion Approach.,"Quaternion state estimation techniques have been used in various applications, yet they are only suitable for dynamical systems represented by a single known model. In order to deal with model uncertainty, this paper proposes a class of widely linear quaternion multiple-model adaptive estimation (WL-QMMAE) algorithms based on widely linear quaternion Kalman filters and Bayesian inference. The augmented second-order quaternion statistics is employed to capture complete second-order statistical information in improper quaternion signals. Within the WL-QMMAE framework, a widely linear quaternion interacting multiple-model algorithm is proposed to track time-variant model uncertainty, while a widely linear quaternion static multiple-model algorithm is proposed for time-invariant model uncertainty. A performance analysis of the proposed algorithms shows that, as expected, the WL-QMMAE reduces to semiwidely linear QMMAE for [Formula: see text]-improper signals and further reduces to strictly linear QMMAE for proper signals. Simulation results indicate that for improper signals, the proposed WL-QMMAE algorithms exhibit an enhanced performance over their strictly linear counterparts. The effectiveness of the proposed recursive performance analysis algorithm is also validated.",4
Design and Adaptive Control for an Upper Limb Robotic Exoskeleton in Presence of Input Saturation.,"This paper addresses the control design for an upper limb exoskeleton in the presence of input saturation. An adaptive controller employing the neural network technology is proposed to approximate the uncertain robotic dynamics. Also, an auxiliary system is designed to deal with the effect of input saturation. Furthermore, we develop both the state feedback and the output feedback control strategies, which effectively estimates the uncertainties online from the measured feedback errors, instead of the model-based control. In addition to the proposed control, a disturbance observer is designed to reject the unknown disturbance online for achieving the trajectory tracking. The method requires a minimal amount of a priori knowledge of system dynamics. Subsequently, the principle of Lyapunov synthesis ensures the stability of the closed-loop system. Finally, the experimental studies are carried out on this robotic exoskeleton.",4
SyMIL: MinMax Latent SVM for Weakly Labeled Data.,"Designing powerful models able to handle weakly labeled data are a crucial problem in machine learning. In this paper, we propose a new multiple instance learning (MIL) framework. Examples are represented as bags of instances, but we depart from standard MIL assumptions by introducing a symmetric strategy (SyMIL) that seeks discriminative instances in positive and negative bags. The idea is to use the instance the most distant from the hyper-plan to classify the bag. We provide a theoretical analysis featuring the generalization properties of our model. We derive a large margin formulation of our problem, which is cast as a difference of convex functions, and optimized using concave-convex procedure. We provide a primal version optimizing with stochastic subgradient descent and a dual version optimizing with one-slack cutting-plane. Successful experimental results are reported on standard MIL and weakly supervised object detection data sets: SyMIL significantly outperforms competitive methods (mi/MI/Latent-SVM), and gives very competitive performance compared to state-of-the-art works. We also analyze the selected instances of symmetric and asymmetric approaches on weakly supervised object detection and text classification tasks. Finally, we show complementarity of SyMIL with recent works on learning with label proportions on standard MIL data sets.",4
Neural-Dynamic Optimization-Based Model Predictive Control for Tracking and Formation of Nonholonomic Multirobot Systems.,"In this paper, a neural-dynamic optimization-based nonlinear model predictive control (NMPC) is developed for the multiple nonholonomic mobile robots formation. First, a model-based monocular vision method is developed to obtain the location information of the leader. Then, a separation-bearing-orientation scheme (SBOS) control strategy is proposed. During the formation motion, the leader robot is controlled to track the desired trajectory and the desired leader-follower relationship can be maintained through the SBOS method. Finally, the model predictive control (MPC) is utilized to maintain the desired leader-follower relationship. To solve the MPC generated constrained quadratic programming problem, the neural-dynamic optimization approach is used to search for the global optimal solution. Compared to other existing formation control approaches, the proposed solution is that the NMPC scheme exploit prime-dual neural network for online optimization. Finally, by using several actual mobile robots, the effectiveness of the proposed approach has been verified through the experimental studies.",4
Adaptive Neural Tracking Control of Switched Stochastic Pure-Feedback Nonlinear Systems With Unknown Bouc-Wen Hysteresis Input.,"This paper aims to analyze the problem of adaptive neural network (NN) tracking control for a class of switched stochastic nonlinear pure-feedback systems with unknown direction hysteresis. In the light of recent studies on the hysteresis phenomenon in the field of nonlinear switched systems, this paper focuses on Bouc-Wen hysteresis model with unknown parameters and direction conditions. To simplify the control design, the following procedure is applied. Prior to tackling the unknown direction hysteresis problem based on the Nussbaum function and the backstepping techniques, the pure-feedback structure difficulty is governed by the mean value theorem. Furthermore, an optimized adaptation method is utilized to cope with computational burden. Universal approximation capability of radial basis function NNs and Lyapunov function method is synthesized to develop an adaptive NN tracking control scheme. It is demonstrated that under arbitrary deterministic switching, the presented controller can guarantee that all signals in the closed-loop system are semiglobally uniformly ultimately bounded in probability and the tracking error converges to a neighborhood of the origin. Finally, two simulation examples are given to illustrate the advantages of the proposed control design approach.",4
Classification and Recall With Binary Hyperdimensional Computing: Tradeoffs in Choice of Density and Mapping Characteristics.,"Hyperdimensional (HD) computing is a promising paradigm for future intelligent electronic appliances operating at low power. This paper discusses tradeoffs of selecting parameters of binary HD representations when applied to pattern recognition tasks. Particular design choices include density of representations and strategies for mapping data from the original representation. It is demonstrated that for the considered pattern recognition tasks (using synthetic and real-world data) both sparse and dense representations behave nearly identically. This paper also discusses implementation peculiarities which may favor one type of representations over the other. Finally, the capacity of representations of various densities is discussed.",4
Sensitive Finite-State Computations Using a Distributed Network With a Noisy Network Attractor.,"We exhibit a class of smooth continuous-state neural-inspired networks composed of simple nonlinear elements that can be made to function as a finite-state computational machine. We give an explicit construction of arbitrary finite-state virtual machines in the spatiotemporal dynamics of the network. The dynamics of the functional network can be completely characterized as a ""noisy network attractor"" in phase space operating in either an ""excitable"" or a ""free-running"" regime, respectively, corresponding to excitable or heteroclinic connections between states. The regime depends on the sign of an ""excitability parameter."" Viewing the network as a nonlinear stochastic differential equation where a deterministic (signal) and/or a stochastic (noise) input is applied to any element, we explore the influence of the signal-to-noise ratio on the error rate of the computations. The free-running regime is extremely sensitive to inputs: arbitrarily small amplitude perturbations can be used to perform computations with the system as long as the input dominates the noise. We find a counter-intuitive regime where increasing noise amplitude can lead to more, rather than less, accurate computation. We suggest that noisy network attractors will be useful for understanding neural networks that reliably and sensitively perform finite-state computations in a noisy environment.",4
Image-Text Surgery: Efficient Concept Learning in Image Captioning by Generating Pseudopairs.,"Image captioning aims to generate natural language sentences to describe the salient parts of a given image. Although neural networks have recently achieved promising results, a key problem is that they can only describe concepts seen in the training image-sentence pairs. Efficient learning of novel concepts has thus been a topic of recent interest to alleviate the expensive manpower of labeling data. In this paper, we propose a novel method, Image-Text Surgery, to synthesize pseudoimage-sentence pairs. The pseudopairs are generated under the guidance of a knowledge base, with syntax from a seed data set (i.e., MSCOCO) and visual information from an existing large-scale image base (i.e., ImageNet). Via pseudodata, the captioning model learns novel concepts without any corresponding human-labeled pairs. We further introduce adaptive visual replacement, which adaptively filters unnecessary visual features in pseudodata with an attention mechanism. We evaluate our approach on a held-out subset of the MSCOCO data set. The experimental results demonstrate that the proposed approach provides significant performance improvements over state-of-the-art methods in terms of F1 score and sentence quality. An ablation study and the qualitative results further validate the effectiveness of our approach.",4
Learning to Map Social Network Users by Unified Manifold Alignment on Hypergraph.,"Nowadays, a lot of people possess accounts on multiple online social networks, e.g., Facebook and Twitter. These networks are overlapped, but the correspondences between their users are not explicitly given. Mapping common users across these social networks will be beneficial for applications such as cross-network recommendation. In recent years, a lot of mapping algorithms have been proposed which exploited social and/or profile relations between users from different networks. However, there is still a lack of unified mapping framework which can well exploit high-order relational information in both social structures and profiles. In this paper, we propose a unified hypergraph learning framework named unified manifold alignment on hypergraph (UMAH) for this task. UMAH models social structures and user profile relations in a unified hypergraph where the relative weights of profile hyperedges are determined automatically. Given a set of training user correspondences, a common subspace is learned by preserving the hypergraph structure as well as the correspondence relations of labeled users. UMAH intrinsically performs semisupervised manifold alignment with profile information for calibration. For a target user in one network, UMAH ranks all the users in the other network by their probabilities of being the corresponding user (measured by similarity in the subspace). In experiments, we evaluate UMAH on three real world data sets and compare it to state-of-art baseline methods. Experimental results have demonstrated the effectiveness of UMAH in mapping users across networks.",4
A Locally Weighted Project Regression Approach-Aided Nonlinear Constrained Tracking Control.,"An intelligent data-driven predictive control strategy is proposed in this paper. The predictive controller is designed by combining predictive control and local weighted projection regression. The presented control strategy needs less prior knowledge and has fewer parameters that are hard to determine compared to other data-driven predictive controller, e.g., the one in dynamic partial least square (PLS) framework. Furthermore, the proposed predictive controller performs better in the control of nonlinear processes and is able to update its parameters based on the online data. The predictive model validity and intelligence of the control strategy are guaranteed by the online updating strategy to a certain degree. The control performance of the proposed predictive controller against the model predictive control (MPC) in dynamic PLS framework is illustrated through the simulation of a typical numerical example and the benchmark of a continuous stirred tank heater system. It can be observed from the simulation that the proposed MPC strategy has higher prediction precision and stronger ability in coping with nonlinear dynamic processes which are quite common in practical applications, for instance, the industrial process.",4
Actor-Critic Learning Control Based on -Regularized Temporal-Difference Prediction With Gradient Correction.,"Actor-critic based on the policy gradient (PG-based AC) methods have been widely studied to solve learning control problems. In order to increase the data efficiency of learning prediction in the critic of PG-based AC, studies on how to use recursive least-squares temporal difference (RLS-TD) algorithms for policy evaluation have been conducted in recent years. In such contexts, the critic RLS-TD evaluates an unknown mixed policy generated by a series of different actors, but not one fixed policy generated by the current actor. Therefore, this AC framework with RLS-TD critic cannot be proved to converge to the optimal fixed point of learning problem. To address the above problem, this paper proposes a new AC framework named critic-iteration PG (CIPG), which learns the state-value function of current policy in an on-policy way and performs gradient ascent in the direction of improving discounted total reward. During each iteration, CIPG keeps the policy parameters fixed and evaluates the resulting fixed policy by -regularized RLS-TD critic. Our convergence analysis extends previous convergence analysis of PG with function approximation to the case of RLS-TD critic. The simulation results demonstrate that the -regularization term in the critic of CIPG is undamped during the learning process, and CIPG has better learning efficiency and faster convergence rate than conventional AC learning control methods.",4
Decentralized Global Optimization Based on a Growth Transform Dynamical System Model.,"Conservation principles, such as conservation of charge, energy, or mass, provide a natural way to couple and constrain spatially separated variables. In this paper, we propose a dynamical system model that exploits these constraints for solving nonconvex and discrete global optimization problems. Unlike the traditional simulated annealing or quantum annealing-based global optimization techniques, the proposed method optimizes a target objective function by continuously evolving a driver functional over a conservation manifold, using a generalized variant of growth transformations. As a result, the driver functional asymptotically converges toward a Dirac-delta function that is centered at the global optimum of the target objective function. In this paper, we provide an outline of the proof of convergence for the dynamical system model and investigate different properties of the model using a benchmark nonlinear optimization problem. Also, we demonstrate how a discrete variant of the proposed dynamical system can be used for implementing decentralized optimization algorithms, where an ensemble of spatially separated entities (for example, biological cells or simple computational units) can collectively implement specific functions, such as winner-take-all and ranking, by exchanging signals only with its immediate substrate or environment. The proposed dynamical system model could potentially be used to implement continuous-time optimizers, annealers, and neural networks.",4
Deep Cascade Learning.,"In this paper, we propose a novel approach for efficient training of deep neural networks in a bottom-up fashion using a layered structure. Our algorithm, which we refer to as deep cascade learning, is motivated by the cascade correlation approach of Fahlman and Lebiere, who introduced it in the context of perceptrons. We demonstrate our algorithm on networks of convolutional layers, though its applicability is more general. Such training of deep networks in a cascade directly circumvents the well-known vanishing gradient problem by ensuring that the output is always adjacent to the layer being trained. We present empirical evaluations comparing our deep cascade training with standard end-end training using back propagation of two convolutional neural network architectures on benchmark image classification tasks (CIFAR-10 and CIFAR-100). We then investigate the features learned by the approach and find that better, domain-specific, representations are learned in early layers when compared to what is learned in end-end training. This is partially attributable to the vanishing gradient problem that inhibits early layer filters to change significantly from their initial settings. While both networks perform similarly overall, recognition accuracy increases progressively with each added layer, with discriminative features learned in every stage of the network, whereas in end-end training, no such systematic feature representation was observed. We also show that such cascade training has significant computational and memory advantages over end-end training, and can be used as a pretraining algorithm to obtain a better performance.",4
Complex Gaussian Processes for Regression.,"In this paper, we propose a novel Bayesian solution for nonlinear regression in complex fields. Previous solutions for kernels methods usually assume a complexification approach, where the real-valued kernel is replaced by a complex-valued one. This approach is limited. Based on the results in complex-valued linear theory and Gaussian random processes, we show that a pseudo-kernel must be included. This is the starting point to develop the new complex-valued formulation for Gaussian process for regression (CGPR). We face the design of the covariance and pseudo-covariance based on a convolution approach and for several scenarios. Just in the particular case where the outputs are proper, the pseudo-kernel cancels. Also, the hyperparameters of the covariance can be learned maximizing the marginal likelihood using Wirtinger's calculus and patterned complex-valued matrix derivatives. In the experiments included, we show how CGPR successfully solves systems where the real and imaginary parts are correlated. Besides, we successfully solve the nonlinear channel equalization problem by developing a recursive solution with basis removal. We report remarkable improvements compared to previous solutions: a 2-4-dB reduction of the mean squared error with just a quarter of the training samples used by previous approaches.",4
Optimizing Kernel Machines Using Deep Learning.,"Building highly nonlinear and nonparametric models is central to several state-of-the-art machine learning systems. Kernel methods form an important class of techniques that induce a reproducing kernel Hilbert space (RKHS) for inferring non-linear models through the construction of similarity functions from data. These methods are particularly preferred in cases where the training data sizes are limited and when prior knowledge of the data similarities is available. Despite their usefulness, they are limited by the computational complexity and their inability to support end-to-end learning with a task-specific objective. On the other hand, deep neural networks have become the de facto solution for end-to-end inference in several learning paradigms. In this paper, we explore the idea of using deep architectures to perform kernel machine optimization, for both computational efficiency and end-to-end inferencing. To this end, we develop the deep kernel machine optimization framework, that creates an ensemble of dense embeddings using Nystrom kernel approximations and utilizes deep learning to generate task-specific representations through the fusion of the embeddings. Intuitively, the filters of the network are trained to fuse information from an ensemble of linear subspaces in the RKHS. Furthermore, we introduce the kernel dropout regularization to enable improved training convergence. Finally, we extend this framework to the multiple kernel case, by coupling a global fusion layer with pretrained deep kernel machines for each of the constituent kernels. Using case studies with limited training data, and lack of explicit feature sources, we demonstrate the effectiveness of our framework over conventional model inferencing techniques.",4
Optimized Backstepping for Tracking Control of Strict-Feedback Systems.,"In this paper, a control technique named optimized backstepping is first proposed by implementing tracking control for a class of strict-feedback systems, which considers optimization as a design philosophy of the high-order system control. The basic idea is that designing the actual and virtual controls of backstepping is the optimized solutions of the corresponding subsystems so that overall control of the high-order system is optimized. In general, optimization control is designed based on the solution of Hamilton-Jacobi-Bellman equation, but solving the equation is very difficult due to the inherent nonlinearity and intractability. In order to overcome the difficulty, the neural network (NN)-based reinforcement learning strategy of actor-critic architecture is used. In every backstepping step, the actor and critic NNs are constructed for executing control behavior and evaluating control performance, respectively. According to the Lyapunov stability theorem, it is proven that the desired control performance can be obtained. Finally, a simulation example is carried out to further demonstrate the effectiveness of the proposed control approach.",4
Recursive Neural Networks for Density Estimation Over Generalized Random Graphs.,"Structured data in the form of labeled graphs (with variable order and topology) may be thought of as the outcomes of a random graph (RG) generating process characterized by an underlying probabilistic law. This paper formalizes the notions of generalized RG (GRG) and probability density function (pdf) for GRGs. Thence, a ""universal"" learning machine (combining the encoding module of a recursive neural network and a radial basis functions' network) is introduced for estimating the unknown pdf from an unsupervised sample of GRGs. A maximum likelihood training algorithm is presented and constrained so as to ensure that the resulting model satisfies the axioms of probability. Techniques for preventing the model from degenerate solutions are proposed, as well as variants of the algorithm suitable to the tasks of graphs classification and graphs clustering. The major properties of the machine are discussed. The approach is validated empirically through experimental investigations in the estimation of pdfs for synthetic and real-life GRGs, in the classification of images from the Caltech Benchmark data set and molecules from the Mutagenesis data set, and in clustering of images from the LabelMe data set.",4
Event-Triggered Cooperative Global Robust Practical Output Regulation for Second-Order Uncertain Nonlinear Multiagent Systems.,"In this paper, we study the cooperative global robust practical output regulation problem for a class of second-order uncertain nonlinear multiagent systems via a distributed event-triggered state feedback control strategy. Compared with the existing work, one of the main challenges is that we need to design two distributed internal models to learn both the desired steady-state state and steady-state input for each agent. Moreover, to obtain a directly implementable digital control law, the two distributed internal models of each agent only depend on the sampled states of the neighboring agents and itself. As a result, the resulting augmented system is more complicated, and the control law needs to be recursively designed. To overcome the difficulty, we propose a novel distributed event-triggered control law and a novel distributed event-triggered mechanism to deal with our problem. By adjusting a design parameter in the proposed event-triggered mechanism, we show that the Zeno behavior does not happen and the ultimate bound of the tracking error can be made arbitrarily small. Our design will be illustrated by two examples.",4
A Game-Theoretic Approach to Design Secure and Resilient Distributed Support Vector Machines.,"Distributed support vector machines (DSVMs) have been developed to solve large-scale classification problems in networked systems with a large number of sensors and control units. However, the systems become more vulnerable, as detection and defense are increasingly difficult and expensive. This paper aims to develop secure and resilient DSVM algorithms under adversarial environments in which an attacker can manipulate the training data to achieve his objective. We establish a game-theoretic framework to capture the conflicting interests between an adversary and a set of distributed data processing units. The Nash equilibrium of the game allows predicting the outcome of learning algorithms in adversarial environments and enhancing the resilience of the machine learning through dynamic distributed learning algorithms. We prove that the convergence of the distributed algorithm is guaranteed without assumptions on the training data or network topologies. Numerical experiments are conducted to corroborate the results. We show that the network topology plays an important role in the security of DSVM. Networks with fewer nodes and higher average degrees are more secure. Moreover, a balanced network is found to be less vulnerable to attacks.",4
A Supervised Learning Algorithm for Learning Precise Timing of Multiple Spikes in Multilayer Spiking Neural Networks.,"There is a biological evidence to prove information is coded through precise timing of spikes in the brain. However, training a population of spiking neurons in a multilayer network to fire at multiple precise times remains a challenging task. Delay learning and the effect of a delay on weight learning in a spiking neural network (SNN) have not been investigated thoroughly. This paper proposes a novel biologically plausible supervised learning algorithm for learning precisely timed multiple spikes in a multilayer SNNs. Based on the spike-timing-dependent plasticity learning rule, the proposed learning method trains an SNN through the synergy between weight and delay learning. The weights of the hidden and output neurons are adjusted in parallel. The proposed learning method captures the contribution of synaptic delays to the learning of synaptic weights. Interaction between different layers of the network is realized through biofeedback signals sent by the output neurons. The trained SNN is used for the classification of spatiotemporal input patterns. The proposed learning method also trains the spiking network not to fire spikes at undesired times which contribute to misclassification. Experimental evaluation on benchmark data sets from the UCI machine learning repository shows that the proposed method has comparable results with classical rate-based methods such as deep belief network and the autoencoder models. Moreover, the proposed method can achieve higher classification accuracies than single layer and a similar multilayer SNN.",4
Multiview Clustering via Unified and View-Specific Embeddings Learning.,"Multiview clustering, which aims at using multiple distinct feature sets to boost clustering performance, has a wide range of applications. A subspace-based approach, a type of widely used methods, learns unified embedding from multiple sources of information and gives a relatively good performance. However, these methods usually ignore data similarity rankings; for example, example A may be more similar to B than C, and such similarity triplets may be more effective in revealing the data cluster structure. Motivated by recent embedding methods for modeling knowledge graph in natural-language processing, this paper proposes to mimic different views as different relations in a knowledge graph for unified and view-specific embedding learning. Moreover, in real applications, it happens so often that some views suffer from missing information, leading to incomplete multiview data. Under such a scenario, the performance of conventional multiview clustering degenerates notably, whereas the method we propose here can be naturally extended for incomplete multiview clustering, which enables full use of examples with incomplete feature sets for model promotion. Finally, we demonstrate through extensive experiments that our method performs better than the state-of-the-art clustering methods.",4
Efficient Reinforcement Learning via Probabilistic Trajectory Optimization.,"We present a trajectory optimization approach to reinforcement learning in continuous state and action spaces, called probabilistic differential dynamic programming (PDDP). Our method represents systems dynamics using Gaussian processes (GPs), and performs local dynamic programming iteratively around a nominal trajectory in Gaussian belief spaces. Different from model-based policy search methods, PDDP does not require a policy parameterization and learns a time-varying control policy via successive forward-backward sweeps. A convergence analysis of the iterative scheme is given, showing that our algorithm converges to a stationary point globally under certain conditions. We show that prior model knowledge can be incorporated into the proposed framework to speed up learning, and a generalized optimization criterion based on the predicted cost distribution can be employed to enable risk-sensitive learning. We demonstrate the effectiveness and efficiency of the proposed algorithm using nontrivial tasks. Compared with a state-of-the-art GP-based policy search method, PDDP offers a superior combination of learning speed, data efficiency, and applicability.",4
Deep Sparse Tensor Filtering Network for Synthetic Aperture Radar Images Classification.,"Recognizing scenes from synthetic aperture radar (SAR) images has been a challenging task due to the increasing resolution of SAR data. Extracting discriminative features from SAR images is extremely difficult for their sensitivity to target aspect. Considering the intractability of the available deep neural networks in practical implementations, in this brief, we propose a simple and efficient deep sparse tensor filtering network (DSTFN) for SAR image classification. An SAR image is first organized into a data tensor by an overlapped partition. Then, a set of dimension-inseparable geometric filters is developed from a least squares support vector machine, followed by a learned sparse filtering of tensors. Finally, the constructed sparse tensor filters are cascaded to a deep network to automatically extract the discriminative features of the image for accurate classification. Simulations are carried out to verify the effectiveness of the proposed DSTFN.",4
A Highly Effective and Robust Membrane Potential-Driven Supervised Learning Method for Spiking Neurons.,"Spiking neurons are becoming increasingly popular owing to their biological plausibility and promising computational properties. Unlike traditional rate-based neural models, spiking neurons encode information in the temporal patterns of the transmitted spike trains, which makes them more suitable for processing spatiotemporal information. One of the fundamental computations of spiking neurons is to transform streams of input spike trains into precisely timed firing activity. However, the existing learning methods, used to realize such computation, often result in relatively low accuracy performance and poor robustness to noise. In order to address these limitations, we propose a novel highly effective and robust membrane potential-driven supervised learning (MemPo-Learn) method, which enables the trained neurons to generate desired spike trains with higher precision, higher efficiency, and better noise robustness than the current state-of-the-art spiking neuron learning methods. While the traditional spike-driven learning methods use an error function based on the difference between the actual and desired output spike trains, the proposed MemPo-Learn method employs an error function based on the difference between the output neuron membrane potential and its firing threshold. The efficiency of the proposed learning method is further improved through the introduction of an adaptive strategy, called skip scan training strategy, that selectively identifies the time steps when to apply weight adjustment. The proposed strategy enables the MemPo-Learn method to effectively and efficiently learn the desired output spike train even when much smaller time steps are used. In addition, the learning rule of MemPo-Learn is improved further to help mitigate the impact of the input noise on the timing accuracy and reliability of the neuron firing dynamics. The proposed learning method is thoroughly evaluated on synthetic data and is further demonstrated on real-world classification tasks. Experimental results show that the proposed method can achieve high learning accuracy with a significant improvement in learning time and better robustness to different types of noise.",4
A Cost-Sensitive Deep Belief Network for Imbalanced Classification.,"Imbalanced data with a skewed class distribution are common in many real-world applications. Deep Belief Network (DBN) is a machine learning technique that is effective in classification tasks. However, conventional DBN does not work well for imbalanced data classification because it assumes equal costs for each class. To deal with this problem, cost-sensitive approaches assign different misclassification costs for different classes without disrupting the true data sample distributions. However, due to lack of prior knowledge, the misclassification costs are usually unknown and hard to choose in practice. Moreover, it has not been well studied as to how cost-sensitive learning could improve DBN performance on imbalanced data problems. This paper proposes an evolutionary cost-sensitive deep belief network (ECS-DBN) for imbalanced classification. ECS-DBN uses adaptive differential evolution to optimize the misclassification costs based on the training data that presents an effective approach to incorporating the evaluation measure (i.e., G-mean) into the objective function. We first optimize the misclassification costs, and then apply them to DBN. Adaptive differential evolution optimization is implemented as the optimization algorithm that automatically updates its corresponding parameters without the need of prior domain knowledge. The experiments have shown that the proposed approach consistently outperforms the state of the art on both benchmark data sets and real-world data set for fault diagnosis in tool condition monitoring.",4
Enhanced Robot Speech Recognition Using Biomimetic Binaural Sound Source Localization.,"Inspired by the behavior of humans talking in noisy environments, we propose an embodied embedded cognition approach to improve automatic speech recognition (ASR) systems for robots in challenging environments, such as with ego noise, using binaural sound source localization (SSL). The approach is verified by measuring the impact of SSL with a humanoid robot head on the performance of an ASR system. More specifically, a robot orients itself toward the angle where the signal-to-noise ratio (SNR) of speech is maximized for one microphone before doing an ASR task. First, a spiking neural network inspired by the midbrain auditory system based on our previous work is applied to calculate the sound signal angle. Then, a feedforward neural network is used to handle high levels of ego noise and reverberation in the signal. Finally, the sound signal is fed into an ASR system. For ASR, we use a system developed by our group and compare its performance with and without the support from SSL. We test our SSL and ASR systems on two humanoid platforms with different structural and material properties. With our approach we halve the sentence error rate with respect to the common downmixing of both channels. Surprisingly, the ASR performance is more than two times better when the angle between the humanoid head and the sound source allows sound waves to be reflected most intensely from the pinna to the ear microphone, rather than when sound waves arrive perpendicularly to the membrane.",4
Adaptive Learning-Based -Nearest Neighbor Classifiers With Resilience to Class Imbalance.,"The classification accuracy of a -nearest neighbor ( NN) classifier is largely dependent on the choice of the number of nearest neighbors denoted by . However, given a data set, it is a tedious task to optimize the performance of NN by tuning . Moreover, the performance of NN degrades in the presence of class imbalance, a situation characterized by disparate representation from different classes. We aim to address both the issues in this paper and propose a variant of NN called the Adaptive NN (Ada- NN). The Ada- NN classifier uses the density and distribution of the neighborhood of a test point and learns a suitable point-specific for it with the help of artificial neural networks. We further improve our proposal by replacing the neural network with a heuristic learning method guided by an indicator of the local density of a test point and using information about its neighboring training points. The proposed heuristic learning algorithm preserves the simplicity of NN without incurring serious computational burden. We call this method Ada- NN2. Ada- NN and Ada- NN2 perform very competitive when compared with NN, five of NN's state-of-the-art variants, and other popular classifiers. Furthermore, we propose a class-based global weighting scheme (Global Imbalance Handling Scheme or GIHS) to compensate for the effect of class imbalance. We perform extensive experiments on a wide variety of data sets to establish the improvement shown by Ada- NN and Ada- NN2 using the proposed GIHS, when compared with NN, and its 12 variants specifically tailored for imbalanced classification.",4
High-Performance Mixed-Signal Neurocomputing With Nanoscale Floating-Gate Memory Cell Arrays.,"Potential advantages of analog- and mixed-signal nanoelectronic circuits, based on floating-gate devices with adjustable conductance, for neuromorphic computing had been realized long time ago. However, practical realizations of this approach suffered from using rudimentary floating-gate cells of relatively large area. Here, we report a prototype $28\times28$ binary-input, ten-output, three-layer neuromorphic network based on arrays of highly optimized embedded nonvolatile floating-gate cells, redesigned from a commercial 180-nm nor flash memory. All active blocks of the circuit, including 101 780 floating-gate cells, have a total area below 1 mm2. The network has shown a 94.7% classification fidelity on the common Modified National Institute of Standards and Technology benchmark, close to the 96.2% obtained in simulation. The classification of one pattern takes a sub-1- $\mu \text{s}$ time and a sub-20-nJ energy-both numbers much better than in the best reported digital implementations of the same task. Estimates show that a straightforward optimization of the hardware and its transfer to the already available 55-nm technology may increase this advantage to more than $10^{2}\times $ in speed and $10^{4}\times $ in energy efficiency.",4
Robust Object Tracking by Nonlinear Learning.,"We propose a method that obtains a discriminative visual dictionary and a nonlinear classifier for visual tracking tasks in a sparse coding manner based on the globally linear approximation for a nonlinear learning theory. Traditional discriminative tracking methods based on sparse representation learn a dictionary in an unsupervised way and then train a classifier, which may not generate both descriptive and discriminative models for targets by treating dictionary learning and classifier learning separately. In contrast, the proposed tracking approach can construct a dictionary that fully reflects the intrinsic manifold structure of visual data and introduces more discriminative ability in a unified learning framework. Finally, an iterative optimization approach, which computes the optimal dictionary, the associated sparse coding, and a classifier, is introduced. Experiments on two benchmarks show that our tracker achieves a better performance compared with some popular tracking algorithms.",4
Adaptive Fault-Tolerant Control for Nonlinear Systems With Multiple Sensor Faults and Unknown Control Directions.,"This paper investigates the problem of adaptive fault-tolerant control for a class of nonlinear parametric strict-feedback systems with multiple unknown control directions. Multiple sensor faults are first considered such that all real state variables are unavailable. Then, a constructive design method for the problem is set up by exploiting a parameter separation and regrouping technique. To circumvent the main obstacle caused by the coupling effects of multiple unknown control directions and sensor faults, a region-dependent segmentation analysis method is proposed. It is proven that the closed-loop system is globally exponentially stable. Simulation results are presented to illustrate the effectiveness of the proposed scheme.",4
Reinforcement Learning-Based Differential Evolution With Cooperative Coevolution for a Compensatory Neuro-Fuzzy Controller.,"This paper presents the integration of reinforcement learning-based differential evolution (DE) with the cooperative coevolution (R-CCDE) method in a compensatory neuro-fuzzy controller (CNFC). The CNFC model employs compensatory fuzzy operations, which increase the adaptability and effectiveness of the controller. The R-CCDE method was used to determine an adequate control policy for nonlinear system problems. The evolution of a population involved the use of DE with cooperative coevolution to adjust CNFC parameters, and the fitness function of the R-CCDE method is used by a reinforcement signal to determine the controller that can be used to solve the control problem. This paper identified the best performing controller to solve nonlinear system problems. The simulation results of the proposed R-CCDE method were compared with those of various DE methods and the performance of the proposed R-CCDE method was superior to that of the other methods.",4
GCRNN: Group-Constrained Convolutional Recurrent Neural Network.,"In this paper, we propose a new end-to-end deep neural network model for time-series classification (TSC) with emphasis on both the accuracy and the interpretation. The proposed model contains a convolutional network component to extract high-level features and a recurrent network component to enhance the modeling of the temporal characteristics of TS data. In addition, a feedforward fully connected network with the sparse group lasso (SGL) regularization is used to generate the final classification. The proposed architecture not only achieves satisfying classification accuracy, but also obtains good interpretability through the SGL regularization. All these networks are connected and jointly trained in an end-to-end framework, and it can be generally applied to TSC tasks across different domains without the efforts of feature engineering. Our experiments in various TS data sets show that the proposed model outperforms the traditional convolutional neural network model for the classification accuracy, and also demonstrate how the SGL contributes to a better model interpretation.",4
Online Training of LSTM Networks in Distributed Systems for Variable Length Data Sequences.,"In this brief, we investigate online training of long short term memory (LSTM) architectures in a distributed network of nodes, where each node employs an LSTM-based structure for online regression. In particular, each node sequentially receives a variable length data sequence with its label and can only exchange information with its neighbors to train the LSTM architecture. We first provide a generic LSTM-based regression structure for each node. In order to train this structure, we put the LSTM equations in a nonlinear state-space form for each node and then introduce a highly effective and efficient distributed particle filtering (DPF)-based training algorithm. We also introduce a distributed extended Kalman filtering-based training algorithm for comparison. Here, our DPF-based training algorithm guarantees convergence to the performance of the optimal LSTM coefficients in the mean square error sense under certain conditions. We achieve this performance with communication and computational complexity in the order of the first-order gradient-based methods. Through both simulated and real-life examples, we illustrate significant performance improvements with respect to the state-of-the-art methods.",4
Brain-Inspired Wireless Communications: Where Reservoir Computing Meets MIMO-OFDM.,"Reservoir computing (RC) is a class of neuromorphic computing approaches that deals particularly well with time-series prediction tasks. It significantly reduces the training complexity of recurrent neural networks and is also suitable for hardware implementation whereby device physics are utilized in performing data processing. In this paper, the RC concept is applied to detecting a transmitted symbol in multiple-input multiple-output orthogonal frequency division multiplexing (MIMO-OFDM) systems. Due to wireless propagation, the transmitted signal may undergo severe distortion before reaching the receiver. The nonlinear distortion introduced by the power amplifier at the transmitter may further complicate this process. Therefore, an efficient symbol detection strategy becomes critical. The conventional approach for symbol detection at the receiver requires accurate channel estimation of the underlying MIMO-OFDM system. However, in this paper, we introduce a novel symbol detection scheme where the estimation of the MIMO-OFDM channel becomes unnecessary. The introduced scheme utilizes an echo state network (ESN), which is a special class of RC. The ESN acts as a black box for system modeling purposes and can predict nonlinear dynamic systems in an efficient way. Simulation results for the uncoded bit error rate of nonlinear MIMO-OFDM systems show that the introduced scheme outperforms conventional symbol detection methods.",4
Quantized CNN: A Unified Approach to Accelerate and Compress Convolutional Networks.,"We are witnessing an explosive development and widespread application of deep neural networks (DNNs) in various fields. However, DNN models, especially a convolutional neural network (CNN), usually involve massive parameters and are computationally expensive, making them extremely dependent on high-performance hardware. This prohibits their further extensions, e.g., applications on mobile devices. In this paper, we present a quantized CNN, a unified approach to accelerate and compress convolutional networks. Guided by minimizing the approximation error of individual layer's response, both fully connected and convolutional layers are carefully quantized. The inference computation can be effectively carried out on the quantized network, with much lower memory and storage consumption. Quantitative evaluation on two publicly available benchmarks demonstrates the promising performance of our approach: with comparable classification accuracy, it achieves 4 to $6 \times $ acceleration and 15 to $20\times $ compression. With our method, accurate image classification can even be directly carried out on mobile devices within 1 s.",4
Rank-One Matrix Completion With Automatic Rank Estimation via L1-Norm Regularization.,"Completing a matrix from a small subset of its entries, i.e., matrix completion is a challenging problem arising from many real-world applications, such as machine learning and computer vision. One popular approach to solve the matrix completion problem is based on low-rank decomposition/factorization. Low-rank matrix decomposition-based methods often require a prespecified rank, which is difficult to determine in practice. In this paper, we propose a novel low-rank decomposition-based matrix completion method with automatic rank estimation. Our method is based on rank-one approximation, where a matrix is represented as a weighted summation of a set of rank-one matrices. To automatically determine the rank of an incomplete matrix, we impose L1-norm regularization on the weight vector and simultaneously minimize the reconstruction error. After obtaining the rank, we further remove the L1-norm regularizer and refine recovery results. With a correctly estimated rank, we can obtain the optimal solution under certain conditions. Experimental results on both synthetic and real-world data demonstrate that the proposed method not only has good performance in rank estimation, but also achieves better recovery accuracy than competing methods.",4
Marginal Representation Learning With Graph Structure Self-Adaptation.,"Learning discriminative feature representations has shown remarkable importance due to its promising performance for machine learning problems. This paper presents a discriminative data representation learning framework by employing a simple yet powerful marginal regression function with probabilistic graphical structure adaptation. A marginally structured representation learning (MSRL) method is proposed by seamlessly incorporating distinguishable regression targets analysis, graph structure adaptation, and robust linear structural learning into a joint framework. Specifically, MSRL learns marginal regression targets from data rather than exploiting the conventional zero-one matrix that greatly hinders the freedom of regression fitness and degrades the performance of regression results. Meanwhile, an optimized graph regularization term with self-improving adaptation is constructed based on probabilistic connection knowledge to improve the compactness of the learned representation. Additionally, the regression targets are further predicted by utilizing the explanatory factors from the latent subspace of data, which can uncover the underlying feature correlations to enhance the reliability. The resulting optimization problem can be elegantly solved by an efficient iterative algorithm. Finally, the proposed method is evaluated by eight diverse but related tasks, including object, face, texture, and scene, categorization data sets. The encouraging experimental results and the explicit theoretical analysis demonstrate the efficacy of the proposed representation learning method in comparison with state-of-the-art algorithms.",4
Spoofing Detection in Automatic Speaker Verification Systems Using DNN Classifiers and Dynamic Acoustic Features.,"With the development of speech synthesis technology, automatic speaker verification (ASV) systems have encountered the serious challenge of spoofing attacks. In order to improve the security of ASV systems, many antispoofing countermeasures have been developed. In the front-end domain, much research has been conducted on finding effective features which can distinguish spoofed speech from genuine speech and the published results show that dynamic acoustic features work more effectively than static ones. In the back-end domain, Gaussian mixture model (GMM) and deep neural networks (DNNs) are the two most popular types of classifiers used for spoofing detection. The log-likelihood ratios (LLRs) generated by the difference of human and spoofing log-likelihoods are used as spoofing detection scores. In this paper, we train a five-layer DNN spoofing detection classifier using dynamic acoustic features and propose a novel, simple scoring method only using human log-likelihoods (HLLs) for spoofing detection. We mathematically prove that the new HLL scoring method is more suitable for the spoofing detection task than the classical LLR scoring method, especially when the spoofing speech is very similar to the human speech. We extensively investigate the performance of five different dynamic filter bank-based cepstral features and constant Q cepstral coefficients (CQCC) in conjunction with the DNN-HLL method. The experimental results show that, compared to the GMM-LLR method, the DNN-HLL method is able to significantly improve the spoofing detection accuracy. Compared with the CQCC-based GMM-LLR baseline, the proposed DNN-HLL model reduces the average equal error rate of all attack types to 0.045%, thus exceeding the performance of previously published approaches for the ASVspoof 2015 Challenge task. Fusing the CQCC-based DNN-HLL spoofing detection system with ASV systems, the false acceptance rate on spoofing attacks can be reduced significantly.",4
Learning With Kernels: A Local Rademacher Complexity-Based Analysis With Application to Graph Kernels.,"When dealing with kernel methods, one has to decide which kernel and which values for the hyperparameters to use. Resampling techniques can address this issue but these procedures are time-consuming. This problem is particularly challenging when dealing with structured data, in particular with graphs, since several kernels for graph data have been proposed in literature, but no clear relationship among them in terms of learning properties is defined. In these cases, exhaustive search seems to be the only reasonable approach. Recently, the global Rademacher complexity (RC) and local Rademacher complexity (LRC), two powerful measures of the complexity of a hypothesis space, have shown to be suited for studying kernels properties. In particular, the LRC is able to bound the generalization error of an hypothesis chosen in a space by disregarding those ones which will not be taken into account by any learning procedure because of their high error. In this paper, we show a new approach to efficiently bound the RC of the space induced by a kernel, since its exact computation is an NP-Hard problem. Then we show for the first time that RC can be used to estimate the accuracy and expressivity of different graph kernels under different parameter configurations. The authors' claims are supported by experimental results on several real-world graph data sets.",4
Complete Stability Analysis With Respect to Delay for Neural Networks.,"The stability property of delayed neural networks (NNs) along the whole delay axis is studied in this paper. Such a complete stability problem with respect to the delay parameter has not been addressed in the community of NNs. Most of the existing studies focus on the stability interval of delay starting from zero and are not applicable for the complete stability problem. In this paper, we will present some examples to show that there are various types of stability intervals for NNs, demonstrating the necessity of the complete stability analysis. We will adopt a frequency-sweeping approach to study delayed NNs in this paper. As a result, the complete stability problem with respect to delay for NNs can be systematically solved. The approach is applicable in the general case and simple to implement. Finally, some representative examples illustrate the approach.",4
Tracking Control for Linear Discrete-Time Networked Control Systems With Unknown Dynamics and Dropout.,"This paper develops a new method for solving the optimal control tracking problem for networked control systems (NCSs), where network-induced dropout can occur and the system dynamics are unknown. First, a novel dropout Smith predictor is designed to predict the current state based on historical data measurements over the communication network. Then, it is shown that the quadratic form of the performance index is preserved even with dropout, and the optimal tracker solution with dropout is given based on a novel dropout generalized algebraic Riccati equation. New algorithms for off-line policy iteration (PI), online PI, and Q-learning PI are presented for NCS with dropout. The Q-learning algorithm adaptively learns the optimal control online using data measured over the communication network based on reinforcement learning, including dropout, without requiring any knowledge of the system dynamics. Simulation results are provided to show that the proposed approaches give proper optimal tracking performance for the NCS with unknown dynamics and dropout.",4
Parallelized Tensor Train Learning of Polynomial Classifiers.,"In pattern classification, polynomial classifiers are well-studied methods as they are capable of generating complex decision surfaces. Unfortunately, the use of multivariate polynomials is limited to kernels as in support-vector machines, because polynomials quickly become impractical for high-dimensional problems. In this paper, we effectively overcome the curse of dimensionality by employing the tensor train (TT) format to represent a polynomial classifier. Based on the structure of TTs, two learning algorithms are proposed, which involve solving different optimization problems of low computational complexity. Furthermore, we show how both regularization to prevent overfitting and parallelization, which enables the use of large training sets, are incorporated into these methods. The efficiency and efficacy of our tensor-based polynomial classifier are then demonstrated on the two popular data sets U.S. Postal Service and Modified NIST.",4
Probabilistic Guaranteed Gradient Learning-Based Spark Advance Self-Optimizing Control for Spark-Ignited Engines.,"In spark-ignited (SI) engines, the spark advance (SA) controls the combustion phase that has a significant impact on the efficiency. Online self-optimizing control (SOC) of SA to maximize the indicated fuel conversion efficiency (IFCE) forms a stochastic optimization problem for a static map due to the stochasticity of combustion. Gradient-based optimization algorithms using periodic dithers are effective methods of dealing with such problems. However, decision sequences corrupted by periodic dithers are undesirable in SA online SOC. To choose a proper decision sequence for this problem, a gradient descent-based dither-free SOC scheme iteratively updates the decision based on probabilistic guaranteed gradient learning (PGGL). The PGGL approach uses the statistical distribution of the past samples to approximate the gradient on which the sample size can be adaptively adjusted to achieve the probabilistic target. The proposed scheme not only guarantees the accuracy of gradient learning but also adaptively adjusts the sample size in the learning process, achieving a tradeoff between a rapid response and a stable decision sequence. Moreover, the convergence performance of the obtained decision sequence is analyzed with respect to the probability distribution. Finally, experimental validations performed on an SI engine test bench show that the proposed PGGL-based SOC scheme successfully manages engine operation around the optimal IFCE with a fast response and stable SA behavior, under both steady and mild transient conditions.",4
Event-Based Adaptive NN Tracking Control of Nonlinear Discrete-Time Systems.,"This paper is concerned with the simultaneous design of a neural network (NN)-based adaptive control law and an event-triggering condition for a class of strict feedback nonlinear discrete-time systems. The stability and tracking performance of the closed-loop network control system under the event-triggering strategy is formally proven based on the Lyapunov theory in a hybrid framework. The proposed Lyapunov formulation yields an event-triggered algorithm to update the control input and NN weights based on conditions involving the closed-loop state. Different from the existing traditional NN control schemes where the feedback signals are transmitted and executed periodically, the feedback signals are transmitted and executed only when the event-trigger error exceeds the specified threshold, which can largely reduce the communication load. The effectiveness of the approach is evaluated through a simulation example.",4
Robust Zeroing Neural-Dynamics and Its Time-Varying Disturbances Suppression Model Applied to Mobile Robot Manipulators.,"This paper proposes a novel robust zeroing neural-dynamics (RZND) approach as well as its associated model for solving the inverse kinematics problem of mobile robot manipulators. Unlike existing works based on the assumption that neural network models are free of external disturbances, four common forms of time-varying disturbances suppressed by the proposed RZND model are investigated in this paper. In addition, theoretical analyses on the antidisturbance performance are presented in detail to prove the effectiveness and robustness of the proposed RZND model with time-varying disturbances suppressed for solving the inverse kinematics problem of mobile robot manipulators. That is, the RZND model converges toward the exact solution of the inverse kinematics problem of mobile robot manipulators with bounded or zero-oriented steady-state position error. Moreover, simulation studies and comprehensive comparisons with existing neural network models, e.g., the conventional Zhang neural network model and the gradient-based recurrent neural network model, together with extensive tests with four common forms of time-varying disturbances substantiate the efficacy, robustness, and superiority of the proposed RZND approach as well as its time-varying disturbances suppression model for solving the inverse kinematics problem of mobile robot manipulators.",4
Dynamic Analysis of Hybrid Impulsive Delayed Neural Networks With Uncertainties.,"Neural networks (NNs) have emerged as a powerful illustrative diagram for the brain. Unveiling the mechanism of neural-dynamic evolution is one of the crucial steps toward understanding how the brain works and evolves. Inspired by the universal existence of impulses in many real systems, this paper formulates a type of hybrid NNs (HNNs) with impulses, time delays, and interval uncertainties, and studies its global dynamic evolution by a robust interval analysis. The HNNs incorporate both continuous-time implementation and impulsive jump in mutual activations, where time delays and interval uncertainties are represented simultaneously. By constructing a Banach contraction mapping, the existence and uniqueness of the equilibrium of the HNN model are proved and analyzed in detail. Based on nonsmooth Lyapunov functions and delayed impulsive differential equations, new criteria are derived for ensuring the global robust exponential stability of the HNNs. Convergence analysis together with illustrative examples show the effectiveness of the theoretical results.",4
Multilabel Prediction via Cross-View Search.,"Embedding methods have shown promising performance in multilabel prediction, as they are able to discover the label dependence. However, most methods ignore the correlations between the input and output, such that their learned embeddings are not well aligned, which leads to degradation in prediction performance. This paper presents a formulation for multilabel learning, from the perspective of cross-view learning, that explores the correlations between the input and the output. The proposed method, called Co-Embedding (CoE), jointly learns a semantic common subspace and view-specific mappings within one framework. The semantic similarity structure among the embeddings is further preserved, ensuring that close embeddings share similar labels. Additionally, CoE conducts multilabel prediction through the cross-view $k$ nearest neighborhood ( $k$ NN) search among the learned embeddings, which significantly reduces computational costs compared with conventional decoding schemes. A hashing-based model, i.e., Co-Hashing (CoH), is further proposed. CoH is based on CoE, and imposes the binary constraint on continuous latent embeddings. CoH aims to generate compact binary representations to improve the prediction efficiency by benefiting from the efficient $k$ NN search of multiple labels in the Hamming space. Extensive experiments on various real-world data sets demonstrate the superiority of the proposed methods over the state of the arts in terms of both prediction accuracy and efficiency.",4
Distributed Event-Triggered Adaptive Control for Cooperative Output Regulation of Heterogeneous Multiagent Systems Under Switching Topology.,"This paper investigates the cooperative output regulation problem for heterogeneous multiagent systems (MASs) under switching topology. Two novel distributed event-triggered adaptive control strategies based on state feedback and output feedback are developed, which can avoid using the minimal nonzero eigenvalue of Laplacian matrix associated with global system topologies. It is shown that under the proposed control protocols, MASs could achieve asymptotic tracking and disturbance rejection, and meanwhile, the amount of transmission data and communication cost among agents can be reduced. Then, the leader-following consensus problem of MASs is given as an application of our main results. Finally, an example is presented to verify the effectiveness of the proposed control schemes.",4
Large-Scale Metric Learning: A Voyage From Shallow to Deep.,"Despite its attractive properties, the performance of the recently introduced Keep It Simple and Straightforward MEtric learning (KISSME) method is greatly dependent on principal component analysis as a preprocessing step. This dependence can lead to difficulties, e.g., when the dimensionality is not meticulously set. To address this issue, we devise a unified formulation for joint dimensionality reduction and metric learning based on the KISSME algorithm. Our joint formulation is expressed as an optimization problem on the Grassmann manifold, and hence enjoys the properties of Riemannian optimization techniques. Following the success of deep learning in recent years, we also devise end-to-end learning of a generic deep network for metric learning using our derivation.",4
Recursive Adaptive Sparse Exponential Functional Link Neural Network for Nonlinear AEC in Impulsive Noise Environment.,"Recently, an adaptive exponential trigonometric functional link neural network (AETFLN) architecture has been introduced to enhance the nonlinear processing capability of the trigonometric functional link neural network (TFLN). However, it suffers from slow convergence speed, heavy computational burden, and poor robustness to noise in nonlinear acoustic echo cancellation, especially in the double-talk scenario. To reduce its computational complexity and improve its robustness against impulsive noise, this paper develops a recursive adaptive sparse exponential TFLN (RASETFLN). Based on sparse representations of functional links, the robust proportionate adaptive algorithm is deduced from the robust cost function over the RASETFLN in impulsive noise environments. Theoretical analysis shows that the proposed RASETFLN is stable under certain conditions. Finally, computer simulations illustrate that the proposed RASETFLN achieves much improved performance over the AETFLN in several nonlinear scenarios in terms of convergence rate, steady-state error, and robustness against noise.",4
Improved Stability Analysis for Delayed Neural Networks.,"In this brief, by constructing an augmented Lyapunov-Krasovskii functional in a triple integral form, the stability analysis of delayed neural networks is investigated. In order to exploit more accurate bounds for the derivatives of triple integrals, new double integral inequalities are developed, which include some recently introduced estimation techniques as special cases. The information on the activation function is taken into full consideration. Taking advantages of the proposed inequalities, the stability criteria with less conservatism are derived. The improvement of the obtained approaches is verified by numerical examples.",4
Connectivity-Preserving Consensus Tracking of Uncertain Nonlinear Strict-Feedback Multiagent Systems: An Error Transformation Approach.,"This brief addresses a distributed connectivity-preserving adaptive consensus tracking problem of uncertain nonlinear strict-feedback multiagent systems with limited communication ranges. Compared with existing consensus results for uncertain nonlinear lower triangular multiagent systems, the main contribution of this brief is to present an error-transformation-based design methodology to preserve initial connectivity patterns in the consensus tracking field, namely, both connectivity preservation and consensus tracking problems are considered for uncertain nonlinear lower triangular multiagent systems. A dynamic surface design based on nonlinearly transformed errors and neural network function approximators is established to construct the local controller of each follower. In addition, a technical lemma is derived to analyze the stability of the proposed connectivity-preserving consensus scheme in the Lyapunov sense.",4
Modified Primal-Dual Neural Networks for Motion Control of Redundant Manipulators With Dynamic Rejection of Harmonic Noises.,"In recent decades, primal-dual neural networks, as a special type of recurrent neural networks, have received great success in real-time manipulator control. However, noises are usually ignored when neural controllers are designed based on them, and thus, they may fail to perform well in the presence of intensive noises. Harmonic noises widely exist in real applications and can severely affect the control accuracy. This work proposes a novel primal-dual neural network design that directly takes noise control into account. By taking advantage of the fact that the unknown amplitude and phase information of a harmonic signal can be eliminated from its dynamics, our deliberately designed neural controller is able to reach the accurate tracking of reference trajectories in a noisy environment. Theoretical analysis and extensive simulations show that the proposed controller stabilizes the control system polluted by harmonic noises and converges the position tracking error to zero. Comparisons show that our proposed solution consistently and significantly outperforms the existing primal-dual neural solutions as well as feedforward neural one and adaptive neural one for redundancy resolution of manipulators.",4
Multiple-Instance Ordinal Regression.,"Ordinal regression (OR) is a paradigm in supervised learning, which aims at learning a prediction model for ordered classes. The existing studies mainly focus on single-instance OR, and the multi-instance OR problem has not been explicitly addressed. In many real-world applications, considering the OR problem from a multiple-instance aspect can yield better classification performance than from a single-instance aspect. For example, in image retrieval, an image may contain multiple and possibly heterogeneous objects. The user is usually interested in only a small part of the objects. If we represent the whole image as a global feature vector, the useful information from the targeted objects that the user is of interest may be overridden by the noisy information from irrelevant objects. However, this problem fits in the multiple-instance setting well. Each image is considered as a bag, and each object region is treated as an instance. The image is considered as of the user interest if it contains at least one targeted object region. In this paper, we address the multi-instance OR where the OR classifier is learned on multiple-instance data, instead of single-instance data. To solve this problem, we present a novel multiple-instance ordinal regression (MIOR) method. In MIOR, a set of parallel hyperplanes is used to separate the classes, and the label ordering information is incorporated into learning the classifier by imputing the parallel hyperplanes with an order. Moreover, considering that a bag may contain instances not belonging to its class, for each bag, the instance which is nearest to the middle of the corresponding class is selected to learn the classifier. Compared with the existing single-instance OR work, MIOR is able to learn a more accurate OR classifier on multiple-instance data where only the bag label is available and the instance label is unknown. Extensive experiments show that MIOR outperforms the existing single-instance OR methods.",4
Neuroadaptive Control With Given Performance Specifications for MIMO Strict-Feedback Systems Under Nonsmooth Actuation and Output Constraints.,"This paper studies the prescribed performance tracking control problem for a class of multi-input multi-output strict-feedback systems with asymmetric nonsmooth actuator characteristics and output constraints as well as unexpected external disturbances. By combining a novel speed transformation with barrier Lyapunov function, a neural adaptive control scheme is developed that is able to achieve given tracking precision within preassigned finite time at prespecified converging mode. At each of the first $n-1$ steps of backstepping design, we make use of the radial basis function neural networks to cope with the uncertainties arising from unknown and time-varying virtual control gains, and in the last step, we introduce a matrix factorization technique to remove the restrictive requirement on the unknown control gain matrix and its NN-approximation, simplifying control design. Furthermore, to reduce the number of parameters to be online updated, we introduce a virtual parameter to handle the lumped uncertainties, resulting in a control scheme with low complexity and inexpensive computations. The effectiveness of the proposed control strategy is validated by systematic stability analysis and numerical simulation.",4
Lagrangean-Based Combinatorial Optimization for Large-Scale S3VMs.,"The process of manually labeling instances, essential to a supervised classifier, can be expensive and time-consuming. In such a scenario the semisupervised approach, which makes the use of unlabeled patterns when building the decision function, is a more appealing choice. Indeed, large amounts of unlabeled samples often can be easily obtained. Many optimization techniques have been developed in the last decade to include the unlabeled patterns in the support vector machines formulation. Two broad strategies are followed: continuous and combinatorial. The approach presented in this paper belongs to the latter family and is especially suitable when a fair estimation of the proportion of positive and negative samples is available. Our method is very simple and requires a very light parameter selection. Several medium- and large-scale experiments on both artificial and real-world data sets have been carried out proving the effectiveness and the efficiency of the proposed algorithm.",4
Early Classification of Time Series by Simultaneously Optimizing the Accuracy and Earliness.,"The problem of early classification of time series appears naturally in contexts where the data, of temporal nature, are collected over time, and early class predictions are interesting or even required. The objective is to classify the incoming sequence as soon as possible, while maintaining suitable levels of accuracy in the predictions. Thus, we can say that the problem of early classification consists of optimizing two objectives simultaneously: accuracy and earliness. In this context, we present a method for early classification based on combining a set of probabilistic classifiers together with a stopping rule (SR). This SR will act as a trigger and will tell us when to output a prediction or when to wait for more data, and its main novelty lies in the fact that it is built by explicitly optimizing a cost function based on accuracy and earliness. We have selected a large set of benchmark data sets and four other state-of-the-art early classification methods, and we have evaluated and compared our framework obtaining superior results in terms of both earliness and accuracy.",4
"Design, Analysis, and Representation of Novel Five-Step DTZD Algorithm for Time-Varying Nonlinear Optimization.","Continuous-time and discrete-time forms of Zhang dynamics (ZD) for time-varying nonlinear optimization have been developed recently. In this paper, a novel discrete-time ZD (DTZD) algorithm is proposed and investigated based on the previous research. Specifically, the DTZD algorithm for time-varying nonlinear optimization is developed by adopting a new Taylor-type difference rule. This algorithm is a five-step iteration process, and thus, is referred to as the five-step DTZD algorithm in this paper. Theoretical analysis and results of the proposed five-step DTZD algorithm are presented to highlight its excellent computational performance. The geometric representation of the proposed algorithm for time-varying nonlinear optimization is also provided. Comparative numerical results are illustrated with four examples to substantiate the efficacy and superiority of the proposed five-step DTZD algorithm for time-varying nonlinear optimization compared with the previous DTZD algorithms.",4
Shared Autoencoder Gaussian Process Latent Variable Model for Visual Classification.,"Multiview learning reveals the latent correlation among different modalities and utilizes the complementary information to achieve a better performance in many applications. In this paper, we propose a novel multiview learning model based on the Gaussian process latent variable model (GPLVM) to learn a set of nonlinear and nonparametric mapping functions and obtain a shared latent variable in the manifold space. Different from the previous work on the GPLVM, the proposed shared autoencoder Gaussian process (SAGP) latent variable model assumes that there is an additional mapping from the observed data to the shared manifold space. Due to the introduction of the autoencoder framework, both nonlinear projections from and to the observation are considered simultaneously. Additionally, instead of fully connecting used in the conventional autoencoder, the SAGP achieves the mappings utilizing the GP, which remarkably reduces the number of estimated parameters and avoids the phenomenon of overfitting. To make the proposed method adaptive for classification, a discriminative regularization is embedded into the proposed method. In the optimization process, an efficient algorithm based on the alternating direction method and gradient decent techniques is designed to solve the encoder and decoder parts alternatively. Experimental results on three real-world data sets substantiate the effectiveness and superiority of the proposed approach as compared with the state of the art.",4
Online Supervised Learning for Hardware-Based Multilayer Spiking Neural Networks Through the Modulation of Weight-Dependent Spike-Timing-Dependent Plasticity.,"In this paper, we propose an online learning algorithm for supervised learning in multilayer spiking neural networks (SNNs). It is found that the spike timings of neurons in an SNN can be exploited to estimate the gradients that are associated with each synapse. With the proposed method of estimating gradients, learning similar to the stochastic gradient descent process employed in a conventional artificial neural network (ANN) can be achieved. In addition to the conventional layer-by-layer backpropagation, a one-pass direct backpropagation is possible using the proposed learning algorithm. Two neural networks, with one and two hidden layers, are employed as examples to demonstrate the effectiveness of the proposed learning algorithms. Several techniques for more effective learning are discussed, including utilizing a random refractory period to avoid saturation of spikes, employing a quantization noise injection technique and pseudorandom initial conditions to decorrelate spike timings, in addition to leveraging the progressive precision in an SNN to reduce the inference latency and energy. Extensive parametric simulations are conducted to examine the aforementioned techniques. The learning algorithm is developed with the considerations of ease of hardware implementation and relative compatibility with the classic ANN-based learning. Therefore, the proposed algorithm not only enjoys the high energy efficiency and good scalability of an SNN in its specialized hardware but also benefits from the well-developed theory and techniques of conventional ANN-based learning. The Modified National Institute of Standards and Technology database benchmark test is conducted to verify the newly proposed learning algorithm. Classification correct rates of 97.2% and 97.8% are achieved for the one-hidden-layer and two-hidden-layer neural networks, respectively. Moreover, a brief discussion of the hardware implementations is presented for two mainstream architectures.",4
Stability Analysis of Neural Networks With Time-Varying Delay by Constructing Novel Lyapunov Functionals.,"This paper presents two novel Lyapunov functionals for analyzing the stability of neural networks with time-varying delay. Based on our newly proposed Lyapunov functionals and a relaxed Wirtinger-based integral inequality, new stability criteria are derived in the form of linear matrix inequalities. A comprehensive comparison of results is given to illustrate the newly proposed stability criteria from both the conservative and computational complexity point of views.",4
Neural Observer and Adaptive Neural Control Design for a Class of Nonlinear Systems.,"This paper addresses the problem of adaptive neural tracking control for nonlinear nonstrict-feedback systems. The state variables are immeasurable and only the system output is available. A neural observer is constructed to estimate these unknown system state variables. An observer-based adaptive neural tracking control scheme is developed via backstepping approach. It is shown that the designed controller guarantees that the system output well follows the desired reference signal, and meanwhile, other closed-loop signals remain bounded. Finally, two simulation examples are used to test our results.",4
Neural-Network-Based Adaptive Backstepping Control With Application to Spacecraft Attitude Regulation.,"This paper investigates the neural-network-based adaptive control problem for a class of continuous-time nonlinear systems with actuator faults and external disturbances. The model uncertainties in the system are not required to satisfy the norm-bounded assumption, and the exact information for components faults and external disturbance is totally unknown, which represents more general cases in practical systems. An indirect adaptive backstepping control strategy is proposed to cope with the stabilization problem, where the unknown nonlinearity is approximated by the adaptive neural-network scheme, and the loss of effectiveness of actuators faults and the norm bounds of exogenous disturbances are estimated via designed online adaptive updating laws. The developed adaptive backstepping control law can ensure the asymptotic stability of the fault closed-loop system despite of unknown nonlinear function, actuator faults, and disturbances. Finally, an application example based on spacecraft attitude regulation is provided to demonstrate the effectiveness and the potential of the developed new neural adaptive control approach.",4
A Solution Path Algorithm for General Parametric Quadratic Programming Problem.,"Parameter in learning problems (usually arising from the tradeoff between training error minimization and regularization) is often tuned by cross validation (CV). A solution path provides a compact representation of all optimal solutions, which can be used to determine the parameter with the global minimum CV error, without solving original optimization problems multiple times based on grid search. However, existing solution path algorithms do not provide a unified implementation to various learning problems. In this paper, we first introduce a general parametric quadratic programming (PQP) problem that can be instantiated to an extensive number of learning problems. Then, we propose a generalized solution path (GSP) for the general PQP problem. Particularly, we use the $QR$ decomposition to handle singularities in GSP. Finally, we analyze the finite convergence and the time complexity of GSP. Our experimental results on a variety of data sets not only confirm the identicality between GSP and several existing solution path algorithms but also show the superiority of our GSP over the existing solution path algorithms on both generalization and robustness. Finally, we provide a practical guild of using the GSP to solve two important learning problems, i.e., generalized error path and Ivanov SVM.",4
An Algorithm for Clustering Categorical Data With Set-Valued Features.,"In data mining, objects are often represented by a set of features, where each feature of an object has only one value. However, in reality, some features can take on multiple values, for instance, a person with several job titles, hobbies, and email addresses. These features can be referred to as set-valued features and are often treated with dummy features when using existing data mining algorithms to analyze data with set-valued features. In this paper, we propose an SV- $k$ -modes algorithm that clusters categorical data with set-valued features. In this algorithm, a distance function is defined between two objects with set-valued features, and a set-valued mode representation of cluster centers is proposed. We develop a heuristic method to update cluster centers in the iterative clustering process and an initialization algorithm to select the initial cluster centers. The convergence and complexity of the SV- $k$ -modes algorithm are analyzed. Experiments are conducted on both synthetic data and real data from five different applications. The experimental results have shown that the SV- $k$ -modes algorithm performs better when clustering real data than do three other categorical clustering algorithms and that the algorithm is scalable to large data.",4
Vectorial Dimension Reduction for Tensors Based on Bayesian Inference.,"Dimension reduction for high-order tensors is a challenging problem. In conventional approaches, dimension reduction for higher order tensors is implemented via Tucker decomposition to obtain lower dimensional tensors. This paper introduces a probabilistic vectorial dimension reduction model for tensorial data. The model represents a tensor by using a linear combination of the same order basis tensors, thus it offers a learning approach to directly reduce a tensor to a vector. Under this expression, the projection base of the model is based on the tensor CandeComp/PARAFAC (CP) decomposition and the number of free parameters in the model only grows linearly with the number of modes rather than exponentially. A Bayesian inference has been established via the variational Expectation Maximization (EM) approach. A criterion to set the parameters (a factor number of CP decomposition and the number of extracted features) is empirically given. The model outperforms several existing principal component analysis-based methods and CP decomposition on several publicly available databases in terms of classification and clustering accuracy.",4
Object Categorization Using Class-Specific Representations.,"Object categorization refers to the task of automatically classifying objects based on the visual content. Existing approaches simply represent each image with the visual features without considering the specific characters of images within the same class. However, objects of the same class may exhibit unique characters, which should be represented accordingly. In this brief, we propose a novel class-specific representation strategy for object categorization. For each class, we first model the characters of images within the same class using Gaussian mixture model (GMM). We then represent each image by calculating the Euclidean distance and relative Euclidean distance between the image and the GMM model for each class. We concatenate the representations of each class for joint representation. In this way, we can represent an image by not only considering the visual contents but also combining the class-specific characters. Experiments on several public available data sets validate the superiority of the proposed class-specific representation method over well-established algorithms for object category predictions.",4
Learning With Coefficient-Based Regularized Regression on Markov Resampling.,"Big data research has become a globally hot topic in recent years. One of the core problems in big data learning is how to extract effective information from the huge data. In this paper, we propose a Markov resampling algorithm to draw useful samples for handling coefficient-based regularized regression (CBRR) problem. The proposed Markov resampling algorithm is a selective sampling method, which can automatically select uniformly ergodic Markov chain (u.e.M.c.) samples according to transition probabilities. Based on u.e.M.c. samples, we analyze the theoretical performance of CBRR algorithm and generalize the existing results on independent and identically distributed observations. To be specific, when the kernel is infinitely differentiable, the learning rate depending on the sample size $m$ can be arbitrarily close to $\mathcal {O}(m^{-1})$ under a mild regularity condition on the regression function. The good generalization ability of the proposed method is validated by experiments on simulated and real data sets.",4
Symmetric Predictive Estimator for Biologically Plausible Neural Learning.,"In a real brain, the act of perception is a bidirectional process, depending on both feedforward sensory pathways and feedback pathways that carry expectations. We are interested in how such a neural network might emerge from a biologically plausible learning rule. Other neural network learning methods either only apply to feedforward networks, or employ assumptions (such as weight copying) that render them unlikely in a real brain. Predictive estimators (PEs) offer a better solution to this bidirectional learning scenario. However, PEs also depend on weight copying. In this paper, we propose the symmetric PE (SPE), an architecture that can learn both feedforward and feedback connection weights individually using only locally available information. We demonstrate that the SPE can learn complicated mappings without the use of weight copying. The SPE networks also show promise in deeper architectures.",4
A Distance-Based Weighted Undersampling Scheme for Support Vector Machines and its Application to Imbalanced Classification.,"A support vector machine (SVM) plays a prominent role in classic machine learning, especially classification and regression. Through its structural risk minimization, it has enjoyed a good reputation in effectively reducing overfitting, avoiding dimensional disaster, and not falling into local minima. Nevertheless, existing SVMs do not perform well when facing class imbalance and large-scale samples. Undersampling is a plausible alternative to solve imbalanced problems in some way, but suffers from soaring computational complexity and reduced accuracy because of its enormous iterations and random sampling process. To improve their classification performance in dealing with data imbalance problems, this work proposes a weighted undersampling (WU) scheme for SVM based on space geometry distance, and thus produces an improved algorithm named WU-SVM. In WU-SVM, majority samples are grouped into some subregions (SRs) and assigned different weights according to their Euclidean distance to the hyper plane. The samples in an SR with higher weight have more chance to be sampled and put to use in each learning iteration, so as to retain the data distribution information of original data sets as much as possible. Comprehensive experiments are performed to test WU-SVM via 21 binary-class and six multiclass publically available data sets. The results show that it well outperforms the state-of-the-art methods in terms of three popular metrics for imbalanced classification, i.e., area under the curve, F-Measure, and G-Mean.",4
Incremental Design of Simplex Basis Function Model for Dynamic System Identification.,"In this paper, we propose a novel adaptive piecewise linear model for dynamic system identification. It has four unique features. First, the model designs a new kind of basis function for function approximation. It maintains the uniform shape for each basis function, so as to achieve a satisfactory tradeoff between generalization ability and model complexity. Second, the model takes the structure of basis functions as decision variables to optimize the formulated identification problems instead of taking expansion coefficients as decision variables as proposed by many existing approaches. Third, we establish an incremental design strategy to solve the system identification problems. In each step of the identification, the selection of optimal basis function is a Lipschitz continuous optimization problem that is likely to be easily handled with some mature toolboxes. This incremental design strategy greatly reduces the estimation cost. Fourth, we introduce a smoothing mechanism to avoid overfitting, when the output of dynamic systems is disturbed by noise. Tests on several benchmark dynamic systems demonstrate the potential of the proposed model.",4
Deep Learning in Microscopy Image Analysis: A Survey.,"Computerized microscopy image analysis plays an important role in computer aided diagnosis and prognosis. Machine learning techniques have powered many aspects of medical investigation and clinical practice. Recently, deep learning is emerging as a leading machine learning tool in computer vision and has attracted considerable attention in biomedical image analysis. In this paper, we provide a snapshot of this fast-growing field, specifically for microscopy image analysis. We briefly introduce the popular deep neural networks and summarize current deep learning achievements in various tasks, such as detection, segmentation, and classification in microscopy image analysis. In particular, we explain the architectures and the principles of convolutional neural networks, fully convolutional networks, recurrent neural networks, stacked autoencoders, and deep belief networks, and interpret their formulations or modelings for specific tasks on various microscopy images. In addition, we discuss the open challenges and the potential trends of future research in microscopy image analysis using deep learning.",4
Design of Distributed Observers in the Presence of Arbitrarily Large Communication Delays.,"This paper focuses on the construction of distributed observers in the presence of arbitrarily large communication time delays. In contrast with the traditional centralized observer with the ability to acquire full output of the plant, we design a set of distributed observers, each having access to partial output of the plant through a distributed sensor network. More specifically, each observer obtains partial plant output and communicates with its neighboring observers through consensus protocols. The communication among the network is subject to arbitrarily large time delays. We consider three representative network topologies and for each topology establish conditions to guarantee the observation error systems be exponentially stable. We also consider the design of a pinning synchronization problem as a dual problem of the design of distributed observers. Numerical simulation is carried out to verify the effectiveness of our theoretical analysis.",4
"On Wang $k$ WTA With Input Noise, Output Node Stochastic, and Recurrent State Noise.","In this paper, the effect of input noise, output node stochastic, and recurrent state noise on the Wang $k$ WTA is analyzed. Here, we assume that noise exists at the recurrent state $y(t)$ and it can either be additive or multiplicative. Besides, its dynamical change (i.e., $dy/dt$ ) is corrupted by noise as well. In sequel, we model the dynamics of $y(t)$ as a stochastic differential equation and show that the stochastic behavior of $y(t)$ is equivalent to an Ito diffusion. Its stationary distribution is a Gibbs distribution, whose modality depends on the noise condition. With moderate input noise and very small recurrent state noise, the distribution is single modal and hence $y(\infty )$ has high probability varying within the input values of the $k$ and $k+1$ winners (i.e., correct output). With small input noise and large recurrent state noise, the distribution could be multimodal and hence $y(\infty )$ could have probability varying outside the input values of the $k$ and $k+1$ winners (i.e., incorrect output). In this regard, we further derive the conditions that the $k$ WTA has high probability giving correct output. Our results reveal that recurrent state noise could have severe effect on Wang $k$ WTA. But, input noise and output node stochastic could alleviate such an effect.",4
Event-Driven Stereo Visual Tracking Algorithm to Solve Object Occlusion.,"Object tracking is a major problem for many computer vision applications, but it continues to be computationally expensive. The use of bio-inspired neuromorphic event-driven dynamic vision sensors (DVSs) has heralded new methods for vision processing, exploiting reduced amount of data and very precise timing resolutions. Previous studies have shown these neural spiking sensors to be well suited to implementing single-sensor object tracking systems, although they experience difficulties when solving ambiguities caused by object occlusion. DVSs have also performed well in 3-D reconstruction in which event matching techniques are applied in stereo setups. In this paper, we propose a new event-driven stereo object tracking algorithm that simultaneously integrates 3-D reconstruction and cluster tracking, introducing feedback information in both tasks to improve their respective performances. This algorithm, inspired by human vision, identifies objects and learns their position and size in order to solve ambiguities. This strategy has been validated in four different experiments where the 3-D positions of two objects were tracked in a stereo setup even when occlusion occurred. The objects studied in the experiments were: 1) two swinging pens, the distance between which during movement was measured with an error of less than 0.5%; 2) a pen and a box, to confirm the correctness of the results obtained with a more complex object; 3) two straws attached to a fan and rotating at 6 revolutions per second, to demonstrate the high-speed capabilities of this approach; and 4) two people walking in a real-world environment.",4
The Stability of Stochastic Coupled Systems With Time-Varying Coupling and General Topology Structure.,"We introduce a class of novel stochastic coupled systems in which the coupling structure is time-varying and the topology structure is not strongly connected, and first establish the system on a digraph with a time-varying weight matrix. Motivated by Du and Li (2014), we give a hierarchical method to deal with digraphs without strong connectivity and establish the corresponding hierarchical algorithm to realize this approach. Also, an example is given to illustrate our hierarchical algorithm and its feasibility. In the sequel, based on the theory of asymptotically autonomous systems, Kirchhoff's matrix tree theorem, and Lyapunov method, several moment exponential stability criteria are presented, including a Lyapunov-type theorem and a coefficient-type criterion. Furthermore, theoretical results are applied to stochastic coupled oscillators with time-varying coupling structure (SCTCS), and the stability criterion of SCTCS is obtained. Finally, the effectiveness of theoretical results is illustrated by two numerical examples.",4
Sequential Labeling With Structural SVM Under Nondecomposable Losses.,"Sequential labeling addresses the classification of sequential data, which are widespread in fields as diverse as computer vision, finance, and genomics. The model traditionally used for sequential labeling is the hidden Markov model (HMM), where the sequence of class labels to be predicted is encoded as a Markov chain. In recent years, HMMs have benefited from minimum-loss training approaches, such as the structural support vector machine (SSVM), which, in many cases, has reported higher classification accuracy. However, the loss functions available for training are restricted to decomposable cases, such as the 0-1 loss and the Hamming loss. In many practical cases, other loss functions, such as those based on the $F_{1}$ measure, the precision/recall break-even point, and the average precision (AP), can describe desirable performance more effectively. For this reason, in this paper, we propose a training algorithm for SSVM that can minimize any loss based on the classification contingency table, and we present a training algorithm that minimizes an AP loss. Experimental results over a set of diverse and challenging data sets (TUM Kitchen, CMU Multimodal Activity, and Ozone Level Detection) show that the proposed training algorithms achieve significant improvements of the $F_{1}$ measure and AP compared with the conventional SSVM, and their performance is in line with or above that of other state-of-the-art sequential labeling approaches.",4
Stability Analysis of Quaternion-Valued Neural Networks: Decomposition and Direct Approaches.,"In this paper, we investigate the global stability of quaternion-valued neural networks (QVNNs) with time-varying delays. On one hand, in order to avoid the noncommutativity of quaternion multiplication, the QVNN is decomposed into four real-valued systems based on Hamilton rules: $ij=-ji=k,~jk=-kj=i$ , $ki=-ik=j$ , $i^{2}=j^{2}=k^{2}=ijk=-1$ . With the Lyapunov function method, some criteria are, respectively, presented to ensure the global $\mu $ -stability and power stability of the delayed QVNN. On the other hand, by considering the noncommutativity of quaternion multiplication and time-varying delays, the QVNN is investigated directly by the techniques of the Lyapunov-Krasovskii functional and the linear matrix inequality (LMI) where quaternion self-conjugate matrices and quaternion positive definite matrices are used. Some new sufficient conditions in the form of quaternion-valued LMI are, respectively, established for the global $\mu $ -stability and exponential stability of the considered QVNN. Besides, some assumptions are presented for the two different methods, which can help to choose quaternion-valued activation functions. Finally, two numerical examples are given to show the feasibility and the effectiveness of the main results.",4
Learning-Based Adaptive Optimal Tracking Control of Strict-Feedback Nonlinear Systems.,"This paper proposes a novel data-driven control approach to address the problem of adaptive optimal tracking for a class of nonlinear systems taking the strict-feedback form. Adaptive dynamic programming (ADP) and nonlinear output regulation theories are integrated for the first time to compute an adaptive near-optimal tracker without any a priori knowledge of the system dynamics. Fundamentally different from adaptive optimal stabilization problems, the solution to a Hamilton-Jacobi-Bellman (HJB) equation, not necessarily a positive definite function, cannot be approximated through the existing iterative methods. This paper proposes a novel policy iteration technique for solving positive semidefinite HJB equations with rigorous convergence analysis. A two-phase data-driven learning method is developed and implemented online by ADP. The efficacy of the proposed adaptive optimal tracking control methodology is demonstrated via a Van der Pol oscillator with time-varying exogenous signals.",4
Extreme Trust Region Policy Optimization for Active Object Recognition.,"In this brief, we develop a deep reinforcement learning method to actively recognize objects by choosing a sequence of actions for an active camera that helps to discriminate between the objects. The method is realized using trust region policy optimization, in which the policy is realized by an extreme learning machine and, therefore, leads to efficient optimization algorithm. The experimental results on the publicly available data set show the advantages of the developed extreme trust region optimization method.",4
Action-Driven Visual Object Tracking With Deep Reinforcement Learning.,"In this paper, we propose an efficient visual tracker, which directly captures a bounding box containing the target object in a video by means of sequential actions learned using deep neural networks. The proposed deep neural network to control tracking actions is pretrained using various training video sequences and fine-tuned during actual tracking for online adaptation to a change of target and background. The pretraining is done by utilizing deep reinforcement learning (RL) as well as supervised learning. The use of RL enables even partially labeled data to be successfully utilized for semisupervised learning. Through the evaluation of the object tracking benchmark data set, the proposed tracker is validated to achieve a competitive performance at three times the speed of existing deep network-based trackers. The fast version of the proposed method, which operates in real time on graphics processing unit, outperforms the state-of-the-art real-time trackers with an accuracy improvement of more than 8%.",4
Multisource Transfer Double DQN Based on Actor Learning.,"Deep reinforcement learning (RL) comprehensively uses the psychological mechanisms of ""trial and error"" and ""reward and punishment"" in RL as well as powerful feature expression and nonlinear mapping in deep learning. Currently, it plays an essential role in the fields of artificial intelligence and machine learning. Since an RL agent needs to constantly interact with its surroundings, the deep Q network (DQN) is inevitably faced with the need to learn numerous network parameters, which results in low learning efficiency. In this paper, a multisource transfer double DQN (MTDDQN) based on actor learning is proposed. The transfer learning technique is integrated with deep RL to make the RL agent collect, summarize, and transfer action knowledge, including policy mimic and feature regression, to the training of related tasks. There exists action overestimation in DQN, i.e., the lower probability limit of action corresponding to the maximum Q value is nonzero. Therefore, the transfer network is trained by using double DQN to eliminate the error accumulation caused by action overestimation. In addition, to avoid negative transfer, i.e., to ensure strong correlations between source and target tasks, a multisource transfer learning mechanism is applied. The Atari2600 game is tested on the arcade learning environment platform to evaluate the feasibility and performance of MTDDQN by comparing it with some mainstream approaches, such as DQN and double DQN. Experiments prove that MTDDQN achieves not only human-like actor learning transfer capability, but also the desired learning efficiency and testing accuracy on target task.",4
Self-Paced Prioritized Curriculum Learning With Coverage Penalty in Deep Reinforcement Learning.,"In this paper, a new training paradigm is proposed for deep reinforcement learning using self-paced prioritized curriculum learning with coverage penalty. The proposed deep curriculum reinforcement learning (DCRL) takes the most advantage of experience replay by adaptively selecting appropriate transitions from replay memory based on the complexity of each transition. The criteria of complexity in DCRL consist of self-paced priority as well as coverage penalty. The self-paced priority reflects the relationship between the temporal-difference error and the difficulty of the current curriculum for sample efficiency. The coverage penalty is taken into account for sample diversity. With comparison to deep Q network (DQN) and prioritized experience replay (PER) methods, the DCRL algorithm is evaluated on Atari 2600 games, and the experimental results show that DCRL outperforms DQN and PER on most of these games. More results further show that the proposed curriculum training paradigm of DCRL is also applicable and effective for other memory-based deep reinforcement learning approaches, such as double DQN and dueling network. All the experimental results demonstrate that DCRL can achieve improved training efficiency and robustness for deep reinforcement learning.",4
Reusable Reinforcement Learning via Shallow Trails.,"Reinforcement learning has shown great success in helping learning agents accomplish tasks autonomously from environment interactions. Meanwhile in many real-world applications, an agent needs to accomplish not only a fixed task but also a range of tasks. For this goal, an agent can learn a metapolicy over a set of training tasks that are drawn from an underlying distribution. By maximizing the total reward summed over all the training tasks, the metapolicy can then be reused in accomplishing test tasks from the same distribution. However, in practice, we face two major obstacles to train and reuse metapolicies well. First, how to identify tasks that are unrelated or even opposite with each other, in order to avoid their mutual interference in the training. Second, how to characterize task features, according to which a metapolicy can be reused. In this paper, we propose the MetA-Policy LEarning (MAPLE) approach that overcomes the two difficulties by introducing the shallow trail. It probes a task by running a roughly trained policy. Using the rewards of the shallow trail, MAPLE automatically groups similar tasks. Moreover, when the task parameters are unknown, the rewards of the shallow trail also serve as task features. Empirical studies on several controlling tasks verify that MAPLE can train metapolicies well and receives high reward on test tasks.",4
Distributed Economic Dispatch in Microgrids Based on Cooperative Reinforcement Learning.,"Microgrids incorporated with distributed generation (DG) units and energy storage (ES) devices are expected to play more and more important roles in the future power systems. Yet, achieving efficient distributed economic dispatch in microgrids is a challenging issue due to the randomness and nonlinear characteristics of DG units and loads. This paper proposes a cooperative reinforcement learning algorithm for distributed economic dispatch in microgrids. Utilizing the learning algorithm can avoid the difficulty of stochastic modeling and high computational complexity. In the cooperative reinforcement learning algorithm, the function approximation is leveraged to deal with the large and continuous state spaces. And a diffusion strategy is incorporated to coordinate the actions of DG units and ES devices. Based on the proposed algorithm, each node in microgrids only needs to communicate with its local neighbors, without relying on any centralized controllers. Algorithm convergence is analyzed, and simulations based on real-world meteorological and load data are conducted to validate the performance of the proposed algorithm.",4
Optimal Fault-Tolerant Control for Discrete-Time Nonlinear Strict-Feedback Systems Based on Adaptive Critic Design.,"This paper investigates the problem of optimal fault-tolerant control (FTC) for a class of unknown nonlinear discrete-time systems with actuator fault in the framework of adaptive critic design (ACD). A pivotal highlight is the adaptive auxiliary signal of the actuator fault, which is designed to offset the effect of the fault. The considered systems are in strict-feedback forms and involve unknown nonlinear functions, which will result in the causal problem. To solve this problem, the original nonlinear systems are transformed into a novel system by employing the diffeomorphism theory. Besides, the action neural networks (ANNs) are utilized to approximate a predefined unknown function in the backstepping design procedure. Combined the strategic utility function and the ACD technique, a reinforcement learning algorithm is proposed to set up an optimal FTC, in which the critic neural networks (CNNs) provide an approximate structure of the cost function. In this case, it not only guarantees the stability of the systems, but also achieves the optimal control performance as well. In the end, two simulation examples are used to show the effectiveness of the proposed optimal FTC strategy.",4
Suboptimal Scheduling in Switched Systems With Continuous-Time Dynamics: A Least Squares Approach.,"Two approximate solutions for optimal control of switched systems with autonomous subsystems and continuous-time dynamics are presented. The first solution formulates a policy iteration (PI) algorithm for the switched systems with recursive least squares. To reduce the computational burden imposed by the PI algorithm, a second solution, called single loop PI, is presented. Online and concurrent training algorithms are discussed for implementing each solution. At last, effectiveness of the presented algorithms is evaluated through numerical simulations.",4
Approximate Dynamic Programming: Combining Regional and Local State Following Approximations.,"An infinite-horizon optimal regulation problem for a control-affine deterministic system is solved online using a local state following (StaF) kernel and a regional model-based reinforcement learning (R-MBRL) method to approximate the value function. Unlike traditional methods such as R-MBRL that aim to approximate the value function over a large compact set, the StaF kernel approach aims to approximate the value function in a local neighborhood of the state that travels within a compact set. In this paper, the value function is approximated using a state-dependent convex combination of the StaF-based and the R-MBRL-based approximations. As the state enters a neighborhood containing the origin, the value function transitions from being approximated by the StaF approach to the R-MBRL approach. Semiglobal uniformly ultimately bounded (SGUUB) convergence of the system states to the origin is established using a Lyapunov-based analysis. Simulation results are provided for two, three, six, and ten-state dynamical systems to demonstrate the scalability and performance of the developed method.",4
Leader-Follower Output Synchronization of Linear Heterogeneous Systems With Active Leader Using Reinforcement Learning.,"This paper develops optimal control protocols for the distributed output synchronization problem of leader-follower multiagent systems with an active leader. Agents are assumed to be heterogeneous with different dynamics and dimensions. The desired trajectory is assumed to be preplanned and is generated by the leader. Other follower agents autonomously synchronize to the leader by interacting with each other using a communication network. The leader is assumed to be active in the sense that it has a nonzero control input so that it can act independently and update its control to keep the followers away from possible danger. A distributed observer is first designed to estimate the leader's state and generate the reference signal for each follower. Then, the output synchronization of leader-follower systems with an active leader is formulated as a distributed optimal tracking problem, and inhomogeneous algebraic Riccati equations (AREs) are derived to solve it. The resulting distributed optimal control protocols not only minimize the steady-state error but also optimize the transient response of the agents. An off-policy reinforcement learning algorithm is developed to solve the inhomogeneous AREs online in real time and without requiring any knowledge of the agents' dynamics. Finally, two simulation examples are conducted to illustrate the effectiveness of the proposed algorithm.",4
Robust ADP Design for Continuous-Time Nonlinear Systems With Output Constraints.,"In this paper, a novel robust adaptive dynamic programming (RADP)-based control strategy is presented for the optimal control of a class of output-constrained continuous-time unknown nonlinear systems. Our contribution includes a step forward beyond the usual optimal control result to show that the output of the plant is always within user-defined bounds. To achieve the new results, an error transformation technique is first established to generate an equivalent nonlinear system, whose asymptotic stability guarantees both the asymptotic stability and the satisfaction of the output restriction of the original system. Furthermore, RADP algorithms are developed to solve the transformed nonlinear optimal control problem with completely unknown dynamics as well as a robust design to guarantee the stability of the closed-loop systems in the presence of unavailable internal dynamic state. Via small-gain theorem, asymptotic stability of the original and transformed nonlinear system is theoretically guaranteed. Finally, comparison results demonstrate the merits of the proposed control policy.",4
Optimal Guaranteed Cost Sliding Mode Control for Constrained-Input Nonlinear Systems With Matched and Unmatched Disturbances.,"Based on integral sliding mode and approximate dynamic programming (ADP) theory, a novel optimal guaranteed cost sliding mode control is designed for constrained-input nonlinear systems with matched and unmatched disturbances. When the system moves on the sliding surface, the optimal guaranteed cost control problem of sliding mode dynamics is transformed into the optimal control problem of a reformulated auxiliary system with a modified cost function. The ADP algorithm based on single critic neural network (NN) is applied to obtain the approximate optimal control law for the auxiliary system. Lyapunov techniques are used to demonstrate the convergence of the NN weight errors. In addition, the derived approximate optimal control is verified to guarantee the sliding mode dynamics system to be stable in the sense of uniform ultimate boundedness. Some simulation results are presented to verify the feasibility of the proposed control scheme.",4
Guided Policy Exploration for Markov Decision Processes Using an Uncertainty-Based Value-of-Information Criterion.,"Reinforcement learning in environments with many action-state pairs is challenging. The issue is the number of episodes needed to thoroughly search the policy space. Most conventional heuristics address this search problem in a stochastic manner. This can leave large portions of the policy space unvisited during the early training stages. In this paper, we propose an uncertainty-based, information-theoretic approach for performing guided stochastic searches that more effectively cover the policy space. Our approach is based on the value of information, a criterion that provides the optimal tradeoff between expected costs and the granularity of the search process. The value of information yields a stochastic routine for choosing actions during learning that can explore the policy space in a coarse to fine manner. We augment this criterion with a state-transition uncertainty factor, which guides the search process into previously unexplored regions of the policy space. We evaluate the uncertainty-based value-of-information policies on the games Centipede and Crossy Road. Our results indicate that our approach yields better performing policies in fewer episodes than stochastic-based exploration strategies. We show that the training rate for our approach can be further improved by using the policy cross entropy to guide our criterion's hyperparameter selection.",4
Applications of Deep Learning and Reinforcement Learning to Biological Data.,"Rapid advances in hardware-based technologies during the past decades have opened up new possibilities for life scientists to gather multimodal data in various application domains, such as omics, bioimaging, medical imaging, and (brain/body)-machine interfaces. These have generated novel opportunities for development of dedicated data-intensive machine learning techniques. In particular, recent research in deep learning (DL), reinforcement learning (RL), and their combination (deep RL) promise to revolutionize the future of artificial intelligence. The growth in computational power accompanied by faster and increased data storage, and declining computing costs have already allowed scientists in various fields to apply these techniques on data sets that were previously intractable owing to their size and complexity. This paper provides a comprehensive survey on the application of DL, RL, and deep RL techniques in mining biological data. In addition, we compare the performances of DL techniques when applied to different data sets across various application domains. Finally, we outline open issues in this challenging research area and discuss future development perspectives.",4
Optimal and Autonomous Control Using Reinforcement Learning: A Survey.,"This paper reviews the current state of the art on reinforcement learning (RL)-based feedback control solutions to optimal regulation and tracking of single and multiagent systems. Existing RL solutions to both optimal and control problems, as well as graphical games, will be reviewed. RL methods learn the solution to optimal control and game problems online and using measured data along the system trajectories. We discuss Q-learning and the integral RL algorithm as core algorithms for discrete-time (DT) and continuous-time (CT) systems, respectively. Moreover, we discuss a new direction of off-policy RL for both CT and DT systems. Finally, we review several applications.",4
Laplacian Echo State Network for Multivariate Time Series Prediction.,"Echo state network is a novel kind of recurrent neural networks, with a trainable linear readout layer and a large fixed recurrent connected hidden layer, which can be used to map the rich dynamics of complex real-world data sets. It has been extensively studied in time series prediction. However, there may be an ill-posed problem caused by the number of real-world training samples less than the size of the hidden layer. In this brief, a Laplacian echo state network (LAESN), is proposed to overcome the ill-posed problem and obtain low-dimensional output weights. First, an echo state network is used to map the multivariate time series into a large reservoir. Then, assuming that an unknown underlying manifold is inside the reservoir, we employ the Laplacian eigenmaps to estimate the manifold by constructing an adjacency graph associated with the reservoir states. Finally, the output weights are calculated by the low-dimensional manifold. In addition, some criteria of transient stability, local controllability, and local observability are given. Experimental results based on two real-world data sets substantiate the effectiveness and characteristics of the proposed LAESN model.",4
Robust Neuro-Optimal Control of Underactuated Snake Robots With Experience Replay.,"In this paper, the problem of path following for underactuated snake robots is investigated by using approximate dynamic programming and neural networks (NNs). The lateral undulatory gait of a snake robot is stabilized in a virtual holonomic constraint manifold through a partial feedback linearizing control law. Based on a dynamic compensator and Line-of-Sight guidance law, the path-following problem is transformed to a regulation problem of a nonlinear system with uncertainties. Subsequently, it is solved by an infinite horizon optimal control scheme using a single critic NN. A novel fluctuating learning algorithm is derived to approximate the associated cost function online and relax the initial stabilizing control requirement. The approximate optimal control input is derived by solving a modified Hamilton-Jacobi-Bellman equation. The conventional persistence of excitation condition is relaxed by using experience replay technique. The proposed control scheme ensures that all states of the snake robot are uniformly ultimate bounded which is analyzed by using the Lyapunov approach, and the tracking error asymptotically converges to a residual set. Simulation results are presented to verify the effectiveness of the proposed method.",4
Stability Analysis of Optimal Adaptive Control Under Value Iteration Using a Stabilizing Initial Policy.,"Adaptive optimal control using value iteration initiated from a stabilizing control policy is theoretically analyzed. The analysis is in terms of stability of the system during the learning stage and includes the system controlled by any fixed control policy and also by an evolving policy. A feature of the presented results is finding subsets of the region of attraction. This is done so that if the initial condition belongs to this region, the entire state trajectory remains within the training region. Therefore, the function approximation results remain reliable, as no extrapolation will be conducted.",4
On Adaptive Boosting for System Identification.,"In the field of machine learning, the algorithm Adaptive Boosting has been successfully applied to a wide range of regression and classification problems. However, to the best of the authors' knowledge, the use of this algorithm to estimate dynamical systems has not been exploited. In this brief, we explore the connection between Adaptive Boosting and system identification, and give examples of an identification method that makes use of this connection. We prove that the resulting estimate converges to the true underlying system for an output-error model structure under reasonable assumptions in the large sample limit and derive a bound of the model mismatch for the noise-free case.",4
A Deep Machine Learning Method for Classifying Cyclic Time Series of Biological Signals Using Time-Growing Neural Network.,"This paper presents a novel method for learning the cyclic contents of stochastic time series: the deep time-growing neural network (DTGNN). The DTGNN combines supervised and unsupervised methods in different levels of learning for an enhanced performance. It is employed by a multiscale learning structure to classify cyclic time series (CTS), in which the dynamic contents of the time series are preserved in an efficient manner. This paper suggests a systematic procedure for finding the design parameter of the classification method for a one-versus-multiple class application. A novel validation method is also suggested for evaluating the structural risk, both in a quantitative and a qualitative manner. The effect of the DTGNN on the performance of the classifier is statistically validated through the repeated random subsampling using different sets of CTS, from different medical applications. The validation involves four medical databases, comprised of 108 recordings of the electroencephalogram signal, 90 recordings of the electromyogram signal, 130 recordings of the heart sound signal, and 50 recordings of the respiratory sound signal. Results of the statistical validations show that the DTGNN significantly improves the performance of the classification and also exhibits an optimal structural risk.",4
Transductive Zero-Shot Learning With Adaptive Structural Embedding.,"Zero-shot learning (ZSL) endows the computer vision system with the inferential capability to recognize new categories that have never seen before. Two fundamental challenges in it are visual-semantic embedding and domain adaptation in cross-modality learning and unseen class prediction steps, respectively. This paper presents two corresponding methods named Adaptive STructural Embedding (ASTE) and Self-PAced Selective Strategy (SPASS) for both challenges. Specifically, ASTE formulates the visual-semantic interactions in a latent structural support vector machine framework by adaptively adjusting the slack variables to embody different reliablenesses among training instances. To alleviate the domain shift problem in ZSL, SPASS borrows the idea from self-paced learning by iteratively selecting the unseen instances from reliable to less reliable to gradually adapt the knowledge from the seen domain to the unseen domain. Consequently, by combining SPASS and ASTE, we present a self-paced Transductive ASTE (TASTE) method to progressively reinforce the classification capacity. Extensive experiments on three benchmark data sets (i.e., AwA, CUB, and aPY) demonstrate the superiorities of ASTE and TASTE. Furthermore, we also propose a fast training (FT) strategy to improve the efficiency of most existing ZSL methods. The FT strategy is surprisingly simple and general enough, which speeds up the training time of most existing ZSL methods by 4~300 times while holding the previous performance.",4
Universal Approximation by Using the Correntropy Objective Function.,"Several objective functions have been proposed in the literature to adjust the input parameters of a node in constructive networks. Furthermore, many researchers have focused on the universal approximation capability of the network based on the existing objective functions. In this brief, we use a correntropy measure based on the sigmoid kernel in the objective function to adjust the input parameters of a newly added node in a cascade network. The proposed network is shown to be capable of approximating any continuous nonlinear mapping with probability one in a compact input sample space. Thus, the convergence is guaranteed. The performance of our method was compared with that of eight different objective functions, as well as with an existing one hidden layer feedforward network on several real regression data sets with and without impulsive noise. The experimental results indicate the benefits of using a correntropy measure in reducing the root mean square error and increasing the robustness to noise.",4
Bayesian Nonparametric Regression Modeling of Panel Data for Sequential Classification.,"This paper proposes a Bayesian nonparametric regression model of panel data for sequential pattern classification. The proposed method provides a flexible and parsimonious model that allows both time-independent spatial variables and time-dependent exogenous variables to be predictors. Not only this method improves the accuracy of parameter estimation for limited data, but also it facilitates model interpretation by identifying statistically significant predictors with hypothesis testing. Moreover, as the data length approaches infinity, posterior consistency of the model is guaranteed for general data-generating processes under regular conditions. The resulting model of panel data can also be used for sequential classification. The proposed method has been tested by numerical simulation, then validated on an econometric public data set, and subsequently validated for detection of combustion instabilities with experimental data that have been generated in a laboratory environment.",4
Dimensionality Reduction in Multiple Ordinal Regression.,"Supervised dimensionality reduction (DR) plays an important role in learning systems with high-dimensional data. It projects the data into a low-dimensional subspace and keeps the projected data distinguishable in different classes. In addition to preserving the discriminant information for binary or multiple classes, some real-world applications also require keeping the preference degrees of assigning the data to multiple aspects, e.g., to keep the different intensities for co-occurring facial expressions or the product ratings in different aspects. To address this issue, we propose a novel supervised DR method for DR in multiple ordinal regression (DRMOR), whose projected subspace preserves all the ordinal information in multiple aspects or labels. We formulate this problem as a joint optimization framework to simultaneously perform DR and ordinal regression. In contrast to most existing DR methods, which are conducted independently of the subsequent classification or ordinal regression, the proposed framework fully benefits from both of the procedures. We experimentally demonstrate that the proposed DRMOR method (DRMOR-M) well preserves the ordinal information from all the aspects or labels in the learned subspace. Moreover, DRMOR-M exhibits advantages compared with representative DR or ordinal regression algorithms on three standard data sets.",4
Classification of Imbalanced Data by Oversampling in Kernel Space of Support Vector Machines.,"Historical data sets for fault stage diagnosis in industrial machines are often imbalanced and consist of multiple categories or classes. Learning discriminative models from such data sets is challenging due to the lack of representative data and the bias of traditional classifiers toward the majority class. Sampling methods like synthetic minority oversampling technique (SMOTE) have been traditionally used for such problems to artificially balance the data set before being trained by a classifier. This paper proposes a weighted kernel-based SMOTE (WK-SMOTE) that overcomes the limitation of SMOTE for nonlinear problems by oversampling in the feature space of support vector machine (SVM) classifier. The proposed oversampling algorithm along with a cost-sensitive SVM formulation is shown to improve performance when compared to other baseline methods on multiple benchmark imbalanced data sets. In addition, a hierarchical framework is developed for multiclass imbalanced problems that have a progressive class order. The proposed WK-SMOTE and hierarchical framework are validated on a real-world industrial fault detection problem to identify deterioration in insulation of high-voltage equipments.",4
A Novel Error-Compensation Control for a Class of High-Order Nonlinear Systems With Input Delay.,"A novel tracking error-compensation-based adaptive neural control scheme is proposed for a class of high-order nonlinear systems with completely unknown nonlinearities and input delay. In the tracking errors of existing papers, there exist the following difficulties: first, output curve always lags behind the desired trajectory, second, some big peak errors cause a decrease in tracking precision, and third, a big initial value of the modified tracking error can make the closed-loop system unstable. To tackle them, three corresponding error-compensation terms are constructed, including a prediction and compensation term, an auxiliary signal produced by the constructed auxiliary system, and a damping term. However, inequality amplification caused by high order will weaken the effectiveness of the proposed error-compensation scheme, and the control precision will decrease under an assumption that the lower bounds of the unknown control coefficients should be exactly known. To overcome aforementioned difficulties, in the derivation of the first virtual control law, the radial basis function neural network is used to approximate a hybrid term online constructed by unknown nonlinearities, a lumped control coefficient achieved by state transformation, and the dynamic of the proposed error-compensation terms and desired signal. Meanwhile, input delay is coped with a robust compensation signal constructed based on a finite integral of the past control values. Finally, it is proven that all the closed-loop signals are semiglobally uniformly ultimately bounded. Simulation results demonstrate the effectiveness of the proposed method.",4
Online Heterogeneous Transfer by Hedge Ensemble of Offline and Online Decisions.,"In this paper, we study the online heterogeneous transfer (OHT) learning problem, where the target data of interest arrive in an online manner, while the source data and auxiliary co-occurrence data are from offline sources and can be easily annotated. OHT is very challenging, since the feature spaces of the source and target domains are different. To address this, we propose a novel technique called OHT by hedge ensemble by exploiting both offline knowledge and online knowledge of different domains. To this end, we build an offline decision function based on a heterogeneous similarity that is constructed using labeled source data and unlabeled auxiliary co-occurrence data. After that, an online decision function is learned from the target data. Last, we employ a hedge weighting strategy to combine the offline and online decision functions to exploit knowledge from the source and target domains of different feature spaces. We also provide a theoretical analysis regarding the mistake bounds of the proposed approach. Comprehensive experiments on three real-world data sets demonstrate the effectiveness of the proposed technique.",4
Extensions to Online Feature Selection Using Bagging and Boosting.,"Feature subset selection can be used to sieve through large volumes of data and discover the most informative subset of variables for a particular learning problem. Yet, due to memory and other resource constraints (e.g., CPU availability), many of the state-of-the-art feature subset selection methods cannot be extended to high dimensional data, or data sets with an extremely large volume of instances. In this brief, we extend online feature selection (OFS), a recently introduced approach that uses partial feature information, by developing an ensemble of online linear models to make predictions. The OFS approach employs a linear model as the base classifier, which allows the $l_{0}$ -norm of the parameter vector to be constrained to perform feature selection leading to sparse linear models. We demonstrate that the proposed ensemble model typically yields a smaller error rate than any single linear model, while maintaining the same level of sparsity and complexity at the time of testing.",4
Adaptive Constrained Optimal Control Design for Data-Based Nonlinear Discrete-Time Systems With Critic-Only Structure.,"Reinforcement learning has proved to be a powerful tool to solve optimal control problems over the past few years. However, the data-based constrained optimal control problem of nonaffine nonlinear discrete-time systems has rarely been studied yet. To solve this problem, an adaptive optimal control approach is developed by using the value iteration-based Q-learning (VIQL) with the critic-only structure. Most of the existing constrained control methods require the use of a certain performance index and only suit for linear or affine nonlinear systems, which is unreasonable in practice. To overcome this problem, the system transformation is first introduced with the general performance index. Then, the constrained optimal control problem is converted to an unconstrained optimal control problem. By introducing the action-state value function, i.e., Q-function, the VIQL algorithm is proposed to learn the optimal Q-function of the data-based unconstrained optimal control problem. The convergence results of the VIQL algorithm are established with an easy-to-realize initial condition . To implement the VIQL algorithm, the critic-only structure is developed, where only one neural network is required to approximate the Q-function. The converged Q-function obtained from the critic-only VIQL method is employed to design the adaptive constrained optimal controller based on the gradient descent scheme. Finally, the effectiveness of the developed adaptive control method is tested on three examples with computer simulation.",4
Global Asymptotic Stability for Delayed Neural Networks Using an Integral Inequality Based on Nonorthogonal Polynomials.,"This brief is concerned with global asymptotic stability of a neural network with a time-varying delay. First, by introducing an auxiliary vector with some nonorthogonal polynomials, a slack-matrix-based integral inequality is established, which includes some existing one as its special case. Second, a novel Lyapunov-Krasovskii functional is constructed to suit for the use of the obtained integral inequality. As a result, a less conservative stability criterion is derived, whose effectiveness is finally demonstrated through two well-used numerical examples.",4
Continuous Dropout.,"Dropout has been proven to be an effective algorithm for training robust deep networks because of its ability to prevent overfitting by avoiding the co-adaptation of feature detectors. Current explanations of dropout include bagging, naive Bayes, regularization, and sex in evolution. According to the activation patterns of neurons in the human brain, when faced with different situations, the firing rates of neurons are random and continuous, not binary as current dropout does. Inspired by this phenomenon, we extend the traditional binary dropout to continuous dropout. On the one hand, continuous dropout is considerably closer to the activation characteristics of neurons in the human brain than traditional binary dropout. On the other hand, we demonstrate that continuous dropout has the property of avoiding the co-adaptation of feature detectors, which suggests that we can extract more independent feature detectors for model averaging in the test stage. We introduce the proposed continuous dropout to a feedforward neural network and comprehensively compare it with binary dropout, adaptive dropout, and DropConnect on Modified National Institute of Standards and Technology, Canadian Institute for Advanced Research-10, Street View House Numbers, NORB, and ImageNet large scale visual recognition competition-12. Thorough experiments demonstrate that our method performs better in preventing the co-adaptation of feature detectors and improves test performance.",4
Heterogeneous Multitask Metric Learning Across Multiple Domains.,"Distance metric learning plays a crucial role in diverse machine learning algorithms and applications. When the labeled information in a target domain is limited, transfer metric learning (TML) helps to learn the metric by leveraging the sufficient information from other related domains. Multitask metric learning (MTML), which can be regarded as a special case of TML, performs transfer across all related domains. Current TML tools usually assume that the same feature representation is exploited for different domains. However, in real-world applications, data may be drawn from heterogeneous domains. Heterogeneous transfer learning approaches can be adopted to remedy this drawback by deriving a metric from the learned transformation across different domains. However, they are often limited in that only two domains can be handled. To appropriately handle multiple domains, we develop a novel heterogeneous MTML (HMTML) framework. In HMTML, the metrics of all different domains are learned together. The transformations derived from the metrics are utilized to induce a common subspace, and the high-order covariance among the predictive structures of these domains is maximized in this subspace. There do exist a few heterogeneous transfer learning approaches that deal with multiple domains, but the high-order statistics (correlation information), which can only be exploited by simultaneously examining all domains, is ignored in these approaches. Compared with them, the proposed HMTML can effectively explore such high-order information, thus obtaining more reliable feature transformations and metrics. Effectiveness of our method is validated by the extensive and intensive experiments on text categorization, scene classification, and social image annotation.",4
L1-Norm Distance Minimization-Based Fast Robust Twin Support Vector $k$ -Plane Clustering.,"Twin support vector clustering (TWSVC) is a recently proposed powerful k-plane clustering method. It, however, is prone to outliers due to the utilization of squared L2-norm distance. Besides, TWSVC is computationally expensive, attributing to the need of solving a series of constrained quadratic programming problems (CQPPs) in learning each clustering plane. To address these problems, this brief first develops a new k-plane clustering method called L1-norm distance minimization-based robust TWSVC by using robust L1-norm distance. To achieve this objective, we propose a novel iterative algorithm. In each iteration of the algorithm, one CQPP is solved. To speed up the computation of TWSVC and simultaneously inherit the merit of robustness, we further propose Fast RTWSVC and design an effective iterative algorithm to optimize it. Only a system of linear equations needs to be computed in each iteration. These characteristics make our methods more powerful and efficient than TWSVC. We also conduct some insightful analysis on the existence of local minimum and the convergence of the proposed algorithms. Theoretical insights and effectiveness of our methods are further supported by promising experimental results.",4
Detection of Sources in Non-Negative Blind Source Separation by Minimum Description Length Criterion.,"While non-negative blind source separation (nBSS) has found many successful applications in science and engineering, model order selection, determining the number of sources, remains a critical yet unresolved problem. Various model order selection methods have been proposed and applied to real-world data sets but with limited success, with both order over- and under-estimation reported. By studying existing schemes, we have found that the unsatisfactory results are mainly due to invalid assumptions, model oversimplification, subjective thresholding, and/or to assumptions made solely for mathematical convenience. Building on our earlier work that reformulated model order selection for nBSS with more realistic assumptions and models, we report a newly and formally revised model order selection criterion rooted in the minimum description length (MDL) principle. Adopting widely invoked assumptions for achieving a unique nBSS solution, we consider the mixing matrix as consisting of deterministic unknowns, with the source signals following a multivariate Dirichlet distribution. We derive a computationally efficient, stochastic algorithm to obtain approximate maximum-likelihood estimates of model parameters and apply Monte Carlo integration to determine the description length. Our modeling and estimation strategy exploits the characteristic geometry of the data simplex in nBSS. We validate our nBSS-MDL criterion through extensive simulation studies and on four real-world data sets, demonstrating its strong performance and general applicability to nBSS. The proposed nBSS-MDL criterion consistently detects the true number of sources, in all of our case studies.",4
Nonparametric Coupled Bayesian Dictionary and Classifier Learning for Hyperspectral Classification.,"We present a principled approach to learn a discriminative dictionary along a linear classifier for hyperspectral classification. Our approach places Gaussian Process priors over the dictionary to account for the relative smoothness of the natural spectra, whereas the classifier parameters are sampled from multivariate Gaussians. We employ two Beta-Bernoulli processes to jointly infer the dictionary and the classifier. These processes are coupled under the same sets of Bernoulli distributions. In our approach, these distributions signify the frequency of the dictionary atom usage in representing class-specific training spectra, which also makes the dictionary discriminative. Due to the coupling between the dictionary and the classifier, the popularity of the atoms for representing different classes gets encoded into the classifier. This helps in predicting the class labels of test spectra that are first represented over the dictionary by solving a simultaneous sparse optimization problem. The labels of the spectra are predicted by feeding the resulting representations to the classifier. Our approach exploits the nonparametric Bayesian framework to automatically infer the dictionary size-the key parameter in discriminative dictionary learning. Moreover, it also has the desirable property of adaptively learning the association between the dictionary atoms and the class labels by itself. We use Gibbs sampling to infer the posterior probability distributions over the dictionary and the classifier under the proposed model, for which, we derive analytical expressions. To establish the effectiveness of our approach, we test it on benchmark hyperspectral images. The classification performance is compared with the state-of-the-art dictionary learning-based classification methods.",4
Neural Network Learning and Robust Stabilization of Nonlinear Systems With Dynamic Uncertainties.,"Due to the existence of dynamical uncertainties, it is important to pay attention to the robustness of nonlinear control systems, especially when designing adaptive critic control strategies. In this paper, based on the neural network learning component, the robust stabilization scheme of nonlinear systems with general uncertainties is developed. Through system transformation and employing adaptive critic technique, the approximate optimal controller of the nominal plant can be applied to accomplish robust stabilization for the original uncertain dynamics. The neural network weight vector is very convenient to initialize by virtue of the improved critic learning formulation. Under the action of the approximate optimal control law, the stability issues for the closed-loop form of nominal and uncertain plants are analyzed, respectively. Simulation illustrations via a typical nonlinear system and a practical power system are included to verify the control performance.",4
Data-Driven Robust M-LS-SVR-Based NARX Modeling for Estimation and Control of Molten Iron Quality Indices in Blast Furnace Ironmaking.,"Optimal operation of an industrial blast furnace (BF) ironmaking process largely depends on a reliable measurement of molten iron quality (MIQ) indices, which are not feasible using the conventional sensors. This paper proposes a novel data-driven robust modeling method for the online estimation and control of MIQ indices. First, a nonlinear autoregressive exogenous (NARX) model is constructed for the MIQ indices to completely capture the nonlinear dynamics of the BF process. Then, considering that the standard least-squares support vector regression (LS-SVR) cannot directly cope with the multioutput problem, a multitask transfer learning is proposed to design a novel multioutput LS-SVR (M-LS-SVR) for the learning of the NARX model. Furthermore, a novel M-estimator is proposed to reduce the interference of outliers and improve the robustness of the M-LS-SVR model. Since the weights of different outlier data are properly given by the weight function, their corresponding contributions on modeling can properly be distinguished, thus a robust modeling result can be achieved. Finally, a novel multiobjective evaluation index on the modeling performance is developed by comprehensively considering the root-mean-square error of modeling and the correlation coefficient on trend fitting, based on which the nondominated sorting genetic algorithm II is used to globally optimize the model parameters. Both experiments using industrial data and industrial applications illustrate that the proposed method can eliminate the adverse effect caused by the fluctuation of data in BF process efficiently. This indicates its stronger robustness and higher accuracy. Moreover, control testing shows that the developed model can be well applied to realize data-driven control of the BF process.",4
Image-Specific Classification With Local and Global Discriminations.,"Most image classification methods try to learn classifiers for each class using training images alone. Due to the interclass and intraclass variations, it would be more effective to take the testing images into consideration for classifier learning. In this brief, we propose a novel image-specific classification method by combing the local and global discriminations of training images. We adaptively train classifier for each testing image instead of generating classifiers for each class with training images alone. For each testing image, we first select its ${k}$ nearest neighbors in the training set with the corresponding labels for local classifier training. This helps to model the distinctive characters of each testing image. Besides, we also use all the training images for global discrimination modeling. The local and global discriminations are combined for final classification. In this way, we could not only model the specific character of each testing image but also avoid the local optimum by jointly considering all the training images. To evaluate the usefulness of the proposed image-specific classification with local and global discrimination (ISC-LG) method, we conduct image classification experiments on several public image data sets. The superior performances over other baseline methods prove the effectiveness of the proposed ISC-LG method.",4
A Novel Pruning Algorithm for Smoothing Feedforward Neural Networks Based on Group Lasso Method.,"In this paper, we propose four new variants of the backpropagation algorithm to improve the generalization ability for feedforward neural networks. The basic idea of these methods stems from the Group Lasso concept which deals with the variable selection problem at the group level. There are two main drawbacks when the Group Lasso penalty has been directly employed during network training. They are numerical oscillations and theoretical challenges in computing the gradients at the origin. To overcome these obstacles, smoothing functions have then been introduced by approximating the Group Lasso penalty. Numerical experiments for classification and regression problems demonstrate that the proposed algorithms perform better than the other three classical penalization methods, Weight Decay, Weight Elimination, and Approximate Smoother, on both generalization and pruning efficiency. In addition, detailed simulations based on a specific data set have been performed to compare with some other common pruning strategies, which verify the advantages of the proposed algorithm. The pruning abilities of the proposed strategy have been investigated in detail for a relatively large data set, MNIST, in terms of various smoothing approximation cases.",4
Deep Learning of Constrained Autoencoders for Enhanced Understanding of Data.,"Unsupervised feature extractors are known to perform an efficient and discriminative representation of data. Insight into the mappings they perform and human ability to understand them, however, remain very limited. This is especially prominent when multilayer deep learning architectures are used. This paper demonstrates how to remove these bottlenecks within the architecture of non-negativity constrained autoencoder. It is shown that using both L1 and L2 regularizations that induce non-negativity of weights, most of the weights in the network become constrained to be non-negative, thereby resulting into a more understandable structure with minute deterioration in classification accuracy. Also, this proposed approach extracts features that are more sparse and produces additional output layer sparsification. The method is analyzed for accuracy and feature interpretation on the MNIST data, the NORB normalized uniform object data, and the Reuters text categorization data set.",4
Support Vector Data Descriptions and $k$ -Means Clustering: One Class?,"We present ClusterSVDD, a methodology that unifies support vector data descriptions (SVDDs) and $k$ -means clustering into a single formulation. This allows both methods to benefit from one another, i.e., by adding flexibility using multiple spheres for SVDDs and increasing anomaly resistance and flexibility through kernels to $k$ -means. In particular, our approach leads to a new interpretation of $k$ -means as a regularized mode seeking algorithm. The unifying formulation further allows for deriving new algorithms by transferring knowledge from one-class learning settings to clustering settings and vice versa. As a showcase, we derive a clustering method for structured data based on a one-class learning scenario. Additionally, our formulation can be solved via a particularly simple optimization scheme. We evaluate our approach empirically to highlight some of the proposed benefits on artificially generated data, as well as on real-world problems, and provide a Python software package comprising various implementations of primal and dual SVDD as well as our proposed ClusterSVDD.",4
Learning Methods for Dynamic Topic Modeling in Automated Behavior Analysis.,"Semisupervised and unsupervised systems provide operators with invaluable support and can tremendously reduce the operators' load. In the light of the necessity to process large volumes of video data and provide autonomous decisions, this paper proposes new learning algorithms for activity analysis in video. The activities and behaviors are described by a dynamic topic model. Two novel learning algorithms based on the expectation maximization approach and variational Bayes inference are proposed. Theoretical derivations of the posterior estimates of model parameters are given. The designed learning algorithms are compared with the Gibbs sampling inference scheme introduced earlier in the literature. A detailed comparison of the learning algorithms is presented on real video data. We also propose an anomaly localization procedure, elegantly embedded in the topic modeling framework. It is shown that the developed learning algorithms can achieve 95% success rate. The proposed framework can be applied to a number of areas, including transportation systems, security, and surveillance.",4
Online Recorded Data-Based Composite Neural Control of Strict-Feedback Systems With Application to Hypersonic Flight Dynamics.,"This paper investigates the online recorded data-based composite neural control of uncertain strict-feedback systems using the backstepping framework. In each step of the virtual control design, neural network (NN) is employed for uncertainty approximation. In previous works, most designs are directly toward system stability ignoring the fact how the NN is working as an approximator. In this paper, to enhance the learning ability, a novel prediction error signal is constructed to provide additional correction information for NN weight update using online recorded data. In this way, the neural approximation precision is highly improved, and the convergence speed can be faster. Furthermore, the sliding mode differentiator is employed to approximate the derivative of the virtual control signal, and thus, the complex analysis of the backstepping design can be avoided. The closed-loop stability is rigorously established, and the boundedness of the tracking error can be guaranteed. Through simulation of hypersonic flight dynamics, the proposed approach exhibits better tracking performance.",4
AdOn HDP-HMM: An Adaptive Online Model for Segmentation and Classification of Sequential Data.,"Recent years have witnessed an increasing need for the automated classification of sequential data, such as activities of daily living, social media interactions, financial series, and others. With the continuous flow of new data, it is critical to classify the observations on-the-fly and without being limited by a predetermined number of classes. In addition, a model should be able to update its parameters in response to a possible evolution in the distributions of the classes. This compelling problem, however, does not seem to have been adequately addressed in the literature, since most studies focus on offline classification over predefined class sets. In this paper, we present a principled solution for this problem based on an adaptive online system leveraging Markov switching models and hierarchical Dirichlet process priors. This adaptive online approach is capable of classifying the sequential data over an unlimited number of classes while meeting the memory and delay constraints typical of streaming contexts. In this paper, we introduce an adaptive ""learning rate"" that is responsible for balancing the extent to which the model retains its previous parameters or adapts to new observations. Experimental results on stationary and evolving synthetic data and two video data sets, TUM Assistive Kitchen and collated Weizmann, show a remarkable performance in terms of segmentation and classification, particularly for sequences from evolutionary distributions and/or those containing previously unseen classes.",4
Multiple Structure-View Learning for Graph Classification.,"Many applications involve objects containing structure and rich content information, each describing different feature aspects of the object. Graph learning and classification is a common tool for handling such objects. To date, existing graph classification has been limited to the single-graph setting with each object being represented as one graph from a single structure-view. This inherently limits its use to the classification of complicated objects containing complex structures and uncertain labels. In this paper, we advance graph classification to handle multigraph learning for complicated objects from multiple structure views, where each object is represented as a bag containing several graphs and the label is only available for each graph bag but not individual graphs inside the bag. To learn such graph classification models, we propose a multistructure-view bag constrained learning (MSVBL) algorithm, which aims to explore substructure features across multiple structure views for learning. By enabling joint regularization across multiple structure views and enforcing labeling constraints at the bag and graph levels, MSVBL is able to discover the most effective substructure features across all structure views. Experiments and comparisons on real-world data sets validate and demonstrate the superior performance of MSVBL in representing complicated objects as multigraph for classification, e.g., MSVBL outperforms the state-of-the-art multiview graph classification and multiview multi-instance learning approaches.",4
Haze Removal Using Radial Basis Function Networks for Visibility Restoration Applications.,"Restoration of visibility in hazy images is the first relevant step of information analysis in many outdoor computer vision applications. To this aim, the restored image must feature clear visibility with sufficient brightness and visible edges, while avoiding the production of noticeable artifacts. In this paper, we propose a haze removal approach based on the radial basis function (RBF) through artificial neural networks dedicated to effectively removing haze formation while retaining not only the visible edges but also the brightness of restored images. Unlike traditional haze-removal methods that consist of single atmospheric veils, the multiatmospheric veil is generated and then dynamically learned by the neurons of the proposed RBF networks according to the scene complexity. Through this process, more visible edges are retained in the restored images. Subsequently, the activation function during the testing process is employed to represent the brightness of the restored image. We compare the proposed method with the other state-of-the-art haze-removal methods and report experimental results in terms of qualitative and quantitative evaluations for benchmark color images captured in typical hazy weather conditions. The experimental results demonstrate that the proposed method is able to produce brighter and more vivid haze-free images with more visible edges than can the other state-of-the-art methods.",4
Dissipativity and Synchronization of Generalized BAM Neural Networks With Multivariate Discontinuous Activations.,"This paper is concerned with the dissipativity and synchronization problems of a class of delayed bidirectional associative memory (BAM) neural networks in which neuron activations are modeled by discontinuous bivariate functions. First, the concept of the Filippov solution is extended to functional differential equations with discontinuous right-hand sides and mixed delays via functional differential inclusions. The global dissipativity of the Filippov solution to the considered BAM neural networks is proven using generalized Halanay inequalities and matrix measure approaches. Second, to realize global exponential complete synchronization of BAM neural networks with multivariate discontinuous activations, discontinuous state feedback controllers are designed using functional differential inclusions theory and nonsmooth analysis theory with generalized Lyapunov functional method. Finally, several numerical examples are provided to demonstrate the applicability and effectiveness of our proposed results.",4
Deep Manifold Learning Combined With Convolutional Neural Networks for Action Recognition.,"Learning deep representations have been applied in action recognition widely. However, there have been a few investigations on how to utilize the structural manifold information among different action videos to enhance the recognition accuracy and efficiency. In this paper, we propose to incorporate the manifold of training samples into deep learning, which is defined as deep manifold learning (DML). The proposed DML framework can be adapted to most existing deep networks to learn more discriminative features for action recognition. When applied to a convolutional neural network, DML embeds the previous convolutional layer's manifold into the next convolutional layer; thus, the discriminative capacity of the next layer can be promoted. We also apply the DML on a restricted Boltzmann machine, which can alleviate the overfitting problem. Experimental results on four standard action databases (i.e., UCF101, HMDB51, KTH, and UCF sports) show that the proposed method outperforms the state-of-the-art methods.",4
Jointly Learning Structured Analysis Discriminative Dictionary and Analysis Multiclass Classifier.,"In this paper, we propose an analysis mechanism-based structured analysis discriminative dictionary learning analysis discriminative dictionary learning, framework. The ADDL seamlessly integrates ADDL, analysis representation, and analysis classifier training into a unified model. The applied analysis mechanism can make sure that the learned dictionaries, representations, and linear classifiers over different classes are independent and discriminating as much as possible. The dictionary is obtained by minimizing a reconstruction error and an analytical incoherence promoting term that encourages the subdictionaries associated with different classes to be independent. To obtain the representation coefficients, ADDL imposes a sparse -norm constraint on the coding coefficients instead of using or norm, since the - or -norm constraint applied in most existing DL criteria makes the training phase time consuming. The code-extraction projection that bridges data with the sparse codes by extracting special features from the given samples is calculated via minimizing a sparse code approximation term. Then we compute a linear classifier based on the approximated sparse codes by an analysis mechanism to simultaneously consider the classification and representation powers. Thus, the classification approach of our model is very efficient, because it can avoid the extra time-consuming sparse reconstruction process with trained dictionary for each new test data as most existing DL algorithms. Simulations on real image databases demonstrate that our ADDL model can obtain superior performance over other state of the arts.",4
Efficient Online Learning Algorithms Based on LSTM Neural Networks.,"We investigate online nonlinear regression and introduce novel regression structures based on the long short term memory (LSTM) networks. For the introduced structures, we also provide highly efficient and effective online training methods. To train these novel LSTM-based structures, we put the underlying architecture in a state space form and introduce highly efficient and effective particle filtering (PF)-based updates. We also provide stochastic gradient descent and extended Kalman filter-based updates. Our PF-based training method guarantees convergence to the optimal parameter estimation in the mean square error sense provided that we have a sufficient number of particles and satisfy certain technical conditions. More importantly, we achieve this performance with a computational complexity in the order of the first-order gradient-based methods by controlling the number of particles. Since our approach is generic, we also introduce a gated recurrent unit (GRU)-based approach by directly replacing the LSTM architecture with the GRU architecture, where we demonstrate the superiority of our LSTM-based approach in the sequential prediction task via different real life data sets. In addition, the experimental results illustrate significant performance improvements achieved by the introduced algorithms with respect to the conventional methods over several different benchmark real life data sets.",4
Online Density Estimation of Nonstationary Sources Using Exponential Family of Distributions.,"We investigate online probability density estimation (or learning) of nonstationary (and memoryless) sources using exponential family of distributions. To this end, we introduce a truly sequential algorithm that achieves Hannan-consistent log-loss regret performance against true probability distribution without requiring any information about the observation sequence (e.g., the time horizon $T$ and the drift of the underlying distribution $C$ ) to optimize its parameters. Our results are guaranteed to hold in an individual sequence manner. Our log-loss performance with respect to the true probability density has regret bounds of $O(({CT})^{1/2})$ , where $C$ is the total change (drift) in the natural parameters of the underlying distribution. To achieve this, we design a variety of probability density estimators with exponentially quantized learning rates and merge them with a mixture-of-experts notion. Hence, we achieve this square-root regret with computational complexity only logarithmic in the time horizon. Thus, our algorithm can be efficiently used in big data applications. Apart from the regret bounds, through synthetic and real-life experiments, we demonstrate substantial performance gains with respect to the state-of-the-art probability density estimation algorithms in the literature.",4
Credit Card Fraud Detection: A Realistic Modeling and a Novel Learning Strategy.,"Detecting frauds in credit card transactions is perhaps one of the best testbeds for computational intelligence algorithms. In fact, this problem involves a number of relevant challenges, namely: concept drift (customers' habits evolve and fraudsters change their strategies over time), class imbalance (genuine transactions far outnumber frauds), and verification latency (only a small set of transactions are timely checked by investigators). However, the vast majority of learning algorithms that have been proposed for fraud detection rely on assumptions that hardly hold in a real-world fraud-detection system (FDS). This lack of realism concerns two main aspects: 1) the way and timing with which supervised information is provided and 2) the measures used to assess fraud-detection performance. This paper has three major contributions. First, we propose, with the help of our industrial partner, a formalization of the fraud-detection problem that realistically describes the operating conditions of FDSs that everyday analyze massive streams of credit card transactions. We also illustrate the most appropriate performance measures to be used for fraud-detection purposes. Second, we design and assess a novel learning strategy that effectively addresses class imbalance, concept drift, and verification latency. Third, in our experiments, we demonstrate the impact of class unbalance and concept drift in a real-world data stream containing more than 75 million transactions, authorized over a time window of three years.",4
Finite-Time Synchronization of Discontinuous Neural Networks With Delays and Mismatched Parameters.,"This paper investigates the problem of finite-time drive-response synchronization for a class of neural networks with discontinuous activations, time-varying discrete and infinite-time distributed delays, and mismatched parameters. In order to cope with the difficulties induced by discontinuous activations, time delays, as well as mismatched parameters simultaneously, new 1-norm-based analytical techniques are developed. Both state feedback and adaptive controllers with and without the sign function are designed. Based on differential inclusion theory and Lyapunov functional method, several sufficient conditions on the finite-time synchronization are obtained. Our results show that the controllers with a sign function can reduce the conservativeness of control gains and the controllers without a sign function can overcome the chattering phenomenon. Numerical examples are given to show the effectiveness of the theoretical analysis.",4
Partial-Nodes-Based State Estimation for Complex Networks With Unbounded Distributed Delays.,"In this brief, the new problem of partial-nodes-based (PNB) state estimation problem is investigated for a class of complex network with unbounded distributed delays and energy-bounded measurement noises. The main novelty lies in that the states of the complex network are estimated through measurement outputs of a fraction of the network nodes. Such fraction of the nodes is determined by either the practical availability or the computational necessity. The PNB state estimator is designed such that the error dynamics of the network state estimation is exponentially ultimately bounded in the presence of measurement errors. Sufficient conditions are established to ensure the existence of the PNB state estimators and then the explicit expression of the gain matrices of such estimators is characterized. When the network measurements are free of noises, the main results specialize to the case of exponential stability for error dynamics. Numerical examples are presented to verify the theoretical results.",4
Self-Weighted Supervised Discriminative Feature Selection.,"In this brief, a novel self-weighted orthogonal linear discriminant analysis (SOLDA) problem is proposed, and a self-weighted supervised discriminative feature selection (SSD-FS) method is derived by introducing sparsity-inducing regularization to the proposed SOLDA problem. By using the row-sparse projection, the proposed SSD-FS method is superior to multiple sparse feature selection approaches, which can overly suppress the nonzero rows such that the associated features are insufficient for selection. More specifically, the orthogonal constraint ensures the minimal number of selectable features for the proposed SSD-FS method. In addition, the proposed feature selection method is able to harness the discriminant power such that the discriminative features are selected. Consequently, the effectiveness of the proposed SSD-FS method is validated theoretically and experimentally.",4
Adaptive Approximation-Based Regulation Control for a Class of Uncertain Nonlinear Systems Without Feedback Linearizability.,"In this paper, for a general class of uncertain nonlinear (cascade) systems, including unknown dynamics, which are not feedback linearizable and cannot be solved by existing approaches, an innovative adaptive approximation-based regulation control (AARC) scheme is developed. Within the framework of adding a power integrator (API), by deriving adaptive laws for output weights and prediction error compensation pertaining to single-hidden-layer feedforward network (SLFN) from the Lyapunov synthesis, a series of SLFN-based approximators are explicitly constructed to exactly dominate completely unknown dynamics. By the virtue of significant advancements on the API technique, an adaptive API methodology is eventually established in combination with SLFN-based adaptive approximators, and it contributes to a recursive mechanism for the AARC scheme. As a consequence, the output regulation error can asymptotically converge to the origin, and all other signals of the closed-loop system are uniformly ultimately bounded. Simulation studies and comprehensive comparisons with backstepping- and API-based approaches demonstrate that the proposed AARC scheme achieves remarkable performance and superiority in dealing with unknown dynamics.",4
LANN-SVD: A Non-Iterative SVD-Based Learning Algorithm for One-Layer Neural Networks.,"In the scope of data analytics, the volume of a data set can be defined as a product of instance size and dimensionality of the data. In many real problems, data sets are mainly large only on one of these aspects. Machine learning methods proposed in the literature are able to efficiently learn in only one of these two situations, when the number of variables is much greater than instances or vice versa. However, there is no proposal allowing to efficiently handle either circumstances in a large-scale scenario. In this brief, we present an approach to integrally address both situations, large dimensionality or large instance size, by using a singular value decomposition (SVD) within a learning algorithm for one-layer feedforward neural network. As a result, a noniterative solution is obtained, where the weights can be calculated in a closed-form manner, thereby avoiding low convergence rate and also hyperparameter tuning. The proposed learning method, LANN-SVD in short, presents a good computational efficiency for large-scale data analytic. Comprehensive comparisons were conducted to assess LANN-SVD against other state-of-the-art algorithms. The results of this brief exhibited the superior efficiency of the proposed method in any circumstance.",4
Stability and Guaranteed Cost Analysis of Time-Triggered Boolean Networks.,"This paper investigates stability and guaranteed cost of time-triggered Boolean networks (BNs) based on the semitensor product of matrices. The time triggering is generated by mode-dependent average dwell-time switching signals in the BNs. With the help of the copositive Lyapunov function, a sufficient condition is derived to ensure that the considered network is globally stable under a designed average dwell-time switching signal. Subsequently, an infinite time cost function is further discussed and its bound is presented according to the obtained stability result. Numerical examples are finally given to show the feasibility of the theoretical results.",4
Beyond Pairwise Matching: Person Reidentification via High-Order Relevance Learning.,"Person reidentification has attracted extensive research efforts in recent years. It is challenging due to the varied visual appearance from illumination, view angle, background, and possible occlusions, leading to the difficulties when measuring the relevance, i.e., similarities, between probe and gallery images. Existing methods mainly focus on pairwise distance metric learning for person reidentification. In practice, pairwise image matching may limit the data for comparison (just the probe and one gallery subject) and yet lead to suboptimal results. The correlation among gallery data can be also helpful for the person reidentification task. In this paper, we propose to investigate the high-order correlation among the probe and gallery data, not the pairwise matching, to jointly learn the relevance of gallery data to the probe. Recalling recent progresses on feature representation in person reidentification, it is difficult to select the best feature and each type of feature can benefit person description from different aspects. Under such circumstances, we propose a multihypergraph joint learning algorithm to learn the relevance in corporation with multiple features of the imaging data. More specifically, one hypergraph is constructed using one type of feature and multiple hypergraphs can be generated accordingly. Then, the learning process is conducted on the multihypergraph structure, and the identity of a probe is determined by its relevance to each gallery data. The merit of the proposed scheme is twofold. First, different from pairwise image matching, the proposed method jointly explores the relationships among different images. Second, multimodal data, i.e., different features, can be formulated in the multihypergraph structure, which can convey more information in the learning process and can be easily extended. We note that the proposed method is a general framework to incorporate with any combination of features, and thus is flexible in practice. Experimental results and comparisons with the state-of-the-art methods on three public benchmarking data sets demonstrate the superiority of the proposed method.",4
Global Exponential Stability of Impulsive Fuzzy High-Order BAM Neural Networks With Continuously Distributed Delays.,"This paper investigates the stability of equilibrium point and periodic solution for impulsive fuzzy high-order bidirectional associative memory neural networks with continuously distributed delays. By applying the inequality analysis technique, -matrix, and Banach contraction mapping principle and constructing some suitable Lyapunov functionals, some sufficient conditions for the uniqueness and global exponential stability of equilibrium point and global exponential stability of periodic solutions are established. In addition, three examples with numerical simulations are presented to demonstrate the feasibility and effectiveness of the theoretical results.",4
Exploiting Spatio-Temporal Structure With Recurrent Winner-Take-All Networks.,"We propose a convolutional recurrent neural network (ConvRNNs), with winner-take-all (WTA) dropout for high-dimensional unsupervised feature learning in multidimensional time series. We apply the proposed method for object recognition using temporal context in videos and obtain better results than comparable methods in the literature, including the deep predictive coding networks (DPCNs) previously proposed by Chalasani and Principe. Our contributions can be summarized as a scalable reinterpretation of the DPCNs trained end-to-end with backpropagation through time, an extension of the previously proposed WTA autoencoders to sequences in time, and a new technique for initializing and regularizing ConvRNNs.",4
Learning Semantic-Aligned Action Representation.,"A fundamental bottleneck for achieving highly discriminative action representation is that local motion/appearance features are usually not semantic aligned. Namely, a local feature, such as a motion vector or motion trajectory, does not possess any attribute that indicates which moving body part or operated object it is associated with. This mostly leads to global feature pooling/representation learning methods that are often too coarse. Inspired by the recent success of end-to-end (pixel-to-pixel) deep convolutional neural networks (DCNNs), in this paper, we first propose a DCNN architecture, which maps a human centric image region onto human body part response maps. Based on these response maps, we propose a second DCNN, which achieves semantic-aligned feature representation learning. Prior knowledge that only a few parts are responsible for a certain action is also utilized by introducing a group (part) sparseness prior during feature learning. The learned semantic-aligned feature not only boosts the discriminative capability of action representation, but also possesses the good nature of robustness to pose variations and occlusions. Finally, an iterative mining method is employed for learning discriminative action primitive detectors. Extensive experiments on action recognition benchmarks demonstrate a superior recognition performance of the proposed framework.",4
Event-Triggered State Estimation for Delayed Stochastic Memristive Neural Networks With Missing Measurements: The Discrete Time Case.,"In this paper, the event-triggered state estimation problem is investigated for a class of discrete-time stochastic memristive neural networks (DSMNNs) with time-varying delays and missing measurements. The DSMNN is subject to both the additive deterministic disturbances and the multiplicative stochastic noises. The missing measurements are governed by a sequence of random variables obeying the Bernoulli distribution. For the purpose of energy saving, an event-triggered communication scheme is used for DSMNNs to determine whether the measurement output is transmitted to the estimator or not. The problem addressed is to design an event-triggered estimator such that the dynamics of the estimation error is exponentially mean-square stable and the prespecified disturbance rejection attenuation level is also guaranteed. By utilizing a Lyapunov-Krasovskii functional and stochastic analysis techniques, sufficient conditions are derived to guarantee the existence of the desired estimator, and then, the estimator gains are characterized in terms of the solution to certain matrix inequalities. Finally, a numerical example is used to demonstrate the usefulness of the proposed event-triggered state estimation scheme.",4
Boundary Control of 2-D Burgers' PDE: An Adaptive Dynamic Programming Approach.,"In this paper, an adaptive dynamic programming-based near optimal boundary controller is developed for partial differential equations (PDEs) modeled by the uncertain Burgers' equation under Neumann boundary condition in 2-D. Initially, Hamilton-Jacobi-Bellman equation is derived in infinite-dimensional space. Subsequently, a novel neural network (NN) identifier is introduced to approximate the nonlinear dynamics in the 2-D PDE. The optimal control input is derived by online estimation of the value function through an additional NN-based forward-in-time estimation and approximated dynamic model. Novel update laws are developed for estimation of the identifier and value function online. The designed control policy can be applied using a finite number of actuators at the boundaries. Local ultimate boundedness of the closed-loop system is studied in detail using Lyapunov theory. Simulation results confirm the optimizing performance of the proposed controller on an unstable 2-D Burgers' equation.",4
Deterministic Convergence for Learning Control Systems Over Iteration-Dependent Tracking Intervals.,"This brief addresses the iterative learning control (ILC) problems for discrete-time systems subject to iteration-dependent tracking time intervals. A modified class of P-type ILC algorithms is proposed by properly defining an available modified output, for which robust convergence analysis is performed with an inductive approach. It is shown that if a persistent full-learning property is ensured, then a necessary and sufficient convergence condition of ILC can be derived to reach the perfect output tracking objective though the tracking time interval is iteration-dependent. That is, the tracking of ILC for iteration-dependent time intervals can be guaranteed in the same deterministic (not stochastic) convergence way as that of traditional ILC over a fixed time interval. Furthermore, the developed tracking results can be extended to admit iteration-dependent uncertainties in initial state and external disturbances. Simulation tests are also included to demonstrate the effectiveness of the modified P-type ILC.",4
Adaptive Neural Output-Feedback Control for a Class of Nonlower Triangular Nonlinear Systems With Unmodeled Dynamics.,"This paper presents the development of an adaptive neural controller for a class of nonlinear systems with unmodeled dynamics and immeasurable states. An observer is designed to estimate system states. The structure consistency of virtual control signals and the variable partition technique are combined to overcome the difficulties appearing in a nonlower triangular form. An adaptive neural output-feedback controller is developed based on the backstepping technique and the universal approximation property of the radial basis function (RBF) neural networks. By using the Lyapunov stability analysis, the semiglobally and uniformly ultimate boundedness of all signals within the closed-loop system is guaranteed. The simulation results show that the controlled system converges quickly, and all the signals are bounded. This paper is novel at least in the two aspects: 1) an output-feedback control strategy is developed for a class of nonlower triangular nonlinear systems with unmodeled dynamics and 2) the nonlinear disturbances and their bounds are the functions of all states, which is in a more general form than existing results.",4
Learning Low-Rank Decomposition for Pan-Sharpening With Spatial-Spectral Offsets.,"Finding accurate injection components is the key issue in pan-sharpening methods. In this paper, a low-rank pan-sharpening (LRP) model is developed from a new perspective of offset learning. Two offsets are defined to represent the spatial and spectral differences between low-resolution multispectral and high-resolution multispectral (HRMS) images, respectively. In order to reduce spatial and spectral distortions, spatial equalization and spectral proportion constraints are designed and cast on the offsets, to develop a spatial and spectral constrained stable low-rank decomposition algorithm via augmented Lagrange multiplier. By fine modeling and heuristic learning, our method can simultaneously reduce spatial and spectral distortions in the fused HRMS images. Moreover, our method can efficiently deal with noises and outliers in source images, for exploring low-rank and sparse characteristics of data. Extensive experiments are taken on several image data sets, and the results demonstrate the efficiency of the proposed LRP.",4
Sophisticated Merging Over Random Partitions: A Scalable and Robust Causal Discovery Approach.,"Scalable causal discovery is an essential technology to a wide spectrum of applications, including biomedical studies and social network evolution analysis. To tackle the difficulty of high dimensionality, a number of solutions are proposed in the literature, generally dividing the original variable domain into smaller subdomains by computation intensive partitioning strategies. These approaches usually suffer significant structural errors when the partitioning strategies fail to recognize true causal edges across the output subdomains. Such a structural error accumulates quickly with the growing depth of recursive partitioning, due to the lack of correction mechanism over causally connected variables when they are wrongly divided into two subdomains, finally jeopardizing the robustness of the integrated results. This paper proposes a completely different strategy to solve the problem, powered by a lightweight random partitioning scheme together with a carefully designed merging algorithm over results from the random partitions. Based on the randomness properties of the partitioning scheme, we design a suite of tricks for the merging algorithm, in order to support propagation-based significance enhancement, maximal acyclic subgraph causal ordering, and order-sensitive redundancy elimination. Theoretical studies as well as empirical evaluations verify the genericity, effectiveness, and scalability of our proposal on both simulated and real-world causal structures when the scheme is used in combination with a variety of causal solvers known effective on smaller domains.",4
Using Directional Fibers to Locate Fixed Points of Recurrent Neural Networks.,"We introduce mathematical objects that we call ""directional fibers,"" and show how they enable a new strategy for systematically locating fixed points in recurrent neural networks. We analyze this approach mathematically and use computer experiments to show that it consistently locates many fixed points in many networks with arbitrary sizes and unconstrained connection weights. Comparison with a traditional method shows that our strategy is competitive and complementary, often finding larger and distinct sets of fixed points. We provide theoretical groundwork for further analysis and suggest next steps for developing the method into a more powerful solver.",4
On Selecting Effective Patterns for Fast Support Vector Regression Training.,"It is time consuming to train support vector regression (SVR) for large-scale problems even with efficient quadratic programming solvers. This issue is particularly serious when tuning the model's parameters. One way to address the issue is to reduce the problem's scale by selecting a subset of the training set. This paper presents a fast pattern selection method by scanning the training data set to reduce a problem's scale. In particular, we find the k-nearest neighbors (kNNs) in a local region around each pattern's target value, and then determine to retain the pattern according to the distribution of its nearest neighbors. There is a high probability that the pattern locates outside the -tube. Since the kNNs of a pattern are found in a very small region, it is fast to scan the whole training data set. The proposed method deals with the year prediction Million Song Data set, which contains 463 715 patterns, within 10 s on a personal computer with an Intel Core i5-4690 CPU at 3.50 GHz and 8GB DRAM. An additional advantage of the proposed method is that it can predefine the size of the selected subset according to the training set. Comprehensive empirical evaluations demonstrate that the proposed method can significantly eliminate redundant patterns for SVR training with only a slight decrease in performance.",4
Cost-Sensitive Learning of Deep Feature Representations From Imbalanced Data.,"Class imbalance is a common problem in the case of real-world object detection and classification tasks. Data of some classes are abundant, making them an overrepresented majority, and data of other classes are scarce, making them an underrepresented minority. This imbalance makes it challenging for a classifier to appropriately learn the discriminating boundaries of the majority and minority classes. In this paper, we propose a cost-sensitive (CoSen) deep neural network, which can automatically learn robust feature representations for both the majority and minority classes. During training, our learning procedure jointly optimizes the class-dependent costs and the neural network parameters. The proposed approach is applicable to both binary and multiclass problems without any modification. Moreover, as opposed to data-level approaches, we do not alter the original data distribution, which results in a lower computational cost during the training process. We report the results of our experiments on six major image classification data sets and show that the proposed approach significantly outperforms the baseline algorithms. Comparisons with popular data sampling techniques and CoSen classifiers demonstrate the superior performance of our proposed method.",4
Event-Triggered Asynchronous Guaranteed Cost Control for Markov Jump Discrete-Time Neural Networks With Distributed Delay and Channel Fading.,"This paper is concerned with the guaranteed cost control problem for a class of Markov jump discrete-time neural networks (NNs) with event-triggered mechanism, asynchronous jumping, and fading channels. The Markov jump NNs are introduced to be close to reality, where the modes of the NNs and guaranteed cost controller are determined by two mutually independent Markov chains. The asynchronous phenomenon is considered, which increases the difficulty of designing required mode-dependent controller. The event-triggered mechanism is designed by comparing the relative measurement error with the last triggered state at the process of data transmission, which is used to eliminate dispensable transmission and reduce the networked energy consumption. In addition, the signal fading is considered for the effect of signal reflection and shadow in wireless networks, which is modeled by the novel Rice fading models. Some novel sufficient conditions are obtained to guarantee that the closed-loop system reaches a specified cost value under the designed jumping state feedback control law in terms of linear matrix inequalities. Finally, some simulation results are provided to illustrate the effectiveness of the proposed method.",4
Event-Based Impulsive Control of Continuous-Time Dynamic Systems and Its Application to Synchronization of Memristive Neural Networks.,"This paper investigates exponential stabilization of continuous-time dynamic systems (CDSs) via event-based impulsive control (EIC) approaches, where the impulsive instants are determined by certain state-dependent triggering condition. The global exponential stability criteria via EIC are derived for nonlinear and linear CDSs, respectively. It is also shown that there is no Zeno-behavior for the concerned closed loop control system. In addition, the developed event-based impulsive scheme is applied to the synchronization problem of master and slave memristive neural networks. Furthermore, a self-triggered impulsive control scheme is developed to avoid continuous communication between the master system and slave system. Finally, two numerical simulation examples are presented to illustrate the effectiveness of the proposed event-based impulsive controllers.",4
Rank- 2-D Multinomial Logistic Regression for Matrix Data Classification.,"The amount of matrix data has increased rapidly nowadays. How to classify matrix data efficiently is an important issue. In this paper, by discovering the shortages of 2-D linear discriminant analysis and 2-D logistic regression, a novel 2-D framework named rank- 2-D multinomial logistic regression (2DMLR-RK) is proposed. The 2DMLR-RK is designed for a multiclass matrix classification problem. In the proposed framework, each category is modeled by a left projection matrix and a right projection matrix with rank . The left projection matrices capture the row information of matrix data, and the right projection matrices acquire the column information. We identify the parameter plays the role of balancing the capacity of learning and generalization of the 2DMLR-RK. In addition, we develop an effective framework for solving the proposed nonconvex optimization problem. The convergence, initialization, and computational complexity are discussed. Extensive experiments on various types of data sets are conducted. Comparing with 1-D methods, 2DMLR-RK not only achieves a better classification accuracy, but also costs less computation time. Comparing with other state-of-the-art 2-D methods, the 2DMLR-RK achieves a better performance for matrix data classification.",4
Augmented Lagrange Programming Neural Network for Localization Using Time-Difference-of-Arrival Measurements.,"A commonly used measurement model for locating a mobile source is time-difference-of-arrival (TDOA). As each TDOA measurement defines a hyperbola, it is not straightforward to compute the mobile source position due to the nonlinear relationship in the measurements. This brief exploits the Lagrange programming neural network (LPNN), which provides a general framework to solve nonlinear constrained optimization problems, for the TDOA-based localization. The local stability of the proposed LPNN solution is also analyzed. Simulation results are included to evaluate the localization accuracy of the LPNN scheme by comparing with the state-of-the-art methods and the optimality benchmark of Cramer-Rao lower bound.",4
ADMM-Based Algorithm for Training Fault Tolerant RBF Networks and Selecting Centers.,"In the training stage of radial basis function (RBF) networks, we need to select some suitable RBF centers first. However, many existing center selection algorithms were designed for the fault-free situation. This brief develops a fault tolerant algorithm that trains an RBF network and selects the RBF centers simultaneously. We first select all the input vectors from the training set as the RBF centers. Afterward, we define the corresponding fault tolerant objective function. We then add an -norm term into the objective function. As the -norm term is able to force some unimportant weights to zero, center selection can be achieved at the training stage. Since the -norm term is nondifferentiable, we formulate the original problem as a constrained optimization problem. Based on the alternating direction method of multipliers framework, we then develop an algorithm to solve the constrained optimization problem. The convergence proof of the proposed algorithm is provided. Simulation results show that the proposed algorithm is superior to many existing center selection algorithms.",4
Adaptive Unknown Input Estimation by Sliding Modes and Differential Neural Network Observer.,"In this paper, a differential neural network (DNN) implemented as a robust observer estimates the dynamics of perturbed uncertain nonlinear systems affected by exogenous unknown inputs. In the first stage, the identification error converges into a neighborhood around the origin. Then, the second-order sliding mode supertwisting algorithm implemented as a robust exact differentiator reconstructed the unknown inputs. The approach proposed in this paper can be applied in the case of full access to the state vector (identification problem) and in the case of partial access to the state vector (estimation problem). In the second case, the nonlinear system under study must have well-defined full relative degree with respect to the unknown input. Numerical examples showed the effectiveness of the proposed algorithm. The first example tested the DNN working as an identifier into a mathematical model describing the dynamics of a spatial minisatellite. The second example (with a DNN implemented as an observer) tested the methodology of this paper over a single link flexible robot manipulator represented in a canonical (Brunovsky) form. In both examples, the mathematical models served as data generators in the testing of the neural networks. Even when not exact mathematical description of both models was used in the input estimation, the accuracy obtained with the DNN is comparable with the case of applying a high-order differentiator with complete knowledge of the plant.",4
Adaptive Consensus Control of Nonlinear Multiagent Systems With Unknown Control Directions Under Stochastic Topologies.,"The consensus problem over high-order nonlinear multiagent systems with the Brunovsky-type model is studied. The model parameters and control directions of agents are supposed to be unknown. Hence, based on Nussbaum-type functions, an adaptive protocol is proposed, which guarantees achieving consensus in the network when the parameters and control directions of the agents are unknown and unidentical. The main contribution of this paper (compared with the existing similar results in the literature) is to guarantee achieving consensus in networks of agents when the communication topology is not connected constantly, and communication links stochastically switch over time. It is shown that if the probability of the network connectivity is not zero, under some conditions, almost sure consensus can be achieved. Illustrative examples verify the accuracy of the proposed consensus protocol.",4
Prototype-Incorporated Emotional Neural Network.,"Artificial neural networks (ANNs) aim to simulate the biological neural activities. Interestingly, many ""engineering"" prospects in ANN have relied on motivations from cognition and psychology studies. So far, two important learning theories that have been subject of active research are the prototype and adaptive learning theories. The learning rules employed for ANNs can be related to adaptive learning theory, where several examples of the different classes in a task are supplied to the network for adjusting internal parameters. Conversely, the prototype-learning theory uses prototypes (representative examples); usually, one prototype per class of the different classes contained in the task. These prototypes are supplied for systematic matching with new examples so that class association can be achieved. In this paper, we propose and implement a novel neural network algorithm based on modifying the emotional neural network (EmNN) model to unify the prototype- and adaptive-learning theories. We refer to our new model as ""prototype-incorporated EmNN"". Furthermore, we apply the proposed model to two real-life challenging tasks, namely, static hand-gesture recognition and face recognition, and compare the result to those obtained using the popular back-propagation neural network (BPNN), emotional BPNN (EmNN), deep networks, an exemplar classification model, and k-nearest neighbor.",4
A Novel Consistent Random Forest Framework: Bernoulli Random Forests.,"Random forests (RFs) are recognized as one type of ensemble learning method and are effective for the most classification and regression tasks. Despite their impressive empirical performance, the theory of RFs has yet been fully proved. Several theoretically guaranteed RF variants have been presented, but their poor practical performance has been criticized. In this paper, a novel RF framework is proposed, named Bernoulli RFs (BRFs), with the aim of solving the RF dilemma between theoretical consistency and empirical performance. BRF uses two independent Bernoulli distributions to simplify the tree construction, in contrast to the RFs proposed by Breiman. The two Bernoulli distributions are separately used to control the splitting feature and splitting point selection processes of tree construction. Consequently, theoretical consistency is ensured in BRF, i.e., the convergence of learning performance to optimum will be guaranteed when infinite data are given. Importantly, our proposed BRF is consistent for both classification and regression. The best empirical performance is achieved by BRF when it is compared with state-of-the-art theoretical/consistent RFs. This advance in RF research toward closing the gap between theory and practice is verified by the theoretical and experimental studies in this paper.",4
Adaboost-LLP: A Boosting Method for Learning With Label Proportions.,"How to solve the classification problem with only label proportions has recently drawn increasing attention in the machine learning field. In this paper, we propose an ensemble learning strategy to deal with the learning problem with label proportions (LLP). In detail, we first give a loss function based on different weights for LLP, and then construct the corresponding weak classifier, at the same time, estimate its conditional probabilities by a standard logistic function. At last, by introducing the maximum likelihood estimation, we propose a new anyboost learning system for LLP (called Adaboost-LLP). Unlike traditional methods, our method does not make any restrictive assumptions on training set; at the same time, compared with alter- SVM, Adaboost-LLP exploits more extra weight information and uses multiple weak classifiers that can be solved efficiently to combine a strong classifier. All experiments show that our method outperforms the existing methods in both accuracy and training time.",4
Hybrid Fuzzy Wavelet Neural Networks Architecture Based on Polynomial Neural Networks and Fuzzy Set/Relation Inference-Based Wavelet Neurons.,"This paper presents a hybrid fuzzy wavelet neural network (HFWNN) realized with the aid of polynomial neural networks (PNNs) and fuzzy inference-based wavelet neurons (FIWNs). Two types of FIWNs including fuzzy set inference-based wavelet neurons (FSIWNs) and fuzzy relation inference-based wavelet neurons (FRIWNs) are proposed. In particular, a FIWN without any fuzzy set component (viz., a premise part of fuzzy rule) becomes a wavelet neuron (WN). To alleviate the limitations of the conventional wavelet neural networks or fuzzy wavelet neural networks whose parameters are determined based on a purely random basis, the parameters of wavelet functions standing in FIWNs or WNs are initialized by using the C-Means clustering method. The overall architecture of the HFWNN is similar to the one of the typical PNNs. The main strategies in the design of HFWNN are developed as follows. First, the first layer of the network consists of FIWNs (e.g., FSIWN or FRIWN) that are used to reflect the uncertainty of data, while the second and higher layers consist of WNs, which exhibit a high level of flexibility and realize a linear combination of wavelet functions. Second, the parameters used in the design of the HFWNN are adjusted through genetic optimization. To evaluate the performance of the proposed HFWNN, several publicly available data are considered. Furthermore a thorough comparative analysis is covered.",4
Integration of Semantic and Episodic Memories.,"This paper describes the integration of semantic and episodic memory (EM) models and the benefits of such integration. Semantic memory (SM) is used as a foundation of knowledge and concept learning, and is needed for the operation of any cognitive system. EM retains personal experiences stored based on their significance-it is supported by the SM, and in return, it supports SM operations. Integrated declarative memories are critical for cognitive system development, yet very little research has been done to develop their computational models. We considered structural self-organization of both semantic and episodic memories with a symbolic representation of input events. Sequences of events are stored in EM and are used to build associations in SM. We demonstrated that integration of semantic and episodic memories improves the native operation of both types of memories. Experimental results are presented to illustrate how the two memories complement each other by improving recognition, prediction, and context-based generalization of individual memories.",4
Multiview Privileged Support Vector Machines.,"Multiview learning (MVL), by exploiting the complementary information among multiple feature sets, can improve the performance of many existing learning tasks. Support vector machine (SVM)-based models have been frequently used for MVL. A typical SVM-based MVL model is SVM-2K, which extends SVM for MVL by using the distance minimization version of kernel canonical correlation analysis. However, SVM-2K cannot fully unleash the power of the complementary information among different feature views. Recently, a framework of learning using privileged information (LUPI) has been proposed to model data with complementary information. Motivated by LUPI, we propose a new multiview privileged SVM model, multi-view privileged SVM model (PSVM-2V), for MVL. This brings a new perspective that extends LUPI to MVL. The optimization of PSVM-2V can be solved by the classical quadratic programming solver. We theoretically analyze the performance of PSVM-2V from the viewpoints of the consensus principle, the generalization error bound, and the SVM-2K learning model. Experimental results on 95 binary data sets demonstrate the effectiveness of the proposed method.",4
Structured Weak Semantic Space Construction for Visual Categorization.,"Visual features have been widely used for image representation and categorization. However, visual features are often inconsistent with human perception. Besides, constructing explicit semantic space is still an open problem. To alleviate these two problems, in this paper, we propose to construct structured weak semantic space for image representation. Exemplar classifier is first trained to separate each training image from other images for weak semantic space construction. However, each exemplar classifier separates one training image from other images, and it only has limited semantic separability. Besides, the outputs of exemplar classifiers are inconsistent with each other. We jointly construct the weak semantic space using structured constraint. This is achieved by imposing low-rank constraint on the outputs of exemplar classifiers with sparsity constraint. An alternative optimization procedure is used to learn the exemplar classifiers. Since the proposed method does not dependent on the initial image representation strategy, we can make use of various visual features for efficient exemplar classifier training (e.g., fisher vector-based methods and convolutional neural networks-based methods). We apply the proposed structured weak semantic space-based image representation method for categorization. The experimental results on several public image data sets prove the effectiveness of the proposed method.",4
Prescribed Performance Control of Uncertain Euler-Lagrange Systems Subject to Full-State Constraints.,"This paper studies the zero-error tracking control problem of Euler-Lagrange systems subject to full-state constraints and nonparametric uncertainties. By blending an error transformation with barrier Lyapunov function, a neural adaptive tracking control scheme is developed, resulting in a solution with several salient features: 1) the control action is continuous and smooth; 2) the full-state tracking error converges to a prescribed compact set around origin within a given finite time at a controllable rate of convergence that can be uniformly prespecified; 3) with Nussbaum gain in the loop, the tracking error further shrinks to zero as ; and 4) the neural network (NN) unit can be safely included in the loop during the entire system operational envelope without the danger of violating the compact set precondition imposed on the NN training inputs. Furthermore, by using the Lyapunov analysis, it is proven that all the signals of the closed-loop systems are semiglobally uniformly ultimately bounded. The effectiveness and benefits of the proposed control method are validated via computer simulation.",4
Avoiding Congestion in Cluster Consensus of the Second-Order Nonlinear Multiagent Systems.,"In order to avoid congestion in the second-order nonlinear leader-following multiagent systems over capacity-limited paths, an approach called cluster lag consensus is proposed, which means that the agents in different clusters will pass through the same positions with the same velocities but lag behind the leader at different times. Lyapunov functionals and matrix theory are applied to analyze such cluster lag consensus. It is shown that when the graphic roots of clusters are influenced by the leader and the intracoupling of cluster agents is larger than a threshold, the cluster lag consensus can be achieved. Furthermore, the cluster lag consensus with a time-varying communication topology is investigated. Finally, an illustrative example is presented to demonstrate the effectiveness of the theoretical results. In particular, when the physical sizes of the agents are taken into consideration, it is shown that with a rearrangement and a position transformation, the multiagent system will reach cluster lag consensus in the new coordinate system. This means that all agents in the same cluster will reach consensus on the velocity, but their positions may be different and yet their relative positions converge to a constant asymptotically.",4
Synchronizing Neural Networks With Proportional Delays Based on a Class of -Type Allowable Time Scales.,"Without confines of the continuous-time domain, this paper addresses synchronization control problem of neural networks in the face of multiple proportional delays on general time scales. The idea to deal with proportional delays is to propose a class of -type allowable time scales on which we design an appropriate controller to achieve exponential synchronization based on a calculus theory on time scales and Lyapunov function/functional methods. It is shown that adopting properties of -type time scales is an effective approach to establish synchronization for the networks with proportional delays. This helps us to have insight into the synchronization problems on general intermittent time domain. Finally, simulation examples are given to illustrate the effectiveness of the theoretical results.",4
Dimensionality Reduction Using Similarity-Induced Embeddings.,"The vast majority of dimensionality reduction (DR) techniques rely on the second-order statistics to define their optimization objective. Even though this provides adequate results in most cases, it comes with several shortcomings. The methods require carefully designed regularizers and they are usually prone to outliers. In this paper, a new DR framework that can directly model the target distribution using the notion of similarity instead of distance is introduced. The proposed framework, called similarity embedding framework (SEF), can overcome the aforementioned limitations and provides a conceptually simpler way to express optimization targets similar to existing DR techniques. Deriving a new DR technique using the SEF becomes simply a matter of choosing an appropriate target similarity matrix. A variety of classical tasks, such as performing supervised DR and providing out-of-sample extensions, as well as, new novel techniques, such as providing fast linear embeddings for complex techniques, are demonstrated in this paper using the proposed framework. Six data sets from a diverse range of domains are used to evaluate the proposed method and it is demonstrated that it can outperform many existing DR techniques.",4
Subspace Clustering of Categorical and Numerical Data With an Unknown Number of Clusters.,"In clustering analysis, data attributes may have different contributions to the detection of various clusters. To solve this problem, the subspace clustering technique has been developed, which aims at grouping the data objects into clusters based on the subsets of attributes rather than the entire data space. However, the most existing subspace clustering methods are only applicable to either numerical or categorical data, but not both. This paper, therefore, studies the soft subspace clustering of data with both of the numerical and categorical attributes (also simply called mixed data for short). Specifically, an attribute-weighted clustering model based on the definition of object-cluster similarity is presented. Accordingly, a unified weighting scheme for the numerical and categorical attributes is proposed, which quantifies the attribute-to-cluster contribution by taking into account both of intercluster difference and intracluster similarity. Moreover, a rival penalized competitive learning mechanism is further introduced into the proposed soft subspace clustering algorithm so that the subspace cluster structure as well as the most appropriate number of clusters can be learned simultaneously in a single learning paradigm. In addition, an initialization-oriented method is also presented, which can effectively improve the stability and accuracy of -means-type clustering methods on numerical, categorical, and mixed data. The experimental results on different benchmark data sets show the efficacy of the proposed approach.",4
Model Approximation for Switched Genetic Regulatory Networks.,"The model approximation problem is studied in this paper for switched genetic regulatory networks (GRNs) with time-varying delays. We focus on constructing a reduced-order model to approximate the high-order GRNs considered under the switching signal subject to certain constraints, such that the approximation error system between the original and reduced-order systems is exponentially stable with a disturbance attenuation performance. The stability conditions and the disturbance attenuation performance are established by utilizing two integral inequality bounding techniques and the average dwell-time method for the approximation error system. Then, the solvability conditions for the reduced-order models for the GRNs are also established using the projection method. Furthermore, the model approximation problem can be transferred into a sequential minimization problem that is subject to linear matrix inequality constraints by using the cone complementarity algorithm. Finally, several examples are provided to illustrate the effectiveness and the advantages of the proposed methods.",4
Regularized Semipaired Kernel CCA for Domain Adaptation.,"Domain adaptation learning is one of the fundamental research topics in pattern recognition and machine learning. This paper introduces a regularized semipaired kernel canonical correlation analysis formulation for learning a latent space for the domain adaptation problem. The optimization problem is formulated in the primal-dual least squares support vector machine setting where side information can be readily incorporated through regularization terms. The proposed model learns a joint representation of the data set across different domains by solving a generalized eigenvalue problem or linear system of equations in the dual. The approach is naturally equipped with out-of-sample extension property, which plays an important role for model selection. Furthermore, the Nystrom approximation technique is used to make the computational issues due to the large size of the matrices involved in the eigendecomposition feasible. The learned latent space of the source domain is fed to a multiclass semisupervised kernel spectral clustering model that can learn from both labeled and unlabeled data points of the source domain in order to classify the data instances of the target domain. Experimental results are given to illustrate the effectiveness of the proposed approaches on synthetic and real-life data sets.",4
Distributed Optimal Consensus Control for Nonlinear Multiagent System With Unknown Dynamic.,"This paper focuses on the distributed optimal cooperative control for continuous-time nonlinear multiagent systems (MASs) with completely unknown dynamics via adaptive dynamic programming (ADP) technology. By introducing predesigned extra compensators, the augmented neighborhood error systems are derived, which successfully circumvents the system knowledge requirement for ADP. It is revealed that the optimal consensus protocols actually work as the solutions of the MAS differential game. Policy iteration algorithm is adopted, and it is theoretically proved that the iterative value function sequence strictly converges to the solution of the coupled Hamilton-Jacobi-Bellman equation. Based on this point, a novel online iterative scheme is proposed, which runs based on the data sampled from the augmented system and the gradient of the value function. Neural networks are employed to implement the algorithm and the weights are updated, in the least-square sense, to the ideal value, which yields approximated optimal consensus protocols. Finally, a numerical example is given to illustrate the effectiveness of the proposed scheme.",4
Observer-Based Discrete-Time Nonnegative Edge Synchronization of Networked Systems.,"This paper studies the multi-input and multi-output discrete-time nonnegative edge synchronization of networked systems based on neighbors' output information. The communication relationship among the edges of networked systems is modeled by well-known line graph. Two observer-based edge synchronization algorithms are designed, for which some necessary and sufficient synchronization conditions are derived. Moreover, some computable sufficient synchronization conditions are obtained, in which the feedback matrix and the observer matrix are computed by solving the linear programming problems. We finally design several simulation examples to demonstrate the validity of the given nonnegative edge synchronization algorithms.",4
Fast Kronecker Product Kernel Methods via Generalized Vec Trick.,"Kronecker product kernel provides the standard approach in the kernel methods' literature for learning from graph data, where edges are labeled and both start and end vertices have their own feature representations. The methods allow generalization to such new edges, whose start and end vertices do not appear in the training data, a setting known as zero-shot or zero-data learning. Such a setting occurs in numerous applications, including drug-target interaction prediction, collaborative filtering, and information retrieval. Efficient training algorithms based on the so-called vec trick that makes use of the special structure of the Kronecker product are known for the case where the training data are a complete bipartite graph. In this paper, we generalize these results to noncomplete training graphs. This allows us to derive a general framework for training Kronecker product kernel methods, as specific examples we implement Kronecker ridge regression and support vector machine algorithms. Experimental results demonstrate that the proposed approach leads to accurate models, while allowing order of magnitude improvements in training and prediction time.",4
Robust Adaptive Embedded Label Propagation With Weight Learning for Inductive Classification.,"We propose a robust inductive semi-supervised label prediction model over the embedded representation, termed adaptive embedded label propagation with weight learning (AELP-WL), for classification. AELP-WL offers several properties. First, our method seamlessly integrates the robust adaptive embedded label propagation with adaptive weight learning into a unified framework. By minimizing the reconstruction errors over embedded features and embedded soft labels jointly, our AELP-WL can explicitly ensure the learned weights to be joint optimal for representation and classification, which differs from most existing LP models that perform weight learning separately by an independent step before label prediction. Second, existing models usually precalculate the weights over the original samples that may contain unfavorable features and noise decreasing performance. To this end, our model adds a constraint that decomposes original data into a sparse component encoding embedded noise-removed sparse representations of samples and a sparse error part fitting noise, and then performs the adaptive weight learning over the embedded sparse representations. Third, our AELP-WL computes the projected soft labels by trading-off the manifold smoothness and label fitness errors over the adaptive weights and the embedded representations for enhancing the label estimation power. By including a regressive label approximation error for simultaneous minimization to correlate sample features with the embedded soft labels, the out-of-sample issue is naturally solved. By minimizing the reconstruction errors over features and embedded soft labels, classification error and label approximation error jointly, state-of-the-art results are delivered.",4
Patch Alignment Manifold Matting.,"Image matting is generally modeled as a space transform from the color space to the alpha space. By estimating the alpha factor of the model, the foreground of an image can be extracted. However, there is some dimensional information redundancy in the alpha space. It usually leads to the misjudgments of some pixels near the boundary between the foreground and the background. In this paper, a manifold matting framework named Patch Alignment Manifold Matting is proposed for image matting. In particular, we first propose a part modeling of color space in the local image patch. We then perform whole alignment optimization for approximating the alpha results using subspace reconstructing error. Furthermore, we utilize Nesterov's algorithm to solve the optimization problem. Finally, we apply some manifold learning methods in the framework, and obtain several image matting methods, such as named ISOMAP matting and its derived Cascade ISOMAP matting. The experimental results reveal that the manifold matting framework and its two examples are effective when compared with several representative matting methods.",4
Analysis and Control of Output Synchronization in Directed and Undirected Complex Dynamical Networks.,"This research focuses on the problem of output synchronization in undirected and directed complex dynamical networks, respectively, by applying Barbalat's lemma. First, to ensure the output synchronization, several sufficient criteria are established for these network models based on some mathematical techniques, such as the Lyapunov functional method and matrix theory. Furthermore, some adaptive schemes to adjust the coupling weights among network nodes are developed to achieve the output synchronization. By applying the designed adaptive laws, several criteria for output synchronization are deduced for the network models. In addition, a design procedure of the adaptive law is shown. Finally, two simulation examples are used to show the effectiveness of the previous results.",4
Spiking Neural P Systems With Polarizations.,"Spiking neural P (SN P) systems are a class of parallel computation models inspired by neurons, where the firing condition of a neuron is described by a regular expression associated with spiking rules. However, it is NP-complete to decide whether the number of spikes is in the length set of the language associated with the regular expression. In this paper, in order to avoid using regular expressions, two major and rather natural modifications in their form and functioning are proposed: the spiking rules no longer check the number of spikes in a neuron, but, in exchange, a polarization is associated with neurons and rules, one of the three electrical charges -, 0,+. Surprisingly enough, the computing devices obtained are still computationally complete, which are able to compute all Turing computable sets of natural numbers. On this basis, the number of neurons in a universal SN P system with polarizations is estimated. Several research directions are mentioned at the end of this paper.",4
Organizational Data Classification Based on the Importance Concept of Complex Networks.,"Data classification is a common task, which can be performed by both computers and human beings. However, a fundamental difference between them can be observed: computer-based classification considers only physical features (e.g., similarity, distance, or distribution) of input data; by contrast, brain-based classification takes into account not only physical features, but also the organizational structure of data. In this paper, we figure out the data organizational structure for classification using complex networks constructed from training data. Specifically, an unlabeled instance is classified by the importance concept characterized by Google's PageRank measure of the underlying data networks. Before a test data instance is classified, a network is constructed from vector-based data set and the test instance is inserted into the network in a proper manner. To this end, we also propose a measure, called spatio-structural differential efficiency, to combine the physical and topological features of the input data. Such a method allows for the classification technique to capture a variety of data patterns using the unique importance measure. Extensive experiments demonstrate that the proposed technique has promising predictive performance on the detection of heart abnormalities.",4
Supervised Learning Based on Temporal Coding in Spiking Neural Networks.,"Gradient descent training techniques are remarkably successful in training analog-valued artificial neural networks (ANNs). Such training techniques, however, do not transfer easily to spiking networks due to the spike generation hard nonlinearity and the discrete nature of spike communication. We show that in a feedforward spiking network that uses a temporal coding scheme where information is encoded in spike times instead of spike rates, the network input-output relation is differentiable almost everywhere. Moreover, this relation is piecewise linear after a transformation of variables. Methods for training ANNs thus carry directly to the training of such spiking networks as we show when training on the permutation invariant MNIST task. In contrast to rate-based spiking networks that are often used to approximate the behavior of ANNs, the networks we present spike much more sparsely and their behavior cannot be directly approximated by conventional ANNs. Our results highlight a new approach for controlling the behavior of spiking networks with realistic temporal dynamics, opening up the potential for using these networks to process spike patterns with complex temporal information.",4
A New Neural Dynamic Classification Algorithm.,"The keys for the development of an effective classification algorithm are: 1) discovering feature spaces with large margins between clusters and close proximity of the classmates and 2) discovering the smallest number of the features to perform accurate classification. In this paper, a new supervised classification algorithm, called neural dynamic classification (NDC), is presented with the goal of: 1) discovering the most effective feature spaces and 2) finding the optimum number of features required for accurate classification using the patented robust neural dynamic optimization model of Adeli and Park. The new classification algorithm is compared with the probabilistic neural network (PNN), enhanced PNN (EPNN), and support vector machine using two sets of classification problems. The first set consists of five standard benchmark problems. The second set is a large benchmark problem called Mixed National Institute of Standards and Technology database of handwritten digits. In general, NDC yields the most accurate classification results followed by EPNN. A beauty of the new algorithm is the smoothness of convergence curves which is an indication of robustness and good performance of the algorithm. The main aim is to maximize the prediction accuracy.",4
$k$ -Times Markov Sampling for SVMC.,"Support vector machine (SVM) is one of the most widely used learning algorithms for classification problems. Although SVM has good performance in practical applications, it has high algorithmic complexity as the size of training samples is large. In this paper, we introduce SVM classification (SVMC) algorithm based on -times Markov sampling and present the numerical studies on the learning performance of SVMC with -times Markov sampling for benchmark data sets. The experimental results show that the SVMC algorithm with -times Markov sampling not only have smaller misclassification rates, less time of sampling and training, but also the obtained classifier is more sparse compared with the classical SVMC and the previously known SVMC algorithm based on Markov sampling. We also give some discussions on the performance of SVMC with -times Markov sampling for the case of unbalanced training samples and large-scale training samples.",4
Broad Learning System: An Effective and Efficient Incremental Learning System Without the Need for Deep Architecture.,"Broad Learning System (BLS) that aims to offer an alternative way of learning in deep structure is proposed in this paper. Deep structure and learning suffer from a time-consuming training process because of a large number of connecting parameters in filters and layers. Moreover, it encounters a complete retraining process if the structure is not sufficient to model the system. The BLS is established in the form of a flat network, where the original inputs are transferred and placed as ""mapped features"" in feature nodes and the structure is expanded in wide sense in the ""enhancement nodes."" The incremental learning algorithms are developed for fast remodeling in broad expansion without a retraining process if the network deems to be expanded. Two incremental learning algorithms are given for both the increment of the feature nodes (or filters in deep structure) and the increment of the enhancement nodes. The designed model and algorithms are very versatile for selecting a model rapidly. In addition, another incremental learning is developed for a system that has been modeled encounters a new incoming input. Specifically, the system can be remodeled in an incremental way without the entire retraining from the beginning. Satisfactory result for model reduction using singular value decomposition is conducted to simplify the final structure. Compared with existing deep neural networks, experimental results on the Modified National Institute of Standards and Technology database and NYU NORB object recognition dataset benchmark data demonstrate the effectiveness of the proposed BLS.",4
DANoC: An Efficient Algorithm and Hardware Codesign of Deep Neural Networks on Chip.,"Deep neural networks (NNs) are the state-of-the-art models for understanding the content of images and videos. However, implementing deep NNs in embedded systems is a challenging task, e.g., a typical deep belief network could exhaust gigabytes of memory and result in bandwidth and computational bottlenecks. To address this challenge, this paper presents an algorithm and hardware codesign for efficient deep neural computation. A hardware-oriented deep learning algorithm, named the deep adaptive network, is proposed to explore the sparsity of neural connections. By adaptively removing the majority of neural connections and robustly representing the reserved connections using binary integers, the proposed algorithm could save up to 99.9% memory utility and computational resources without undermining classification accuracy. An efficient sparse-mapping-memory-based hardware architecture is proposed to fully take advantage of the algorithmic optimization. Different from traditional Von Neumann architecture, the deep-adaptive network on chip (DANoC) brings communication and computation in close proximity to avoid power-hungry parameter transfers between on-board memory and on-chip computational units. Experiments over different image classification benchmarks show that the DANoC system achieves competitively high accuracy and efficiency comparing with the state-of-the-art approaches.",4
Causal Inference on Multidimensional Data Using Free Probability Theory.,"In this paper, we deal with the problem of inferring causal relations for multidimensional data. Based on the postulate that the distribution of the cause and the conditional distribution of the effect given cause are generated independently, we show that the covariance matrix of the mean embedding of the cause in reproducing kernel Hilbert space (RKHS) is free independent with the covariance matrix of the conditional embedding of the effect given cause. This, called freeness condition, induces a cause-effect asymmetry that a designed measurement is 0 in the causal direction but smaller than 0 in the anticausal direction, and it uncovers the causal direction. One important novel aspect of this paper is that we interpret the independence as a freeness condition between covariance matrices of RKHS distribution embeddings, and it has a wide applicability. We show that our freeness condition-based inference method succeeds in scenarios like additive noise cases, where other methods fail, by theoretical analysis and experimental results.",4
MR-NTD: Manifold Regularization Nonnegative Tucker Decomposition for Tensor Data Dimension Reduction and Representation.,"With the advancement of data acquisition techniques, tensor (multidimensional data) objects are increasingly accumulated and generated, for example, multichannel electroencephalographies, multiview images, and videos. In these applications, the tensor objects are usually nonnegative, since the physical signals are recorded. As the dimensionality of tensor objects is often very high, a dimension reduction technique becomes an important research topic of tensor data. From the perspective of geometry, high-dimensional objects often reside in a low-dimensional submanifold of the ambient space. In this paper, we propose a new approach to perform the dimension reduction for nonnegative tensor objects. Our idea is to use nonnegative Tucker decomposition (NTD) to obtain a set of core tensors of smaller sizes by finding a common set of projection matrices for tensor objects. To preserve geometric information in tensor data, we employ a manifold regularization term for the core tensors constructed in the Tucker decomposition. An algorithm called manifold regularization NTD (MR-NTD) is developed to solve the common projection matrices and core tensors in an alternating least squares manner. The convergence of the proposed algorithm is shown, and the computational complexity of the proposed method scales linearly with respect to the number of tensor objects and the size of the tensor objects, respectively. These theoretical results show that the proposed algorithm can be efficient. Extensive experimental results have been provided to further demonstrate the effectiveness and efficiency of the proposed MR-NTD algorithm.",4
Designing and Implementation of Stable Sinusoidal Rough-Neural Identifier.,"A rough neuron is defined as a pair of conventional neurons that are called the upper and lower bound neurons. In this paper, the sinusoidal rough-neural networks (SR-NNs) are used to identify the discrete dynamic nonlinear systems (DDNSs) with or without noise in series-parallel configuration. In the identification of periodic nonlinear systems, sinusoidal activation functions provide more efficient neural networks than the sigmoidal activation functions. Based on the Lyapunov stability theory, an online learning algorithm is developed to train the SR-NNs. The asymptotically convergence of the identification error to zero and the boundedness of parameters as well as predictions are proved. SR-NNs are used to identify some DDNSs and the cement rotary kiln (CRK). CRK is a complex nonlinear system in the cement factory, which produces the cement clinker. The experiments show that the SR-NNs in the identification of nonlinear systems have better performances than multilayer perceptrons (MLPs), sinusoidal neural networks, and rough MLPs, particularly in the presence of noise.",4
Normalization and Solvability of Dynamic-Algebraic Boolean Networks.,"In this brief, we first study the normalization of dynamic-algebraic Boolean networks (DABNs). A new expression for the normalized DABNs is obtained. As applications of this result, the solvability and uniqueness of the solution to DABNs are then investigated. Necessary and sufficient conditions for the solvability and the uniqueness are obtained. In addition, pinning control to ensure the solvability and uniqueness of the solution to DABNs is also studied. Numerical examples are given to illustrate the efficiency of the proposed results.",4
Distributed Adaptive Finite-Time Approach for Formation-Containment Control of Networked Nonlinear Systems Under Directed Topology.,"This paper presents a distributed adaptive finite-time control solution to the formation-containment problem for multiple networked systems with uncertain nonlinear dynamics and directed communication constraints. By integrating the special topology feature of the new constructed symmetrical matrix, the technical difficulty in finite-time formation-containment control arising from the asymmetrical Laplacian matrix under single-way directed communication is circumvented. Based upon fractional power feedback of the local error, an adaptive distributed control scheme is established to drive the leaders into the prespecified formation configuration in finite time. Meanwhile, a distributed adaptive control scheme, independent of the unavailable inputs of the leaders, is designed to keep the followers within a bounded distance from the moving leaders and then to make the followers enter the convex hull shaped by the formation of the leaders in finite time. The effectiveness of the proposed control scheme is confirmed by the simulation.",4
th Moment Exponential Input-to-State Stability of Delayed Recurrent Neural Networks With Markovian Switching via Vector Lyapunov Function.,"In this paper, the th moment input-to-state exponential stability for delayed recurrent neural networks (DRNNs) with Markovian switching is studied. By using stochastic analysis techniques and classical Razumikhin techniques, a generalized vector -operator differential inequality including cross item is obtained. Without additional restrictive conditions on the time-varying delay, the sufficient criteria on the th moment input-to-state exponential stability for DRNNs with Markovian switching are derived by means of the vector -operator differential inequality. When the input is zero, an improved criterion on exponential stability is obtained. Two numerical examples are provided to examine the correctness of the derived results.",4
Robustness to Training Disturbances in SpikeProp Learning.,"Stability is a key issue during spiking neural network training using SpikeProp. The inherent nonlinearity of Spiking Neuron means that the learning manifold changes abruptly; therefore, we need to carefully choose the learning steps at every instance. Other sources of instability are the external disturbances that come along with training sample as well as the internal disturbances that arise due to modeling imperfection. The unstable learning scenario can be indirectly observed in the form of surges, which are sudden increases in the learning cost and are a common occurrence during SpikeProp training. Research in the past has shown that proper learning step size is crucial to minimize surges during training process. To determine proper learning step in order to avoid steep learning manifolds, we perform weight convergence analysis of SpikeProp learning in the presence of disturbance signals. The weight convergence analysis is further extended to robust stability analysis linked with overall system error. This ensures boundedness of the total learning error with minimal assumption of bounded disturbance signals. These analyses result in the learning rate normalization scheme, which are the key results of this paper. The performance of learning using this scheme has been compared with the prevailing methods for different benchmark data sets and the results show that this method has stable learning reflected by minimal surges during learning, higher success in training instances, and faster learning as well.",4
Bayesian Neighborhood Component Analysis.,"Learning a distance metric in feature space potentially improves the performance of the nearest neighbor classifier and is useful in many real-world applications. Many metric learning (ML) algorithms are, however, based on the point estimation of a quadratic optimization problem, which is time-consuming, susceptible to overfitting, and lacks a natural mechanism to reason with parameter uncertainty-a property useful especially when the training set is small and/or noisy. To deal with these issues, we present a novel Bayesian ML (BML) method, called Bayesian neighborhood component analysis (NCA), based on the well-known NCA method, in which the metric posterior is characterized by the local label consistency constraints of observations, encoded with a similarity graph instead of independent pairwise constraints. For efficient Bayesian inference, we explore the variational lower bound over the log-likelihood of the original NCA objective. Experiments on several publicly available data sets demonstrate that the proposed method is able to learn robust metric measures from small size data set and/or from challenging training set with labels contaminated by errors. The proposed method is also shown to outperform a previous pairwise constrained BML method.",4
Discriminative Block-Diagonal Representation Learning for Image Recognition.,"Existing block-diagonal representation studies mainly focuses on casting block-diagonal regularization on training data, while only little attention is dedicated to concurrently learning both block-diagonal representations of training and test data. In this paper, we propose a discriminative block-diagonal low-rank representation (BDLRR) method for recognition. In particular, the elaborate BDLRR is formulated as a joint optimization problem of shrinking the unfavorable representation from off-block-diagonal elements and strengthening the compact block-diagonal representation under the semisupervised framework of LRR. To this end, we first impose penalty constraints on the negative representation to eliminate the correlation between different classes such that the incoherence criterion of the extra-class representation is boosted. Moreover, a constructed subspace model is developed to enhance the self-expressive power of training samples and further build the representation bridge between the training and test samples, such that the coherence of the learned intraclass representation is consistently heightened. Finally, the resulting optimization problem is solved elegantly by employing an alternative optimization strategy, and a simple recognition algorithm on the learned representation is utilized for final prediction. Extensive experimental results demonstrate that the proposed method achieves superb recognition results on four face image data sets, three character data sets, and the 15 scene multicategories data set. It not only shows superior potential on image recognition but also outperforms the state-of-the-art methods.",4
An Algorithm for Finding the Most Similar Given Sized Subgraphs in Two Weighted Graphs.,"We propose a weighted common subgraph (WCS) matching algorithm to find the most similar subgraphs in two labeled weighted graphs. WCS matching, as a natural generalization of equal-sized graph matching and subgraph matching, has found wide applications in many computer vision and machine learning tasks. In this brief, WCS matching is first formulated as a combinatorial optimization problem over the set of partial permutation matrices. Then, it is approximately solved by a recently proposed combinatorial optimization framework-graduated nonconvexity and concavity procedure. Experimental comparisons on both synthetic graphs and real-world images validate its robustness against noise level, problem size, outlier number, and edge density.",4
Discriminative Transfer Learning Using Similarities and Dissimilarities.,"Transfer learning (TL) aims at solving the problem of learning an effective classification model for a target category, which has few training samples, by leveraging knowledge from source categories with far more training data. We propose a new discriminative TL (DTL) method, combining a series of hypotheses made by both the model learned with target training samples and the additional models learned with source category samples. Specifically, we use the sparse reconstruction residual as a basic discriminant and enhance its discriminative power by comparing two residuals from a positive and a negative dictionary. On this basis, we make use of similarities and dissimilarities by choosing both positively correlated and negatively correlated source categories to form additional dictionaries. A new Wilcoxon-Mann-Whitney statistic-based cost function is proposed to choose the additional dictionaries with unbalanced training data. Also, two parallel boosting processes are applied to both the positive and negative data distributions to further improve classifier performance. On two different image classification databases, the proposed DTL consistently outperforms other state-of-the-art TL methods while at the same time maintaining very efficient runtime.",4
Convolutional Sparse Autoencoders for Image Classification.,"Convolutional sparse coding (CSC) can model local connections between image content and reduce the code redundancy when compared with patch-based sparse coding. However, CSC needs a complicated optimization procedure to infer the codes (i.e., feature maps). In this brief, we proposed a convolutional sparse auto-encoder (CSAE), which leverages the structure of the convolutional AE and incorporates the max-pooling to heuristically sparsify the feature maps for feature learning. Together with competition over feature channels, this simple sparsifying strategy makes the stochastic gradient descent algorithm work efficiently for the CSAE training; thus, no complicated optimization procedure is involved. We employed the features learned in the CSAE to initialize convolutional neural networks for classification and achieved competitive results on benchmark data sets. In addition, by building connections between the CSAE and CSC, we proposed a strategy to construct local descriptors from the CSAE for classification. Experiments on Caltech-101 and Caltech-256 clearly demonstrated the effectiveness of the proposed method and verified the CSAE as a CSC model has the ability to explore connections between neighboring image content for classification tasks.",4
Adaptive Neural Networks Prescribed Performance Control Design for Switched Interconnected Uncertain Nonlinear Systems.,"In this paper, an adaptive neural net- works (NNs)-based decentralized control scheme with the prescribed performance is proposed for uncertain switched nonstrict-feedback interconnected nonlinear systems. It is assumed that nonlinear interconnected terms and nonlinear functions of the concerned systems are unknown, and also the switching signals are unknown and arbitrary. A linear state estimator is constructed to solve the problem of unmeasured states. The NNs are employed to approximate unknown interconnected terms and nonlinear functions. A new output feedback decentralized control scheme is developed by using the adaptive backstepping design technique. The control design problem of nonlinear interconnected switched systems with unknown switching signals can be solved by the proposed scheme, and only a tuning parameter is needed for each subsystem. The proposed scheme can ensure that all variables of the control systems are semi-globally uniformly ultimately bounded and the tracking errors converge to a small residual set with the prescribed performance bound. The effectiveness of the proposed control approach is verified by some simulation results.",4
Observer-Based Adaptive Fault-Tolerant Tracking Control of Nonlinear Nonstrict-Feedback Systems.,"This paper studies an output-based adaptive fault-tolerant control problem for nonlinear systems with nonstrict-feedback form. Neural networks are utilized to identify the unknown nonlinear characteristics in the system. An observer and a general fault model are constructed to estimate the unavailable states and describe the fault, respectively. Adaptive parameters are constructed to overcome the difficulties in the design process for nonstrict-feedback systems. Meanwhile, dynamic surface control technique is introduced to avoid the problem of ""explosion of complexity"". Furthermore, based on adaptive backstepping control method, an output-based adaptive neural tracking control strategy is developed for the considered system against actuator fault, which can ensure that all the signals in the resulting closed-loop system are bounded, and the system output signal can be regulated to follow the response of the given reference signal with a small error. Finally, the simulation results are provided to validate the effectiveness of the control strategy proposed in this paper.",4
Optimal Triggering of Networked Control Systems.,"This paper is focused on bandwidth allocation in nonlinear networked control systems. The objective is optimal triggering/scheduling for transmitting sensor measurements to the controller through a communication network. An algorithm based on approximate dynamic programming is developed for problems with fixed final times and then the result is extended to problems with infinite horizon. Zero-order-hold (ZOH), generalized ZOH, and networks with packet dropouts are the investigated cases. Problems with unknown models are also addressed and a model-free scheme is established for learning the (approximate) optimal solution. The convergence, optimality, and stability of the results are analyzed and, afterwards, some numerical analyses are presented for demonstrating the potentials of the algorithms in practice.",4
Robust and Efficient Boosting Method Using the Conditional Risk.,"Well known for its simplicity and effectiveness in classification, AdaBoost, however, suffers from overfitting when class-conditional distributions have significant overlap. Moreover, it is very sensitive to noise that appears in the labels. This paper tackles the above limitations simultaneously via optimizing a modified loss function (i.e., the conditional risk). The proposed approach has the following two advantages. First, it is able to directly take into account label uncertainty with an associated label confidence. Second, it introduces a trustworthiness measure on training samples via the Bayesian risk rule, and hence the resulting classifier tends to have finite sample performance that is superior to that of the original AdaBoost when there is a large overlap between class conditional distributions. Theoretical properties of the proposed method are investigated. Extensive experimental results using synthetic data and real-world data sets from UCI machine learning repository are provided. The empirical study shows the high competitiveness of the proposed method in predication accuracy and robustness when compared with the original AdaBoost and several existing robust AdaBoost algorithms.",4
Multistability of Recurrent Neural Networks With Nonmonotonic Activation Functions and Unbounded Time-Varying Delays.,"This paper is concerned with the coexistence of multiple equilibrium points and dynamical behaviors of recurrent neural networks with nonmonotonic activation functions and unbounded time-varying delays. Based on a state space partition by using the geometrical properties of the activation functions, it is revealed that an -neuron neural network can exhibit equilibrium points with . In particular, several sufficient criteria are proposed to ascertain the asymptotical stability of equilibrium points for recurrent neural networks. These theoretical results cover both monostability and multistability. Furthermore, the attraction basins of asymptotically stable equilibrium points are estimated. It is shown that the attraction basins of the stable equilibrium points can be larger than their originally partitioned subsets. Finally, the results are illustrated by using the simulation results of four examples.",4
Joint Estimation of Multiple Conditional Gaussian Graphical Models.,"In this paper, we propose a joint conditional graphical Lasso to learn multiple conditional Gaussian graphical models, also known as Gaussian conditional random fields, with some similar structures. Our model builds on the maximum likelihood method with the convex sparse group Lasso penalty. Moreover, our model is able to model multiple multivariate linear regressions with unknown noise covariances via a convex formulation. In addition, we develop an efficient approximated Newton's method for optimizing our model. Theoretically, we establish the asymptotic properties of our model on consistency and sparsistency under the high-dimensional settings. Finally, extensive numerical results on simulations and real data sets demonstrate that our method outperforms the compared methods on structure recovery and structured output prediction. To the best of our knowledge, the joint learning of multiple multivariate regressions with unknown covariance is first studied.",4
Learning Deep Generative Models With Doubly Stochastic Gradient MCMC.,"Deep generative models (DGMs), which are often organized in a hierarchical manner, provide a principled framework of capturing the underlying causal factors of data. Recent work on DGMs focussed on the development of efficient and scalable variational inference methods that learn a single model under some mean-field or parameterization assumptions. However, little work has been done on extending Markov chain Monte Carlo (MCMC) methods to Bayesian DGMs, which enjoy many advantages compared with variational methods. We present doubly stochastic gradient MCMC, a simple and generic method for (approximate) Bayesian inference of DGMs in a collapsed continuous parameter space. At each MCMC sampling step, the algorithm randomly draws a mini-batch of data samples to estimate the gradient of log-posterior and further estimates the intractable expectation over hidden variables via a neural adaptive importance sampler, where the proposal distribution is parameterized by a deep neural network and learnt jointly along with the sampling process. We demonstrate the effectiveness of learning various DGMs on a wide range of tasks, including density estimation, data generation, and missing data imputation. Our method outperforms many state-of-the-art competitors.",4
Stability Analysis of Genetic Regulatory Networks With Switching Parameters and Time Delays.,"This paper is concerned with the exponential stability analysis of genetic regulatory networks (GRNs) with switching parameters and time delays. In this paper, a new integral inequality and an improved reciprocally convex combination inequality are considered. By using the average dwell time approach together with a novel Lyapunov-Krasovskii functional, we derived some conditions to ensure the switched GRNs with switching parameters and time delays are exponentially stable. Finally, we give two numerical examples to clarify that our derived results are effective.",4
Feature Selection Based on Neighborhood Discrimination Index.,"Feature selection is viewed as an important preprocessing step for pattern recognition, machine learning, and data mining. Neighborhood is one of the most important concepts in classification learning and can be used to distinguish samples with different decisions. In this paper, a neighborhood discrimination index is proposed to characterize the distinguishing information of a neighborhood relation. It reflects the distinguishing ability of a feature subset. The proposed discrimination index is computed by considering the cardinality of a neighborhood relation rather than neighborhood similarity classes. Variants of the discrimination index, including joint discrimination index, conditional discrimination index, and mutual discrimination index, are introduced to compute the change of distinguishing information caused by the combination of multiple feature subsets. They have the similar properties as Shannon entropy and its variants. A parameter, named neighborhood radius, is introduced in these discrimination measures to address the analysis of real-valued data. Based on the proposed discrimination measures, the significance measure of a candidate feature is defined and a greedy forward algorithm for feature selection is designed. Data sets selected from public data sources are used to compare the proposed algorithm with existing algorithms. The experimental results confirm that the discrimination index-based algorithm yields superior performance compared to other classical algorithms.",4
Time-Varying System Identification Using an Ultra-Orthogonal Forward Regression and Multiwavelet Basis Functions With Applications to EEG.,"A new parametric approach is proposed for nonlinear and nonstationary system identification based on a time-varying nonlinear autoregressive with exogenous input (TV-NARX) model. The TV coefficients of the TV-NARX model are expanded using multiwavelet basis functions, and the model is thus transformed into a time-invariant regression problem. An ultra-orthogonal forward regression (UOFR) algorithm aided by mutual information (MI) is designed to identify a parsimonious model structure and estimate the associated model parameters. The UOFR-MI algorithm, which uses not only the observed data themselves but also weak derivatives of the signals, is more powerful in model structure detection. The proposed approach combining the advantages of both the basis function expansion method and the UOFR-MI algorithm is proved to be capable of tracking the change of TV parameters effectively in both numerical simulations and the real EEG data.",4
Convex Formulation for Kernel PCA and Its Use in Semisupervised Learning.,"In this brief, kernel principal component analysis (KPCA) is reinterpreted as the solution to a convex optimization problem. Actually, there is a constrained convex problem for each principal component, so that the constraints guarantee that the principal component is indeed a solution, and not a mere saddle point. Although these insights do not imply any algorithmic improvement, they can be used to further understand the method, formulate possible extensions, and properly address them. As an example, a new convex optimization problem for semisupervised classification is proposed, which seems particularly well suited whenever the number of known labels is small. Our formulation resembles a least squares support vector machine problem with a regularization parameter multiplied by a negative sign, combined with a variational principle for KPCA. Our primal optimization principle for semisupervised learning is solved in terms of the Lagrange multipliers. Numerical experiments in several classification tasks illustrate the performance of the proposed model in problems with only a few labeled data.",4
Neural Decomposition of Time-Series Data for Effective Generalization.,"We present a neural network technique for the analysis and extrapolation of time-series data called neural decomposition (ND). Units with a sinusoidal activation function are used to perform a Fourier-like decomposition of training samples into a sum of sinusoids, augmented by units with nonperiodic activation functions to capture linear trends and other nonperiodic components. We show how careful weight initialization can be combined with regularization to form a simple model that generalizes well. Our method generalizes effectively on the Mackey-Glass series, a data set of unemployment rates as reported by the U.S. Department of Labor Statistics, a time-series of monthly international airline passengers, the monthly ozone concentration in downtown Los Angeles, and an unevenly sampled time series of oxygen isotope measurements from a cave in north India. We find that ND outperforms popular time-series forecasting techniques, including long short-term memory network, echo-state networks, autoregressive integrated moving average (ARIMA), seasonal ARIMA, support vector regression with a radial basis function, and Gashler and Ashmore's model.",4
Delayed Feedback Control for Stabilization of Boolean Control Networks With State Delay.,"In this brief, we study the delayed feedback stabilization problem for Boolean control networks (BCNs) with state delay. Using the semi-tensor product of matrices, some necessary and sufficient conditions are obtained. For the stabilization of BCNs, detailed procedure to construct the feedback controllers is also presented. We further derive the number of different feedback controllers, which can successfully stabilize the BCN in a finite time. Finally, an illustrative example is presented to show the effectiveness of our method.",4
Learning Multimodal Parameters: A Bare-Bones Niching Differential Evolution Approach.,"Most learning methods contain optimization as a substep, where the nondifferentiability and multimodality of objectives push forward the interplay of evolutionary optimization algorithms and machine learning models. The recently emerged evolutionary multimodal optimization (MMOP) technique enables the learning of diverse sets of effective parameters for the models simultaneously, providing new opportunities to the applications requiring both accuracy and diversity, such as ensemble, interactive, and interpretive learning. Targeting at locating multiple optima simultaneously in the multimodal landscape, this paper develops an efficient neighborhood-based niching algorithm. Bare-bones differential evolution is used as the baseline. Further, using Gaussian mutation with local mean and standard deviations, the neighborhoods capture niches that match well with the contours of peaks in the landscape. To increase diversity and enhance global exploration, the proposed algorithm embeds a diversity preserving operator to reinitialize converged or overlapped neighborhoods. The experimental results verify that the proposed algorithm has superior and consistent performance for a wide range of MMOP problems. Further, the algorithm has been successfully applied to train neural network ensembles, which validates its effectiveness and benefits of learning multimodal parameters.",4
Sufficient Condition for the Existence of the Compact Set in the RBF Neural Network Control.,"In this brief, sufficient conditions are proposed for the existence of the compact sets in the neural network controls. First, we point out that the existence of the compact set in a classical neural network control scheme is unsolved and its result is incomplete. Next, as a simple case, we derive the sufficient condition of the existence of the compact set for the neural network control of first-order systems. Finally, we propose the sufficient condition of the existence of the compact set for the neural-network-based backstepping control of high-order nonlinear systems. The theoretic result is illustrated through a simulation example.",4
Aggregation Analysis for Competitive Multiagent Systems With Saddle Points via Switching Strategies.,"This paper addresses the aggregation issues of competitive multiagent systems (CMASs) consisting of competitive agents with multimodes and saddle points. In such CMASs, due to existing mutual competitions, every agent is equipped with finite multimodes, and every mode in any agent is described as a second-order linear time-invariant (LTI) control system. When the origin is the same saddle point of all modes of agents, to investigate aggregation of the CMASs with switching strategies, we first use switched LTI systems with saddle points to formulate such CMASs. Then, two new stability concepts, called initial-state-dependent (ISD) stability and initial-state-independent (ISI) stability, are defined for the CMASs. Based on these new stability concepts, a practical criterion of local/global ISI asymptotic aggregation is proposed for the CMASs. A local/global ISD/ISI asymptotical-stabilizing-control observed as distributed controls of multimodes, stabilizing-switching-paths, and a corresponding algorithm are all designed for local/global aggregation of such CMASs with switching delays. Finally, a numerical example illustrates the effectiveness and practicality of our new results.",4
Joint Attributes and Event Analysis for Multimedia Event Detection.,"Semantic attributes have been increasingly used the past few years for multimedia event detection (MED) with promising results. The motivation is that multimedia events generally consist of lower level components such as objects, scenes, and actions. By characterizing multimedia event videos with semantic attributes, one could exploit more informative cues for improved detection results. Much existing work obtains semantic attributes from images, which may be suboptimal for video analysis since these image-inferred attributes do not carry dynamic information that is essential for videos. To address this issue, we propose to learn semantic attributes from external videos using their semantic labels. We name them video attributes in this paper. In contrast with multimedia event videos, these external videos depict lower level contents such as objects, scenes, and actions. To harness video attributes, we propose an algorithm established on a correlation vector that correlates them to a target event. Consequently, we could incorporate video attributes latently as extra information into the event detector learnt from multimedia event videos in a joint framework. To validate our method, we perform experiments on the real-world large-scale TRECVID MED 2013 and 2014 data sets and compare our method with several state-of-the-art algorithms. The experiments show that our method is advantageous for MED.",4
Robust Least-Squares Support Vector Machine With Minimization of Mean and Variance of Modeling Error.,"The least-squares support vector machine (LS-SVM) is a popular data-driven modeling method and has been successfully applied to a wide range of applications. However, it has some disadvantages, including being ineffective at handling non-Gaussian noise as well as being sensitive to outliers. In this paper, a robust LS-SVM method is proposed and is shown to have more reliable performance when modeling a nonlinear system under conditions where Gaussian or non-Gaussian noise is present. The construction of a new objective function allows for a reduction of the mean of the modeling error as well as the minimization of its variance, and it does not constrain the mean of the modeling error to zero. This differs from the traditional LS-SVM, which uses a worst-case scenario approach in order to minimize the modeling error and constrains the mean of the modeling error to zero. In doing so, the proposed method takes the modeling error distribution information into consideration and is thus less conservative and more robust in regards to random noise. A solving method is then developed in order to determine the optimal parameters for the proposed robust LS-SVM. An additional analysis indicates that the proposed LS-SVM gives a smaller weight to a large-error training sample and a larger weight to a small-error training sample, and is thus more robust than the traditional LS-SVM. The effectiveness of the proposed robust LS-SVM is demonstrated using both artificial and real life cases.",4
Tree-Based Kernel for Graphs With Continuous Attributes.,"The availability of graph data with node attributes that can be either discrete or real-valued is constantly increasing. While existing Kernel methods are effective techniques for dealing with graphs having discrete node labels, their adaptation to nondiscrete or continuous node attributes has been limited, mainly for computational issues. Recently, a few kernels especially tailored for this domain, and that trade predictive performance for computational efficiency, have been proposed. In this brief, we propose a graph kernel for complex and continuous nodes' attributes, whose features are tree structures extracted from specific graph visits. The kernel manages to keep the same complexity of the state-of-the-art kernels while implicitly using a larger feature space. We further present an approximated variant of the kernel, which reduces its complexity significantly. Experimental results obtained on six real-world data sets show that the kernel is the best performing one on most of them. Moreover, in most cases, the approximated version reaches comparable performances to the current state-of-the-art kernels in terms of classification accuracy while greatly shortening the running times.",4
"Training DCNN by Combining Max-Margin, Max-Correlation Objectives, and Correntropy Loss for Multilabel Image Classification.","In this paper, we build a multilabel image classifier using a general deep convolutional neural network (DCNN). We propose a novel objective function that consists of three parts, i.e., max-margin objective, max-correlation objective, and correntropy loss. The max-margin objective explicitly enforces that the minimum score of positive labels must be larger than the maximum score of negative labels by a predefined margin, which not only improves accuracies of the multilabel classifier, but also eases the threshold determination. The max-correlation objective can make the DCNN model learn a latent semantic space, which maximizes the correlations between the feature vectors of the training samples and their corresponding ground-truth label vectors projected into this space. Instead of using the traditional softmax loss, we adopt the correntropy loss from the information theory field to minimize the training errors of the DCNN model. The proposed framework can be end-to-end trained. Comprehensive experimental evaluations on Pascal VOC 2007 and MIR Flickr 25K multilabel benchmark data sets with four DCNN models, i.e., AlexNet, VGG-16, GoogLeNet, and ResNet demonstrate that the proposed objective function can remarkably improve the performance accuracies of a DCNN model for the task of multilabel image classification.",4
Distribution-Preserving Stratified Sampling for Learning Problems.,"The need for extracting a small sample from a large amount of real data, possibly streaming, arises routinely in learning problems, e.g., for storage, to cope with computational limitations, obtain good training/test/validation sets, and select minibatches for stochastic gradient neural network training. Unless we have reasons to select the samples in an active way dictated by the specific task and/or model at hand, it is important that the distribution of the selected points is as similar as possible to the original data. This is obvious for unsupervised learning problems, where the goal is to gain insights on the distribution of the data, but it is also relevant for supervised problems, where the theory explains how the training set distribution influences the generalization error. In this paper, we analyze the technique of stratified sampling from the point of view of distances between probabilities. This allows us to introduce an algorithm, based on recursive binary partition of the input space, aimed at obtaining samples that are distributed as much as possible as the original data. A theoretical analysis is proposed, proving the (greedy) optimality of the procedure together with explicit error bounds. An adaptive version of the algorithm is also introduced to cope with streaming data. Simulation tests on various data sets and different learning tasks are also provided.",4
Improving CNN Performance Accuracies With Min-Max Objective.,"We propose a novel method for improving performance accuracies of convolutional neural network (CNN) without the need to increase the network complexity. We accomplish the goal by applying the proposed Min-Max objective to a layer below the output layer of a CNN model in the course of training. The Min-Max objective explicitly ensures that the feature maps learned by a CNN model have the minimum within-manifold distance for each object manifold and the maximum between-manifold distances among different object manifolds. The Min-Max objective is general and able to be applied to different CNNs with insignificant increases in computation cost. Moreover, an incremental minibatch training procedure is also proposed in conjunction with the Min-Max objective to enable the handling of large-scale training data. Comprehensive experimental evaluations on several benchmark data sets with both the image classification and face verification tasks reveal that employing the proposed Min-Max objective in the training process can remarkably improve performance accuracies of a CNN model in comparison with the same model trained without using this objective.",4
Online Feature Transformation Learning for Cross-Domain Object Category Recognition.,"In this paper, we introduce a new research problem termed online feature transformation learning in the context of multiclass object category recognition. The learning of a feature transformation is viewed as learning a global similarity metric function in an online manner. We first consider the problem of online learning a feature transformation matrix expressed in the original feature space and propose an online passive aggressive feature transformation algorithm. Then these original features are mapped to kernel space and an online single kernel feature transformation (OSKFT) algorithm is developed to learn a nonlinear feature transformation. Based on the OSKFT and the existing Hedge algorithm, a novel online multiple kernel feature transformation algorithm is also proposed, which can further improve the performance of online feature transformation learning in large-scale application. The classifier is trained with k nearest neighbor algorithm together with the learned similarity metric function. Finally, we experimentally examined the effect of setting different parameter values in the proposed algorithms and evaluate the model performance on several multiclass object recognition data sets. The experimental results demonstrate the validity and good performance of our methods on cross-domain and multiclass object recognition application.",4
Single-Input Pinning Controller Design for Reachability of Boolean Networks.,"This brief is concerned with the problem of a single-input pinning control design for reachability of Boolean networks (BNs). Specifically, the transition matrix of a BN is designed to steer the BN from an initial state to a desirable one. In addition, some nodes are selected as the pinning nodes by solving some logical matrix equations. Furthermore, a single-input pinning control algorithm is given. Eventually, a genetic regulatory network is provided to demonstrate the effectiveness and feasibility of the developed method.",4
Driving Under the Influence (of Language).,"We present a unified framework which supports grounding natural-language semantics in robotic driving. This framework supports acquisition (learning grounded meanings of nouns and prepositions from human sentential annotation of robotic driving paths), generation (using such acquired meanings to generate sentential description of new robotic driving paths), and comprehension (using such acquired meanings to support automated driving to accomplish navigational goals specified in natural language). We evaluate the performance of these three tasks by having independent human judges rate the semantic fidelity of the sentences associated with paths. Overall, machine performance is 74.9%, while the performance of human annotators is 83.8%.",4
Event-Triggered Distributed Approximate Optimal State and Output Control of Affine Nonlinear Interconnected Systems.,"This paper presents an approximate optimal distributed control scheme for a known interconnected system composed of input affine nonlinear subsystems using event-triggered state and output feedback via a novel hybrid learning scheme. First, the cost function for the overall system is redefined as the sum of cost functions of individual subsystems. A distributed optimal control policy for the interconnected system is developed using the optimal value function of each subsystem. To generate the optimal control policy, forward-in-time, neural networks are employed to reconstruct the unknown optimal value function at each subsystem online. In order to retain the advantages of event-triggered feedback for an adaptive optimal controller, a novel hybrid learning scheme is proposed to reduce the convergence time for the learning algorithm. The development is based on the observation that, in the event-triggered feedback, the sampling instants are dynamic and results in variable interevent time. To relax the requirement of entire state measurements, an extended nonlinear observer is designed at each subsystem to recover the system internal states from the measurable feedback. Using a Lyapunov-based analysis, it is demonstrated that the system states and the observer errors remain locally uniformly ultimately bounded and the control policy converges to a neighborhood of the optimal policy. Simulation results are presented to demonstrate the performance of the developed controller.",4
A Peak Price Tracking-Based Learning System for Portfolio Selection.,"We propose a novel linear learning system based on the peak price tracking (PPT) strategy for portfolio selection (PS). Recently, the topic of tracking control attracts intensive attention and some novel models are proposed based on backstepping methods, such that the system output tracks a desired trajectory. The proposed system has a similar evolution with a transform function that aggressively tracks the increasing power of different assets. As a result, the better performing assets will receive more investment. The proposed PPT objective can be formulated as a fast backpropagation algorithm, which is suitable for large-scale and time-limited applications, such as high-frequency trading. Extensive experiments on several benchmark data sets from diverse real financial markets show that PPT outperforms other state-of-the-art systems in computational time, cumulative wealth, and risk-adjusted metrics. It suggests that PPT is effective and even more robust than some defensive systems in PS.",4
Improving Sparsity and Scalability in Regularized Nonconvex Truncated-Loss Learning Problems.,"The truncated regular -loss support vector machine can eliminate the excessive number of support vectors (SVs); thus, it has significant advantages in robustness and scalability. However, in this paper, we discover that the associated state-of-the-art solvers, such as difference convex algorithm and concave-convex procedure, not only have limited sparsity promoting property for general truncated losses especially the -loss but also have poor scalability for large-scale problems. To circumvent these drawbacks, we present a general multistage scheme with explicit interpretation regarding SVs as well as outliers. In particular, we solve the general nonconvex truncated loss minimization through a sequence of associated convex subproblems, in which the outliers are removed in advance. The proposed algorithm can be regarded as a structural optimization attempt carefully considering sparsity imposed by the nonconvex truncated losses. We show that this general multistage algorithm offers sufficient sparsity especially for the truncated -loss. To further improve the scalability, we propose a linear multistep algorithm by employing a single iteration of coordinate descent to monotonically decrease the objective function at each stage and a kernel algorithm by using the Karush-Kuhn-Tucker conditions to cheaply find most part of the outliers for the next stage. Comparison experiments demonstrate that our methods have superiority in sparsity as well as efficiency in scalability.",4
Multilateral Telecoordinated Control of Multiple Robots With Uncertain Kinematics.,"This paper addresses the telecoordinated control of multiple robots in the simultaneous presence of asymmetric time-varying delays, nonpassive external forces, and uncertain kinematics/dynamics. To achieve the control objective, a neuroadaptive controller with utilizing prescribed performance control and switching control technique is developed, where the basic idea is to employ the concept of motion synchronization in each pair of master-slave robots and among all slave robots. By using the multiple Lyapunov-Krasovskii functionals method, the state-independent input-to-output practical stability of the closed-loop system is established. Compared with the previous approaches, the new design is straightforward and easier to implement and is applicable to a wider area. Simulation results on three pairs of three degrees-of-freedom robots confirm the theoretical findings.",4
Generalized Self-Organizing Maps for Automatic Determination of the Number of Clusters and Their Multiprototypes in Cluster Analysis.,"This paper presents a generalization of self-organizing maps with 1-D neighborhoods (neuron chains) that can be effectively applied to complex cluster analysis problems. The essence of the generalization consists in introducing mechanisms that allow the neuron chain-during learning-to disconnect into subchains, to reconnect some of the subchains again, and to dynamically regulate the overall number of neurons in the system. These features enable the network-working in a fully unsupervised way (i.e., using unlabeled data without a predefined number of clusters)-to automatically generate collections of multiprototypes that are able to represent a broad range of clusters in data sets. First, the operation of the proposed approach is illustrated on some synthetic data sets. Then, this technique is tested using several real-life, complex, and multidimensional benchmark data sets available from the University of California at Irvine (UCI) Machine Learning repository and the Knowledge Extraction based on Evolutionary Learning data set repository. A sensitivity analysis of our approach to changes in control parameters and a comparative analysis with an alternative approach are also performed.",4
Stability Analysis of Continuous-Time and Discrete-Time Quaternion-Valued Neural Networks With Linear Threshold Neurons.,"This paper addresses the problem of stability for continuous-time and discrete-time quaternion-valued neural networks (QVNNs) with linear threshold neurons. Applying the semidiscretization technique to the continuous-time QVNNs, the discrete-time analogs are obtained, which preserve the dynamical characteristics of their continuous-time counterparts. Via the plural decomposition method of quaternion, homeomorphic mapping theorem, as well as Lyapunov theorem, some sufficient conditions on the existence, uniqueness, and global asymptotical stability of the equilibrium point are derived for the continuous-time QVNNs and their discrete-time analogs, respectively. Furthermore, a uniform sufficient condition on the existence, uniqueness, and global asymptotical stability of the equilibrium point is obtained for both continuous-time QVNNs and their discrete-time version. Finally, two numerical examples are provided to substantiate the effectiveness of the proposed results.",4
Policy Approximation in Policy Iteration Approximate Dynamic Programming for Discrete-Time Nonlinear Systems.,"Policy iteration approximate dynamic programming (DP) is an important algorithm for solving optimal decision and control problems. In this paper, we focus on the problem associated with policy approximation in policy iteration approximate DP for discrete-time nonlinear systems using infinite-horizon undiscounted value functions. Taking policy approximation error into account, we demonstrate asymptotic stability of the control policy under our problem setting, show boundedness of the value function during each policy iteration step, and introduce a new sufficient condition for the value function to converge to a bounded neighborhood of the optimal value function. Aiming for practical implementation of an approximate policy, we consider using Volterra series, which has been extensively covered in controls literature for its good theoretical properties and for its success in practical applications. We illustrate the effectiveness of the main ideas developed in this paper using several examples including a practical problem of excitation control of a hydrogenerator.",4
Variance-Constrained State Estimation for Complex Networks With Randomly Varying Topologies.,"This paper investigates the variance-constrained state estimation problem for a class of nonlinear time-varying complex networks with randomly varying topologies, stochastic inner coupling, and measurement quantization. A Kronecker delta function and Markovian jumping parameters are utilized to describe the random changes of network topologies. A Gaussian random variable is introduced to model the stochastic disturbances in the inner coupling of complex networks. As a kind of incomplete measurements, measurement quantization is taken into consideration so as to account for the signal distortion phenomenon in the transmission process. Stochastic nonlinearities with known statistical characteristics are utilized to describe the stochastic evolution of the complex networks. We aim to design a finite-horizon estimator, such that in the simultaneous presence of quantized measurements and stochastic inner coupling, the prescribed variance constraints on the estimation error and the desired performance requirements are guaranteed over a finite horizon. Sufficient conditions are established by means of a series of recursive linear matrix inequalities, and subsequently, the estimator gain parameters are derived. A simulation example is presented to illustrate the effectiveness and applicability of the proposed estimator design algorithm.",4
Transductive Regression for Data With Latent Dependence Structure.,"Analyzing data with latent spatial and/or temporal structure is a challenge for machine learning. In this paper, we propose a novel nonlinear model for studying data with latent dependence structure. It successfully combines the concepts of Markov random fields, transductive learning, and regression, making heavy use of the notion of joint feature maps. Our transductive conditional random field regression model is able to infer the latent states by combining limited labeled data of high precision with unlabeled data containing measurement uncertainty. In this manner, we can propagate accurate information and greatly reduce uncertainty. We demonstrate the usefulness of our novel framework on generated time series data with the known temporal structure and successfully validate it on synthetic as well as real-world offshore data with the spatial structure from the oil industry to predict rock porosities from acoustic impedance data.",4
Manifold Preserving: An Intrinsic Approach for Semisupervised Distance Metric Learning.,"In this paper, we address the semisupervised distance metric learning problem and its applications in classification and image retrieval. First, we formulate a semisupervised distance metric learning model by considering the metric information of inner classes and interclasses. In this model, an adaptive parameter is designed to balance the inner metrics and intermetrics by using data structure. Second, we convert the model to a minimization problem whose variable is symmetric positive-definite matrix. Third, in implementation, we deduce an intrinsic steepest descent method, which assures that the metric matrix is strictly symmetric positive-definite at each iteration, with the manifold structure of the symmetric positive-definite matrix manifold. Finally, we test the proposed algorithm on conventional data sets, and compare it with other four representative methods. The numerical results validate that the proposed method significantly improves the classification with the same computational efficiency.",4
Multiclass Learning With Partially Corrupted Labels.,"Traditional classification systems rely heavily on sufficient training data with accurate labels. However, the quality of the collected data depends on the labelers, among which inexperienced labelers may exist and produce unexpected labels that may degrade the performance of a learning system. In this paper, we investigate the multiclass classification problem where a certain amount of training examples are randomly labeled. Specifically, we show that this issue can be formulated as a label noise problem. To perform multiclass classification, we employ the widely used importance reweighting strategy to enable the learning on noisy data to more closely reflect the results on noise-free data. We illustrate the applicability of this strategy to any surrogate loss functions and to different classification settings. The proportion of randomly labeled examples is proved to be upper bounded and can be estimated under a mild condition. The convergence analysis ensures the consistency of the learned classifier to the optimal classifier with respect to clean data. Two instantiations of the proposed strategy are also introduced. Experiments on synthetic and real data verify that our approach yields improvements over the traditional classifiers as well as the robust classifiers. Moreover, we empirically demonstrate that the proposed strategy is effective even on asymmetrically noisy data.",4
An Information-Theoretic-Cluster Visualization for Self-Organizing Maps.,"Improved data visualization will be a significant tool to enhance cluster analysis. In this paper, an information-theoretic-based method for cluster visualization using self-organizing maps (SOMs) is presented. The information-theoretic visualization (IT-vis) has the same structure as the unified distance matrix, but instead of depicting Euclidean distances between adjacent neurons, it displays the similarity between the distributions associated with adjacent neurons. Each SOM neuron has an associated subset of the data set whose cardinality controls the granularity of the IT-vis and with which the first- and second-order statistics are computed and used to estimate their probability density functions. These are used to calculate the similarity measure, based on Renyi's quadratic cross entropy and cross information potential (CIP). The introduced visualizations combine the low computational cost and kernel estimation properties of the representative CIP and the data structure representation of a single-linkage-based grouping algorithm to generate an enhanced SOM-based visualization. The visual quality of the IT-vis is assessed by comparing it with other visualization methods for several real-world and synthetic benchmark data sets. Thus, this paper also contains a significant literature survey. The experiments demonstrate the IT-vis cluster revealing capabilities, in which cluster boundaries are sharply captured. Additionally, the information-theoretic visualizations are used to perform clustering of the SOM. Compared with other methods, IT-vis of large SOMs yielded the best results in this paper, for which the quality of the final partitions was evaluated using external validity indices.",4
Neural AILC for Error Tracking Against Arbitrary Initial Shifts.,"This paper concerns with the adaptive iterative learning control using neural networks for systems performing repetitive tasks over a finite time interval. Two standing issues of such iterative learning control processes are addressed: one is the initial condition problem and the other is that related to the approximation error. Instead of the state tracking, an error tracking approach is proposed to tackle the problem arising from arbitrary initial shifts. The desired error trajectory is prespecified at the design stage, suitable to different tracking tasks. The initial value of the desired error trajectory for each cycle is required to be the same as that of the actual error trajectory. It is just a requirement for the initial value of the desired error trajectory, but does not pose any requirement for the initial value of the actual error trajectory. It is shown that the actual error trajectory is adjustable and is able to converge to a prespecified neighborhood of the origin, while all variables of the closed-loop system are of uniform boundedness. The robustness improvement in case of nonzero approximation error is made possible due to the use of a deadzone modified Lyapunov functional. The resultant estimation for the bound of the approximation error avoids deterioration in tracking performance. The effectiveness of the designed learning controller is validated through an illustrative example.",4
A Self-Paced Regularization Framework for Multilabel Learning.,"In this brief, we propose a novel multilabel learning framework, called multilabel self-paced learning, in an attempt to incorporate the SPL scheme into the regime of multilabel learning. Specifically, we first propose a new multilabel learning formulation by introducing a self-paced function as a regularizer, so as to simultaneously prioritize label learning tasks and instances in each iteration. Considering that different multilabel learning scenarios often need different self-paced schemes during learning, we thus provide a general way to find the desired self-paced functions. To the best of our knowledge, this is the first work to study multilabel learning by jointly taking into consideration the complexities of both training instances and labels. Experimental results on four publicly available data sets suggest the effectiveness of our approach, compared with the state-of-the-art methods.",4
Neighborhood-Based Stopping Criterion for Contrastive Divergence.,"Restricted Boltzmann Machines (RBMs) are general unsupervised learning devices to ascertain generative models of data distributions. RBMs are often trained using the Contrastive Divergence (CD) learning algorithm, an approximation to the gradient of the data log-likelihood (logL). A simple reconstruction error is often used as a stopping criterion for CD, although several authors have raised doubts concerning the feasibility of this procedure. In many cases, the evolution curve of the reconstruction error is monotonic, while the logL is not, thus indicating that the former is not a good estimator of the optimal stopping point for learning. However, not many alternatives to the reconstruction error have been discussed in the literature. An estimation of the logL of the training data based on annealed importance sampling is feasible but computationally very expensive. In this manuscript, we present a simple and cheap alternative, based on the inclusion of information contained in neighboring states to the training set, as a stopping criterion for CD learning.",4
Boundary-Eliminated Pseudoinverse Linear Discriminant for Imbalanced Problems.,"Existing learning models for classification of imbalanced data sets can be grouped as either boundary-based or nonboundary-based depending on whether a decision hyperplane is used in the learning process. The focus of this paper is a new approach that leverages the advantage of both approaches. Specifically, our new model partitions the input space into three parts by creating two additional boundaries in the training process, and then makes the final decision based on a heuristic measurement between the test sample and a subset of selected training samples. Since the original hyperplane used by the underlying original classifier will be eliminated, the proposed model is named the boundary-eliminated (BE) model. Additionally, the pseudoinverse linear discriminant (PILD) is adopted for the BE model so as to obtain a novel classifier abbreviated as BEPILD. Experiments validate both the effectiveness and the efficiency of BEPILD, compared with 13 state-of-the-art classification methods, based on 31 imbalanced and 7 standard data sets.",4
RankMap: A Framework for Distributed Learning From Dense Data Sets.,"This paper introduces RankMap, a platform-aware end-to-end framework for efficient execution of a broad class of iterative learning algorithms for massive and dense data sets. Our framework exploits data structure to scalably factorize it into an ensemble of lower rank subspaces. The factorization creates sparse low-dimensional representations of the data, a property which is leveraged to devise effective mapping and scheduling of iterative learning algorithms on the distributed computing machines. We provide two APIs, one matrix-based and one graph-based, which facilitate automated adoption of the framework for performing several contemporary learning applications. To demonstrate the utility of RankMap, we solve sparse recovery and power iteration problems on various real-world data sets with up to 1.8 billion nonzeros. Our evaluations are performed on Amazon EC2 and IBM iDataPlex servers using up to 244 cores. The results demonstrate up to two orders of magnitude improvements in memory usage, execution speed, and bandwidth compared with the best reported prior work, while achieving the same level of learning accuracy.",4
Barrier Function-Based Neural Adaptive Control With Locally Weighted Learning and Finite Neuron Self-Growing Strategy.,"This paper presents a new approach to construct neural adaptive control for uncertain nonaffine systems. By integrating locally weighted learning with barrier Lyapunov function (BLF), a novel control design method is presented to systematically address the two critical issues in neural network (NN) control field: one is how to fulfill the compact set precondition for NN approximation, and the other is how to use varying rather than a fixed NN structure to improve the functionality of NN control. A BLF is exploited to ensure the NN inputs to remain bounded during the entire system operation. To account for system nonlinearities, a neuron self-growing strategy is proposed to guide the process for adding new neurons to the system, resulting in a self-adjustable NN structure for better learning capabilities. It is shown that the number of neurons needed to accomplish the control task is finite, and better performance can be obtained with less number of neurons as compared with traditional methods. The salient feature of the proposed method also lies in the continuity of the control action everywhere. Furthermore, the resulting control action is smooth almost everywhere except for a few time instants at which new neurons are added. Numerical example illustrates the effectiveness of the proposed approach.",4
Exponential Synchronization of Networked Chaotic Delayed Neural Network by a Hybrid Event Trigger Scheme.,"This paper is concerned with the exponential synchronization for master-slave chaotic delayed neural network with event trigger control scheme. The model is established on a network control framework, where both external disturbance and network-induced delay are taken into consideration. The desired aim is to synchronize the master and slave systems with limited communication capacity and network bandwidth. In order to save the network resource, we adopt a hybrid event trigger approach, which not only reduces the data package sending out, but also gets rid of the Zeno phenomenon. By using an appropriate Lyapunov functional, a sufficient criterion for the stability is proposed for the error system with extended ( , , )-dissipativity performance index. Moreover, hybrid event trigger scheme and controller are codesigned for network-based delayed neural network to guarantee the exponential synchronization between the master and slave systems. The effectiveness and potential of the proposed results are demonstrated through a numerical example.",4
A Sequential Learning Approach for Scaling Up Filter-Based Feature Subset Selection.,"Increasingly, many machine learning applications are now associated with very large data sets whose sizes were almost unimaginable just a short time ago. As a result, many of the current algorithms cannot handle, or do not scale to, today's extremely large volumes of data. Fortunately, not all features that make up a typical data set carry information that is relevant or useful for prediction, and identifying and removing such irrelevant features can significantly reduce the total data size. The unfortunate dilemma, however, is that some of the current data sets are so large that common feature selection algorithms-whose very goal is to reduce the dimensionality-cannot handle such large data sets, creating a vicious cycle. We describe a sequential learning framework for feature subset selection (SLSS) that can scale with both the number of features and the number of observations. The proposed framework uses multiarm bandit algorithms to sequentially search a subset of variables, and assign a level of importance for each feature. The novel contribution of SLSS is its ability to naturally scale to large data sets, evaluate such data in a very small amount of time, and be performed independently of the optimization of any classifier to reduce unnecessary complexity. We demonstrate the capabilities of SLSS on synthetic and real-world data sets.",4
Graph Regularized Restricted Boltzmann Machine.,"The restricted Boltzmann machine (RBM) has received an increasing amount of interest in recent years. It determines good mapping weights that capture useful latent features in an unsupervised manner. The RBM and its generalizations have been successfully applied to a variety of image classification and speech recognition tasks. However, most of the existing RBM-based models disregard the preservation of the data manifold structure. In many real applications, the data generally reside on a low-dimensional manifold embedded in high-dimensional ambient space. In this brief, we propose a novel graph regularized RBM to capture features and learning representations, explicitly considering the local manifold structure of the data. By imposing manifold-based locality that preserves constraints on the hidden layer of the RBM, the model ultimately learns sparse and discriminative representations. The representations can reflect data distributions while simultaneously preserving the local manifold structure of data. We test our model using several benchmark image data sets for unsupervised clustering and supervised classification problem. The results demonstrate that the performance of our method exceeds the state-of-the-art alternatives.",4
Cascaded Subpatch Networks for Effective CNNs.,"Conventional convolutional neural networks use either a linear or a nonlinear filter to extract features from an image patch (region) of spatial size (typically, is small and is equal to , e.g., is 5 or 7). Generally, the size of the filter is equal to the size of the input patch. We argue that the representational ability of equal-size strategy is not strong enough. To overcome the drawback, we propose to use subpatch filter whose spatial size is smaller than . The proposed subpatch filter consists of two subsequent filters. The first one is a linear filter of spatial size and is aimed at extracting features from spatial domain. The second one is of spatial size and is used for strengthening the connection between different input feature channels and for reducing the number of parameters. The subpatch filter convolves with the input patch and the resulting network is called a subpatch network. Taking the output of one subpatch network as input, we further repeat constructing subpatch networks until the output contains only one neuron in spatial domain. These subpatch networks form a new network called the cascaded subpatch network (CSNet). The feature layer generated by CSNet is called the csconv layer. For the whole input image, we construct a deep neural network by stacking a sequence of csconv layers. Experimental results on five benchmark data sets demonstrate the effectiveness and compactness of the proposed CSNet. For example, our CSNet reaches a test error of 5.68% on the CIFAR10 data set without model averaging. To the best of our knowledge, this is the best result ever obtained on the CIFAR10 data set.",4
Substructural Regularization With Data-Sensitive Granularity for Sequence Transfer Learning.,"Sequence transfer learning is of interest in both academia and industry with the emergence of numerous new text domains from Twitter and other social media tools. In this paper, we put forward the data-sensitive granularity for transfer learning, and then, a novel substructural regularization transfer learning model (STLM) is proposed to preserve target domain features at substructural granularity in the light of the condition of labeled data set size. Our model is underpinned by hidden Markov model and regularization theory, where the substructural representation can be integrated as a penalty after measuring the dissimilarity of substructures between target domain and STLM with relative entropy. STLM can achieve the competing goals of preserving the target domain substructure and utilizing the observations from both the target and source domains simultaneously. The estimation of STLM is very efficient since an analytical solution can be derived as a necessary and sufficient condition. The relative usability of substructures to act as regularization parameters and the time complexity of STLM are also analyzed and discussed. Comprehensive experiments of part-of-speech tagging with both Brown and Twitter corpora fully justify that our model can make improvements on all the combinations of source and target domains.",4
New Splitting Criteria for Decision Trees in Stationary Data Streams.,"The most popular tools for stream data mining are based on decision trees. In previous 15 years, all designed methods, headed by the very fast decision tree algorithm, relayed on Hoeffding's inequality and hundreds of researchers followed this scheme. Recently, we have demonstrated that although the Hoeffding decision trees are an effective tool for dealing with stream data, they are a purely heuristic procedure; for example, classical decision trees such as ID3 or CART cannot be adopted to data stream mining using Hoeffding's inequality. Therefore, there is an urgent need to develop new algorithms, which are both mathematically justified and characterized by good performance. In this paper, we address this problem by developing a family of new splitting criteria for classification in stationary data streams and investigating their probabilistic properties. The new criteria, derived using appropriate statistical tools, are based on the misclassification error and the Gini index impurity measures. The general division of splitting criteria into two types is proposed. Attributes chosen based on type- splitting criteria guarantee, with high probability, the highest expected value of split measure. Type- criteria ensure that the chosen attribute is the same, with high probability, as it would be chosen based on the whole infinite data stream. Moreover, in this paper, two hybrid splitting criteria are proposed, which are the combinations of single criteria based on the misclassification error and Gini index.",4
Memcomputing Numerical Inversion With Self-Organizing Logic Gates.,"We propose to use digital memcomputing machines (DMMs), implemented with self-organizing logic gates (SOLGs), to solve the problem of numerical inversion. Starting from fixed-point scalar inversion, we describe the generalization to solving linear systems and matrix inversion. This method, when realized in hardware, will output the result in only one computational step. As an example, we perform simulations of the scalar case using a 5-bit logic circuit made of SOLGs, and show that the circuit successfully performs the inversion. Our method can be extended efficiently to any level of precision, since we prove that producing -bit precision in the output requires extending the circuit by at most bits. This type of numerical inversion can be implemented by DMM units in hardware; it is scalable, and thus of great benefit to any real-time computing application.",4
Improved Stability and Stabilization Results for Stochastic Synchronization of Continuous-Time Semi-Markovian Jump Neural Networks With Time-Varying Delay.,"Continuous-time semi-Markovian jump neural networks (semi-MJNNs) are those MJNNs whose transition rates are not constant but depend on the random sojourn time. Addressing stochastic synchronization of semi-MJNNs with time-varying delay, an improved stochastic stability criterion is derived in this paper to guarantee stochastic synchronization of the response systems with the drive systems. This is achieved through constructing a semi-Markovian Lyapunov-Krasovskii functional together as well as making use of a novel integral inequality and the characteristics of cumulative distribution functions. Then, with a linearization procedure, controller synthesis is carried out for stochastic synchronization of the drive-response systems. The desired state-feedback controller gains can be determined by solving a linear matrix inequality-based optimization problem. Simulation studies are carried out to demonstrate the effectiveness and less conservatism of the presented approach.",4
Robust Latent Subspace Learning for Image Classification.,"This paper proposes a novel method, called robust latent subspace learning (RLSL), for image classification. We formulate an RLSL problem as a joint optimization problem over both the latent SL and classification model parameter predication, which simultaneously minimizes: 1) the regression loss between the learned data representation and objective outputs and 2) the reconstruction error between the learned data representation and original inputs. The latent subspace can be used as a bridge that is expected to seamlessly connect the origin visual features and their class labels and hence improve the overall prediction performance. RLSL combines feature learning with classification so that the learned data representation in the latent subspace is more discriminative for classification. To learn a robust latent subspace, we use a sparse item to compensate error, which helps suppress the interference of noise via weakening its response during regression. An efficient optimization algorithm is designed to solve the proposed optimization problem. To validate the effectiveness of the proposed RLSL method, we conduct experiments on diverse databases and encouraging recognition results are achieved compared with many state-of-the-arts methods.",4
End-to-End Feature-Aware Label Space Encoding for Multilabel Classification With Many Classes.,"To make the problem of multilabel classification with many classes more tractable, in recent years, academia has seen efforts devoted to performing label space dimension reduction (LSDR). Specifically, LSDR encodes high-dimensional label vectors into low-dimensional code vectors lying in a latent space, so as to train predictive models at much lower costs. With respect to the prediction, it performs classification for any unseen instance by recovering a label vector from its predicted code vector via a decoding process. In this paper, we propose a novel method, namely End-to-End Feature-aware label space Encoding (E(2)FE), to perform LSDR. Instead of requiring an encoding function like most previous works, E(2)FE directly learns a code matrix formed by code vectors of the training instances in an end-to-end manner. Another distinct property of E(2)FE is its feature awareness attributable to the fact that the code matrix is learned by jointly maximizing the recoverability of the label space and the predictability of the latent space. Based on the learned code matrix, E(2)FE further trains predictive models to map instance features into code vectors, and also learns a linear decoding matrix for efficiently recovering the label vector of any unseen instance from its predicted code vector. Theoretical analyses show that both the code matrix and the linear decoding matrix in E(2)FE can be efficiently learned. Moreover, similar to previous works, E(2)FE can be specified to learn an encoding function. And it can also be extended with kernel tricks to handle nonlinear correlations between the feature space and the latent space. Comprehensive experiments conducted on diverse benchmark data sets with many classes show consistent performance gains of E(2)FE over the state-of-the-art methods.",4
Distributed Adaptive Containment Control for a Class of Nonlinear Multiagent Systems With Input Quantization.,"This paper is devoted to distributed adaptive containment control for a class of nonlinear multiagent systems with input quantization. By employing a matrix factorization and a novel matrix normalization technique, some assumptions involving control gain matrices in existing results are relaxed. By fusing the techniques of sliding mode control and backstepping control, a two-step design method is proposed to construct controllers and, with the aid of neural networks, all system nonlinearities are allowed to be unknown. Moreover, a linear time-varying model and a similarity transformation are introduced to circumvent the obstacle brought by quantization, and the controllers need no information about the quantizer parameters. The proposed scheme is able to ensure the boundedness of all closed-loop signals and steer the containment errors into an arbitrarily small residual set. The simulation results illustrate the effectiveness of the scheme.",4
Reversed Spectral Hashing.,"Hashing is emerging as a powerful tool for building highly efficient indices in large-scale search systems. In this paper, we study spectral hashing (SH), which is a classical method of unsupervised hashing. In general, SH solves for the hash codes by minimizing an objective function that tries to preserve the similarity structure of the data given. Although computationally simple, very often SH performs unsatisfactorily and lags distinctly behind the state-of-the-art methods. We observe that the inferior performance of SH is mainly due to its imperfect formulation; that is, the optimization of the minimization problem in SH actually cannot ensure that the similarity structure of the high-dimensional data is really preserved in the low-dimensional hash code space. In this paper, we, therefore, introduce reversed SH (ReSH), which is SH with its input and output interchanged. Unlike SH, which estimates the similarity structure from the given high-dimensional data, our ReSH defines the similarities between data points according to the unknown low-dimensional hash codes. Equipped with such a reversal mechanism, ReSH can seamlessly overcome the drawback of SH. More precisely, the minimization problem in our ReSH can be optimized if and only if similar data points are mapped to adjacent hash codes, and mostly important, dissimilar data points are considerably separated from each other in the code space. Finally, we solve the minimization problem in ReSH by multilayer neural networks and obtain state-of-the-art retrieval results on three benchmark data sets.",4
Data-Driven Learning Control for Stochastic Nonlinear Systems: Multiple Communication Constraints and Limited Storage.,"This paper proposes a data-driven learning control method for stochastic nonlinear systems under random communication conditions, including data dropouts, communication delays, and packet transmission disordering. A renewal mechanism is added to the buffer to regulate the arrived packets, and a recognition mechanism is introduced to the controller for the selection of suitable update packets. Both intermittent and successive update schemes are proposed based on the conventional P-type iterative learning control algorithm, and are shown to converge to the desired input with probability one. The convergence and effectiveness of the proposed algorithms are verified by means of illustrative simulations.",4
Structure Learning for Deep Neural Networks Based on Multiobjective Optimization.,"This paper focuses on the connecting structure of deep neural networks and proposes a layerwise structure learning method based on multiobjective optimization. A model with better generalization can be obtained by reducing the connecting parameters in deep networks. The aim is to find the optimal structure with high representation ability and better generalization for each layer. Then, the visible data are modeled with respect to structure based on the products of experts. In order to mitigate the difficulty of estimating the denominator in PoE, the denominator is simplified and taken as another objective, i.e., the connecting sparsity. Moreover, for the consideration of the contradictory nature between the representation ability and the network connecting sparsity, the multiobjective model is established. An improved multiobjective evolutionary algorithm is used to solve this model. Two tricks are designed to decrease the computational cost according to the properties of input data. The experiments on single-layer level, hierarchical level, and application level demonstrate the effectiveness of the proposed algorithm, and the learned structures can improve the performance of deep neural networks.",4
On the Dynamics of Hopfield Neural Networks on Unit Quaternions.,"In this paper, we first address the dynamics of the elegant multivalued quaternionic Hopfield neural network (MV-QHNN) proposed by Minemoto et al. Contrary to what was expected, we show that the MV-QHNN, as well as one of its variation, does not always come to rest at an equilibrium state under the usual conditions. In fact, we provide simple examples in which the network yields a periodic sequence of quaternionic state vectors. Afterward, we turn our attention to the continuous-valued quaternionic Hopfield neural network (CV-QHNN), which can be derived from the MV-QHNN by means of a limit process. The CV-QHNN can be implemented more easily than the MV-QHNN model. Furthermore, the asynchronous CV-QHNN always settles down into an equilibrium state under the usual conditions. Theoretical issues are all illustrated by examples in this paper.",4
Distributed Optimal Consensus Over Resource Allocation Network and Its Application to Dynamical Economic Dispatch.,"The resource allocation problem is studied and reformulated by a distributed interior point method via a -logarithmic barrier. By the facilitation of the graph Laplacian, a fully distributed continuous-time multiagent system is developed for solving the problem. Specifically, to avoid high singularity of the -logarithmic barrier at boundary, an adaptive parameter switching strategy is introduced into this dynamical multiagent system. The convergence rate of the distributed algorithm is obtained. Moreover, a novel distributed primal-dual dynamical multiagent system is designed in a smart grid scenario to seek the saddle point of dynamical economic dispatch, which coincides with the optimal solution. The dual decomposition technique is applied to transform the optimization problem into easily solvable resource allocation subproblems with local inequality constraints. The good performance of the new dynamical systems is, respectively, verified by a numerical example and the IEEE six-bus test system-based simulations.",4
Uncertain Data Clustering in Distributed Peer-to-Peer Networks.,"Uncertain data clustering has been recognized as an essential task in the research of data mining. Many centralized clustering algorithms are extended by defining new distance or similarity measurements to tackle this issue. With the fast development of network applications, these centralized methods show their limitations in conducting data clustering in a large dynamic distributed peer-to-peer network due to the privacy and security concerns or the technical constraints brought by distributive environments. In this paper, we propose a novel distributed uncertain data clustering algorithm, in which the centralized global clustering solution is approximated by performing distributed clustering. To shorten the execution time, the reduction technique is then applied to transform the proposed method into its deterministic form by replacing each uncertain data object with its expected centroid. Finally, the attribute-weight-entropy regularization technique enhances the proposed distributed clustering method to achieve better results in data clustering and extract the essential features for cluster identification. The experiments on both synthetic and real-world data have shown the efficiency and superiority of the presented algorithm.",4
"Spiking, Bursting, and Population Dynamics in a Network of Growth Transform Neurons.","This paper investigates the dynamical properties of a network of neurons, each of which implements an asynchronous mapping based on polynomial growth transforms. In the first part of this paper, we present a geometric approach for visualizing the dynamics of the network where each of the neurons traverses a trajectory in a dual optimization space, whereas the network itself traverses a trajectory in an equivalent primal optimization space. We show that as the network learns to solve basic classification tasks, different choices of primal-dual mapping produce unique but interpretable neural dynamics like noise shaping, spiking, and bursting. While the proposed framework is general enough, in this paper, we demonstrate its use for designing support vector machines (SVMs) that exhibit noise-shaping properties similar to those of modulators, and for designing SVMs that learn to encode information using spikes and bursts. It is demonstrated that the emergent switching, spiking, and burst dynamics produced by each neuron encodes its respective margin of separation from a classification hyperplane whose parameters are encoded by the network population dynamics. We believe that the proposed growth transform neuron model and the underlying geometric framework could serve as an important tool to connect well-established machine learning algorithms like SVMs to neuromorphic principles like spiking, bursting, population encoding, and noise shaping.",4
Nonlinear Decoupling Control With ANFIS-Based Unmodeled Dynamics Compensation for a Class of Complex Industrial Processes.,"Complex industrial processes are multivariable and generally exhibit strong coupling among their control loops with heavy nonlinear nature. These make it very difficult to obtain an accurate model. As a result, the conventional and data-driven control methods are difficult to apply. Using a twin-tank level control system as an example, a novel multivariable decoupling control algorithm with adaptive neural-fuzzy inference system (ANFIS)-based unmodeled dynamics (UD) compensation is proposed in this paper for a class of complex industrial processes. At first, a nonlinear multivariable decoupling controller with UD compensation is introduced. Different from the existing methods, the decomposition estimation algorithm using ANFIS is employed to estimate the UD, and the desired estimating and decoupling control effects are achieved. Second, the proposed method does not require the complicated switching mechanism which has been commonly used in the literature. This significantly simplifies the obtained decoupling algorithm and its realization. Third, based on some new lemmas and theorems, the conditions on the stability and convergence of the closed-loop system are analyzed to show the uniform boundedness of all the variables. This is then followed by the summary on experimental tests on a heavily coupled nonlinear twin-tank system that demonstrates the effectiveness and the practicability of the proposed method.",4
Robust Structured Nonnegative Matrix Factorization for Image Representation.,"Dimensionality reduction has attracted increasing attention, because high-dimensional data have arisen naturally in numerous domains in recent years. As one popular dimensionality reduction method, nonnegative matrix factorization (NMF), whose goal is to learn parts-based representations, has been widely studied and applied to various applications. In contrast to the previous approaches, this paper proposes a novel semisupervised NMF learning framework, called robust structured NMF, that learns a robust discriminative representation by leveraging the block-diagonal structure and the -norm (especially when ) loss function. Specifically, the problems of noise and outliers are well addressed by the -norm ( ) loss function, while the discriminative representations of both the labeled and unlabeled data are simultaneously learned by explicitly exploring the block-diagonal structure. The proposed problem is formulated as an optimization problem with a well-defined objective function solved by the proposed iterative algorithm. The convergence of the proposed optimization algorithm is analyzed both theoretically and empirically. In addition, we also discuss the relationships between the proposed method and some previous methods. Extensive experiments on both the synthetic and real-world data sets are conducted, and the experimental results demonstrate the effectiveness of the proposed method in comparison to the state-of-the-art methods.",4
User Preference-Based Dual-Memory Neural Model With Memory Consolidation Approach.,"Memory modeling has been a popular topic of research for improving the performance of autonomous agents in cognition related problems. Apart from learning distinct experiences correctly, significant or recurring experiences are expected to be learned better and be retrieved easier. In order to achieve this objective, this paper proposes a user preference-based dual-memory adaptive resonance theory network model, which makes use of a user preference to encode memories with various strengths and to learn and forget at various rates. Over a period of time, memories undergo a consolidation-like process at a rate proportional to the user preference at the time of encoding and the frequency of recall of a particular memory. Consolidated memories are easier to recall and are more stable. This dual-memory neural model generates distinct episodic memories and a flexible semantic-like memory component. This leads to an enhanced retrieval mechanism of experiences through two routes. The simulation results are presented to evaluate the proposed memory model based on various kinds of cues over a number of trials. The experimental results on Mybot are also presented. The results verify that not only are distinct experiences learned correctly but also that experiences associated with higher user preference and recall frequency are consolidated earlier. Thus, these experiences are recalled more easily relative to the unconsolidated experiences.",4
Robust Multiview Data Analysis Through Collective Low-Rank Subspace.,"Multiview data are of great abundance in real-world applications, since various viewpoints and multiple sensors desire to represent the data in a better way. Conventional multiview learning methods aimed to learn multiple view-specific transformations meanwhile assumed the view knowledge of training, and test data were available in advance. However, they would fail when we do not have any prior knowledge for the probe data's view information, since the correct view-specific projections cannot be utilized to extract effective feature representations. In this paper, we develop a collective low-rank subspace (CLRS) algorithm to deal with this problem in multiview data analysis. CLRS attempts to reduce the semantic gap across multiple views through seeking a view-free low-rank projection shared by multiple view-specific transformations. Moreover, we exploit low-rank reconstruction to build a bridge between the view-specific features and those view-free ones transformed with the CLRS. Furthermore, a supervised cross-view regularizer is developed to couple the within-class data across different views to make the learned collective subspace more discriminative. Our CLRS makes our algorithm more flexible when addressing the challenging issue without any prior knowledge of the probe data's view information. To that end, two different settings of experiments on several multiview benchmarks are designed to evaluate the proposed approach. Experimental results have verified the effective performance of our proposed method by comparing with the state-of-the-art algorithms.",4
Learning to Predict Consequences as a Method of Knowledge Transfer in Reinforcement Learning.,"The reinforcement learning (RL) paradigm allows agents to solve tasks through trial-and-error learning. To be capable of efficient, long-term learning, RL agents should be able to apply knowledge gained in the past to new tasks they may encounter in the future. The ability to predict actions' consequences may facilitate such knowledge transfer. We consider here domains where an RL agent has access to two kinds of information: agent-centric information with constant semantics across tasks, and environment-centric information, which is necessary to solve the task, but with semantics that differ between tasks. For example, in robot navigation, environment-centric information may include the robot's geographic location, while agent-centric information may include sensor readings of various nearby obstacles. We propose that these situations provide an opportunity for a very natural style of knowledge transfer, in which the agent learns to predict actions' environmental consequences using agent-centric information. These predictions contain important information about the affordances and dangers present in a novel environment, and can effectively transfer knowledge from agent-centric to environment-centric learning systems. Using several example problems including spatial navigation and network routing, we show that our knowledge transfer approach can allow faster and lower cost learning than existing alternatives.",4
On Better Exploring and Exploiting Task Relationships in Multitask Learning: Joint Model and Feature Learning.,"Multitask learning (MTL) aims to learn multiple tasks simultaneously through the interdependence between different tasks. The way to measure the relatedness between tasks is always a popular issue. There are mainly two ways to measure relatedness between tasks: common parameters sharing and common features sharing across different tasks. However, these two types of relatedness are mainly learned independently, leading to a loss of information. In this paper, we propose a new strategy to measure the relatedness that jointly learns shared parameters and shared feature representations. The objective of our proposed method is to transform the features of different tasks into a common feature space in which the tasks are closely related and the shared parameters can be better optimized. We give a detailed introduction to our proposed MTL method. Additionally, an alternating algorithm is introduced to optimize the nonconvex objection. A theoretical bound is given to demonstrate that the relatedness between tasks can be better measured by our proposed MTL algorithm. We conduct various experiments to verify the superiority of the proposed joint model and feature MTL method.",4
A Discrete-Time Recurrent Neural Network for Solving Rank-Deficient Matrix Equations With an Application to Output Regulation of Linear Systems.,"This paper presents a discrete-time recurrent neural network approach to solving systems of linear equations with two features. First, the system of linear equations may not have a unique solution. Second, the system matrix is not known precisely, but a sequence of matrices that converges to the unknown system matrix exponentially is known. The problem is motivated from solving the output regulation problem for linear systems. Thus, an application of our main result leads to an online solution to the output regulation problem for linear systems.",4
Adaptive Backstepping-Based Neural Tracking Control for MIMO Nonlinear Switched Systems Subject to Input Delays.,"This brief proposes a new neural-network (NN)-based adaptive output tracking control scheme for a class of disturbed multiple-input multiple-output uncertain nonlinear switched systems with input delays. By combining the universal approximation ability of radial basis function NNs and adaptive backstepping recursive design with an improved multiple Lyapunov function (MLF) scheme, a novel adaptive neural output tracking controller design method is presented for the switched system. The feature of the developed design is that different coordinate transformations are adopted to overcome the conservativeness caused by adopting a common coordinate transformation for all subsystems. It is shown that all the variables of the resulting closed-loop system are semiglobally uniformly ultimately bounded under a class of switching signals in the presence of MLF and that the system output can follow the desired reference signal. To demonstrate the practicability of the obtained result, an adaptive neural output tracking controller is designed for a mass-spring-damper system.",4
Extended Polynomial Growth Transforms for Design and Training of Generalized Support Vector Machines.,"Growth transformations constitute a class of fixed-point multiplicative update algorithms that were originally proposed for optimizing polynomial and rational functions over a domain of probability measures. In this paper, we extend this framework to the domain of bounded real variables which can be applied towards optimizing the dual cost function of a generic support vector machine (SVM). The approach can, therefore, not only be used to train traditional soft-margin binary SVMs, one-class SVMs, and probabilistic SVMs but can also be used to design novel variants of SVMs with different types of convex and quasi-convex loss functions. In this paper, we propose an efficient training algorithm based on polynomial growth transforms, and compare and contrast the properties of different SVM variants using several synthetic and benchmark data sets. The preliminary experiments show that the proposed multiplicative update algorithm is more scalable and yields better convergence compared to standard quadratic and nonlinear programming solvers. While the formulation and the underlying algorithms have been validated in this paper only for SVM-based learning, the proposed approach is general and can be applied to a wide variety of optimization problems and statistical learning models.",4
Tensor-Factorized Neural Networks.,"The growing interests in multiway data analysis and deep learning have drawn tensor factorization (TF) and neural network (NN) as the crucial topics. Conventionally, the NN model is estimated from a set of one-way observations. Such a vectorized NN is not generalized for learning the representation from multiway observations. The classification performance using vectorized NN is constrained, because the temporal or spatial information in neighboring ways is disregarded. More parameters are required to learn the complicated data structure. This paper presents a new tensor-factorized NN (TFNN), which tightly integrates TF and NN for multiway feature extraction and classification under a unified discriminative objective. This TFNN is seen as a generalized NN, where the affine transformation in an NN is replaced by the multilinear and multiway factorization for tensor-based NN. The multiway information is preserved through layerwise factorization. Tucker decomposition and nonlinear activation are performed in each hidden layer. The tensor-factorized error backpropagation is developed to train TFNN with the limited parameter size and computation time. This TFNN can be further extended to realize the convolutional TFNN (CTFNN) by looking at small subtensors through the factorized convolution. Experiments on real-world classification tasks demonstrate that TFNN and CTFNN attain substantial improvement when compared with an NN and a convolutional NN, respectively.",4
Online Hashing.,"Although hash function learning algorithms have achieved great success in recent years, most existing hash models are off-line, which are not suitable for processing sequential or online data. To address this problem, this paper proposes an online hash model to accommodate data coming in stream for online learning. Specifically, a new loss function is proposed to measure the similarity loss between a pair of data samples in hamming space. Then, a structured hash model is derived and optimized in a passive-aggressive way. Theoretical analysis on the upper bound of the cumulative loss for the proposed online hash model is provided. Furthermore, we extend our online hashing (OH) from a single model to a multimodel OH that trains multiple models so as to retain diverse OH models in order to avoid biased update. The competitive efficiency and effectiveness of the proposed online hash models are verified through extensive experiments on several large-scale data sets as compared with related hashing methods.",4
Online Learning Algorithm Based on Adaptive Control Theory.,"This paper proposes a new online learning algorithm which is based on adaptive control (AC) theory, thus, we call this proposed algorithm as AC algorithm. Comparing to the gradient descent (GD) and exponential gradient (EG) algorithm which have been applied to online prediction problems, we find a new form of AC theory for online prediction problems and investigate two key questions: how to get a new update law which has a tighter upper bound on the error than the square loss? How to compare the upper bound for accumulated losses for the three algorithms? We obtain a new update law which fully utilizes model reference AC theory. Moreover, we present upper bound on the worst-case expected loss for AC algorithm and compare it with previously known bounds for the GD and EG algorithm. The loss bound we get in this paper is a time-varying function, which provides increasingly accurate estimates for upper bound. The AC algorithm has a much smaller loss only if the number of the samples meets certain conditions which can be seen in this paper. We also performed experiments which show that our update law is reasonably feasible and our upper bound is quite tight on both simple artificial and real data sets. The main contributions of this paper are twofold. First of all, we develop a new online algorithm called AC algorithm, and second, we obtain improved bounds, see Theorems 2-4 in this paper.",4
Online Learning Algorithms Can Converge Comparably Fast as Batch Learning.,"Online learning algorithms in a reproducing kernel Hilbert space associated with convex loss functions are studied. We show that in terms of the expected excess generalization error, they can converge comparably fast as corresponding kernel-based batch learning algorithms. Under mild conditions on loss functions and approximation errors, fast learning rates and finite sample upper bounds are established using polynomially decreasing step-size sequences. For some commonly used loss functions for classification, such as the logistic and the -norm hinge loss functions with , the learning rates are the same as those for Tikhonov regularization and can be of order , which are nearly optimal up to a logarithmic factor. Our novelty lies in a sharp estimate for the expected values of norms of the learning sequence (or an inductive argument to uniformly bound the expected risks of the learning sequence in expectation) and a refined error decomposition for online learning algorithms.",4
A Parallel Multiclassification Algorithm for Big Data Using an Extreme Learning Machine.,"As data sets become larger and more complicated, an extreme learning machine (ELM) that runs in a traditional serial environment cannot realize its ability to be fast and effective. Although a parallel ELM (PELM) based on MapReduce to process large-scale data shows more efficient learning speed than identical ELM algorithms in a serial environment, some operations, such as intermediate results stored on disks and multiple copies for each task, are indispensable, and these operations create a large amount of extra overhead and degrade the learning speed and efficiency of the PELMs. In this paper, an efficient ELM based on the Spark framework (SELM), which includes three parallel subalgorithms, is proposed for big data classification. By partitioning the corresponding data sets reasonably, the hidden layer output matrix calculation algorithm, matrix decomposition algorithm, and matrix decomposition algorithm perform most of the computations locally. At the same time, they retain the intermediate results in distributed memory and cache the diagonal matrix as broadcast variables instead of several copies for each task to reduce a large amount of the costs, and these actions strengthen the learning ability of the SELM. Finally, we implement our SELM algorithm to classify large data sets. Extensive experiments have been conducted to validate the effectiveness of the proposed algorithms. As shown, our SELM achieves an speedup on a cluster with ten nodes, and reaches a speedup with 15 nodes, an speedup with 20 nodes, a speedup with 25 nodes, a speedup with 30 nodes, and a speedup with 35 nodes.",4
GoDec+: Fast and Robust Low-Rank Matrix Decomposition Based on Maximum Correntropy.,"GoDec is an efficient low-rank matrix decomposition algorithm. However, optimal performance depends on sparse errors and Gaussian noise. This paper aims to address the problem that a matrix is composed of a low-rank component and unknown corruptions. We introduce a robust local similarity measure called correntropy to describe the corruptions and, in doing so, obtain a more robust and faster low-rank decomposition algorithm: GoDec+. Based on half-quadratic optimization and greedy bilateral paradigm, we deliver a solution to the maximum correntropy criterion (MCC)-based low-rank decomposition problem. Experimental results show that GoDec+ is efficient and robust to different corruptions including Gaussian noise, Laplacian noise, salt & pepper noise, and occlusion on both synthetic and real vision data. We further apply GoDec+ to more general applications including classification and subspace clustering. For classification, we construct an ensemble subspace from the low-rank GoDec+ matrix and introduce an MCC-based classifier. For subspace clustering, we utilize GoDec+ values low-rank matrix for MCC-based self-expression and combine it with spectral clustering. Face recognition, motion segmentation, and face clustering experiments show that the proposed methods are effective and robust. In particular, we achieve the state-of-the-art performance on the Hopkins 155 data set and the first 10 subjects of extended Yale B for subspace clustering.",4
Off-Policy Reinforcement Learning for Synchronization in Multiagent Graphical Games.,"This paper develops an off-policy reinforcement learning (RL) algorithm to solve optimal synchronization of multiagent systems. This is accomplished by using the framework of graphical games. In contrast to traditional control protocols, which require complete knowledge of agent dynamics, the proposed off-policy RL algorithm is a model-free approach, in that it solves the optimal synchronization problem without knowing any knowledge of the agent dynamics. A prescribed control policy, called behavior policy, is applied to each agent to generate and collect data for learning. An off-policy Bellman equation is derived for each agent to learn the value function for the policy under evaluation, called target policy, and find an improved policy, simultaneously. Actor and critic neural networks along with least-square approach are employed to approximate target control policies and value functions using the data generated by applying prescribed behavior policies. Finally, an off-policy RL algorithm is presented that is implemented in real time and gives the approximate optimal control policy for each agent using only measured data. It is shown that the optimal distributed policies found by the proposed algorithm satisfy the global Nash equilibrium and synchronize all agents to the leader. Simulation results illustrate the effectiveness of the proposed method.",4
Dissipativity-Based Resilient Filtering of Periodic Markovian Jump Neural Networks With Quantized Measurements.,"The problem of dissipativity-based resilient filtering for discrete-time periodic Markov jump neural networks in the presence of quantized measurements is investigated in this paper. Due to the limited capacities of network medium, a logarithmic quantizer is applied to the underlying systems. Considering the fact that the filter is realized through a network, randomly occurring parameter uncertainties of the filter are modeled by two mode-dependent Bernoulli processes. By establishing the mode-dependent periodic Lyapunov function, sufficient conditions are given to ensure the stability and dissipativity of the filtering error system. The filter parameters are derived via solving a set of linear matrix inequalities. The merits and validity of the proposed design techniques are verified by a simulation example.",4
Manifold Regularized Correlation Object Tracking.,"In this paper, we propose a manifold regularized correlation tracking method with augmented samples. To make better use of the unlabeled data and the manifold structure of the sample space, a manifold regularization-based correlation filter is introduced, which aims to assign similar labels to neighbor samples. Meanwhile, the regression model is learned by exploiting the block-circulant structure of matrices resulting from the augmented translated samples over multiple base samples cropped from both target and nontarget regions. Thus, the final classifier in our method is trained with positive, negative, and unlabeled base samples, which is a semisupervised learning framework. A block optimization strategy is further introduced to learn a manifold regularization-based correlation filter for efficient online tracking. Experiments on two public tracking data sets demonstrate the superior performance of our tracker compared with the state-of-the-art tracking approaches.",4
New Conditions for Global Asymptotic Stability of Memristor Neural Networks.,"Recent papers in the literature introduced a class of neural networks (NNs) with memristors, named dynamic-memristor (DM) NNs, such that the analog processing takes place in the charge-flux domain, instead of the typical current-voltage domain as it happens for Hopfield NNs and standard cellular NNs. One key advantage is that, when a steady state is reached, all currents, voltages, and power of a DM-NN drop off, whereas the memristors act as nonvolatile memories that store the processing result. Previous work in the literature addressed multistability of DM-NNs, i.e., convergence of solutions in the presence of multiple asymptotically stable equilibrium points (EPs). The goal of this paper is to study a basically different dynamical property of DM-NNs, namely, to thoroughly investigate the fundamental issue of global asymptotic stability (GAS) of the unique EP of a DM-NN in the general case of nonsymmetric neuron interconnections. A basic result on GAS of DM-NNs is established using Lyapunov method and the concept of Lyapunov diagonally stable matrices. On this basis, some relevant classes of nonsymmetric DM-NNs enjoying the property of GAS are highlighted.",4
On the Impact of Regularization Variation on Localized Multiple Kernel Learning.,"This brief analyzes the effects of regularization variations in the localized kernel weights on the hypothesis generated by localized multiple kernel learning (LMKL) algorithms. Recent research on LMKL includes imposing different regularizations on the localized kernel weights and has led to varying formulations and solution strategies. Following the stability analysis theory as presented by Bousquet and Elisseeff, we give stability bounds based on the norm of the variation of localized kernel weights for three LMKL methods cast in the support vector machine classification framework, including vector -norm LMKL, matrix-regularized -norm LMKL, and samplewise -norm LMKL. Further comparison of these bounds helps to qualitatively reveal the performance differences produced by these regularization methods, that is, matrix-regularized LMKL achieves superior performance, followed by vector -norm LMKL and samplewise -norm LMKL. Finally, a set of experimental results on ten benchmark machine learning UCI data sets is reported and shown to empirically support our theoretical analysis.",4
Synchronization Criteria for Discontinuous Neural Networks With Mixed Delays via Functional Differential Inclusions.,"This paper investigates the issue of global exponential synchronization for a class of general neural networks that contains discontinuous activation functions and mixed time delays. Functional differential inclusions and nonsmooth analysis theories are used as bases to design discontinuous controllers, such that the discontinuous neural networks can be exponential complete synchronized. This novel approach and its applicability to neural networks with continuous activations are also easily verified. Several numerical examples demonstrate the practicality and effectiveness of the design method.",4
Singularities of Three-Layered Complex-Valued Neural Networks With Split Activation Function.,"There are three important concepts related to learning processes in neural networks: reducibility, nonminimality, and singularity. Although the definitions of these three concepts differ, they are equivalent in real-valued neural networks. This is also true of complex-valued neural networks (CVNNs) with hidden neurons not employing biases. The situation of CVNNs with hidden neurons employing biases, however, is very complicated. Exceptional reducibility was found, and it was shown that reducibility and nonminimality are not the same. Irreducibility consists of minimality and exceptional reducibility. The relationship between minimality and singularity has not yet been established. In this paper, we describe our surprising finding that minimality and singularity are independent. We also provide several examples based on exceptional reducibility.",4
Safe Screening Rules for Accelerating Twin Support Vector Machine Classification.,"The twin support vector machine (TSVM) is widely used in classification problems, but it is not efficient enough for large-scale data sets. Furthermore, to get the optimal parameter, the exhaustive grid search method is applied to TSVM. It is very time-consuming, especially for multiparameter models. Although many techniques have been presented to solve these problems, all of them always affect the performance of TSVM to some extent. In this paper, we propose a safe screening rule (SSR) for linear-TSVM, and give a modified SSR (MSSR) for nonlinear TSVM, which contains multiple parameters. The SSR and MSSR can delete most training samples and reduce the scale of TSVM before solving it. Sequential versions of SSR and MSSR are further introduced to substantially accelerate the whole parameter tuning process. One important advantage of SSR and MSSR is that they are safe, i.e., we can obtain the same solution as the original problem by utilizing them. Experiments on eight real-world data sets and an imbalanced data set with different imbalanced ratios demonstrate the efficiency and safety of SSR and MSSR.",4
Event-Sampled Direct Adaptive NN Output- and State-Feedback Control of Uncertain Strict-Feedback System.,"In this paper, a novel event-triggered implementation of a tracking controller for an uncertain strict-feedback system is presented. Neural networks (NNs) are utilized in the backstepping approach to design a control input by approximating unknown dynamics of the strict-feedback nonlinear system with event-sampled inputs. The system state vector is assumed to be unknown and an NN observer is used to estimate the state vector. By using the estimated state vector and backstepping design approach, an event-sampled controller is introduced. As part of the controller design, first, input-to-state-like stability for a continuously sampled controller that has been injected with bounded measurement errors is demonstrated, and subsequently, an event-execution control law is derived, such that the measurement errors are guaranteed to remain bounded. Lyapunov theory is used to demonstrate that the tracking errors, the observer estimation errors, and the NN weight estimation errors for each NN are locally uniformly ultimately bounded in the presence bounded disturbances, NN reconstruction errors, as well as errors introduced by event sampling. Simulation results are provided to illustrate the effectiveness of the proposed controllers.",4
Doubly Nonparametric Sparse Nonnegative Matrix Factorization Based on Dependent Indian Buffet Processes.,"Sparse nonnegative matrix factorization (SNMF) aims to factorize a data matrix into two optimized nonnegative sparse factor matrices, which could benefit many tasks, such as document-word co-clustering. However, the traditional SNMF typically assumes the number of latent factors (i.e., dimensionality of the factor matrices) to be fixed. This assumption makes it inflexible in practice. In this paper, we propose a doubly sparse nonparametric NMF framework to mitigate this issue by using dependent Indian buffet processes (dIBP). We apply a correlation function for the generation of two stick weights associated with each column pair of factor matrices while still maintaining their respective marginal distribution specified by IBP. As a consequence, the generation of two factor matrices will be columnwise correlated. Under this framework, two classes of correlation function are proposed: 1) using bivariate Beta distribution and 2) using Copula function. Compared with the single IBP-based NMF, this paper jointly makes two factor matrices nonparametric and sparse, which could be applied to broader scenarios, such as co-clustering. This paper is seen to be much more flexible than Gaussian process-based and hierarchial Beta process-based dIBPs in terms of allowing the two corresponding binary matrix columns to have greater variations in their nonzero entries. Our experiments on synthetic data show the merits of this paper compared with the state-of-the-art models in respect of factorization efficiency, sparsity, and flexibility. Experiments on real-world data sets demonstrate the efficiency of this paper in document-word co-clustering tasks.",4
A Novel Recurrent Neural Network for Manipulator Control With Improved Noise Tolerance.,"In this paper, we propose a novel recurrent neural network to resolve the redundancy of manipulators for efficient kinematic control in the presence of noises in a polynomial type. Leveraging the high-order derivative properties of polynomial noises, a deliberately devised neural network is proposed to eliminate the impact of noises and recover the accurate tracking of desired trajectories in workspace. Rigorous analysis shows that the proposed neural law stabilizes the system dynamics and the position tracking error converges to zero in the presence of noises. Extensive simulations verify the theoretical results. Numerical comparisons show that existing dual neural solutions lose stability when exposed to large constant noises or time-varying noises. In contrast, the proposed approach works well and has a low tracking error comparable to noise-free situations.",4
Person Reidentification Based on Elastic Projections.,"Person reidentification usually refers to matching people in different camera views in nonoverlapping multicamera networks. Many existing methods learn a similarity measure by projecting the raw feature to a latent subspace to make the same target's distance smaller than different targets' distances. However, the same targets captured in different camera views should hold the same intrinsic attributes while different targets should hold different intrinsic attributes. Projecting all the data to the same subspace would cause loss of such an information and comparably poor discriminability. To address this problem, in this paper, a method based on elastic projections is proposed to learn a pairwise similarity measure for person reidentification. The proposed model learns two projections, positive projection and negative projection, which are both representative and discriminative. The representability refers to: for the same targets captured in two camera views, the positive projection can bridge the corresponding appearance variation and represent the intrinsic attributes of the same targets, while for the different targets captured in two camera views, the negative projection can explore and utilize the different attributes of different targets. The discriminability means that the intraclass distance should become smaller than its original distance after projection, while the interclass distance becomes larger on the contrary, which is the elastic property of the proposed model. In this case, prior information of the original data space is used to give guidance for the learning phase; more importantly, similar targets (but not the same) are effectively reduced by forcing the same targets to become more similar and different targets to become more distinct. The proposed model is evaluated on three benchmark data sets, including VIPeR, GRID, and CUHK, and achieves better performance than other methods.",4
Structured Learning of Tree Potentials in CRF for Image Segmentation.,"We propose a new approach to image segmentation, which exploits the advantages of both conditional random fields (CRFs) and decision trees. In the literature, the potential functions of CRFs are mostly defined as a linear combination of some predefined parametric models, and then, methods, such as structured support vector machines, are applied to learn those linear coefficients. We instead formulate the unary and pairwise potentials as nonparametric forests-ensembles of decision trees, and learn the ensemble parameters and the trees in a unified optimization problem within the large-margin framework. In this fashion, we easily achieve nonlinear learning of potential functions on both unary and pairwise terms in CRFs. Moreover, we learn classwise decision trees for each object that appears in the image. Experimental results on several public segmentation data sets demonstrate the power of the learned nonlinear nonparametric potentials.",4
Observer-Based Robust Coordinated Control of Multiagent Systems With Input Saturation.,"This paper addresses the robust semiglobal coordinated control of multiple-input multiple-output multiagent systems with input saturation together with dead zone and input additive disturbance. Observer-based coordinated control protocol is constructed, by combining the parameterized low-and-high-gain feedback technique and the high-gain observer design approach. It is shown that, under some mild assumptions on agents' intrinsic dynamics, the robust semiglobal consensus or robust semiglobal swarm can be approached for undirected connected multiagent systems. Then, specific guidelines on the selection of the low-gain parameter, the high-gain parameter, and the high-gain observer gain have been provided. At last, numerical simulations are presented to illustrate the theoretical results.",4
Bioinspired Approach to Modeling Retinal Ganglion Cells Using System Identification Techniques.,"The processing capabilities of biological vision systems are still vastly superior to artificial vision, even though this has been an active area of research for over half a century. Current artificial vision techniques integrate many insights from biology yet they remain far-off the capabilities of animals and humans in terms of speed, power, and performance. A key aspect to modeling the human visual system is the ability to accurately model the behavior and computation within the retina. In particular, we focus on modeling the retinal ganglion cells (RGCs) as they convey the accumulated data of real world images as action potentials onto the visual cortex via the optic nerve. Computational models that approximate the processing that occurs within RGCs can be derived by quantitatively fitting the sets of physiological data using an input-output analysis where the input is a known stimulus and the output is neuronal recordings. Currently, these input-output responses are modeled using computational combinations of linear and nonlinear models that are generally complex and lack any relevance to the underlying biophysics. In this paper, we illustrate how system identification techniques, which take inspiration from biological systems, can accurately model retinal ganglion cell behavior, and are a viable alternative to traditional linear-nonlinear approaches.",4
Sensitivity Analysis for Probabilistic Neural Network Structure Reduction.,"In this paper, we propose the use of local sensitivity analysis (LSA) for the structure simplification of the probabilistic neural network (PNN). Three algorithms are introduced. The first algorithm applies LSA to the PNN input layer reduction by selecting significant features of input patterns. The second algorithm utilizes LSA to remove redundant pattern neurons of the network. The third algorithm combines the proposed two and constitutes the solution of how they can work together. PNN with a product kernel estimator is used, where each multiplicand computes a one-dimensional Cauchy function. Therefore, the smoothing parameter is separately calculated for each dimension by means of the plug-in method. The classification qualities of the reduced and full structure PNN are compared. Furthermore, we evaluate the performance of PNN, for which global sensitivity analysis (GSA) and the common reduction methods are applied, both in the input layer and the pattern layer. The models are tested on the classification problems of eight repository data sets. A 10-fold cross validation procedure is used to determine the prediction ability of the networks. Based on the obtained results, it is shown that the LSA can be used as an alternative PNN reduction approach.",4
Modeling and Analysis of Beta Oscillations in the Basal Ganglia.,"Enhanced beta (12-30 Hz) oscillatory activity in the basal ganglia (BG) is a prominent feature of the Parkinsonian state in animal models and in patients with Parkinson's disease. Increased beta oscillations are associated with severe dopaminergic striatal depletion. However, the mechanisms underlying these pathological beta oscillations remain elusive. Inspired by the experimental observation that only subsets of neurons within each nucleus in the BG exhibit oscillatory activities, a computational model of the BG-thalamus neuronal network is proposed, which is characterized by subdivided nuclei within the BG. Using different currents externally applied to the neurons within a given nucleus, neurons behave according to one of the two subgroups, named ""-N"" and ""-P,"" where ""-N"" and ""-P"" denote the normal and the Parkinsonian states, respectively. The ratio of ""-P"" to ""-N"" neurons indicates the degree of the Parkinsonian state. Simulation results show that if ""-P"" neurons have a high degree of connectivity in the subthalamic nucleus (STN), they will have a significant downstream effect on the generation of beta oscillations in the globus pallidus. Interestingly, however, the generation of beta oscillations in the STN is independent of the selection of the ""-P"" neurons in the external segment of the globus pallidus (GPe), despite the reciprocal structure between STN and GPe. This computational model may pave the way to revealing the mechanism of such pathological behaviors in a realistic way that can replicate experimental observations. The simulation results suggest that the STN is more suitable than GPe as a deep brain stimulation target.",4
Efficient kNN Classification With Different Numbers of Nearest Neighbors.,"nearest neighbor (kNN) method is a popular classification method in data mining and statistics because of its simple implementation and significant classification performance. However, it is impractical for traditional kNN methods to assign a fixed value (even though set by experts) to all test samples. Previous solutions assign different values to different test samples by the cross validation method but are usually time-consuming. This paper proposes a kTree method to learn different optimal values for different test/new samples, by involving a training stage in the kNN classification. Specifically, in the training stage, kTree method first learns optimal values for all training samples by a new sparse reconstruction model, and then constructs a decision tree (namely, kTree) using training samples and the learned optimal values. In the test stage, the kTree fast outputs the optimal value for each test sample, and then, the kNN classification can be conducted using the learned optimal value and all training samples. As a result, the proposed kTree method has a similar running cost but higher classification accuracy, compared with traditional kNN methods, which assign a fixed value to all test samples. Moreover, the proposed kTree method needs less running cost but achieves similar classification accuracy, compared with the newly kNN methods, which assign different values to different test samples. This paper further proposes an improvement version of kTree method (namely, k*Tree method) to speed its test stage by extra storing the information of the training samples in the leaf nodes of kTree, such as the training samples located in the leaf nodes, their kNNs, and the nearest neighbor of these kNNs. We call the resulting decision tree as k*Tree, which enables to conduct kNN classification using a subset of the training samples in the leaf nodes rather than all training samples used in the newly kNN methods. This actually reduces running cost of test stage. Finally, the experimental results on 20 real data sets showed that our proposed methods (i.e., kTree and k*Tree) are much more efficient than the compared methods in terms of classification tasks.",4
SCE: A Manifold Regularized Set-Covering Method for Data Partitioning.,"Cluster analysis plays a very important role in data analysis. In these years, cluster ensemble, as a cluster analysis tool, has drawn much attention for its robustness, stability, and accuracy. Many efforts have been done to combine different initial clustering results into a single clustering solution with better performance. However, they neglect the structure information of the raw data in performing the cluster ensemble. In this paper, we propose a Structural Cluster Ensemble (SCE) algorithm for data partitioning formulated as a set-covering problem. In particular, we construct a Laplacian regularized objective function to capture the structure information among clusters. Moreover, considering the importance of the discriminative information underlying in the initial clustering results, we add a discriminative constraint into our proposed objective function. Finally, we verify the performance of the SCE algorithm on both synthetic and real data sets. The experimental results show the effectiveness of our proposed method SCE algorithm.",4
Cluster Synchronization for Interacting Clusters of Nonidentical Nodes via Intermittent Pinning Control.,"The cluster synchronization problem is investigated using intermittent pinning control for the interacting clusters of nonidentical nodes that may represent either general linear systems or nonlinear oscillators. These nodes communicate over general network topology, and the nodes from different clusters are governed by different self-dynamics. A unified convergence analysis is provided to analyze the synchronization via intermittent pinning controllers. It is observed that the nodes in different clusters synchronize to the given patterns if a directed spanning tree exists in the underlying topology of every extended cluster (which consists of the original cluster of nodes as well as their pinning node) and one algebraic condition holds. Structural conditions are then derived to guarantee such an algebraic condition. That is: 1) if the intracluster couplings are with sufficiently strong strength and the pinning controller is with sufficiently long execution time in every period, then the algebraic condition for general linear systems is warranted and 2) if every cluster is with the sufficiently strong intracluster coupling strength, then the pinning controller for nonlinear oscillators can have its execution time to be arbitrarily short. The lower bounds are explicitly derived both for these coupling strengths and the execution time of the pinning controller in every period. In addition, in regard to the above-mentioned structural conditions for nonlinear systems, an adaptive law is further introduced to adapt the intracluster coupling strength, such that the cluster synchronization for nonlinear systems is achieved.",4
Asynchronous State Estimation for Discrete-Time Switched Complex Networks With Communication Constraints.,"This paper is concerned with the asynchronous state estimation for a class of discrete-time switched complex networks with communication constraints. An asynchronous estimator is designed to overcome the difficulty that each node cannot access to the topology/coupling information. Also, the event-based communication, signal quantization, and the random packet dropout problems are studied due to the limited communication resource. With the help of switched system theory and by resorting to some stochastic system analysis method, a sufficient condition is proposed to guarantee the exponential stability of estimation error system in the mean-square sense and a prescribed performance level is also ensured. The characterization of the desired estimator gains is derived in terms of the solution to a convex optimization problem. Finally, the effectiveness of the proposed design approach is demonstrated by a simulation example.",4
Autonomous Data Collection Using a Self-Organizing Map.,"The self-organizing map (SOM) is an unsupervised learning technique providing a transformation of a high-dimensional input space into a lower dimensional output space. In this paper, we utilize the SOM for the traveling salesman problem (TSP) to develop a solution to autonomous data collection. Autonomous data collection requires gathering data from predeployed sensors by moving within a limited communication radius. We propose a new growing SOM that adapts the number of neurons during learning, which also allows our approach to apply in cases where some sensors can be ignored due to a lower priority. Based on a comparison with available combinatorial heuristic algorithms for relevant variants of the TSP, the proposed approach demonstrates improved results, while also being less computationally demanding. Moreover, the proposed learning procedure can be extended to cases where particular sensors have varying communication radii, and it can also be extended to multivehicle planning.",4
A Preference-Based Multiobjective Evolutionary Approach for Sparse Optimization.,"Iterative thresholding is a dominating strategy for sparse optimization problems. The main goal of iterative thresholding methods is to find a so-called -sparse solution. However, the setting of regularization parameters or the estimation of the true sparsity are nontrivial in iterative thresholding methods. To overcome this shortcoming, we propose a preference-based multiobjective evolutionary approach to solve sparse optimization problems in compressive sensing. Our basic strategy is to search the knee part of weakly Pareto front with preference on the true -sparse solution. In the noiseless case, it is easy to locate the exact position of the -sparse solution from the distribution of the solutions found by our proposed method. Therefore, our method has the ability to detect the true sparsity. Moreover, any iterative thresholding methods can be used as a local optimizer in our proposed method, and no prior estimation of sparsity is required. The proposed method can also be extended to solve sparse optimization problems with noise. Extensive experiments have been conducted to study its performance on artificial signals and magnetic resonance imaging signals. Our experimental results have shown that our proposed method is very effective for detecting sparsity and can improve the reconstruction ability of existing iterative thresholding methods.",4
Finite-Horizon $H_{\infty }$ Tracking Control for Unknown Nonlinear Systems With Saturating Actuators.,"In this paper, a neural network (NN)-based online model-free integral reinforcement learning algorithm is developed to solve the finite-horizon optimal tracking control problem for completely unknown nonlinear continuous-time systems with disturbance and saturating actuators (constrained control input). An augmented system is constructed with the tracking error system and the command generator system. A time-varying Hamilton-Jacobi-Isaacs (HJI) equation is formulated for the augmented problem, which is extremely difficult or impossible to solve due to its time-dependent property and nonlinearity. Then, an actor-critic-disturbance NN structure-based scheme is proposed to learn the time-varying solution to the HJI equation in real time without using the knowledge of system dynamics. Since the solution to the HJI equation is time-dependent, the form of NNs representation with constant weights and time-dependent activation functions is considered. Furthermore, an extra error is incorporated in order to satisfy the terminal constraints in the weight update law. Convergence and stability proofs are given based on the Lyapunov theory for nonautonomous systems. Two simulation examples are provided to demonstrate the effectiveness of the designed algorithm.",4
Classification With Truncated Distance Kernel.,"This brief proposes a truncated distance (TL1) kernel, which results in a classifier that is nonlinear in the global region but is linear in each subregion. With this kernel, the subregion structure can be trained using all the training data and local linear classifiers can be established simultaneously. The TL1 kernel has good adaptiveness to nonlinearity and is suitable for problems which require different nonlinearities in different areas. Though the TL1 kernel is not positive semidefinite, some classical kernel learning methods are still applicable which means that the TL1 kernel can be directly used in standard toolboxes by replacing the kernel evaluation. In numerical experiments, the TL1 kernel with a pregiven parameter achieves similar or better performance than the radial basis function kernel with the parameter tuned by cross validation, implying the TL1 kernel a promising nonlinear kernel for classification tasks.",4
Adaptive Fuzzy Neural Network Control for a Constrained Robot Using Impedance Learning.,"This paper investigates adaptive fuzzy neural network (NN) control using impedance learning for a constrained robot, subject to unknown system dynamics, the effect of state constraints, and the uncertain compliant environment with which the robot comes into contact. A fuzzy NN learning algorithm is developed to identify the uncertain plant model. The prominent feature of the fuzzy NN is that there is no need to get the prior knowledge about the uncertainty and a sufficient amount of observed data. Also, impedance learning is introduced to tackle the interaction between the robot and its environment, so that the robot follows a desired destination generated by impedance learning. A barrier Lyapunov function is used to address the effect of state constraints. With the proposed control, the stability of the closed-loop system is achieved via Lyapunov's stability theory, and the tracking performance is guaranteed under the condition of state constraints and uncertainty. Some simulation studies are carried out to illustrate the effectiveness of the proposed scheme.",4
Discrete-Time Stable Generalized Self-Learning Optimal Control With Approximation Errors.,"In this paper, a generalized policy iteration (GPI) algorithm with approximation errors is developed for solving infinite horizon optimal control problems for nonlinear systems. The developed stable GPI algorithm provides a general structure of discrete-time iterative adaptive dynamic programming algorithms, by which most of the discrete-time reinforcement learning algorithms can be described using the GPI structure. It is for the first time that approximation errors are explicitly considered in the GPI algorithm. The properties of the stable GPI algorithm with approximation errors are analyzed. The admissibility of the approximate iterative control law can be guaranteed if the approximation errors satisfy the admissibility criteria. The convergence of the developed algorithm is established, which shows that the iterative value function is convergent to a finite neighborhood of the optimal performance index function, if the approximate errors satisfy the convergence criterion. Finally, numerical examples and comparisons are presented.",4
Neural-Network-Based Robust Optimal Tracking Control for MIMO Discrete-Time Systems With Unknown Uncertainty Using Adaptive Critic Design.,"This paper is concerned with the robust optimal tracking control strategy for a class of nonlinear multi-input multi-output discrete-time systems with unknown uncertainty via adaptive critic design (ACD) scheme. The main purpose is to establish an adaptive actor-critic control method, so that the cost function in the procedure of dealing with uncertainty is minimum and the closed-loop system is stable. Based on the neural network approximator, an action network is applied to generate the optimal control signal and a critic network is used to approximate the cost function, respectively. In contrast to the previous methods, the main features of this paper are: 1) the ACD scheme is integrated into the controllers to cope with the uncertainty and 2) a novel cost function, which is not in quadric form, is proposed so that the total cost in the design procedure is reduced. It is proved that the optimal control signals and the tracking errors are uniformly ultimately bounded even when the uncertainty exists. Finally, a numerical simulation is developed to show the effectiveness of the present approach.",4
Simultaneous Bayesian Clustering and Feature Selection Through Student's ${t}$ Mixtures Model.,"In this paper, we proposed a generative model for feature selection under the unsupervised learning context. The model assumes that data are independently and identically sampled from a finite mixture of Student's distributions, which can reduce the sensitiveness to outliers. Latent random variables that represent the features' salience are included in the model for the indication of the relevance of features. As a result, the model is expected to simultaneously realize clustering, feature selection, and outlier detection. Inference is carried out by a tree-structured variational Bayes algorithm. Full Bayesian treatment is adopted in the model to realize automatic model selection. Controlled experimental studies showed that the developed model is capable of modeling the data set with outliers accurately. Furthermore, experiment results showed that the developed algorithm compares favorably against existing unsupervised probability model-based Bayesian feature selection algorithms on artificial and real data sets. Moreover, the application of the developed algorithm on real leukemia gene expression data indicated that it is able to identify the discriminating genes successfully.",4
Robust Finite-Time Stabilization of Fractional-Order Neural Networks With Discontinuous and Continuous Activation Functions Under Uncertainty.,"This paper is concerned with robust finite-time stabilization for a class of fractional-order neural networks (FNNs) with two types of activation functions (i.e., discontinuous and continuous activation function) under uncertainty. It is worth noting that there exist few results about FNNs with discontinuous activation functions, which is mainly because classical solutions and theories of differential equations cannot be applied in this case. Especially, there is no relevant finite-time stabilization research for such system, and this paper makes up for the gap. The existence of global solution under the framework of Filippov for such system is guaranteed by limiting discontinuous activation functions. According to set-valued analysis and Kakutani's fixed point theorem, we obtain the existence of equilibrium point. In particular, based on differential inclusion theory and fractional Lyapunov stability theory, several new sufficient conditions are given to ensure finite-time stabilization via a novel discontinuous controller, and the upper bound of the settling time for stabilization is estimated. In addition, we analyze the finite-time stabilization of FNNs with Lipschitz-continuous activation functions under uncertainty. The results of this paper improve corresponding ones of integer-order neural networks with discontinuous and continuous activation functions. Finally, three numerical examples are given to show the effectiveness of the theoretical results.",4
Stability Analysis and Application for Delayed Neural Networks Driven by Fractional Brownian Noise.,"This paper deals with two types of the stability problem for the delayed neural networks driven by fractional Brownian noise (FBN). The existence and the uniqueness of the solution to the main system with respect to FBN are proved via fixed point theory. Based on Hilbert-Schmidt operator theory and analytic semigroup principle, the mild solution of the stochastic neural networks is obtained. By applying the stochastic analytic technique and some well-known inequalities, the asymptotic stability criteria and the exponential stability condition are established. Both numerical example and practical application for synchronization control of multiagent system are provided to illustrate the effectiveness and potential of the proposed techniques.",4
Global Pinning Synchronization of Complex Networks With Sampled-Data Communications.,"This paper investigates the global pinning synchronization problem for a class of complex networks with aperiodic samplings. Combined with the Writinger-based integral inequality, a new less conservative criterion is presented to guarantee the global pinning synchronization of the complex network. Furthermore, a novel condition is proposed under which the complex network is globally pinning synchronized with a given performance index. It is shown that the performance index has a positive correlation with the upper bound of the sampling intervals. Finally, the validity and the advantage of the theoretic results obtained are verified by means of the applications in Chua's circuit and pendulum.",4
Preconditioned Stochastic Gradient Descent.,"Stochastic gradient descent (SGD) still is the workhorse for many practical problems. However, it converges slow, and can be difficult to tune. It is possible to precondition SGD to accelerate its convergence remarkably. But many attempts in this direction either aim at solving specialized problems, or result in significantly more complicated methods than SGD. This paper proposes a new method to adaptively estimate a preconditioner, such that the amplitudes of perturbations of preconditioned stochastic gradient match that of the perturbations of parameters to be optimized in a way comparable to Newton method for deterministic optimization. Unlike the preconditioners based on secant equation fitting as done in deterministic quasi-Newton methods, which assume positive definite Hessian and approximate its inverse, the new preconditioner works equally well for both convex and nonconvex optimizations with exact or noisy gradients. When stochastic gradient is used, it can naturally damp the gradient noise to stabilize SGD. Efficient preconditioner estimation methods are developed, and with reasonable simplifications, they are applicable to large-scale problems. Experimental results demonstrate that equipped with the new preconditioner, without any tuning effort, preconditioned SGD can efficiently solve many challenging problems like the training of a deep neural network or a recurrent neural network requiring extremely long-term memories.",4
Discriminative Sparse Neighbor Approximation for Imbalanced Learning.,"Data imbalance is common in many vision tasks where one or more classes are rare. Without addressing this issue, conventional methods tend to be biased toward the majority class with poor predictive accuracy for the minority class. These methods further deteriorate on small, imbalanced data that have a large degree of class overlap. In this paper, we propose a novel discriminative sparse neighbor approximation (DSNA) method to ameliorate the effect of class-imbalance during prediction. Specifically, given a test sample, we first traverse it through a cost-sensitive decision forest to collect a good subset of training examples in its local neighborhood. Then, we generate from this subset several class-discriminating but overlapping clusters and model each as an affine subspace. From these subspaces, the proposed DSNA iteratively seeks an optimal approximation of the test sample and outputs an unbiased prediction. We show that our method not only effectively mitigates the imbalance issue, but also allows the prediction to extrapolate to unseen data. The latter capability is crucial for achieving accurate prediction on small data set with limited samples. The proposed imbalanced learning method can be applied to both classification and regression tasks at a wide range of imbalance levels. It significantly outperforms the state-of-the-art methods that do not possess an imbalance handling mechanism, and is found to perform comparably or even better than recent deep learning methods by using hand-crafted features only.",4
Observability of Automata Networks: Fixed and Switching Cases.,"Automata networks are a class of fully discrete dynamical systems, which have received considerable interest in various different areas. This brief addresses the observability of automata networks and switched automata networks in a unified framework, and proposes simple necessary and sufficient conditions for observability. The results are achieved by employing methods from symbolic computation, and are suited for implementation using computer algebra systems. Several examples are presented to demonstrate the application of the results.",4
Hyperbolic Gradient Operator and Hyperbolic Back-Propagation Learning Algorithms.,"In this paper, we first extend the Wirtinger derivative which is defined for complex functions to hyperbolic functions, and derive the hyperbolic gradient operator yielding the steepest descent direction by using it. Next, we derive the hyperbolic backpropagation learning algorithms for some multilayered hyperbolic neural networks (NNs) using the hyperbolic gradient operator. It is shown that the use of the Wirtinger derivative reduces the effort necessary for the derivation of the learning algorithms by half, simplifies the representation of the learning algorithms, and makes their computer programs easier to code. In addition, we discuss the differences between the derived Hyperbolic-BP rules and the complex-valued backpropagation learning rule (Complex-BP). Finally, we make some experiments with the derived learning algorithms. As a result, we find that the convergence rates of the Hyperbolic-BP learning algorithms are high even if the fully activation functions are used, and discover that the Hyperbolic-BP learning algorithm for the hyperbolic NN with the split-type hyperbolic activation function has an ability to learn hyperbolic rotation as its inherent property.",4
Recurrent Neural Networks With Auxiliary Memory Units.,"Memory is one of the most important mechanisms in recurrent neural networks (RNNs) learning. It plays a crucial role in practical applications, such as sequence learning. With a good memory mechanism, long term history can be fused with current information, and can thus improve RNNs learning. Developing a suitable memory mechanism is always desirable in the field of RNNs. This paper proposes a novel memory mechanism for RNNs. The main contributions of this paper are: 1) an auxiliary memory unit (AMU) is proposed, which results in a new special RNN model (AMU-RNN), separating the memory and output explicitly and 2) an efficient learning algorithm is developed by employing the technique of error flow truncation. The proposed AMU-RNN model, together with the developed learning algorithm, can learn and maintain stable memory over a long time range. This method overcomes both the learning conflict problem and gradient vanishing problem. Unlike the traditional method, which mixes the memory and output with a single neuron in a recurrent unit, the AMU provides an auxiliary memory neuron to maintain memory in particular. By separating the memory and output in a recurrent unit, the problem of learning conflicts can be eliminated easily. Moreover, by using the technique of error flow truncation, each auxiliary memory neuron ensures constant error flow during the learning process. The experiments demonstrate good performance of the proposed AMU-RNNs and the developed learning algorithm. The method exhibits quite efficient learning performance with stable convergence in the AMU-RNN learning and outperforms the state-of-the-art RNN models in sequence generation and sequence classification tasks.",4
Improving Crowdsourced Label Quality Using Noise Correction.,"Crowdsourcing systems provide a cost effective and convenient way to collect labels, but they often fail to guarantee the quality of the labels. This paper proposes a novel framework that introduces noise correction techniques to further improve the quality of integrated labels that are inferred from the multiple noisy labels of objects. In the proposed general framework, information about the qualities of labelers estimated by a front-end ground truth inference algorithm is utilized to supervise subsequent label noise filtering and correction. The framework uses a novel algorithm termed adaptive voting noise correction (AVNC) to precisely identify and correct the potential noisy labels. After filtering out the instances with noisy labels, the remaining cleansed data set is used to create multiple weak classifiers, based on which a powerful ensemble classifier is induced to correct these noises. Experimental results on eight simulated data sets with different kinds of features and two real-world crowdsourcing data sets in different domains consistently show that: 1) the proposed framework can improve label quality regardless of inference algorithms, especially under the circumstance that each instance has a few repeated labels and 2) since the proposed AVNC algorithm considers both the number of and the probability of potential label noises, it outperforms the state-of-the-art noise correction algorithms.",4
Random Forest Classifier for Zero-Shot Learning Based on Relative Attribute.,"For the zero-shot image classification with relative attributes (RAs), the traditional method requires that not only all seen and unseen images obey Gaussian distribution, but also the classifications on testing samples are made by maximum likelihood estimation. We therefore propose a novel zero-shot image classifier called random forest based on relative attribute. First, based on the ordered and unordered pairs of images from the seen classes, the idea of ranking support vector machine is used to learn ranking functions for attributes. Then, according to the relative relationship between seen and unseen classes, the RA ranking-score model per attribute for each unseen image is built, where the appropriate seen classes are automatically selected to participate in the modeling process. In the third step, the random forest classifier is trained based on the RA ranking scores of attributes for all seen and unseen images. Finally, the class labels of testing images can be predicted via the trained RF. Experiments on Outdoor Scene Recognition, Pub Fig, and Shoes data sets show that our proposed method is superior to several state-of-the-art methods in terms of classification capability for zero-shot learning problems.",4
Logistic Localized Modeling of the Sample Space for Feature Selection and Classification.,"Conventional feature selection algorithms assign a single common feature set to all regions of the sample space. In contrast, this paper proposes a novel algorithm for localized feature selection for which each region of the sample space is characterized by its individual distinct feature subset that may vary in size and membership. This approach can therefore select an optimal feature subset that adapts to local variations of the sample space, and hence offer the potential for improved performance. Feature subsets are computed by choosing an optimal coordinate space so that, within a localized region, within-class distances and between-class distances are, respectively, minimized and maximized. Distances are measured using a logistic function metric within the corresponding region. This enables the optimization process to focus on a localized region within the sample space. A local classification approach is utilized for measuring the similarity of a new input data point to each class. The proposed logistic localized feature selection (lLFS) algorithm is invariant to the underlying probability distribution of the data; hence, it is appropriate when the data are distributed on a nonlinear or disjoint manifold. lLFS is efficiently formulated as a joint convex/increasing quasi-convex optimization problem with a unique global optimum point. The method is most applicable when the number of available training samples is small. The performance of the proposed localized method is successfully demonstrated on a large variety of data sets. We demonstrate that the number of features selected by the lLFS method saturates at the number of available discriminative features. In addition, we have shown that the Vapnik-Chervonenkis dimension of the localized classifier is finite. Both these factors suggest that the lLFS method is insensitive to the overfitting issue, relative to other methods.",4
Application of LMS-Based NN Structure for Power Quality Enhancement in a Distribution Network Under Abnormal Conditions.,"This paper proposes an application of a least mean-square (LMS)-based neural network (NN) structure for the power quality improvement of a three-phase power distribution network under abnormal conditions. It uses a single-layer neuron structure for the control in a distribution static compensator (DSTATCOM) to attenuate the harmonics such as noise, bias, notches, dc offset, and distortion, injected in the grid current due to connection of several nonlinear loads. This admittance LMS-based NN structure has a simple architecture which reduces the computational complexity and burden which makes it easy to implement. A DSTATCOM is a custom power device which performs various functionalities such as harmonics attenuation, reactive power compensation, load balancing, zero voltage regulation, and power factor correction. Other main contribution of this paper involves operation of the system under abnormal conditions of distribution network which means noise and distortion in voltage and imbalance in three-phase voltages at the point of interconnection. For substantiating and demonstrating the performance of proposed control approach, simulations are carried on MATLAB/Simulink software and corresponding experimental tests are conducted on a developed prototype in the laboratory.",4
Convolution in Convolution for Network in Network.,"Network in network (NiN) is an effective instance and an important extension of deep convolutional neural network consisting of alternating convolutional layers and pooling layers. Instead of using a linear filter for convolution, NiN utilizes shallow multilayer perceptron (MLP), a nonlinear function, to replace the linear filter. Because of the powerfulness of MLP and convolutions in spatial domain, NiN has stronger ability of feature representation and hence results in better recognition performance. However, MLP itself consists of fully connected layers that give rise to a large number of parameters. In this paper, we propose to replace dense shallow MLP with sparse shallow MLP. One or more layers of the sparse shallow MLP are sparely connected in the channel dimension or channel-spatial domain. The proposed method is implemented by applying unshared convolution across the channel dimension and applying shared convolution across the spatial dimension in some computational layers. The proposed method is called convolution in convolution (CiC). The experimental results on the CIFAR10 data set, augmented CIFAR10 data set, and CIFAR100 data set demonstrate the effectiveness of the proposed CiC method.",4
AnRAD: A Neuromorphic Anomaly Detection Framework for Massive Concurrent Data Streams.,"The evolution of high performance computing technologies has enabled the large-scale implementation of neuromorphic models and pushed the research in computational intelligence into a new era. Among the machine learning applications, unsupervised detection of anomalous streams is especially challenging due to the requirements of detection accuracy and real-time performance. Designing a computing framework that harnesses the growing computing power of the multicore systems while maintaining high sensitivity and specificity to the anomalies is an urgent research topic. In this paper, we propose anomaly recognition and detection (AnRAD), a bioinspired detection framework that performs probabilistic inferences. We analyze the feature dependency and develop a self-structuring method that learns an efficient confabulation network using unlabeled data. This network is capable of fast incremental learning, which continuously refines the knowledge base using streaming data. Compared with several existing anomaly detection approaches, our method provides competitive detection quality. Furthermore, we exploit the massive parallel structure of the AnRAD framework. Our implementations of the detection algorithm on the graphic processing unit and the Xeon Phi coprocessor both obtain substantial speedups over the sequential implementation on general-purpose microprocessor. The framework provides real-time service to concurrent data streams within diversified knowledge contexts, and can be applied to large problems with multiple local patterns. Experimental results demonstrate high computing performance and memory efficiency. For vehicle behavior detection, the framework is able to monitor up to 16000 vehicles (data streams) and their interactions in real time with a single commodity coprocessor, and uses less than 0.2 ms for one testing subject. Finally, the detection network is ported to our spiking neural network simulator to show the potential of adapting to the emerging neuromorphic architectures.",4
Solving Multiextremal Problems by Using Recurrent Neural Networks.,"In this paper, a neural network model for solving a class of multiextremal smooth nonconvex constrained optimization problems is proposed. Neural network is designed in such a way that its equilibrium points coincide with the local and global optimal solutions of the corresponding optimization problem. Based on the suitable underestimators for the Lagrangian of the problem, one give geometric criteria for an equilibrium point to be a global minimizer of multiextremal constrained optimization problem with or without bounds on the variables. Both necessary and sufficient global optimality conditions for a class of multiextremal constrained optimization problems are presented to determine a global optimal solution. By study of the resulting dynamic system, it is shown that under given assumptions, steady states of the dynamic system are stable and trajectories of the proposed model converge to the local and global optimal solutions of the problem. Numerical results are given and related graphs are depicted to illustrate the global convergence and performance of the solver for multiextremal constrained optimization problems.",4
Dynamic Uncertain Causality Graph for Knowledge Representation and Reasoning: Utilization of Statistical Data and Domain Knowledge in Complex Cases.,"The dynamic uncertain causality graph (DUCG) is a newly presented framework for uncertain causality representation and probabilistic reasoning. It has been successfully applied to online fault diagnoses of large, complex industrial systems, and decease diagnoses. This paper extends the DUCG to model more complex cases than what could be previously modeled, e.g., the case in which statistical data are in different groups with or without overlap, and some domain knowledge and actions (new variables with uncertain causalities) are introduced. In other words, this paper proposes to use -mode, -mode, and -mode of the DUCG to model such complex cases and then transform them into either the standard -mode or the standard -mode. In the former situation, if no directed cyclic graph is involved, the transformed result is simply a Bayesian network (BN), and existing inference methods for BNs can be applied. In the latter situation, an inference method based on the DUCG is proposed. Examples are provided to illustrate the methodology.",4
A Confident Information First Principle for Parameter Reduction and Model Selection of Boltzmann Machines.,"Typical dimensionality reduction (DR) methods are data-oriented, focusing on directly reducing the number of random variables (or features) while retaining the maximal variations in the high-dimensional data. Targeting unsupervised situations, this paper aims to address the problem from a novel perspective and considers model-oriented DR in parameter spaces of binary multivariate distributions. Specifically, we propose a general parameter reduction criterion, called confident-information-first (CIF) principle, to maximally preserve confident parameters and rule out less confident ones. Formally, the confidence of each parameter can be assessed by its contribution to the expected Fisher information distance within a geometric manifold over the neighborhood of the underlying real distribution. Then, we demonstrate two implementations of CIF in different scenarios. First, when there are no observed samples, we revisit the Boltzmann machines (BMs) from a model selection perspective and theoretically show that both the fully visible BM and the BM with hidden units can be derived from the general binary multivariate distribution using the CIF principle. This finding would help us uncover and formalize the essential parts of the target density that BM aims to capture and the nonessential parts that BM should discard. Second, when there exist observed samples, we apply CIF to the model selection for BM, which is in turn made adaptive to the observed samples. The sample-specific CIF is a heuristic method to decide the priority order of parameters, which can improve the search efficiency without degrading the quality of model selection results as shown in a series of density estimation experiments.",4
Multitarget Sparse Latent Regression.,"Multitarget regression has recently generated intensive popularity due to its ability to simultaneously solve multiple regression tasks with improved performance, while great challenges stem from jointly exploring inter-target correlations and input-output relationships. In this paper, we propose multitarget sparse latent regression (MSLR) to simultaneously model intrinsic intertarget correlations and complex nonlinear input-output relationships in one single framework. By deploying a structure matrix, the MSLR accomplishes a latent variable model which is able to explicitly encode intertarget correlations via -norm-based sparse learning; the MSLR naturally admits a representer theorem for kernel extension, which enables it to flexibly handle highly complex nonlinear input-output relationships; the MSLR can be solved efficiently by an alternating optimization algorithm with guaranteed convergence, which ensures efficient multitarget regression. Extensive experimental evaluation on both synthetic data and six greatly diverse real-world data sets shows that the proposed MSLR consistently outperforms the state-of-the-art algorithms, which demonstrates its great effectiveness for multivariate prediction.",4
Adaptive Boundary Iterative Learning Control for an Euler-Bernoulli Beam System With Input Constraint.,"This paper addresses the vibration control and the input constraint for an Euler-Bernoulli beam system under aperiodic distributed disturbance and aperiodic boundary disturbance. Hyperbolic tangent functions and saturation functions are adopted to tackle the input constraint. A restrained adaptive boundary iterative learning control (ABILC) law is proposed based on a time-weighted Lyapunov-Krasovskii-like composite energy function. In order to deal with the uncertainty of a system parameter and reject the external disturbances, three adaptive laws are designed and learned in the iteration domain. All the system states of the closed-loop system are proved to be bounded in each iteration. Along the iteration axis, the displacements asymptotically converge toward zero. Simulation results are provided to illustrate the effectiveness of the proposed ABILC scheme.",4
Data-Driven Multiagent Systems Consensus Tracking Using Model Free Adaptive Control.,"This paper investigates the data-driven consensus tracking problem for multiagent systems with both fixed communication topology and switching topology by utilizing a distributed model free adaptive control (MFAC) method. Here, agent's dynamics are described by unknown nonlinear systems and only a subset of followers can access the desired trajectory. The dynamical linearization technique is applied to each agent based on the pseudo partial derivative, and then, a distributed MFAC algorithm is proposed to ensure that all agents can track the desired trajectory. It is shown that the consensus error can be reduced for both time invariable and time varying desired trajectories. The main feature of this design is that consensus tracking can be achieved using only input-output data of each agent. The effectiveness of the proposed design is verified by simulation examples.",4
Synchronization of Coupled Reaction-Diffusion Neural Networks With Directed Topology via an Adaptive Approach.,"This paper investigates the synchronization issue of coupled reaction-diffusion neural networks with directed topology via an adaptive approach. Due to the complexity of the network structure and the presence of space variables, it is difficult to design proper adaptive strategies on coupling weights to accomplish the synchronous goal. Under the assumptions of two kinds of special network structures, that is, directed spanning path and directed spanning tree, some novel edge-based adaptive laws, which utilized the local information of node dynamics fully are designed on the coupling weights for reaching synchronization. By constructing appropriate energy function, and utilizing some analytical techniques, several sufficient conditions are given. Finally, some simulation examples are given to verify the effectiveness of the obtained theoretical results.",4
Reinforced Robust Principal Component Pursuit.,"High-dimensional data present in the real world is often corrupted by noise and gross outliers. Principal component analysis (PCA) fails to learn the true low-dimensional subspace in such cases. This is the reason why robust versions of PCA, which put a penalty on arbitrarily large outlying entries, are preferred to perform dimension reduction. In this paper, we argue that it is necessary to study the presence of outliers not only in the observed data matrix but also in the orthogonal complement subspace of the authentic principal subspace. In fact, the latter can seriously skew the estimation of the principal components. A reinforced robustification of principal component pursuit is designed in order to cater to the problem of finding out both types of outliers and eliminate their influence on the final subspace estimation. Simulation results under different design situations clearly show the superiority of our proposed method as compared with other popular implementations of robust PCA. This paper also showcases possible applications of our method in critically tough scenarios of face recognition and video background subtraction. Along with approximating a usable low-dimensional subspace from real-world data sets, the technique can capture semantically meaningful outliers.",4
SPANNER: A Self-Repairing Spiking Neural Network Hardware Architecture.,"Recent research has shown that a glial cell of astrocyte underpins a self-repair mechanism in the human brain, where spiking neurons provide direct and indirect feedbacks to presynaptic terminals. These feedbacks modulate the synaptic transmission probability of release (PR). When synaptic faults occur, the neuron becomes silent or near silent due to the low PR of synapses; whereby the PRs of remaining healthy synapses are then increased by the indirect feedback from the astrocyte cell. In this paper, a novel hardware architecture of Self-rePAiring spiking Neural NEtwoRk (SPANNER) is proposed, which mimics this self-repairing capability in the human brain. This paper demonstrates that the hardware can self-detect and self-repair synaptic faults without the conventional components for the fault detection and fault repairing. Experimental results show that SPANNER can maintain the system performance with fault densities of up to 40%, and more importantly SPANNER has only a 20% performance degradation when the self-repairing architecture is significantly damaged at a fault density of 80%.",4
Adaptive Sliding Mode Control of Dynamic Systems Using Double Loop Recurrent Neural Network Structure.,"In this paper, an adaptive sliding mode control system using a double loop recurrent neural network (DLRNN) structure is proposed for a class of nonlinear dynamic systems. A new three-layer RNN is proposed to approximate unknown dynamics with two different kinds of feedback loops where the firing weights and output signal calculated in the last step are stored and used as the feedback signals in each feedback loop. Since the new structure has combined the advantages of internal feedback NN and external feedback NN, it can acquire the internal state information while the output signal is also captured, thus the new designed DLRNN can achieve better approximation performance compared with the regular NNs without feedback loops or the regular RNNs with a single feedback loop. The new proposed DLRNN structure is employed in an equivalent controller to approximate the unknown nonlinear system dynamics, and the parameters of the DLRNN are updated online by adaptive laws to get favorable approximation performance. To investigate the effectiveness of the proposed controller, the designed adaptive sliding mode controller with the DLRNN is applied to a -axis microelectromechanical system gyroscope to control the vibrating dynamics of the proof mass. Simulation results demonstrate that the proposed methodology can achieve good tracking property, and the comparisons of the approximation performance between radial basis function NN, RNN, and DLRNN show that the DLRNN can accurately estimate the unknown dynamics with a fast speed while the internal states of DLRNN are more stable.",4
Manifold Warp Segmentation of Human Action.,"Human action segmentation is important for human action analysis, which is a highly active research area. Most segmentation methods are based on clustering or numerical descriptors, which are only related to data, and consider no relationship between the data and physical characteristics of human actions. Physical characteristics of human motions are those that can be directly perceived by human beings, such as speed, acceleration, continuity, and so on, which are quite helpful in detecting human motion segment points. We propose a new physical-based descriptor of human action by curvature sequence warp space alignment (CSWSA) approach for sequence segmentation in this paper. Furthermore, time series-warp metric curvature segmentation method is constructed by the proposed descriptor and CSWSA. In our segmentation method, descriptor can express the changes of human actions, and CSWSA is an auxiliary method to give suggestions for segmentation. The experimental results show that our segmentation method is effective in both CMU human motion and video-based data sets.",4
Partition-Based Solutions of Static Logical Networks With Applications.,"Given a static logical network, partition-based solutions are investigated. Easily verifiable necessary and sufficient conditions are obtained, and the corresponding formulas are presented to provide all types of the partition-based solutions. Then, the results are extended to mix-valued logical networks. Finally, two applications are presented: 1) an implicit function (IF) theorem of logical equations, which provides necessary and sufficient condition for the existence of IF and 2) converting the difference-algebraic network into a standard difference network.",4
Output Feedback-Based Boundary Control of Uncertain Coupled Semilinear Parabolic PDE Using Neurodynamic Programming.,"In this paper, neurodynamic programming-based output feedback boundary control of distributed parameter systems governed by uncertain coupled semilinear parabolic partial differential equations (PDEs) under Neumann or Dirichlet boundary control conditions is introduced. First, Hamilton-Jacobi-Bellman (HJB) equation is formulated in the original PDE domain and the optimal control policy is derived using the value functional as the solution of the HJB equation. Subsequently, a novel observer is developed to estimate the system states given the uncertain nonlinearity in PDE dynamics and measured outputs. Consequently, the suboptimal boundary control policy is obtained by forward-in-time estimation of the value functional using a neural network (NN)-based online approximator and estimated state vector obtained from the NN observer. Novel adaptive tuning laws in continuous time are proposed for learning the value functional online to satisfy the HJB equation along system trajectories while ensuring the closed-loop stability. Local uniformly ultimate boundedness of the closed-loop system is verified by using Lyapunov theory. The performance of the proposed controller is verified via simulation on an unstable coupled diffusion reaction process.",4
Computational Model Based on Neural Network of Visual Cortex for Human Action Recognition.,"In this paper, we propose a bioinspired model for human action recognition through modeling neural mechanisms of information processing in two visual cortical areas: the primary visual cortex (V1) and the middle temporal cortex (MT) dedicated to motion. This model, named V1-MT, is composed of V1 and MT models (layers) corresponding to their cortical areas, which are built with layered spiking neural networks (SNNs). Some neuron properties in V1 and MT, such as direction and speed selectivity, spatiotemporal inseparability, and center surround suppression, are integrated into SNNs. Based on speed and direction selectivity, V1 and MT models contain multiple SNN channels, each of which processes motion information in sequences with spatiotemporal tunings of neurons at a certain speed and different directions. Therefore, we propose two operations, input signal perceiving with 3-D Gabor filters and surround inhibition processing with 3-D differences of Gaussian functions, to perform this task according to the spatiotemporal inseparability and center surround suppression of neurons. Then, neurons are modeled with our simplified integrate-and-fire model and motion information is transformed into spike trains. Afterward, we define a new feature vector: a mean motion map computed from spike trains in all channels to represent human actions. Finally, a support vector machine is trained to classify actions represented by the feature vectors. We conducted extensive experiments on public action databases, and the results show that our model outperforms other bioinspired models and rivals the state-of-the-art approaches.",4
DeepX: Deep Learning Accelerator for Restricted Boltzmann Machine Artificial Neural Networks.,"Although there have been many decades of research and commercial presence on high performance general purpose processors, there are still many applications that require fully customized hardware architectures for further computational acceleration. Recently, deep learning has been successfully used to learn in a wide variety of applications, but their heavy computation demand has considerably limited their practical applications. This paper proposes a fully pipelined acceleration architecture to alleviate high computational demand of an artificial neural network (ANN) which is restricted Boltzmann machine (RBM) ANNs. The implemented RBM ANN accelerator (integrating network size, using 128 input cases per batch, and running at a 303-MHz clock frequency) integrated in a state-of-the art field-programmable gate array (FPGA) (Xilinx Virtex 7 XC7V-2000T) provides a computational performance of 301-billion connection-updates-per-second and about 193 times higher performance than a software solution running on general purpose processors. Most importantly, the architecture enables over 4 times (12 times in batch learning) higher performance compared with a previous work when both are implemented in an FPGA device (XC2VP70).",4
Policy Iteration Algorithm for Optimal Control of Stochastic Logical Dynamical Systems.,"This brief investigates the infinite horizon optimal control problem for stochastic multivalued logical dynamical systems with discounted cost. Applying the equivalent descriptions of stochastic logical dynamics in term of Markov decision process, the discounted infinite horizon optimal control problem is presented in an algebraic form. Then, employing the method of semitensor product of matrices and the increasing-dimension technique, a succinct algebraic form of the policy iteration algorithm is derived to solve the optimal control problem. To show the effectiveness of the proposed policy iteration algorithm, an optimization problem of p53-Mdm2 gene network is investigated.",4
Learning a No-Reference Quality Assessment Model of Enhanced Images With Big Data.,"In this paper, we investigate into the problem of image quality assessment (IQA) and enhancement via machine learning. This issue has long attracted a wide range of attention in computational intelligence and image processing communities, since, for many practical applications, e.g., object detection and recognition, raw images are usually needed to be appropriately enhanced to raise the visual quality (e.g., visibility and contrast). In fact, proper enhancement can noticeably improve the quality of input images, even better than originally captured images, which are generally thought to be of the best quality. In this paper, we present two most important contributions. The first contribution is to develop a new no-reference (NR) IQA model. Given an image, our quality measure first extracts 17 features through analysis of contrast, sharpness, brightness and more, and then yields a measure of visual quality using a regression module, which is learned with big-data training samples that are much bigger than the size of relevant image data sets. The results of experiments on nine data sets validate the superiority and efficiency of our blind metric compared with typical state-of-the-art full-reference, reduced-reference and NA IQA methods. The second contribution is that a robust image enhancement framework is established based on quality optimization. For an input image, by the guidance of the proposed NR-IQA measure, we conduct histogram modification to successively rectify image brightness and contrast to a proper level. Thorough tests demonstrate that our framework can well enhance natural images, low-contrast images, low-light images, and dehazed images. The source code will be released at https://sites.google.com/site/guke198701/publications.",4
Feature Selection Based on Structured Sparsity: A Comprehensive Study.,"Feature selection (FS) is an important component of many pattern recognition tasks. In these tasks, one is often confronted with very high-dimensional data. FS algorithms are designed to identify the relevant feature subset from the original features, which can facilitate subsequent analysis, such as clustering and classification. Structured sparsity-inducing feature selection (SSFS) methods have been widely studied in the last few years, and a number of algorithms have been proposed. However, there is no comprehensive study concerning the connections between different SSFS methods, and how they have evolved. In this paper, we attempt to provide a survey on various SSFS methods, including their motivations and mathematical representations. We then explore the relationship among different formulations and propose a taxonomy to elucidate their evolution. We group the existing SSFS methods into two categories, i.e., vector-based feature selection (feature selection based on lasso) and matrix-based feature selection (feature selection based on lr,p-norm). Furthermore, FS has been combined with other machine learning algorithms for specific applications, such as multitask learning, multilabel learning, multiview learning, classification, and clustering. This paper not only compares the differences and commonalities of these methods based on regression and regularization strategies, but also provides useful guidelines to practitioners working in related fields to guide them how to do feature selection.",4
Boundary Control of Linear Uncertain 1-D Parabolic PDE Using Approximate Dynamic Programming.,"This paper develops a near optimal boundary control method for distributed parameter systems governed by uncertain linear 1-D parabolic partial differential equations (PDE) by using approximate dynamic programming. A quadratic surface integral is proposed to express the optimal cost functional for the infinite-dimensional state space. Accordingly, the Hamilton-Jacobi-Bellman (HJB) equation is formulated in the infinite-dimensional domain without using any model reduction. Subsequently, a neural network identifier is developed to estimate the unknown spatially varying coefficient in PDE dynamics. Novel tuning law is proposed to guarantee the boundedness of identifier approximation error in the PDE domain. A radial basis network (RBN) is subsequently proposed to generate an approximate solution for the optimal surface kernel function online. The tuning law for near optimal RBN weights is created, such that the HJB equation error is minimized while the dynamics are identified and closed-loop system remains stable. Ultimate boundedness (UB) of the closed-loop system is verified by using the Lyapunov theory. The performance of the proposed controller is successfully confirmed by simulation on an unstable diffusion-reaction process.",4
Adaptive Neural Output Feedback Control for Nonstrict-Feedback Stochastic Nonlinear Systems With Unknown Backlash-Like Hysteresis and Unknown Control Directions.,"This paper investigates the problem of output feedback adaptive stabilization for a class of nonstrict-feedback stochastic nonlinear systems with both unknown backlashlike hysteresis and unknown control directions. A new linear state transformation is applied to the original system, and then, control design for the new system becomes feasible. By combining the neural network's (NN's) parameterization, variable separation technique, and Nussbaum gain function method, an input-driven observer-based adaptive NN control scheme, which involves only one parameter to be updated, is developed for such systems. All closed-loop signals are bounded in probability and the error signals remain semiglobally bounded in the fourth moment (or mean square). Finally, the effectiveness and the applicability of the proposed control design are verified by two simulation examples.",4
Probabilistic Distance for Mixtures of Independent Component Analyzers.,"Independent component analysis (ICA) is a blind source separation technique where data are modeled as linear combinations of several independent non-Gaussian sources. The independence and linear restrictions are relaxed using several ICA mixture models (ICAMMs) obtaining a two-layer artificial neural network structure. This allows for dependence between sources of different classes, and thus, a myriad of multidimensional probability density functions can be accurate modeled. This paper proposes a new probabilistic distance (PDI) between the parameters learned for two ICAMMs. The PDI is computed explicitly, unlike the popular Kullback-Leibler divergence (KLD) and other similar metrics, removing the need for numerical integration. Furthermore, the PDI is symmetric and bounded within 0 and 1, which enables its use as a posterior probability in fusion approaches. In this paper, the PDI is employed for change detection by measuring the distance between two ICAMMs learned in consecutive time windows. The changes might be associated with relevant states from a process under analysis that are explicitly reflected in the learned ICAMM parameters. The proposed distance was tested in two challenging applications using simulated and real data: 1) detecting flaws in materials using ultrasounds and 2) detecting changes in electroencephalography signals from humans performing neuropsychological tests. The results demonstrate that the PDI outperforms the KLD in change-detection capabilities.",4
Improving KPCA Online Extraction by Orthonormalization in the Feature Space.,"Recently, some online kernel principal component analysis (KPCA) techniques based on the generalized Hebbian algorithm (GHA) were proposed for use in large data sets, defining kernel components using concise dictionaries automatically extracted from data. This brief proposes two new online KPCA extraction algorithms, exploiting orthogonalized versions of the GHA rule. In both the cases, the orthogonalization of kernel components is achieved by the inclusion of some low complexity additional steps to the kernel Hebbian algorithm, thus not substantially affecting the computational cost of the algorithm. Results show improved convergence speed and accuracy of components extracted by the proposed methods, as compared with the state-of-the-art online KPCA extraction algorithms.",4
State Estimation for Static Neural Networks With Time-Varying Delays Based on an Improved Reciprocally Convex Inequality.,"This brief is concerned with the problem of neural state estimation for static neural networks with time-varying delays. Notice that a Luenberger estimator can produce an estimation error irrespective of the neuron state trajectory. This brief provides a method for designing such an estimator for static neural networks with time-varying delays. First, in-depth analysis on a well-used reciprocally convex approach is made, leading to an improved reciprocally convex inequality. Second, the improved reciprocally convex inequality and some integral inequalities are employed to provide a tight upper bound on the time-derivative of some Lyapunov-Krasovskii functional. As a result, a novel bounded real lemma (BRL) for the resultant error system is derived. Third, the BRL is applied to present a method for designing suitable Luenberger estimators in terms of solutions of linear matrix inequalities with two tuning parameters. Finally, it is shown through a numerical example that the proposed method can derive less conservative results than some existing ones.",4
Fast-Solving Quasi-Optimal LS-S(3)VM Based on an Extended Candidate Set.,"The semisupervised least squares support vector machine (LS-S(3)VM) is an important enhancement of least squares support vector machines in semisupervised learning. Given that most data collected from the real world are without labels, semisupervised approaches are more applicable than standard supervised approaches. Although a few training methods for LS-S(3)VM exist, the problem of deriving the optimal decision hyperplane efficiently and effectually has not been solved. In this paper, a fully weighted model of LS-S(3)VM is proposed, and a simple integer programming (IP) model is introduced through an equivalent transformation to solve the model. Based on the distances between the unlabeled data and the decision hyperplane, a new indicator is designed to represent the possibility that the label of an unlabeled datum should be reversed in each iteration during training. Using the indicator, we construct an extended candidate set consisting of the indices of unlabeled data with high possibilities, which integrates more information from unlabeled data. Our algorithm is degenerated into a special scenario of the previous algorithm when the extended candidate set is reduced into a set with only one element. Two strategies are utilized to determine the descent directions based on the extended candidate set. Furthermore, we developed a novel method for locating a good starting point based on the properties of the equivalent IP model. Combined with the extended candidate set and the carefully computed starting point, a fast algorithm to solve LS-S(3)VM quasi-optimally is proposed. The choice of quasi-optimal solutions results in low computational cost and avoidance of overfitting. Experiments show that our algorithm equipped with the two designed strategies is more effective than other algorithms in at least one of the following three aspects: 1) computational complexity; 2) generalization ability; and 3) flexibility. However, our algorithm and other algorithms have similar levels of performance in the remaining aspects.",4
Homotopy Methods Based on $l_{0}$ -Norm for Compressed Sensing.,"This paper proposes two homotopy methods for solving the compressed sensing (CS) problem, which combine the homotopy technique with the iterative hard thresholding (IHT) method. The homotopy methods overcome the difficulty of the IHT method on the choice of the regularization parameter value, by tracing solutions of the regularized problem along a homotopy path. We prove that any accumulation point of the sequences generated by the proposed homotopy methods is a feasible solution of the problem. We also show an upper bound on the sparsity level for each solution of the proposed methods. Moreover, to improve the solution quality, we modify the two methods into the corresponding heuristic algorithms. Computational experiments demonstrate effectiveness of the two heuristic algorithms, in accurately and efficiently generating sparse solutions of the CS problem, whether the observation is noisy or not.",4
A Two-Time-Scale Neurodynamic Approach to Constrained Minimax Optimization.,"This paper presents a two-time-scale neurodynamic approach to constrained minimax optimization using two coupled neural networks. One of the recurrent neural networks is used for minimizing the objective function and another is used for maximization. It is shown that the coupled neurodynamic systems operating in two different time scales work well for minimax optimization. The effectiveness and characteristics of the proposed approach are illustrated using several examples. Furthermore, the proposed approach is applied for Hinfinity model predictive control.",4
Neural Network-Based Solutions for Stochastic Optimal Control Using Path Integrals.,"In this paper, an offline approximate dynamic programming approach using neural networks is proposed for solving a class of finite horizon stochastic optimal control problems. There are two approaches available in the literature, one based on stochastic maximum principle (SMP) formalism and the other based on solving the stochastic Hamilton-Jacobi-Bellman (HJB) equation. However, in the presence of noise, the SMP formalism becomes complex and results in having to solve a couple of backward stochastic differential equations. Hence, current solution methodologies typically ignore the noise effect. On the other hand, the inclusion of noise in the HJB framework is very straightforward. Furthermore, the stochastic HJB equation of a control-affine nonlinear stochastic system with a quadratic control cost function and an arbitrary state cost function can be formulated as a path integral (PI) problem. However, due to curse of dimensionality, it might not be possible to utilize the PI formulation for obtaining comprehensive solutions over the entire operating domain. A neural network structure called the adaptive critic design paradigm is used to effectively handle this difficulty. In this paper, a novel adaptive critic approach using the PI formulation is proposed for solving stochastic optimal control problems. The potential of the algorithm is demonstrated through simulation results from a couple of benchmark problems.",4
A Stochastic Spiking Neural Network for Virtual Screening.,"Virtual screening (VS) has become a key computational tool in early drug design and screening performance is of high relevance due to the large volume of data that must be processed to identify molecules with the sought activity-related pattern. At the same time, the hardware implementations of spiking neural networks (SNNs) arise as an emerging computing technique that can be applied to parallelize processes that normally present a high cost in terms of computing time and power. Consequently, SNN represents an attractive alternative to perform time-consuming processing tasks, such as VS. In this brief, we present a smart stochastic spiking neural architecture that implements the ultrafast shape recognition (USR) algorithm achieving two order of magnitude of speed improvement with respect to USR software implementations. The neural system is implemented in hardware using field-programmable gate arrays allowing a highly parallelized USR implementation. The results show that, due to the high parallelization of the system, millions of compounds can be checked in reasonable times. From these results, we can state that the proposed architecture arises as a feasible methodology to efficiently enhance time-consuming data-mining processes such as 3-D molecular similarity search.",4
Pattern-Based NN Control of a Class of Uncertain Nonlinear Systems.,"This paper presents a pattern-based neural network (NN) control approach for a class of uncertain nonlinear systems. The approach consists of two phases of identification and another two phases of recognition and control. First, in the phase (i) of identification, adaptive NN controllers are designed to achieve closed-loop stability and tracking performance of nonlinear systems for different control situations, and the corresponding closed-loop control system dynamics are identified via deterministic learning. The identified control system dynamics are stored in constant radial basis function (RBF) NNs, and a set of constant NN controllers are constructed by using the obtained constant RBF networks. Second, in the phase (ii) of identification, when the plant is operated under different or abnormal conditions, the system dynamics under normal control are identified via deterministic learning. A bank of dynamical estimators is constructed for all the abnormal conditions and the learned knowledge is embedded in the estimators. Third, in the phase of recognition, when one identified control situation recurs, by using the constructed estimators, the recurred control situation will be rapidly recognized. Finally, in the phase of pattern-based control, based on the rapid recognition, the constant NN controller corresponding to the current control situation is selected, and both closed-loop stability and improved control performance can be achieved. The results presented show that the pattern-based control realizes a humanlike control process, and will provide a new framework for fast decision and control in dynamic environments. A simulation example is included to demonstrate the effectiveness of the approach.",4
Differentiation-Free Multiswitching Neuroadaptive Control of Strict-Feedback Systems.,"Issues of differentiation-free multiswitching neuroadaptive tracking control of strict-feedback systems are presented. It mainly consists of a set of nominal adaptive neural network compensators plus an auxiliary switched linear controller that ensures the semiglobally/globally ultimately uniformly bounded stability when the unknown nonlinearities are locally/globally linearly bounded, respectively. In particular, the so-called explosion of complexity is annihilated in two steps. First, a set of first-order low-pass filters are constructed for solving such a problem in the nominal neural compensators. In contrast to most existing dynamic surface control-based schemes, bounded stability of the filter dynamics is ensured by virtue of the localness and hence boundedness of the neural compensators. Separation of controller-filter pairs is thus achieved in this paper. Next, an auxiliary switched linear state feedback control is synthesized to further solve such a problem in the nonneural regions. Besides being differentiation-free, such an approach provides more flexibility for meeting various control objectives at a time. An earlier proposed smooth switching algorithm is also incorporated to tackle the control singularity problem. Finally, simulation works are presented to demonstrate the validity of the proposed scheme.",4
Robustness Analysis on Dual Neural Network-based $k$ WTA With Input Noise.,"This paper studies the effects of uniform input noise and Gaussian input noise on the dual neural network-based WTA (DNN- WTA) model. We show that the state of the network (under either uniform input noise or Gaussian input noise) converges to one of the equilibrium points. We then derive a formula to check if the network produce correct outputs or not. Furthermore, for the uniformly distributed inputs, two lower bounds (one for each type of input noise) on the probability that the network produces the correct outputs are presented. Besides, when the minimum separation amongst inputs is given, we derive the condition for the network producing the correct outputs. Finally, experimental results are presented to verify our theoretical results. Since random drift in the comparators can be considered as input noise, our results can be applied to the random drift situation.",4
Finite-Time State Estimation for Recurrent Delayed Neural Networks With Component-Based Event-Triggering Protocol.,"This paper deals with the event-based finite-time state estimation problem for a class of discrete-time stochastic neural networks with mixed discrete and distributed time delays. In order to mitigate the burden of data communication, a general component-based event-triggered transmission mechanism is proposed to determine whether the measurement output should be released to the estimator at certain time-point according to a specific triggering condition. A new concept of finite-time boundedness in the mean square is put forward to quantify the estimation performance by introducing a settling-like time function. The objective of the addressed problem is to construct an event-based state estimator to estimate the neuron states such that, in the presence of both mixed time delays and external noise disturbances, the dynamics of the estimation error is finite-time bounded in the mean square with a prescribed error upper bound. Sufficient conditions are established, via stochastic analysis techniques, to guarantee the desired estimation performance. By solving an optimization problem with some inequality constraints, the explicit expression of the estimator gain matrix is characterized to minimize the settling-like time. Finally, a numerical simulation example is exploited to demonstrate the effectiveness of the proposed estimator design scheme.",4
Decomposition of Rotor Hopfield Neural Networks Using Complex Numbers.,"A complex-valued Hopfield neural network (CHNN) is a multistate model of a Hopfield neural network. It has the disadvantage of low noise tolerance. Meanwhile, a symmetric CHNN (SCHNN) is a modification of a CHNN that improves noise tolerance. Furthermore, a rotor Hopfield neural network (RHNN) is an extension of a CHNN. It has twice the storage capacity of CHNNs and SCHNNs, and much better noise tolerance than CHNNs, although it requires twice many connection parameters. In this brief, we investigate the relations between CHNN, SCHNN, and RHNN; an RHNN is uniquely decomposed into a CHNN and SCHNN. In addition, the Hebbian learning rule for RHNNs is decomposed into those for CHNNs and SCHNNs.",4
Safe Exploration Algorithms for Reinforcement Learning Controllers.,"Self-learning approaches, such as reinforcement learning, offer new possibilities for autonomous control of uncertain or time-varying systems. However, exploring an unknown environment under limited prediction capabilities is a challenge for a learning agent. If the environment is dangerous, free exploration can result in physical damage or in an otherwise unacceptable behavior. With respect to existing methods, the main contribution of this paper is the definition of a new approach that does not require global safety functions, nor specific formulations of the dynamics or of the environment, but relies on interval estimation of the dynamics of the agent during the exploration phase, assuming a limited capability of the agent to perceive the presence of incoming fatal states. Two algorithms are presented with this approach. The first is the Safety Handling Exploration with Risk Perception Algorithm (SHERPA), which provides safety by individuating temporary safety functions, called backups. SHERPA is shown in a simulated, simplified quadrotor task, for which dangerous states are avoided. The second algorithm, denominated OptiSHERPA, can safely handle more dynamically complex systems for which SHERPA is not sufficient through the use of safety metrics. An application of OptiSHERPA is simulated on an aircraft altitude control task.",4
Quantum-Inspired Multidirectional Associative Memory With a Self-Convergent Iterative Learning.,"Quantum-inspired computing is an emerging research area, which has significantly improved the capabilities of conventional algorithms. In general, quantum-inspired hopfield associative memory (QHAM) has demonstrated quantum information processing in neural structures. This has resulted in an exponential increase in storage capacity while explaining the extensive memory, and it has the potential to illustrate the dynamics of neurons in the human brain when viewed from quantum mechanics perspective although the application of QHAM is limited as an autoassociation. We introduce a quantum-inspired multidirectional associative memory (QMAM) with a one-shot learning model, and QMAM with a self-convergent iterative learning model (IQMAM) based on QHAM in this paper. The self-convergent iterative learning enables the network to progressively develop a resonance state, from inputs to outputs. The simulation experiments demonstrate the advantages of QMAM and IQMAM, especially the stability to recall reliability.",4
Model-Based Adaptive Event-Triggered Control of Strict-Feedback Nonlinear Systems.,"This paper is concerned with the adaptive event-triggered control problem of nonlinear continuous-time systems in strict-feedback form. By using the event-sampled neural network (NN) to approximate the unknown nonlinear function, an adaptive model and an associated event-triggered controller are designed by exploiting the backstepping method. In the proposed method, the feedback signals and the NN weights are aperiodically updated only when the event-triggered condition is violated. A positive lower bound on the minimum intersample time is guaranteed to avoid accumulation point. The closed-loop stability of the resulting nonlinear impulsive dynamical system is rigorously proved via Lyapunov analysis under an adaptive event sampling condition. In comparing with the traditional adaptive backstepping design with a fixed sample period, the event-triggered method samples the state and updates the NN weights only when it is necessary. Therefore, the number of transmissions can be significantly reduced. Finally, two simulation examples are presented to show the effectiveness of the proposed control method.",4
Hamiltonian-Driven Adaptive Dynamic Programming for Continuous Nonlinear Dynamical Systems.,"This paper presents a Hamiltonian-driven framework of adaptive dynamic programming (ADP) for continuous time nonlinear systems, which consists of evaluation of an admissible control, comparison between two different admissible policies with respect to the corresponding the performance function, and the performance improvement of an admissible control. It is showed that the Hamiltonian can serve as the temporal difference for continuous-time systems. In the Hamiltonian-driven ADP, the critic network is trained to output the value gradient. Then, the inner product between the critic and the system dynamics produces the value derivative. Under some conditions, the minimization of the Hamiltonian functional is equivalent to the value function approximation. An iterative algorithm starting from an arbitrary admissible control is presented for the optimal control approximation with its convergence proof. The implementation is accomplished by a neural network approximation. Two simulation studies demonstrate the effectiveness of Hamiltonian-driven ADP.",4
A Collaborative Neurodynamic Approach to Multiple-Objective Distributed Optimization.,"This paper is concerned with multiple-objective distributed optimization. Based on objective weighting and decision space decomposition, a collaborative neurodynamic approach to multiobjective distributed optimization is presented. In the approach, a system of collaborative neural networks is developed to search for Pareto optimal solutions, where each neural network is associated with one objective function and given constraints. Sufficient conditions are derived for ascertaining the convergence to a Pareto optimal solution of the collaborative neurodynamic system. In addition, it is proved that each connected subsystem can generate a Pareto optimal solution when the communication topology is disconnected. Then, a switching-topology-based method is proposed to compute multiple Pareto optimal solutions for discretized approximation of Pareto front. Finally, simulation results are discussed to substantiate the performance of the collaborative neurodynamic approach. A portfolio selection application is also given.",4
Quantization-Based Adaptive Actor-Critic Tracking Control With Tracking Error Constraints.,"In this paper, the problem of adaptive actor-critic (AC) tracking control is investigated for a class of continuous-time nonlinear systems with unknown nonlinearities and quantized inputs. Different from the existing results based on reinforcement learning, the tracking error constraints are considered and new critic functions are constructed to improve the performance further. To ensure that the tracking errors keep within the predefined time-varying boundaries, a tracking error transformation technique is used to constitute an augmented error system. Specific critic functions, rather than the long-term cost function, are introduced to supervise the tracking performance and tune the weights of the AC neural networks (NNs). A novel adaptive controller with a special structure is designed to reduce the effect of the NN reconstruction errors, input quantization, and disturbances. Based on the Lyapunov stability theory, the boundedness of the closed-loop signals and the desired tracking performance can be guaranteed. Finally, simulations on two connected inverted pendulums are given to illustrate the effectiveness of the proposed method.",4
Regularized Label Relaxation Linear Regression.,"Linear regression (LR) and some of its variants have been widely used for classification problems. Most of these methods assume that during the learning phase, the training samples can be exactly transformed into a strict binary label matrix, which has too little freedom to fit the labels adequately. To address this problem, in this paper, we propose a novel regularized label relaxation LR method, which has the following notable characteristics. First, the proposed method relaxes the strict binary label matrix into a slack variable matrix by introducing a nonnegative label relaxation matrix into LR, which provides more freedom to fit the labels and simultaneously enlarges the margins between different classes as much as possible. Second, the proposed method constructs the class compactness graph based on manifold learning and uses it as the regularization item to avoid the problem of overfitting. The class compactness graph is used to ensure that the samples sharing the same labels can be kept close after they are transformed. Two different algorithms, which are, respectively, based on -norm and -norm loss functions are devised. These two algorithms have compact closed-form solutions in each iteration so that they are easily implemented. Extensive experiments show that these two algorithms outperform the state-of-the-art algorithms in terms of the classification accuracy and running time.",4
Collaborative Random Faces-Guided Encoders for Pose-Invariant Face Representation Learning.,"Learning discriminant face representation for pose-invariant face recognition has been identified as a critical issue in visual learning systems. The challenge lies in the drastic changes of facial appearances between the test face and the registered face. To that end, we propose a high-level feature learning framework called ""collaborative random faces (RFs)-guided encoders"" toward this problem. The contributions of this paper are three fold. First, we propose a novel supervised autoencoder that is able to capture the high-level identity feature despite of pose variations. Second, we enrich the identity features by replacing the target values of conventional autoencoders with random signals (RFs in this paper), which are unique for each subject under different poses. Third, we further improve the performance of the framework by incorporating deep convolutional neural network facial descriptors and linking discriminative identity features from different RFs for the augmented identity features. Finally, we conduct face identification experiments on Multi-PIE database, and face verification experiments on labeled faces in the wild and YouTube Face databases, where face recognition rate and verification accuracy with Receiver Operating Characteristic curves are rendered. In addition, discussions of model parameters and connections with the existing methods are provided. These experiments demonstrate that our learning system works fairly well on handling pose variations.",4
On Mixed Data and Event Driven Design for Adaptive-Critic-Based Nonlinear $H_{\infty}$ Control.,"In this paper, based on the adaptive critic learning technique, the control for a class of unknown nonlinear dynamic systems is investigated by adopting a mixed data and event driven design approach. The nonlinear control problem is formulated as a two-player zero-sum differential game and the adaptive critic method is employed to cope with the data-based optimization. The novelty lies in that the data driven learning identifier is combined with the event driven design formulation, in order to develop the adaptive critic controller, thereby accomplishing the nonlinear control. The event driven optimal control law and the time driven worst case disturbance law are approximated by constructing and tuning a critic neural network. Applying the event driven feedback control, the closed-loop system is built with stability analysis. Simulation studies are conducted to verify the theoretical results and illustrate the control performance. It is significant to observe that the present research provides a new avenue of integrating data-based control and event-triggering mechanism into establishing advanced adaptive critic systems.",4
Consensus of Hybrid Multi-Agent Systems.,"In this brief, we consider the consensus problem of hybrid multiagent systems. First, the hybrid multiagent system is proposed, which is composed of continuous-time and discrete-time dynamic agents. Then, three kinds of consensus protocols are presented for the hybrid multiagent system. The analysis tool developed in this brief is based on the matrix theory and graph theory. With different restrictions of the sampling period, some necessary and sufficient conditions are established for solving the consensus of the hybrid multiagent system. The consensus states are also obtained under different protocols. Finally, simulation examples are provided to demonstrate the effectiveness of our theoretical results.",4
Impulsive Effects on Quasi-Synchronization of Neural Networks With Parameter Mismatches and Time-Varying Delay.,"This paper is concerned with the exponential synchronization issue of nonidentically coupled neural networks with time-varying delay. Due to the parameter mismatch phenomena existed in neural networks, the problem of quasi-synchronization is thus discussed by applying some impulsive control strategies. Based on the definition of average impulsive interval and the extended comparison principle for impulsive systems, some criteria for achieving the quasi-synchronization of neural networks are derived. More extensive ranges of impulsive effects are discussed so that impulse could either play an effective role or play an adverse role in the final network synchronization. In addition, according to the extended formula for the variation of parameters with time-varying delay, precisely exponential convergence rates and quasi-synchronization errors are obtained, respectively, in view of different types impulsive effects. Finally, some numerical simulations with different types of impulsive effects are presented to illustrate the effectiveness of theoretical analysis.",4
Multivariate Time-Series Classification Using the Hidden-Unit Logistic Model.,"We present a new model for multivariate time-series classification, called the hidden-unit logistic model (HULM), that uses binary stochastic hidden units to model latent structure in the data. The hidden units are connected in a chain structure that models temporal dependencies in the data. Compared with the prior models for time-series classification such as the hidden conditional random field, our model can model very complex decision boundaries, because the number of latent states grows exponentially with the number of hidden units. We demonstrate the strong performance of our model in experiments on a variety of (computer vision) tasks, including handwritten character recognition, speech recognition, facial expression, and action recognition. We also present a state-of-the-art system for facial action unit detection based on the HULM.",4
Adaptive Unsupervised Feature Selection With Structure Regularization.,"Feature selection is one of the most important dimension reduction techniques for its efficiency and interpretation. Since practical data in large scale are usually collected without labels, and labeling these data are dramatically expensive and time-consuming, unsupervised feature selection has become a ubiquitous and challenging problem. Without label information, the fundamental problem of unsupervised feature selection lies in how to characterize the geometry structure of original feature space and produce a faithful feature subset, which preserves the intrinsic structure accurately. In this paper, we characterize the intrinsic local structure by an adaptive reconstruction graph and simultaneously consider its multiconnected-components (multicluster) structure by imposing a rank constraint on the corresponding Laplacian matrix. To achieve a desirable feature subset, we learn the optimal reconstruction graph and selective matrix simultaneously, instead of using a predetermined graph. We exploit an efficient alternative optimization algorithm to solve the proposed challenging problem, together with the theoretical analyses on its convergence and computational complexity. Finally, extensive experiments on clustering task are conducted over several benchmark data sets to verify the effectiveness and superiority of the proposed unsupervised feature selection algorithm.",4
Manifold Regularized Reinforcement Learning.,"This paper introduces a novel manifold regularized reinforcement learning scheme for continuous Markov decision processes. Smooth feature representations for value function approximation can be automatically learned using the unsupervised manifold regularization method. The learned features are data-driven, and can be adapted to the geometry of the state space. Furthermore, the scheme provides a direct basis representation extension for novel samples during policy learning and control. The performance of the proposed scheme is evaluated on two benchmark control tasks, i.e., the inverted pendulum and the energy storage problem. Simulation results illustrate the concepts of the proposed scheme and show that it can obtain excellent performance.",4
Feature Combination via Clustering.,"In image classification, feature combination is often used to combine the merits of multiple complementary features and improve the classification accuracy compared with one single feature. Existing feature combination algorithms, e.g., multiple kernel learning, usually determine the weights of features based on the optimization with respect to some classifier-dependent objective function. These algorithms are often computationally expensive, and in some cases are found to perform no better than simple baselines. In this paper, we solve the feature combination problem from a totally different perspective. Our algorithm is based on the simple idea of combining only base kernels suitable to be combined. Since the very aim of feature combination is to obtain the highest possible classification accuracy, we measure the combination suitableness of two base kernels by the maximum possible cross-validation accuracy of their combined kernel. By regarding the pairwise suitableness as the kernel adjacency, we obtain a weighted graph of all base kernels and find that the base kernels suitable to be combined correspond to a cluster in the graph. We then use the dominant sets algorithm to find the cluster and determine the weights of base kernels automatically. In this way, we transform the kernel combination problem into a clustering one. Our algorithm can be implemented in parallel easily and the running time can be adjusted based on available memory to a large extent. In experiments on several data sets, our algorithm generates comparable classification accuracy with the state of the art.",4
Adaptive Dynamic Programming for Discrete-Time Zero-Sum Games.,"In this paper, a novel adaptive dynamic programming (ADP) algorithm, called ""iterative zero-sum ADP algorithm,"" is developed to solve infinite-horizon discrete-time two-player zero-sum games of nonlinear systems. The present iterative zero-sum ADP algorithm permits arbitrary positive semidefinite functions to initialize the upper and lower iterations. A novel convergence analysis is developed to guarantee the upper and lower iterative value functions to converge to the upper and lower optimums, respectively. When the saddle-point equilibrium exists, it is emphasized that both the upper and lower iterative value functions are proved to converge to the optimal solution of the zero-sum game, where the existence criteria of the saddle-point equilibrium are not required. If the saddle-point equilibrium does not exist, the upper and lower optimal performance index functions are obtained, respectively, where the upper and lower performance index functions are proved to be not equivalent. Finally, simulation results and comparisons are shown to illustrate the performance of the present method.",4
Online Nonlinear AUC Maximization for Imbalanced Data Sets.,"Classifying binary imbalanced streaming data is a significant task in both machine learning and data mining. Previously, online area under the receiver operating characteristic (ROC) curve (AUC) maximization has been proposed to seek a linear classifier. However, it is not well suited for handling nonlinearity and heterogeneity of the data. In this paper, we propose the kernelized online imbalanced learning (KOIL) algorithm, which produces a nonlinear classifier for the data by maximizing the AUC score while minimizing a functional regularizer. We address four major challenges that arise from our approach. First, to control the number of support vectors without sacrificing the model performance, we introduce two buffers with fixed budgets to capture the global information on the decision boundary by storing the corresponding learned support vectors. Second, to restrict the fluctuation of the learned decision function and achieve smooth updating, we confine the influence on a new support vector to its -nearest opposite support vectors. Third, to avoid information loss, we propose an effective compensation scheme after the replacement is conducted when either buffer is full. With such a compensation scheme, the performance of the learned model is comparable to the one learned with infinite budgets. Fourth, to determine good kernels for data similarity representation, we exploit the multiple kernel learning framework to automatically learn a set of kernels. Extensive experiments on both synthetic and real-world benchmark data sets demonstrate the efficacy of our proposed approach.",4
High-Dimensional Function Approximation With Neural Networks for Large Volumes of Data.,"Approximation of high-dimensional functions is a challenge for neural networks due to the curse of dimensionality. Often the data for which the approximated function is defined resides on a low-dimensional manifold and in principle the approximation of the function over this manifold should improve the approximation performance. It has been show that projecting the data manifold into a lower dimensional space, followed by the neural network approximation of the function over this space, provides a more precise approximation of the function than the approximation of the function with neural networks in the original data space. However, if the data volume is very large, the projection into the low-dimensional space has to be based on a limited sample of the data. Here, we investigate the nature of the approximation error of neural networks trained over the projection space. We show that such neural networks should have better approximation performance than neural networks trained on high-dimensional data even if the projection is based on a relatively sparse sample of the data manifold. We also find that it is preferable to use a uniformly distributed sparse sample of the data for the purpose of the generation of the low-dimensional projection. We illustrate these results considering the practical neural network approximation of a set of functions defined on high-dimensional data including real world data as well.",4
Groupwise Retargeted Least-Squares Regression.,"In this brief, we propose a new groupwise retargeted least squares regression (GReLSR) model for multicategory classification. The main motivation behind GReLSR is to utilize an additional regularization to restrict the translation values of ReLSR, so that they should be similar within same class. By analyzing the regression targets of ReLSR, we propose a new formulation of ReLSR, where the translation values are expressed explicitly. On the basis of the new formulation, discriminative least-squares regression can be regarded as a special case of ReLSR with zero translation values. Moreover, a groupwise constraint is added to ReLSR to form the new GReLSR model. Extensive experiments on various machine leaning data sets illustrate that our method outperforms the current state-of-the-art approaches.",4
Finite-Time Stabilization of Delayed Memristive Neural Networks: Discontinuous State-Feedback and Adaptive Control Approach.,"In this paper, a general class of delayed memristive neural networks (DMNNs) system described by functional differential equation with discontinuous right-hand side is considered. Under the extended Filippov-framework, we investigate the finite-time stabilization problem for DMNNs by using the famous finite-time stability theorem and the generalized Lyapunov functional method. To do so, we design two classes of novel controllers including discontinuous state-feedback controller and discontinuous adaptive controller. Without assuming the boundedness and monotonicity of the activation functions, several sufficient conditions are given to stabilize the states of this class of DMNNs in finite time. Moreover, the upper bounds of the settling time for stabilization are estimated. Finally, numerical examples are provided to demonstrate the effectiveness of the developed method and the theoretical results.",4
Identifying a Probabilistic Boolean Threshold Network From Samples.,"This paper studies the problem of exactly identifying the structure of a probabilistic Boolean network (PBN) from a given set of samples, where PBNs are probabilistic extensions of Boolean networks. Cheng et al. studied the problem while focusing on PBNs consisting of pairs of AND/OR functions. This paper considers PBNs consisting of Boolean threshold functions while focusing on those threshold functions that have unit coefficients. The treatment of Boolean threshold functions, and triplets and -tuplets of such functions, necessitates a deepening of the theoretical analyses. It is shown that wide classes of PBNs with such threshold functions can be exactly identified from samples under reasonable constraints, which include: 1) PBNs in which any number of threshold functions can be assigned provided that all have the same number of input variables and 2) PBNs consisting of pairs of threshold functions with different numbers of input variables. It is also shown that the problem of deciding the equivalence of two Boolean threshold functions is solvable in pseudopolynomial time but remains co-NP complete.",4
Synchronization for the Realization-Dependent Probabilistic Boolean Networks.,"This paper investigates the synchronization problem for the realization-dependent probabilistic Boolean networks (PBNs) coupled unidirectionally in the drive-response configuration. The realization of the response PBN is assumed to be uniquely determined by the realization signal generated by the drive PBN at each discrete time instant. First, the drive-response PBNs are expressed in their algebraic forms based on the semitensor product method, and then, a necessary and sufficient condition is presented for the synchronization of the PBNs. Second, by resorting to a newly defined matrix operator, the reachable set from any initial state is expressed by a column vector. Consequently, an easily computable algebraic criterion is derived assuring the synchronization of the drive-response PBNs. Finally, three illustrative examples are employed to demonstrate the applicability and usefulness of the developed theoretical results.",4
Adaptive Tracking Control for Robots With an Interneural Computing Scheme.,"Adaptive tracking control of mobile robots requires the ability to follow a trajectory generated by a moving target. The conventional analysis of adaptive tracking uses energy minimization to study the convergence and robustness of the tracking error when the mobile robot follows a desired trajectory. However, in the case that the moving target generates trajectories with uncertainties, a common Lyapunov-like function for energy minimization may be extremely difficult to determine. Here, to solve the adaptive tracking problem with uncertainties, we wish to implement an interneural computing scheme in the design of a mobile robot for behavior-based navigation. The behavior-based navigation adopts an adaptive plan of behavior patterns learning from the uncertainties of the environment. The characteristic feature of the interneural computing scheme is the use of neural path pruning with rewards and punishment interacting with the environment. On this basis, the mobile robot can be exploited to change its coupling weights in paths of neural connections systematically, which can then inhibit or enhance the effect of flow elimination in the dynamics of the evolutionary neural network. Such dynamical flow translation ultimately leads to robust sensory-to-motor transformations adapting to the uncertainties of the environment. A simulation result shows that the mobile robot with the interneural computing scheme can perform fault-tolerant behavior of tracking by maintaining suitable behavior patterns at high frequency levels.",4
Adaptive Antisynchronization of Multilayer Reaction-Diffusion Neural Networks.,"In this paper, an antisynchronization problem is considered for an array of linearly coupled reaction-diffusion neural networks with cooperative-competitive interactions and time-varying coupling delays. The interaction topology among the neural nodes is modeled by a multilayer signed graph. The state evolution of a neuron in each layer of the coupled neural network is described by a reaction-diffusion equation (RDE) with Dirichlet boundary conditions. Then, the collective dynamics of the multilayer neural network are modeled by coupled RDEs with both spatial diffusion coupling and state coupling. An edge-based adaptive antisynchronization strategy is proposed for each neural node to achieve antisynchronization by using only local information of neighboring nodes. Furthermore, when the activation functions of the neural nodes are unknown, a linearly parameterized adaptive antisynchronization strategy is also proposed. The convergence of the antisynchronization errors of the nodes is analyzed by using a Lyapunov-Krasovskii functional method and a structural balance condition. Finally, some numerical simulations are presented to demonstrate the effectiveness of the proposed antisynchronization strategies.",4
Robust Estimation for Neural Networks With Randomly Occurring Distributed Delays and Markovian Jump Coupling.,"This paper studies the issue of robust state estimation for coupled neural networks with parameter uncertainty and randomly occurring distributed delays, where the polytopic model is employed to describe the parameter uncertainty. A set of Bernoulli processes with different stochastic properties are introduced to model the randomly occurrences of the distributed delays. Novel state estimators based on the local coupling structure are proposed to make full use of the coupling information. The augmented estimation error system is obtained based on the Kronecker product. A new Lyapunov function, which depends both on the polytopic uncertainty and the coupling information, is introduced to reduce the conservatism. Sufficient conditions, which guarantee the stochastic stability and the performance of the augmented estimation error system, are established. Then, the estimator gains are further obtained on the basis of these conditions. Finally, a numerical example is used to prove the effectiveness of the results.",4
Integral Sliding Mode Fault-Tolerant Control for Uncertain Linear Systems Over Networks With Signals Quantization.,"In this paper, a new robust fault-tolerant compensation control method for uncertain linear systems over networks is proposed, where only quantized signals are assumed to be available. This approach is based on the integral sliding mode (ISM) method where two kinds of integral sliding surfaces are constructed. One is the continuous-state-dependent surface with the aim of sliding mode stability analysis and the other is the quantization-state-dependent surface, which is used for ISM controller design. A scheme that combines the adaptive ISM controller and quantization parameter adjustment strategy is then proposed. Through utilizing Hinfinity control analytical technique, once the system is in the sliding mode, the nature of performing disturbance attenuation and fault tolerance from the initial time can be found without requiring any fault information. Finally, the effectiveness of our proposed ISM control fault-tolerant schemes against quantization errors is demonstrated in the simulation.",4
Binary Set Embedding for Cross-Modal Retrieval.,"Cross-modal retrieval is such a challenging topic that traditional global representations would fail to bridge the semantic gap between images and texts to a satisfactory level. Using local features from images and words from documents directly can be more robust for the scenario with large intraclass variations and small interclass discrepancies. In this paper, we propose a novel unsupervised binary coding algorithm called binary set embedding (BSE) to obtain meaningful hash codes for local features from the image domain and words from text domain. Understanding image features with the word vectors learned from the human language instead of the provided documents from data sets, BSE can map samples into a common Hamming space effectively and efficiently where each sample is represented by the sets of local feature descriptors from image and text domains. In particular, BSE explores relationship among local features in both feature level and image (text) level, which can balance the sensitivity of each other. Furthermore, a recursive orthogonalization procedure is applied to reduce the redundancy of codes. Extensive experiments demonstrate the superior performance of BSE compared with state-of-the-art cross-modal hashing methods using either image or text queries.",4
Adaptive Exponential Synchronization of Multislave Time-Delayed Recurrent Neural Networks With Levy Noise and Regime Switching.,"This paper discusses the problem of adaptive exponential synchronization in mean square for a new neural network model with the following features: 1) the noise is characterized by the Levy process and the parameters of the model change in line with the Markovian process; 2) the master system is also disturbed by the same Levy noise; and 3) there are multiple slave systems, and the state matrix of each slave system is an affine function of the state matrices of all slave systems. Based on the Lyapunov functional theory, the generalized Ito's formula, -matrix method, and the adaptive control technique, some criteria are established to ensure the adaptive exponential synchronization in the mean square of the master system and each slave system. Moreover, the update law of the control gain and the dynamic variation of the parameters of the slave systems are provided. Finally, the effectiveness of the synchronization criteria proposed in this paper is verified by a practical example.",4
Airline Passenger Profiling Based on Fuzzy Deep Machine Learning.,"Passenger profiling plays a vital part of commercial aviation security, but classical methods become very inefficient in handling the rapidly increasing amounts of electronic records. This paper proposes a deep learning approach to passenger profiling. The center of our approach is a Pythagorean fuzzy deep Boltzmann machine (PFDBM), whose parameters are expressed by Pythagorean fuzzy numbers such that each neuron can learn how a feature affects the production of the correct output from both the positive and negative sides. We propose a hybrid algorithm combining a gradient-based method and an evolutionary algorithm for training the PFDBM. Based on the novel learning model, we develop a deep neural network (DNN) for classifying normal passengers and potential attackers, and further develop an integrated DNN for identifying group attackers whose individual features are insufficient to reveal the abnormality. Experiments on data sets from Air China show that our approach provides much higher learning ability and classification accuracy than existing profilers. It is expected that the fuzzy deep learning approach can be adapted for a variety of complex pattern analysis tasks.",4
Joint Sparse Representation and Embedding Propagation Learning: A Framework for Graph-Based Semisupervised Learning.,"In this paper, we propose a novel graph-based semisupervised learning framework, called joint sparse representation and embedding propagation learning (JSREPL). The idea of JSREPL is to join EPL with sparse representation to perform label propagation. Like most of graph-based semisupervised propagation learning algorithms, JSREPL also constructs weights graph matrix from given data. Different from classical approaches which build weights graph matrix and estimate the labels of unlabeled data in sequence, JSREPL simultaneously builds weights graph matrix and estimates the labels of unlabeled data. We also propose an efficient algorithm to solve the proposed problem. The proposed method is applied to the problem of semisupervised image clustering using the ORL, Yale, PIE, and YaleB data sets. Our experiments demonstrate the effectiveness of our proposed algorithm.",4
Finite-Time Stability Analysis for Markovian Jump Memristive Neural Networks With Partly Unknown Transition Probabilities.,"This paper is concerned with the finite-time stochastically stability (FTSS) analysis of Markovian jump memristive neural networks with partly unknown transition probabilities. In the neural networks, there exist a group of modes determined by Markov chain, and thus, the Markovian jump was taken into consideration and the concept of FTSS is first introduced for the memristive model. By introducing a Markov switching Lyapunov functional and stochastic analysis theory, an FTSS test procedure is proposed, from which we can conclude that the settling time function is a stochastic variable and its expectation is finite. The system under consideration is quite general since it contains completely known and completely unknown transition probabilities as two special cases. More importantly, a nonlinear measure method was introduced to verify the uniqueness of the equilibrium point; compared with the fixed point Theorem that has been widely used in the existing results, this method is more easy to implement. Besides, the delay interval was divided into four subintervals, which make full use of the information of the subsystems upper bounds of the time-varying delays. Finally, the effectiveness and superiority of the proposed method is demonstrated by two simulation examples.",4
One-Class Classifiers Based on Entropic Spanning Graphs.,"One-class classifiers offer valuable tools to assess the presence of outliers in data. In this paper, we propose a design methodology for one-class classifiers based on entropic spanning graphs. Our approach also takes into account the possibility to process nonnumeric data by means of an embedding procedure. The spanning graph is learned on the embedded input data, and the outcoming partition of vertices defines the classifier. The final partition is derived by exploiting a criterion based on mutual information minimization. Here, we compute the mutual information by using a convenient formulation provided in terms of the -Jensen difference. Once training is completed, in order to associate a confidence level with the classifier decision, a graph-based fuzzy model is constructed. The fuzzification process is based only on topological information of the vertices of the entropic spanning graph. As such, the proposed one-class classifier is suitable also for data characterized by complex geometric structures. We provide experiments on well-known benchmarks containing both feature vectors and labeled graphs. In addition, we apply the method to the protein solubility recognition problem by considering several representations for the input samples. Experimental results demonstrate the effectiveness and versatility of the proposed method with respect to other state-of-the-art approaches.",4
Cluster Validation Method for Determining the Number of Clusters in Categorical Sequences.,"Cluster validation, which is the process of evaluating the quality of clustering results, plays an important role for practical machine learning systems. Categorical sequences, such as biological sequences in computational biology, have become common in real-world applications. Different from previous studies, which mainly focused on attribute-value data, in this paper, we work on the cluster validation problem for categorical sequences. The evaluation of sequences clustering is currently difficult due to the lack of an internal validation criterion defined with regard to the structural features hidden in sequences. To solve this problem, in this paper, a novel cluster validity index (CVI) is proposed as a function of clustering, with the intracluster structural compactness and intercluster structural separation linearly combined to measure the quality of sequence clusters. A partition-based algorithm for robust clustering of categorical sequences is also proposed, which provides the new measure with high-quality clustering results by the deterministic initialization and the elimination of noise clusters using an information theoretic method. The new clustering algorithm and the CVI are then assembled within the common model selection procedure to determine the number of clusters in categorical sequence sets. A case study on commonly used protein sequences and the experimental results on some real-world sequence sets from different domains are given to demonstrate the performance of the proposed method.",4
Investigating Echo-State Networks Dynamics by Means of Recurrence Analysis.,"In this paper, we elaborate over the well-known interpretability issue in echo-state networks (ESNs). The idea is to investigate the dynamics of reservoir neurons with time-series analysis techniques developed in complex systems research. Notably, we analyze time series of neuron activations with recurrence plots (RPs) and recurrence quantification analysis (RQA), which permit to visualize and characterize high-dimensional dynamical systems. We show that this approach is useful in a number of ways. First, the 2-D representation offered by RPs provides a visualization of the high-dimensional reservoir dynamics. Our results suggest that, if the network is stable, reservoir and input generate similar line patterns in the respective RPs. Conversely, as the ESN becomes unstable, the patterns in the RP of the reservoir change. As a second result, we show that an RQA measure, called , is highly correlated with the well-established maximal local Lyapunov exponent. This suggests that complexity measures based on RP diagonal lines distribution can quantify network stability. Finally, our analysis shows that all RQA measures fluctuate on the proximity of the so-called edge of stability, where an ESN typically achieves maximum computational capability. We leverage on this property to determine the edge of stability and show that our criterion is more accurate than two well-known counterparts, both based on the Jacobian matrix of the reservoir. Therefore, we claim that RPs and RQA-based analyses are valuable tools to design an ESN, given a specific problem.",4
CLAss-Specific Subspace Kernel Representations and Adaptive Margin Slack Minimization for Large Scale Classification.,"In kernel-based classification models, given limited computational power and storage capacity, operations over the full kernel matrix becomes prohibitive. In this paper, we propose a new supervised learning framework using kernel models for sequential data processing. The framework is based on two components that both aim at enhancing the classification capability with a subset selection scheme. The first part is a subspace projection technique in the reproducing kernel Hilbert space using a CLAss-specific Subspace Kernel representation for kernel approximation. In the second part, we propose a novel structural risk minimization algorithm called the adaptive margin slack minimization to iteratively improve the classification accuracy by an adaptive data selection. We motivate each part separately, and then integrate them into learning frameworks for large scale data. We propose two such frameworks: the memory efficient sequential processing for sequential data processing and the parallelized sequential processing for distributed computing with sequential data acquisition. We test our methods on several benchmark data sets and compared with the state-of-the-art techniques to verify the validity of the proposed techniques.",4
Comparative Performance of Complex-Valued B-Spline and Polynomial Models Applied to Iterative Frequency-Domain Decision Feedback Equalization of Hammerstein Channels.,"Complex-valued (CV) B-spline neural network approach offers a highly effective means for identifying and inverting practical Hammerstein systems. Compared with its conventional CV polynomial-based counterpart, a CV B-spline neural network has superior performance in identifying and inverting CV Hammerstein systems, while imposing a similar complexity. This paper reviews the optimality of the CV B-spline neural network approach. Advantages of B-spline neural network approach as compared with the polynomial based modeling approach are extensively discussed, and the effectiveness of the CV neural network-based approach is demonstrated in a real-world application. More specifically, we evaluate the comparative performance of the CV B-spline and polynomial-based approaches for the nonlinear iterative frequency-domain decision feedback equalization (NIFDDFE) of single-carrier Hammerstein channels. Our results confirm the superior performance of the CV B-spline-based NIFDDFE over its CV polynomial-based counterpart.",4
Synchronization of Hierarchical Time-Varying Neural Networks Based on Asynchronous and Intermittent Sampled-Data Control.,"In this brief, our purpose is to apply asynchronous and intermittent sampled-data control methods to achieve the synchronization of hierarchical time-varying neural networks. The asynchronous and intermittent sampled-data controllers are proposed for two reasons: 1) the controllers may not transmit the control information simultaneously and 2) the controllers cannot always exist at any time . The synchronization is then discussed for a kind of hierarchical time-varying neural networks based on the asynchronous and intermittent sampled-data controllers. Finally, the simulation results are given to illustrate the usefulness of the developed criteria.In this brief, our purpose is to apply asynchronous and intermittent sampled-data control methods to achieve the synchronization of hierarchical time-varying neural networks. The asynchronous and intermittent sampled-data controllers are proposed for two reasons: 1) the controllers may not transmit the control information simultaneously and 2) the controllers cannot always exist at any time . The synchronization is then discussed for a kind of hierarchical time-varying neural networks based on the asynchronous and intermittent sampled-data controllers. Finally, the simulation results are given to illustrate the usefulness of the developed criteria.",4
A pdf-Free Change Detection Test Based on Density Difference Estimation.,"The ability to detect online changes in stationarity or time variance in a data stream is a hot research topic with striking implications. In this paper, we propose a novel probability density function-free change detection test, which is based on the least squares density-difference estimation method and operates online on multidimensional inputs. The test does not require any assumption about the underlying data distribution, and is able to operate immediately after having been configured by adopting a reservoir sampling mechanism. Thresholds requested to detect a change are automatically derived once a false positive rate is set by the application designer. Comprehensive experiments validate the effectiveness in detection of the proposed method both in terms of detection promptness and accuracy.",4
State Estimation for Delayed Genetic Regulatory Networks With Reaction-Diffusion Terms.,"This paper addresses the problem of state estimation for delayed genetic regulatory networks (DGRNs) with reaction-diffusion terms using Dirichlet boundary conditions. The nonlinear regulation function of DGRNs is assumed to exhibit the Hill form. The aim of this paper is to design a state observer to estimate the concentrations of mRNAs and proteins via available measurement techniques. By introducing novel integral terms into the Lyapunov-Krasovskii functional and by employing the Wirtinger-type integral inequality, the convex approach, Green's identity, the reciprocally convex approach, and Wirtinger's inequality, an asymptotic stability criterion of the error system was established in terms of linear matrix inequalities (LMIs). The stability criterion depends upon the bounds of delays and their derivatives. It should be noted that if the set of LMIs is feasible, then the desired observation of DGRNs is possible, and the state estimation can be determined. Finally, two numerical examples are presented to illustrate the availability and applicability of the proposed scheme design.",4
Incomplete Multisource Transfer Learning.,"Transfer learning is generally exploited to adapt well-established source knowledge for learning tasks in weakly labeled or unlabeled target domain. Nowadays, it is common to see multiple sources available for knowledge transfer, each of which, however, may not include complete classes information of the target domain. Naively merging multiple sources together would lead to inferior results due to the large divergence among multiple sources. In this paper, we attempt to utilize incomplete multiple sources for effective knowledge transfer to facilitate the learning task in target domain. To this end, we propose an incomplete multisource transfer learning through two directional knowledge transfer, i.e., cross-domain transfer from each source to target, and cross-source transfer. In particular, in cross-domain direction, we deploy latent low-rank transfer learning guided by iterative structure learning to transfer knowledge from each single source to target domain. This practice reinforces to compensate for any missing data in each source by the complete target data. While in cross-source direction, unsupervised manifold regularizer and effective multisource alignment are explored to jointly compensate for missing data from one portion of source to another. In this way, both marginal and conditional distribution discrepancy in two directions would be mitigated. Experimental results on standard cross-domain benchmarks and synthetic data sets demonstrate the effectiveness of our proposed model in knowledge transfer from incomplete multiple sources.",4
Cluster Synchronization on Multiple Nonlinearly Coupled Dynamical Subnetworks of Complex Networks With Nonidentical Nodes.,"In this paper, cluster synchronization on multiple nonlinearly coupled dynamical subnetworks of complex networks with nonidentical nodes and stochastic perturbations is studied. Based on the general leader-follower's model, an improved network structure model that consists of multiple pairs of matching subnetworks, each of which includes a leaders' subnetwork and a followers' subnetwork, is proposed. Moreover, the dynamical behaviors of the nodes belonging to the same pair of matching subnetworks are identical, while the ones belonging to different pairs of unmatched subnetworks are nonidentical. In this new setting, the aim is to design some suitable adaptive pinning controllers on the chosen nodes of each followers' subnetwork, such that the nodes in each subnetwork can be exponentially synchronized onto their reference state. Then, some cluster synchronization criteria for multiple nonlinearly coupled dynamical subnetworks of complex networks are established, and a pinning control scheme that the nodes with very large or low degrees are good candidates for applying pinning controllers is presented. Suitable adaptive update laws are used to deal with the unknown feedback gains between the pinned nodes and their leaders. Finally, several numerical simulations are given to demonstrate the effectiveness and applicability of the proposed approach.",4
Batch Mode Active Learning for Regression With Expected Model Change.,"While active learning (AL) has been widely studied for classification problems, limited efforts have been done on AL for regression. In this paper, we introduce a new AL framework for regression, expected model change maximization (EMCM), which aims at choosing the unlabeled data instances that result in the maximum change of the current model once labeled. The model change is quantified as the difference between the current model parameters and the updated parameters after the inclusion of the newly selected examples. In light of the stochastic gradient descent learning rule, we approximate the change as the gradient of the loss function with respect to each single candidate instance. Under the EMCM framework, we propose novel AL algorithms for the linear and nonlinear regression models. In addition, by simulating the behavior of the sequential AL policy when applied for k iterations, we further extend the algorithms to batch mode AL to simultaneously choose a set of k most informative instances at each query time. Extensive experimental results on both UCI and StatLib benchmark data sets have demonstrated that the proposed algorithms are highly effective and efficient.",4
Prediction Reweighting for Domain Adaptation.,"There are plenty of classification methods that perform well when training and testing data are drawn from the same distribution. However, in real applications, this condition may be violated, which causes degradation of classification accuracy. Domain adaptation is an effective approach to address this problem. In this paper, we propose a general domain adaptation framework from the perspective of prediction reweighting, from which a novel approach is derived. Different from the major domain adaptation methods, our idea is to reweight predictions of the training classifier on testing data according to their signed distance to the domain separator, which is a classifier that distinguishes training data (from source domain) and testing data (from target domain). We then propagate the labels of target instances with larger weights to ones with smaller weights by introducing a manifold regularization method. It can be proved that our reweighting scheme effectively brings the source and target domains closer to each other in an appropriate sense, such that classification in target domain becomes easier. The proposed method can be implemented efficiently by a simple two-stage algorithm, and the target classifier has a closed-form solution. The effectiveness of our approach is verified by the experiments on artificial datasets and two standard benchmarks, a visual object recognition task and a cross-domain sentiment analysis of text. Experimental results demonstrate that our method is competitive with the state-of-the-art domain adaptation algorithms.",4
Quantum Ensemble Classification: A Sampling-Based Learning Control Approach.,"Quantum ensemble classification (QEC) has significant applications in discrimination of atoms (or molecules), separation of isotopes, and quantum information extraction. However, quantum mechanics forbids deterministic discrimination among nonorthogonal states. The classification of inhomogeneous quantum ensembles is very challenging, since there exist variations in the parameters characterizing the members within different classes. In this paper, we recast QEC as a supervised quantum learning problem. A systematic classification methodology is presented by using a sampling-based learning control (SLC) approach for quantum discrimination. The classification task is accomplished via simultaneously steering members belonging to different classes to their corresponding target states (e.g., mutually orthogonal states). First, a new discrimination method is proposed for two similar quantum systems. Then, an SLC method is presented for QEC. Numerical results demonstrate the effectiveness of the proposed approach for the binary classification of two-level quantum ensembles and the multiclass classification of multilevel quantum ensembles.",4
A Telescopic Binary Learning Machine for Training Neural Networks.,"This paper proposes a new algorithm based on multiscale stochastic local search with binary representation for training neural networks [binary learning machine (BLM)]. We study the effects of neighborhood evaluation strategies, the effect of the number of bits per weight and that of the maximum weight range used for mapping binary strings to real values. Following this preliminary investigation, we propose a telescopic multiscale version of local search, where the number of bits is increased in an adaptive manner, leading to a faster search and to local minima of better quality. An analysis related to adapting the number of bits in a dynamic way is presented. The control on the number of bits, which happens in a natural manner in the proposed method, is effective to increase the generalization performance. The learning dynamics are discussed and validated on a highly nonlinear artificial problem and on real-world tasks in many application domains; BLM is finally applied to a problem requiring either feedforward or recurrent architectures for feedback control.",4
Bag of Events: An Efficient Probability-Based Feature Extraction Method for AER Image Sensors.,"Address event representation (AER) image sensors represent the visual information as a sequence of events that denotes the luminance changes of the scene. In this paper, we introduce a feature extraction method for AER image sensors based on the probability theory, namely, bag of events (BOE). The proposed approach represents each object as the joint probability distribution of the concurrent events, and each event corresponds to a unique activated pixel of the AER sensor. The advantages of BOE include: 1) it is a statistical learning method and has a good interpretability in mathematics; 2) BOE can significantly reduce the effort to tune parameters for different data sets, because it only has one hyperparameter and is robust to the value of the parameter; 3) BOE is an online learning algorithm, which does not require the training data to be collected in advance; 4) BOE can achieve competitive results in real time for feature extraction (>275 frames/s and >120,000 events/s); and 5) the implementation complexity of BOE only involves some basic operations, e.g., addition and multiplication. This guarantees the hardware friendliness of our method. The experimental results on three popular AER databases (i.e., MNIST-dynamic vision sensor, Poker Card, and Posture) show that our method is remarkably faster than two recently proposed AER categorization systems while preserving a good classification accuracy.",4
Co-Operative Coevolutionary Neural Networks for Mining Functional Association Rules.,"In this paper, we introduce a novel form of association rules (ARs) that do not require discretization of continuous variables or the use of intervals in either sides of the rule. This rule form captures nonlinear relationships among variables, and provides an alternative pattern representation for mining essential relations hidden in a given data set. We refer to the new rule form as a functional AR (FAR). A new neural network-based, co-operative, coevolutionary algorithm is presented for FAR mining. The algorithm is applied to both synthetic and real-world data sets, and its performance is analyzed. The experimental results show that the proposed mining algorithm is able to discover valid and essential underlying relations in the data. Comparison experiments are also carried out with the two state-of-the-art AR mining algorithms that can handle continuous variables to demonstrate the competitive performance of the proposed method.",4
Design and Application of a Variable Selection Method for Multilayer Perceptron Neural Network With LASSO.,"In this paper, a novel variable selection method for neural network that can be applied to describe nonlinear industrial processes is developed. The proposed method is an iterative two-step approach. First, a multilayer perceptron is constructed. Second, the least absolute shrinkage and selection operator is introduced to select the input variables that are truly essential to the model with the shrinkage parameter is determined using a cross-validation method. Then, variables whose input weights are zero are eliminated from the data set. The algorithm is repeated until there is no improvement in the model accuracy. Simulation examples as well as an industrial application in a crude distillation unit are used to validate the proposed algorithm. The results show that the proposed approach can be used to construct a more compressed model, which incorporates a higher level of prediction accuracy than other existing methods.",4
Clustering Through Hybrid Network Architecture With Support Vectors.,"In this paper, we propose a clustering algorithm based on a two-phased neural network architecture. We combine the strength of an autoencoderlike network for unsupervised representation learning with the discriminative power of a support vector machine (SVM) network for fine-tuning the initial clusters. The first network is referred as prototype encoding network, where the data reconstruction error is minimized in an unsupervised manner. The second phase, i.e., SVM network, endeavors to maximize the margin between cluster boundaries in a supervised way making use of the first output. Both the networks update the cluster centroids successively by establishing a topology preserving scheme like self-organizing map on the latent space of each network. Cluster fine-tuning is accomplished in a network structure by the alternate usage of the encoding part of both the networks. In the experiments, challenging data sets from two popular repositories with different patterns, dimensionality, and the number of clusters are used. The proposed hybrid architecture achieves comparatively better results both visually and analytically than the previous neural network-based approaches available in the literature.",4
Efficient Training of Supervised Spiking Neural Network via Accurate Synaptic-Efficiency Adjustment Method.,"The spiking neural network (SNN) is the third generation of neural networks and performs remarkably well in cognitive tasks, such as pattern recognition. The temporal neural encode mechanism found in biological hippocampus enables SNN to possess more powerful computation capability than networks with other encoding schemes. However, this temporal encoding approach requires neurons to process information serially on time, which reduces learning efficiency significantly. To keep the powerful computation capability of the temporal encoding mechanism and to overcome its low efficiency in the training of SNNs, a new training algorithm, the accurate synaptic-efficiency adjustment method is proposed in this paper. Inspired by the selective attention mechanism of the primate visual system, our algorithm selects only the target spike time as attention areas, and ignores voltage states of the untarget ones, resulting in a significant reduction of training time. Besides, our algorithm employs a cost function based on the voltage difference between the potential of the output neuron and the firing threshold of the SNN, instead of the traditional precise firing time distance. A normalized spike-timing-dependent-plasticity learning window is applied to assigning this error to different synapses for instructing their training. Comprehensive simulations are conducted to investigate the learning properties of our algorithm, with input neurons emitting both single spike and multiple spikes. Simulation results indicate that our algorithm possesses higher learning performance than the existing other methods and achieves the state-of-the-art efficiency in the training of SNN.",4
A Regularizer Approach for RBF Networks Under the Concurrent Weight Failure Situation.,"Many existing results on fault-tolerant algorithms focus on the single fault source situation, where a trained network is affected by one kind of weight failure. In fact, a trained network may be affected by multiple kinds of weight failure. This paper first studies how the open weight fault and the multiplicative weight noise degrade the performance of radial basis function (RBF) networks. Afterward, we define the objective function for training fault-tolerant RBF networks. Based on the objective function, we then develop two learning algorithms, one batch mode and one online mode. Besides, the convergent conditions of our online algorithm are investigated. Finally, we develop a formula to estimate the test set error of faulty networks trained from our approach. This formula helps us to optimize some tuning parameters, such as RBF width.",4
Biomimetic Hybrid Feedback Feedforward Neural-Network Learning Control.,"This brief presents a biomimetic hybrid feedback feedforward neural-network learning control (NNLC) strategy inspired by the human motor learning control mechanism for a class of uncertain nonlinear systems. The control structure includes a proportional-derivative controller acting as a feedback servo machine and a radial-basis-function (RBF) NN acting as a feedforward predictive machine. Under the sufficient constraints on control parameters, the closed-loop system achieves semiglobal practical exponential stability, such that an accurate NN approximation is guaranteed in a local region along recurrent reference trajectories. Compared with the existing NNLC methods, the novelties of the proposed method include: 1) the implementation of an adaptive NN control to guarantee plant states being recurrent is not needed, since recurrent reference signals rather than plant states are utilized as NN inputs, which greatly simplifies the analysis and synthesis of the NNLC and 2) the domain of NN approximation can be determined a priori by the given reference signals, which leads to an easy construction of the RBF-NNs. Simulation results have verified the effectiveness of this approach.",4
Fraction Dynamic-Surface-Based Neuroadaptive Finite-Time Containment Control of Multiagent Systems in Nonaffine Pure-Feedback Form.,"In this paper, the problem of containment control of networked multiagent systems is considered with special emphasis on finite-time convergence. A distributed neural adaptive control scheme for containment is developed, which, different from the current state of the art, is able to achieve dynamic containment in finite time with sufficient accuracy despite unknown nonaffine dynamics and mismatched uncertainties. Such a finite-time feature, highly desirable in practice, is made possible by the fraction dynamic surface control design technique based on the concept of virtual fraction filter. In the proposed containment protocol, only the local information from the neighbor followers and the local position information from the neighbor leaders are required. Furthermore, since the available information utilized is local and is embedded into the control scheme through fraction power feedback, rather than direct linear or regular nonlinear feedback, the resultant control scheme is truly distributed. In addition, although mismatched uncertainties and external disturbances are involved, only one single generalized neural parameter needs to be updated in the control scheme, making its design and implementation straightforward and inexpensive. The effectiveness of the developed method is also confirmed by numerical simulation.",4
Robustly Fitting and Forecasting Dynamical Data With Electromagnetically Coupled Artificial Neural Network: A Data Compression Method.,"In this paper, a dynamical recurrent artificial neural network (ANN) is proposed and studied. Inspired from a recent research in neuroscience, we introduced nonsynaptic coupling to form a dynamical component of the network. We mathematically proved that, with adequate neurons provided, this dynamical ANN model is capable of approximating any continuous dynamic system with an arbitrarily small error in a limited time interval. Its extreme concise Jacobian matrix makes the local stability easy to control. We designed this ANN for fitting and forecasting dynamic data and obtained satisfied results in simulation. The fitting performance is also compared with those of both the classic dynamic ANN and the state-of-the-art models. Sufficient trials and the statistical results indicated that our model is superior to those have been compared. Moreover, we proposed a robust approximation problem, which asking the ANN to approximate a cluster of input-output data pairs in large ranges and to forecast the output of the system under previously unseen input. Our model and learning scheme proposed in this paper have successfully solved this problem, and through this, the approximation becomes much more robust and adaptive to noise, perturbation, and low-order harmonic wave. This approach is actually an efficient method for compressing massive external data of a dynamic system into the weight of the ANN.",4
An Adaptive-PSO-Based Self-Organizing RBF Neural Network.,"In this paper, a self-organizing radial basis function (SORBF) neural network is designed to improve both accuracy and parsimony with the aid of adaptive particle swarm optimization (APSO). In the proposed APSO algorithm, to avoid being trapped into local optimal values, a nonlinear regressive function is developed to adjust the inertia weight. Furthermore, the APSO algorithm can optimize both the network size and the parameters of an RBF neural network simultaneously. As a result, the proposed APSO-SORBF neural network can effectively generate a network model with a compact structure and high accuracy. Moreover, the analysis of convergence is given to guarantee the successful application of the APSO-SORBF neural network. Finally, multiple numerical examples are presented to illustrate the effectiveness of the proposed APSO-SORBF neural network. The results demonstrate that the proposed method is more competitive in solving nonlinear problems than some other existing SORBF neural networks.",4
In Defense of Locality-Sensitive Hashing.,"Hashing-based semantic similarity search is becoming increasingly important for building large-scale content-based retrieval system. The state-of-the-art supervised hashing techniques use flexible two-step strategy to learn hash functions. The first step learns binary codes for training data by solving binary optimization problems with millions of variables, thus usually requiring intensive computations. Despite simplicity and efficiency, locality-sensitive hashing (LSH) has never been recognized as a good way to generate such codes due to its poor performance in traditional approximate neighbor search. We claim in this paper that the true merit of LSH lies in transforming the semantic labels to obtain the binary codes, resulting in an effective and efficient two-step hashing framework. Specifically, we developed the locality-sensitive two-step hashing (LS-TSH) that generates the binary codes through LSH rather than any complex optimization technique. Theoretically, with proper assumption, LS-TSH is actually a useful LSH scheme, so that it preserves the label-based semantic similarity and possesses sublinear query complexity for hash lookup. Experimentally, LS-TSH could obtain comparable retrieval accuracy with state of the arts with two to three orders of magnitudes faster training speed.",4
Nonfragile Exponential Synchronization of Delayed Complex Dynamical Networks With Memory Sampled-Data Control.,"This paper considers nonfragile exponential synchronization for complex dynamical networks (CDNs) with time-varying coupling delay. The sampled-data feedback control, which is assumed to allow norm-bounded uncertainty and involves a constant signal transmission delay, is constructed for the first time in this paper. By constructing a suitable augmented Lyapunov function, and with the help of introduced integral inequalities and employing the convex combination technique, a sufficient condition is developed, such that the nonfragile exponential stability of the error system is guaranteed. As a result, for the case of sampled-data control free of norm-bound uncertainties, some sufficient conditions of sampled-data synchronization criteria for the CDNs with time-varying coupling delay are presented. As the formulations are in the framework of linear matrix inequality, these conditions can be easily solved and implemented. Two illustrative examples are presented to demonstrate the effectiveness and merits of the proposed feedback control.",4
Shrinkage Degree in $L_{2}$ -Rescale Boosting for Regression.,"L2 -rescale boosting ( L2 -RBoosting) is a variant of L2 -Boosting, which can essentially improve the generalization performance of L2 -Boosting. The key feature of L2 -RBoosting lies in introducing a shrinkage degree to rescale the ensemble estimate in each iteration. Thus, the shrinkage degree determines the performance of L2 -RBoosting. The aim of this paper is to develop a concrete analysis concerning how to determine the shrinkage degree in L2 -RBoosting. We propose two feasible ways to select the shrinkage degree. The first one is to parameterize the shrinkage degree and the other one is to develop a data-driven approach. After rigorously analyzing the importance of the shrinkage degree in L2 -RBoosting, we compare the pros and cons of the proposed methods. We find that although these approaches can reach the same learning rates, the structure of the final estimator of the parameterized approach is better, which sometimes yields a better generalization capability when the number of sample is finite. With this, we recommend to parameterize the shrinkage degree of L2 -RBoosting. We also present an adaptive parameter-selection strategy for shrinkage degree and verify its feasibility through both theoretical analysis and numerical verification. The obtained results enhance the understanding of L2 -RBoosting and give guidance on how to use it for regression tasks.",4
Probe Machine.,"In this paper, we present a novel computing model, called probe machine (PM). Unlike the turing machine (TM), PM is a fully parallel computing model in the sense that it can simultaneously process multiple pairs of data, rather than sequentially process every pair of linearly adjacent data. We establish the mathematical model of PM as a nine-tuple consisting of data library, probe library, data controller, probe controller, probe operation, computing platform, detector, true solution storage, and residue collector. We analyze the computation capability of the PM model, and in particular, we show that TM is a special case of PM. We revisit two NP-complete problems, i.e., the graph coloring and Hamilton cycle problems, and devise two algorithms on basis of the established PM model, which can enumerate all solutions to each of these problems by only one probe operation. Furthermore, we show that PM can be implemented by leveraging the nano-DNA probe technologies. The computational power of an electronic computer based on TM is known far more than that of the human brain. A question naturally arises: will a future computer based on PM outperform the human brain in more ways beyond the computational power?",4
Stability of Markovian Jump Generalized Neural Networks With Interval Time-Varying Delays.,"This paper examines the problem of asymptotic stability for Markovian jump generalized neural networks with interval time-varying delays. Markovian jump parameters are modeled as a continuous-time and finite-state Markov chain. By constructing a suitable Lyapunov-Krasovskii functional (LKF) and using the linear matrix inequality (LMI) formulation, new delay-dependent stability conditions are established to ascertain the mean-square asymptotic stability result of the equilibrium point. The reciprocally convex combination technique, Jensen's inequality, and the Wirtinger-based double integral inequality are used to handle single and double integral terms in the time derivative of the LKF. The developed results are represented by the LMI. The effectiveness and advantages of the new design method are explained using five numerical examples.",4
Riemannian Dictionary Learning and Sparse Coding for Positive Definite Matrices.,"Data encoded as symmetric positive definite (SPD) matrices frequently arise in many areas of computer vision and machine learning. While these matrices form an open subset of the Euclidean space of symmetric matrices, viewing them through the lens of non-Euclidean Riemannian (Riem) geometry often turns out to be better suited in capturing several desirable data properties. Inspired by the great success of dictionary learning and sparse coding (DLSC) for vector-valued data, our goal in this paper is to represent data in the form of SPD matrices as sparse conic combinations of SPD atoms from a learned dictionary via a Riem geometric approach. To that end, we formulate a novel Riem optimization objective for DLSC, in which the representation loss is characterized via the affine-invariant Riem metric. We also present a computationally simple algorithm for optimizing our model. Experiments on several computer vision data sets demonstrate superior classification and retrieval performance using our approach when compared with SC via alternative non-Riem formulations.",4
"Greedy Methods, Randomization Approaches, and Multiarm Bandit Algorithms for Efficient Sparsity-Constrained Optimization.","Several sparsity-constrained algorithms, such as orthogonal matching pursuit (OMP) or the Frank-Wolfe (FW) algorithm, with sparsity constraints work by iteratively selecting a novel atom to add to the current nonzero set of variables. This selection step is usually performed by computing the gradient and then by looking for the gradient component with maximal absolute entry. This step can be computationally expensive especially for large-scale and high-dimensional data. In this paper, we aim at accelerating these sparsity-constrained optimization algorithms by exploiting the key observation that, for these algorithms to work, one only needs the coordinate of the gradient's top entry. Hence, we introduce algorithms based on greedy methods and randomization approaches that aim at cheaply estimating the gradient and its top entry. Another of our contribution is to cast the problem of finding the best gradient entry as a best-arm identification in a multiarmed bandit problem. Owing to this novel insight, we are able to provide a bandit-based algorithm that directly estimates the top entry in a very efficient way. Theoretical observations stating that the resulting inexact FW or OMP algorithms act, with high probability, similar to their exact versions are also given. We have carried out several experiments showing that the greedy deterministic and the bandit approaches we propose can achieve an acceleration of an order of magnitude while being as efficient as the exact gradient when used in algorithms, such as OMP, FW, or CoSaMP.",4
Sampled-Data Synchronization of Markovian Coupled Neural Networks With Mode Delays Based on Mode-Dependent LKF.,"This paper investigates sampled-data synchronization problem of Markovian coupled neural networks with mode-dependent interval time-varying delays and aperiodic sampling intervals based on an enhanced input delay approach. A mode-dependent augmented Lyapunov-Krasovskii functional (LKF) is utilized, which makes the LKF matrices mode-dependent as much as possible. By applying an extended Jensen's integral inequality and Wirtinger's inequality, new delay-dependent synchronization criteria are obtained, which fully utilizes the upper bound on variable sampling interval and the sawtooth structure information of varying input delay. In addition, the desired stochastic sampled-data controllers can be obtained by solving a set of linear matrix inequalities. Finally, two examples are provided to demonstrate the feasibility of the proposed method.This paper investigates sampled-data synchronization problem of Markovian coupled neural networks with mode-dependent interval time-varying delays and aperiodic sampling intervals based on an enhanced input delay approach. A mode-dependent augmented Lyapunov-Krasovskii functional (LKF) is utilized, which makes the LKF matrices mode-dependent as much as possible. By applying an extended Jensen's integral inequality and Wirtinger's inequality, new delay-dependent synchronization criteria are obtained, which fully utilizes the upper bound on variable sampling interval and the sawtooth structure information of varying input delay. In addition, the desired stochastic sampled-data controllers can be obtained by solving a set of linear matrix inequalities. Finally, two examples are provided to demonstrate the feasibility of the proposed method.",4
Discontinuous Observers Design for Finite-Time Consensus of Multiagent Systems With External Disturbances.,"This brief investigates the problem of finite-time robust consensus (FTRC) for second-order nonlinear multiagent systems with external disturbances. Based on the global finite-time stability theory of discontinuous homogeneous systems, a novel finite-time convergent discontinuous disturbed observer (DDO) is proposed for the leader-following multiagent systems. The states of the designed DDO are then used to design the control inputs to achieve the FTRC of nonlinear multiagent systems in the presence of bounded disturbances. The simulation results are provided to validate the effectiveness of these theoretical results.This brief investigates the problem of finite-time robust consensus (FTRC) for second-order nonlinear multiagent systems with external disturbances. Based on the global finite-time stability theory of discontinuous homogeneous systems, a novel finite-time convergent discontinuous disturbed observer (DDO) is proposed for the leader-following multiagent systems. The states of the designed DDO are then used to design the control inputs to achieve the FTRC of nonlinear multiagent systems in the presence of bounded disturbances. The simulation results are provided to validate the effectiveness of these theoretical results.",4
Backstepping Design of Adaptive Neural Fault-Tolerant Control for MIMO Nonlinear Systems.,"In this paper, an adaptive controller is developed for a class of multi-input and multioutput nonlinear systems with neural networks (NNs) used as a modeling tool. It is shown that all the signals in the closed-loop system with the proposed adaptive neural controller are globally uniformly bounded for any external input in . In our control design, the upper bound of the NN modeling error and the gains of external disturbance are characterized by unknown upper bounds, which is more rational to establish the stability in the adaptive NN control. Filter-based modification terms are used in the update laws of unknown parameters to improve the transient performance. Finally, fault-tolerant control is developed to accommodate actuator failure. An illustrative example applying the adaptive controller to control a rigid robot arm shows the validation of the proposed controller.In this paper, an adaptive controller is developed for a class of multi-input and multioutput nonlinear systems with neural networks (NNs) used as a modeling tool. It is shown that all the signals in the closed-loop system with the proposed adaptive neural controller are globally uniformly bounded for any external input in . In our control design, the upper bound of the NN modeling error and the gains of external disturbance are characterized by unknown upper bounds, which is more rational to establish the stability in the adaptive NN control. Filter-based modification terms are used in the update laws of unknown parameters to improve the transient performance. Finally, fault-tolerant control is developed to accommodate actuator failure. An illustrative example applying the adaptive controller to control a rigid robot arm shows the validation of the proposed controller.",4
A New Result on $H_{\infty }$ State Estimation of Delayed Static Neural Networks.,"This brief presents a new guaranteed performance state estimation criterion for delayed static neural networks. To facilitate the use of the slope information about activation function, the estimation error of activation function is separated into two parts for the first time. Then, a novel Lyapunov-Krasovskii functional (LKF) is constructed, which has fully captured the slope information of the activation. Based on the new LKF, a less conservative design criterion of estimator is derived to ensure the asymptotic stability of estimation error system with performance. The desired estimator gain matrices and the performance index are obtained by solving a convex optimization problem. The simulation results show that the proposed method has much better performance than the most recent results.",4
Quantized Synchronization of Chaotic Neural Networks With Scheduled Output Feedback Control.,"In this paper, the synchronization problem of master-slave chaotic neural networks with remote sensors, quantization process, and communication time delays is investigated. The information communication channel between the master chaotic neural network and slave chaotic neural network consists of several remote sensors, with each sensor able to access only partial knowledge of output information of the master neural network. At each sampling instants, each sensor updates its own measurement and only one sensor is scheduled to transmit its latest information to the controller's side in order to update the control inputs for the slave neural network. Thus, such communication process and control strategy are much more energy-saving comparing with the traditional point-to-point scheme. Sufficient conditions for output feedback control gain matrix, allowable length of sampling intervals, and upper bound of network-induced delays are derived to ensure the quantized synchronization of master-slave chaotic neural networks. Lastly, Chua's circuit system and 4-D Hopfield neural network are simulated to validate the effectiveness of the main results.In this paper, the synchronization problem of master-slave chaotic neural networks with remote sensors, quantization process, and communication time delays is investigated. The information communication channel between the master chaotic neural network and slave chaotic neural network consists of several remote sensors, with each sensor able to access only partial knowledge of output information of the master neural network. At each sampling instants, each sensor updates its own measurement and only one sensor is scheduled to transmit its latest information to the controller's side in order to update the control inputs for the slave neural network. Thus, such communication process and control strategy are much more energy-saving comparing with the traditional point-to-point scheme. Sufficient conditions for output feedback control gain matrix, allowable length of sampling intervals, and upper bound of network-induced delays are derived to ensure the quantized synchronization of master-slave chaotic neural networks. Lastly, Chua's circuit system and 4-D Hopfield neural network are simulated to validate the effectiveness of the main results.",4
A Fast and Efficient Method for Training Categorical Radial Basis Function Networks.,"This brief presents a novel learning scheme for categorical data based on radial basis function (RBF) networks. The proposed approach replaces the numerical vectors known as RBF centers with categorical tuple centers, and employs specially designed measures for calculating the distance between the center and the input tuples. Furthermore, a fast noniterative categorical clustering algorithm is proposed to accomplish the first stage of RBF training involving categorical center selection, whereas the weights are calculated through linear regression. The method is applied on 22 categorical data sets and compared with several different learning schemes, including neural networks, support vector machines, naive Bayes classifier, and decision trees. Results show that the proposed method is very competitive, outperforming its rivals in terms of predictive capabilities in the majority of the tested cases.",4
Efficient Exact Inference With Loss Augmented Objective in Structured Learning.,"Structural support vector machine (SVM) is an elegant approach for building complex and accurate models with structured outputs. However, its applicability relies on the availability of efficient inference algorithms--the state-of-the-art training algorithms repeatedly perform inference to compute a subgradient or to find the most violating configuration. In this paper, we propose an exact inference algorithm for maximizing nondecomposable objectives due to special type of a high-order potential having a decomposable internal structure. As an important application, our method covers the loss augmented inference, which enables the slack and margin scaling formulations of structural SVM with a variety of dissimilarity measures, e.g., Hamming loss, precision and recall, Fbeta-loss, intersection over union, and many other functions that can be efficiently computed from the contingency table. We demonstrate the advantages of our approach in natural language parsing and sequence segmentation applications.",4
Global Sensitivity Estimates for Neural Network Classifiers.,"Artificial neural networks (ANNs) have traditionally been seen as black-box models, because, although they are able to find ``hidden'' relations between inputs and outputs with a high approximation capacity, their structure seldom provides any insights on the structure of the functions being approximated. Several research papers have tried to debunk the black-box nature of ANNs, since it limits the potential use of ANNs in many research areas. This paper is framed in this context and proposes a methodology to determine the individual and collective effects of the input variables on the outputs for classification problems based on the ANOVA-functional decomposition. The method is applied after the training phase of the ANN and allows researchers to rank the input variables according to their importance in the variance of the ANN output. The computation of the sensitivity indices for product unit neural networks is straightforward as those indices can be calculated analytically by evaluating the integrals in the ANOVA decomposition. Unfortunately, the sensitivity indices associated with ANNs based on sigmoidal basis functions or radial basis functions cannot be calculated analytically. In this paper, the indices for those kinds of ANNs are proposed to be estimated by the (quasi-) Monte Carlo method.",4
Dealing With the Issues Crucially Related to the Functionality and Reliability of NN-Associated Control for Nonlinear Uncertain Systems.,"The ""universal"" approximating/learning feature of neural network (NN), widely and extensively used for control design, is contingent upon some critical conditions, either of which, if not satisfied, would render such feature vanished. In this paper, we show that these conditions are literally linked with several fundamental issues that have been overlooked in most existing NN-based control designs, either unconsciously or deliberately. We further propose a collective approach to explicitly address these issues, establishing a strategy enabling the NN unit to be fully functional in the control loop during the entire process of system operation and ensuring the more reliable and more effective NN-associated control performance. This is achieved by incorporating the control with a new structural NN unit, consisting of a group of diversified neurons with self-adjusting subneurons, each being driven/stimulated by input signals confined within a compact set. Meanwhile, the continuity of the control signal and the boundedness of all the closed-loop signals are ensured. Both the theoretical analysis and numerical simulation validate the effectiveness of the proposed method.The ""universal"" approximating/learning feature of neural network (NN), widely and extensively used for control design, is contingent upon some critical conditions, either of which, if not satisfied, would render such feature vanished. In this paper, we show that these conditions are literally linked with several fundamental issues that have been overlooked in most existing NN-based control designs, either unconsciously or deliberately. We further propose a collective approach to explicitly address these issues, establishing a strategy enabling the NN unit to be fully functional in the control loop during the entire process of system operation and ensuring the more reliable and more effective NN-associated control performance. This is achieved by incorporating the control with a new structural NN unit, consisting of a group of diversified neurons with self-adjusting subneurons, each being driven/stimulated by input signals confined within a compact set. Meanwhile, the continuity of the control signal and the boundedness of all the closed-loop signals are ensured. Both the theoretical analysis and numerical simulation validate the effectiveness of the proposed method.",4
Finite-Time Stabilization and Adaptive Control of Memristor-Based Delayed Neural Networks.,"Finite-time stability problem has been a hot topic in control and system engineering. This paper deals with the finite-time stabilization issue of memristor-based delayed neural networks (MDNNs) via two control approaches. First, in order to realize the stabilization of MDNNs in finite time, a delayed state feedback controller is proposed. Then, a novel adaptive strategy is applied to the delayed controller, and finite-time stabilization of MDNNs can also be achieved by using the adaptive control law. Some easily verified algebraic criteria are derived to ensure the stabilization of MDNNs in finite time, and the estimation of the settling time functional is given. Moreover, several finite-time stability results as our special cases for both memristor-based neural networks (MNNs) without delays and neural networks are given. Finally, three examples are provided for the illustration of the theoretical results.Finite-time stability problem has been a hot topic in control and system engineering. This paper deals with the finite-time stabilization issue of memristor-based delayed neural networks (MDNNs) via two control approaches. First, in order to realize the stabilization of MDNNs in finite time, a delayed state feedback controller is proposed. Then, a novel adaptive strategy is applied to the delayed controller, and finite-time stabilization of MDNNs can also be achieved by using the adaptive control law. Some easily verified algebraic criteria are derived to ensure the stabilization of MDNNs in finite time, and the estimation of the settling time functional is given. Moreover, several finite-time stability results as our special cases for both memristor-based neural networks (MNNs) without delays and neural networks are given. Finally, three examples are provided for the illustration of the theoretical results.",4
A Neurodynamic Optimization Approach to Bilevel Quadratic Programming.,"This paper presents a neurodynamic optimization approach to bilevel quadratic programming (BQP). Based on the Karush-Kuhn-Tucker (KKT) theorem, the BQP problem is reduced to a one-level mathematical program subject to complementarity constraints (MPCC). It is proved that the global solution of the MPCC is the minimal one of the optimal solutions to multiple convex optimization subproblems. A recurrent neural network is developed for solving these convex optimization subproblems. From any initial state, the state of the proposed neural network is convergent to an equilibrium point of the neural network, which is just the optimal solution of the convex optimization subproblem. Compared with existing recurrent neural networks for BQP, the proposed neural network is guaranteed for delivering the exact optimal solutions to any convex BQP problems. Moreover, it is proved that the proposed neural network for bilevel linear programming is convergent to an equilibrium point in finite time. Finally, three numerical examples are elaborated to substantiate the efficacy of the proposed approach.",4
A Unified Fisher's Ratio Learning Method for Spatial Filter Optimization.,"To detect the mental task of interest, spatial filtering has been widely used to enhance the spatial resolution of electroencephalography (EEG). However, the effectiveness of spatial filtering is undermined due to the significant nonstationarity of EEG. Based on regularization, most of the conventional stationary spatial filter design methods address the nonstationarity at the cost of the interclass discrimination. Moreover, spatial filter optimization is inconsistent with feature extraction when EEG covariance matrices could not be jointly diagonalized due to the regularization. In this paper, we propose a novel framework for a spatial filter design. With Fisher's ratio in feature space directly used as the objective function, the spatial filter optimization is unified with feature extraction. Given its ratio form, the selection of the regularization parameter could be avoided. We evaluate the proposed method on a binary motor imagery data set of 16 subjects, who performed the calibration and test sessions on different days. The experimental results show that the proposed method yields improvement in classification performance for both single broadband and filter bank settings compared with conventional nonunified methods. We also provide a systematic attempt to compare different objective functions in modeling data nonstationarity with simulation studies.To detect the mental task of interest, spatial filtering has been widely used to enhance the spatial resolution of electroencephalography (EEG). However, the effectiveness of spatial filtering is undermined due to the significant nonstationarity of EEG. Based on regularization, most of the conventional stationary spatial filter design methods address the nonstationarity at the cost of the interclass discrimination. Moreover, spatial filter optimization is inconsistent with feature extraction when EEG covariance matrices could not be jointly diagonalized due to the regularization. In this paper, we propose a novel framework for a spatial filter design. With Fisher's ratio in feature space directly used as the objective function, the spatial filter optimization is unified with feature extraction. Given its ratio form, the selection of the regularization parameter could be avoided. We evaluate the proposed method on a binary motor imagery data set of 16 subjects, who performed the calibration and test sessions on different days. The experimental results show that the proposed method yields improvement in classification performance for both single broadband and filter bank settings compared with conventional nonunified methods. We also provide a systematic attempt to compare different objective functions in modeling data nonstationarity with simulation studies.",4
A New Discrete-Time Multi-Constrained $K$-Winner-Take-All Recurrent Network and Its Application to Prioritized Scheduling.,"In this paper, we propose a novel discrete-time recurrent neural network aiming to resolve a new class of multi-constrained K-winner-take-all (K-WTA) problems. By facilitating specially designed asymmetric neuron weights, the proposed model is capable of operating in a fully parallel manner, thereby allowing true digital implementation. This paper also provides theorems that delineate the theoretical upper bound of the convergence latency, which is merely O(K). Importantly, via simulations, the average convergence time is close to O(1) in most general cases. Moreover, as the multi-constrained K-WTA problem degenerates to a traditional single-constrained problem, the upper bound becomes exactly two parallel iterations, which significantly outperforms the existing K-WTA models. By associating the neurons and neuron weights with routing paths and path priorities, respectively, we then apply the model to a prioritized flow scheduler for the data center networks. Through extensive simulations, we demonstrate that the proposed scheduler converges to the equilibrium state within near-constant time for different scales of networks while achieving maximal throughput, quality-of-service priority differentiation, and minimum energy consumption, subject to the flow contention-free constraints.",4
Regularized Class-Specific Subspace Classifier.,"In this paper, we mainly focus on how to achieve the translated subspace representation for each class, which could simultaneously indicate the distribution of the associated class and the differences from its complementary classes. By virtue of the reconstruction problem, the class-specific subspace classifier (CSSC) problem could be represented as a series of biobjective optimization problems, which minimize and maximize the reconstruction errors of the related class and its complementary classes, respectively. Besides, the regularization term is specifically introduced to ensure the whole system's stability. Accordingly, a regularized class-specific subspace classifier (RCSSC) method can be further proposed based on solving a general quadratic ratio problem. The proposed RCSSC method consistently converges to the global optimal subspace and translation under the variations of the regularization parameter. Furthermore, the proposed RCSSC method could be extended to the unregularized case, which is known as unregularized CSSC (UCSSC) method via orthogonal decomposition technique. As a result, the effectiveness and the superiority of both proposed RCSSC and UCSSC methods can be verified analytically and experimentally.In this paper, we mainly focus on how to achieve the translated subspace representation for each class, which could simultaneously indicate the distribution of the associated class and the differences from its complementary classes. By virtue of the reconstruction problem, the class-specific subspace classifier (CSSC) problem could be represented as a series of biobjective optimization problems, which minimize and maximize the reconstruction errors of the related class and its complementary classes, respectively. Besides, the regularization term is specifically introduced to ensure the whole system's stability. Accordingly, a regularized class-specific subspace classifier (RCSSC) method can be further proposed based on solving a general quadratic ratio problem. The proposed RCSSC method consistently converges to the global optimal subspace and translation under the variations of the regularization parameter. Furthermore, the proposed RCSSC method could be extended to the unregularized case, which is known as unregularized CSSC (UCSSC) method via orthogonal decomposition technique. As a result, the effectiveness and the superiority of both proposed RCSSC and UCSSC methods can be verified analytically and experimentally.",4
Online Training of an Opto-Electronic Reservoir Computer Applied to Real-Time Channel Equalization.,"Reservoir computing is a bioinspired computing paradigm for processing time-dependent signals. The performance of its analog implementation is comparable to other state-of-the-art algorithms for tasks such as speech recognition or chaotic time series prediction, but these are often constrained by the offline training methods commonly employed. Here, we investigated the online learning approach by training an optoelectronic reservoir computer using a simple gradient descent algorithm, programmed on a field-programmable gate array chip. Our system was applied to wireless communications, a quickly growing domain with an increasing demand for fast analog devices to equalize the nonlinear distorted channels. We report error rates up to two orders of magnitude lower than previous implementations on this task. We show that our system is particularly well suited for realistic channel equalization by testing it on a drifting and a switching channel and obtaining good performances.",4
Consensus of Multiagent Systems With Distance-Dependent Communication Networks.,"In this paper, we study the consensus problem of discrete-time and continuous-time multiagent systems with distance-dependent communication networks, respectively. The communication weight between any two agents is assumed to be a nonincreasing function of their distance. First, we consider the networks with fixed connectivity. In this case, the interaction between adjacent agents always exists but the influence could possibly become negligible if the distance is long enough. We show that consensus can be reached under arbitrary initial states if the decay rate of the communication weight is less than a given bound. Second, we study the networks with distance-dependent connectivity. It is assumed that any two agents interact with each other if and only if their distance does not exceed a fixed range. With the validity of some conditions related to the property of the initial communication graph, we prove that consensus can be achieved asymptotically. Third, we present some applications of the main results to opinion consensus problems and formation control problems. Finally, several simulation examples are presented to illustrate the effectiveness of the theoretical findings.In this paper, we study the consensus problem of discrete-time and continuous-time multiagent systems with distance-dependent communication networks, respectively. The communication weight between any two agents is assumed to be a nonincreasing function of their distance. First, we consider the networks with fixed connectivity. In this case, the interaction between adjacent agents always exists but the influence could possibly become negligible if the distance is long enough. We show that consensus can be reached under arbitrary initial states if the decay rate of the communication weight is less than a given bound. Second, we study the networks with distance-dependent connectivity. It is assumed that any two agents interact with each other if and only if their distance does not exceed a fixed range. With the validity of some conditions related to the property of the initial communication graph, we prove that consensus can be achieved asymptotically. Third, we present some applications of the main results to opinion consensus problems and formation control problems. Finally, several simulation examples are presented to illustrate the effectiveness of the theoretical findings.",4
Fully Decentralized Semi-supervised Learning via Privacy-preserving Matrix Completion.,"Distributed learning refers to the problem of inferring a function when the training data are distributed among different nodes. While significant work has been done in the contexts of supervised and unsupervised learning, the intermediate case of Semi-supervised learning in the distributed setting has received less attention. In this paper, we propose an algorithm for this class of problems, by extending the framework of manifold regularization. The main component of the proposed algorithm consists of a fully distributed computation of the adjacency matrix of the training patterns. To this end, we propose a novel algorithm for low-rank distributed matrix completion, based on the framework of diffusion adaptation. Overall, the distributed Semi-supervised algorithm is efficient and scalable, and it can preserve privacy by the inclusion of flexible privacy-preserving mechanisms for similarity computation. The experimental results and comparison on a wide range of standard Semi-supervised benchmarks validate our proposal.",4
Event-Triggered Adaptive Dynamic Programming for Continuous-Time Systems With Control Constraints.,"In this paper, an event-triggered near optimal control structure is developed for nonlinear continuous-time systems with control constraints. Due to the saturating actuators, a nonquadratic cost function is introduced and the Hamilton-Jacobi-Bellman (HJB) equation for constrained nonlinear continuous-time systems is formulated. In order to solve the HJB equation, an actor-critic framework is presented. The critic network is used to approximate the cost function and the action network is used to estimate the optimal control law. In addition, in the proposed method, the control signal is transmitted in an aperiodic manner to reduce the computational and the transmission cost. Both the networks are only updated at the trigger instants decided by the event-triggered condition. Detailed Lyapunov analysis is provided to guarantee that the closed-loop event-triggered system is ultimately bounded. Three case studies are used to demonstrate the effectiveness of the proposed method.",4
Spectrum-Diverse Neuroevolution With Unified Neural Models.,"Learning algorithms are being increasingly adopted in various applications. However, further expansion will require methods that work more automatically. To enable this level of automation, a more powerful solution representation is needed. However, by increasing the representation complexity, a second problem arises. The search space becomes huge, and therefore, an associated scalable and efficient searching algorithm is also required. To solve both the problems, first a powerful representation is proposed that unifies most of the neural networks features from the literature into one representation. Second, a new diversity preserving method called spectrum diversity is created based on the new concept of chromosome spectrum that creates a spectrum out of the characteristics and frequency of alleles in a chromosome. The combination of spectrum diversity with a unified neuron representation enables the algorithm to either surpass or equal NeuroEvolution of Augmenting Topologies on all of the five classes of problems tested. Ablation tests justify the good results, showing the importance of added new features in the unified neuron representation. Part of the success is attributed to the novelty-focused evolution and good scalability with a chromosome size provided by spectrum diversity. Thus, this paper sheds light on a new representation and diversity preserving mechanism that should impact algorithms and applications to come.",4
Underdetermined Blind Source Separation Using Sparse Coding.,"In an underdetermined mixture system with unknown sources, it is a challenging task to separate these sources from their observed mixture signals, where . By exploiting the technique of sparse coding, we propose an effective approach to discover some 1-D subspaces from the set consisting of all the time-frequency (TF) representation vectors of observed mixture signals. We show that these 1-D subspaces are associated with TF points where only single source possesses dominant energy. By grouping the vectors in these subspaces via hierarchical clustering algorithm, we obtain the estimation of the mixing matrix. Finally, the source signals could be recovered by solving a series of least squares problems. Since the sparse coding strategy considers the linear representation relations among all the TF representation vectors of mixing signals, the proposed algorithm can provide an accurate estimation of the mixing matrix and is robust to the noises compared with the existing underdetermined blind source separation approaches. Theoretical analysis and experimental results demonstrate the effectiveness of the proposed method.",4
Distributed Finite-Time Cooperative Control of Multiple High-Order Nonholonomic Mobile Robots.,"The consensus problem of multiple nonholonomic mobile robots in the form of high-order chained structure is considered in this paper. Based on the model features and the finite-time control technique, a finite-time cooperative controller is explicitly constructed which guarantees that the states consensus is achieved in a finite time. As an application of the proposed results, finite-time formation control of multiple wheeled mobile robots is studied and a finite-time formation control algorithm is proposed. To show effectiveness of the proposed approach, a simulation example is given.",4
Assessing Generalization Ability of Majority Vote Point Classifiers.,"Classification algorithms have been traditionally designed to simultaneously reduce errors caused by bias as well by variance. However, there occur many situations where low generalization error becomes extremely crucial to getting tangible classification solutions, and even slight overfitting causes serious consequences in the test results. In such situations, classifiers with low Vapnik-Chervonenkis (VC) dimension can bring out positive differences due to two main advantages: 1) the classifier manages to keep the test error close to training error and 2) the classifier learns effectively with small number of samples. This paper shows that a class of classifiers named majority vote point (MVP) classifiers, on account of very low VC dimension, can exhibit a generalization error that is even lower than that of linear classifiers. This paper proceeds by theoretically formulating an upper bound on the VC dimension of the MVP classifier. Later, through empirical analysis, the trend of exact values of VC dimension is estimated. Finally, case studies on machine fault diagnosis problems and prostate tumor detection problem revalidate the fact that an MVP classifier can achieve a lower generalization error than most other classifiers.",4
Method for Determining the Optimal Number of Clusters Based on Agglomerative Hierarchical Clustering.,"It is crucial to determine the optimal number of clusters for the clustering quality in cluster analysis. From the standpoint of sample geometry, two concepts, i.e., the sample clustering dispersion degree and the sample clustering synthesis degree, are defined, and a new clustering validity index is designed. Moreover, a method for determining the optimal number of clusters based on an agglomerative hierarchical clustering (AHC) algorithm is proposed. The new index and the method can evaluate the clustering results produced by the AHC and determine the optimal number of clusters for multiple types of datasets, such as linear, manifold, annular, and convex structures. Theoretical research and experimental results indicate the validity and good performance of the proposed index and the method.",4
Mesh Convolutional Restricted Boltzmann Machines for Unsupervised Learning of Features With Structure Preservation on 3-D Meshes.,"Discriminative features of 3-D meshes are significant to many 3-D shape analysis tasks. However, handcrafted descriptors and traditional unsupervised 3-D feature learning methods suffer from several significant weaknesses: 1) the extensive human intervention is involved; 2) the local and global structure information of 3-D meshes cannot be preserved, which is in fact an important source of discriminability; 3) the irregular vertex topology and arbitrary resolution of 3-D meshes do not allow the direct application of the popular deep learning models; 4) the orientation is ambiguous on the mesh surface; and 5) the effect of rigid and nonrigid transformations on 3-D meshes cannot be eliminated. As a remedy, we propose a deep learning model with a novel irregular model structure, called mesh convolutional restricted Boltzmann machines (MCRBMs). MCRBM aims to simultaneously learn structure-preserving local and global features from a novel raw representation, local function energy distribution. In addition, multiple MCRBMs can be stacked into a deeper model, called mesh convolutional deep belief networks (MCDBNs). MCDBN employs a novel local structure preserving convolution (LSPC) strategy to convolve the geometry and the local structure learned by the lower MCRBM to the upper MCRBM. LSPC facilitates resolving the challenging issue of the orientation ambiguity on the mesh surface in MCDBN. Experiments using the proposed MCRBM and MCDBN were conducted on three common aspects: global shape retrieval, partial shape retrieval, and shape correspondence. Results show that the features learned by the proposed methods outperform the other state-of-the-art 3-D shape features.",4
Robust Image Regression Based on the Extended Matrix Variate Power Exponential Distribution of Dependent Noise.,"Dealing with partial occlusion or illumination is one of the most challenging problems in image representation and classification. In this problem, the characterization of the representation error plays a crucial role. In most current approaches, the error matrix needs to be stretched into a vector and each element is assumed to be independently corrupted. This ignores the dependence between the elements of error. In this paper, it is assumed that the error image caused by partial occlusion or illumination changes is a random matrix variate and follows the extended matrix variate power exponential distribution. This has the heavy tailed regions and can be used to describe a matrix pattern of lxm dimensional observations that are not independent. This paper reveals the essence of the proposed distribution: it actually alleviates the correlations between pixels in an error matrix E and makes E approximately Gaussian. On the basis of this distribution, we derive a Schatten p -norm-based matrix regression model with Lq regularization. Alternating direction method of multipliers is applied to solve this model. To get a closed-form solution in each step of the algorithm, two singular value function thresholding operators are introduced. In addition, the extended Schatten p -norm is utilized to characterize the distance between the test samples and classes in the design of the classifier. Extensive experimental results for image reconstruction and classification with structural noise demonstrate that the proposed algorithm works much more robustly than some existing regression-based methods.",4
Neural Approximation-Based Adaptive Control for a Class of Nonlinear Nonstrict Feedback Discrete-Time Systems.,"In this paper, an adaptive control approach-based neural approximation is developed for a class of uncertain nonlinear discrete-time (DT) systems. The main characteristic of the considered systems is that they can be viewed as a class of multi-input multioutput systems in the nonstrict feedback structure. The similar control problem of this class of systems has been addressed in the past, but it focused on the continuous-time systems. Due to the complicacies of the system structure, it will become more difficult for the controller design and the stability analysis. To stabilize this class of systems, a new recursive procedure is developed, and the effect caused by the noncausal problem in the nonstrict feedback DT structure can be solved using a semirecurrent neural approximation. Based on the Lyapunov difference approach, it is proved that all the signals of the closed-loop system are semiglobal, ultimately uniformly bounded, and a good tracking performance can be guaranteed. The feasibility of the proposed controllers can be validated by setting a simulation example.",4
Observer-Based Adaptive NN Control for a Class of Uncertain Nonlinear Systems With Nonsymmetric Input Saturation.,"This paper is concerned with the problem of adaptive tracking control for a class of uncertain nonlinear systems with nonsymmetric input saturation and immeasurable states. The radial basis function of neural network (NN) is employed to approximate unknown functions, and an NN state observer is designed to estimate the immeasurable states. To analyze the effect of input saturation, an auxiliary system is employed. By the aid of adaptive backstepping technique, an adaptive tracking control approach is developed. Under the proposed adaptive tracking controller, the boundedness of all the signals in the closed-loop system is achieved. Moreover, distinct from most of the existing references, the tracking error can be bounded by an explicit function of design parameters and saturation input error. Finally, an example is given to show the effectiveness of the proposed method.",4
Semisupervised Feature Selection Based on Relevance and Redundancy Criteria.,"Feature selection aims to gain relevant features for improved classification performance and remove redundant features for reduced computational cost. How to balance these two factors is a problem especially when the categorical labels are costly to obtain. In this paper, we address this problem using semisupervised learning method and propose a max-relevance and min-redundancy criterion based on Pearson's correlation (RRPC) coefficient. This new method uses the incremental search technique to select optimal feature subsets. The new selected features have strong relevance to the labels in supervised manner, and avoid redundancy to the selected feature subsets under unsupervised constraints. Comparative studies are performed on binary data and multicategory data from benchmark data sets. The results show that the RRPC can achieve a good balance between relevance and redundancy in semisupervised feature selection. We also compare the RRPC with classic supervised feature selection criteria (such as mRMR and Fisher score), unsupervised feature selection criteria (such as Laplacian score), and semisupervised feature selection criteria (such as sSelect and locality sensitive). Experimental results demonstrate the effectiveness of our method.",4
Lazy-Learning-Based Data-Driven Model-Free Adaptive Predictive Control for a Class of Discrete-Time Nonlinear Systems.,"In this paper, a novel data-driven model-free adaptive predictive control method based on lazy learning technique is proposed for a class of discrete-time single-input and single-output nonlinear systems. The feature of the proposed approach is that the controller is designed only using the input-output (I/O) measurement data of the system by means of a novel dynamic linearization technique with a new concept termed pseudogradient (PG). Moreover, the predictive function is implemented in the controller using a lazy-learning (LL)-based PG predictive algorithm, such that the controller not only shows good robustness but also can realize the effect of model-free adaptive prediction for the sudden change of the desired signal. Further, since the LL technique has the characteristic of database queries, both the online and offline I/O measurement data are fully and simultaneously utilized to real-time adjust the controller parameters during the control process. Moreover, the stability of the proposed method is guaranteed by rigorous mathematical analysis. Meanwhile, the numerical simulations and the laboratory experiments implemented on a practical three-tank water level control system both verify the effectiveness of the proposed approach.",4
Novel Formulation of Adaptive MPC as EKF Using ANN Model: Multiproduct Semibatch Polymerization Reactor Case Study.,"In this paper, a novel formulation for nonlinear model predictive control (MPC) has been proposed incorporating the extended Kalman filter (EKF) control concept using a purely data-driven artificial neural network (ANN) model based on measurements for supervisory control. The proposed scheme consists of two modules focusing on online parameter estimation based on past measurements and control estimation over control horizon based on minimizing the deviation of model output predictions from set points along the prediction horizon. An industrial case study for temperature control of a multiproduct semibatch polymerization reactor posed as a challenge problem has been considered as a test bed to apply the proposed ANN-EKFMPC strategy at supervisory level as a cascade control configuration along with proportional integral controller [ANN-EKFMPC with PI (ANN-EKFMPC-PI)]. The proposed approach is formulated incorporating all aspects of MPC including move suppression factor for control effort minimization and constraint-handling capability including terminal constraints. The nominal stability analysis and offset-free tracking capabilities of the proposed controller are proved. Its performance is evaluated by comparison with a standard MPC-based cascade control approach using the same adaptive ANN model. The ANN-EKFMPC-PI control configuration has shown better controller performance in terms of temperature tracking, smoother input profiles, as well as constraint-handling ability compared with the ANN-MPC with PI approach for two products in summer and winter. The proposed scheme is found to be versatile although it is based on a purely data-driven model with online parameter estimation.",4
Hair Segmentation Using Heuristically-Trained Neural Networks.,"We present a method for binary classification using neural networks (NNs) that performs training and classification on the same data using the help of a pretraining heuristic classifier. The heuristic classifier is initially used to segment data into three clusters of high-confidence positives, high-confidence negatives, and low-confidence sets. The high-confidence sets are used to train an NN, which is then used to classify the low-confidence set. Applying this method to the binary classification of hair versus nonhair patches, we obtain a 2.2% performance increase using the heuristically trained NN over the current state-of-the-art hair segmentation method.",4
Markov Blanket Feature Selection Using Representative Sets.,"It has received much attention in recent years to use Markov blankets in a Bayesian network for feature selection. The Markov blanket of a class attribute in a Bayesian network is a unique yet minimal feature subset for optimal feature selection if the probability distribution of a data set can be faithfully represented by this Bayesian network. However, if a data set violates the faithful condition, Markov blankets of a class attribute may not be unique. To tackle this issue, in this paper, we propose a new concept of representative sets and then design the selection via group alpha-investing (SGAI) algorithm to perform Markov blanket feature selection with representative sets for classification. Using a comprehensive set of real data, our empirical studies have demonstrated that SGAI outperforms the state-of-the-art Markov blanket feature selectors and other well-established feature selection methods.It has received much attention in recent years to use Markov blankets in a Bayesian network for feature selection. The Markov blanket of a class attribute in a Bayesian network is a unique yet minimal feature subset for optimal feature selection if the probability distribution of a data set can be faithfully represented by this Bayesian network. However, if a data set violates the faithful condition, Markov blankets of a class attribute may not be unique. To tackle this issue, in this paper, we propose a new concept of representative sets and then design the selection via group alpha-investing (SGAI) algorithm to perform Markov blanket feature selection with representative sets for classification. Using a comprehensive set of real data, our empirical studies have demonstrated that SGAI outperforms the state-of-the-art Markov blanket feature selectors and other well-established feature selection methods.",4
Person Re-identification by Multi-hypergraph Fusion.,"Matching people across nonoverlapping cameras, also known as person re-identification, is an important and challenging research topic. Despite its great demand in many crucial applications such as surveillance, person re-identification is still far from being solved. Due to drastic view changes, even the same person may look quite dissimilar in different cameras. Illumination and pose variations further aggravate this discrepancy. To this end, various feature descriptors have been designed for improving the matching accuracy. Since different features encode information from different aspects, in this paper, we propose to effectively leverage multiple off-the-shelf features via multi-hypergraph fusion. A hypergraph captures not only pairwise but also high-order relationships among the subjects being matched. In addition, different from conventional approaches in which the matching is achieved by computing the pairwise distance or similarity between a probe and a gallery subject, the similarities between the probe and all gallery subjects are learned jointly via hypergraph optimization. Experiments on popular data sets demonstrate the effectiveness of the proposed method, and a superior performance is achieved as compared with the most recent state-of-the-arts.Matching people across nonoverlapping cameras, also known as person re-identification, is an important and challenging research topic. Despite its great demand in many crucial applications such as surveillance, person re-identification is still far from being solved. Due to drastic view changes, even the same person may look quite dissimilar in different cameras. Illumination and pose variations further aggravate this discrepancy. To this end, various feature descriptors have been designed for improving the matching accuracy. Since different features encode information from different aspects, in this paper, we propose to effectively leverage multiple off-the-shelf features via multi-hypergraph fusion. A hypergraph captures not only pairwise but also high-order relationships among the subjects being matched. In addition, different from conventional approaches in which the matching is achieved by computing the pairwise distance or similarity between a probe and a gallery subject, the similarities between the probe and all gallery subjects are learned jointly via hypergraph optimization. Experiments on popular data sets demonstrate the effectiveness of the proposed method, and a superior performance is achieved as compared with the most recent state-of-the-arts.",4
Multicolumn RBF Network.,"This paper proposes the multicolumn RBF network (MCRN) as a method to improve the accuracy and speed of a traditional radial basis function network (RBFN). The RBFN, as a fully connected artificial neural network (ANN), suffers from costly kernel inner-product calculations due to the use of many instances as the centers of hidden units. This issue is not critical for small datasets, as adding more hidden units will not burden the computation time. However, for larger datasets, the RBFN requires many hidden units with several kernel computations to generalize the problem. The MCRN mechanism is constructed based on dividing a dataset into smaller subsets using the k-d tree algorithm. resultant subsets are considered as separate training datasets to train individual RBFNs. Those small RBFNs are stacked in parallel and bulged into the MCRN structure during testing. The MCRN is considered as a well-developed and easy-to-use parallel structure, because each individual ANN has been trained on its own subsets and is completely separate from the other ANNs. This parallelized structure reduces the testing time compared with that of a single but larger RBFN, which cannot be easily parallelized due to its fully connected structure. Small informative subsets provide the MCRN with a regional experience to specify the problem instead of generalizing it. The MCRN has been tested on many benchmark datasets and has shown better accuracy and great improvements in training and testing times compared with a single RBFN. The MCRN also shows good results compared with those of some machine learning techniques, such as the support vector machine and k-nearest neighbors.",4
A Fast Algorithm of Convex Hull Vertices Selection for Online Classification.,"Reducing samples through convex hull vertices selection (CHVS) within each class is an important and effective method for online classification problems, since the classifier can be trained rapidly with the selected samples. However, the process of CHVS is NP-hard. In this paper, we propose a fast algorithm to select the convex hull vertices, based on the convex hull decomposition and the property of projection. In the proposed algorithm, the quadratic minimization problem of computing the distance between a point and a convex hull is converted into a linear equation problem with a low computational complexity. When the data dimension is high, an approximate, instead of exact, convex hull is allowed to be selected by setting an appropriate termination condition in order to delete more nonimportant samples. In addition, the impact of outliers is also considered, and the proposed algorithm is improved by deleting the outliers in the initial procedure. Furthermore, a dimension convention technique via the kernel trick is used to deal with nonlinearly separable problems. An upper bound is theoretically proved for the difference between the support vector machines based on the approximate convex hull vertices selected and all the training samples. Experimental results on both synthetic and real data sets show the effectiveness and validity of the proposed algorithm.",4
A Regularized SNPOM for Stable Parameter Estimation of RBF-AR(X) Model.,"Recently, the radial basis function (RBF) network-style coefficients AutoRegressive (with exogenous inputs) [RBF-AR(X)] model identified by the structured nonlinear parameter optimization method (SNPOM) has attracted considerable interest because of its significant performance in nonlinear system modeling. However, this promising technique may occasionally confront the problem that the parameters are divergent in the optimization process, which may be a potential issue ignored by most researchers. In this paper, a regularized SNPOM, together with the regularization parameter detection technique, is presented to estimate the parameters of RBF-AR(X) models. This approach first separates the parameters of an RBF-AR(X) model into a linear parameters set and a nonlinear parameters set, and then combines a gradient-based nonlinear optimization algorithm for estimating the nonlinear parameters and the regularized least squares method for estimating the linear parameters. Several examples demonstrate that the proposed approach is effective to cope with the potential unstable problem in the parameters search process, and may also yield better or similar multistep forecasting accuracy and better robustness than the previous method.",4
Identifying Objective and Subjective Words via Topic Modeling.,"It is observed that distinct words in a given document have either strong or weak ability in delivering facts (i.e., the objective sense) or expressing opinions (i.e., the subjective sense) depending on the topics they associate with. Motivated by the intuitive assumption that different words have varying degree of discriminative power in delivering the objective sense or the subjective sense with respect to their assigned topics, a model named as dentified bjective- ubjective latent Dirichlet allocation (LDA) ( osLDA) is proposed in this paper. In the osLDA model, the simple Polya urn model adopted in traditional topic models is modified by incorporating it with a probabilistic generative process, in which the novel ""Bag-of-Discriminative-Words"" (BoDW) representation for the documents is obtained; each document has two different BoDW representations with regard to objective and subjective senses, respectively, which are employed in the joint objective and subjective classification instead of the traditional Bag-of-Topics representation. The experiments reported on documents and images demonstrate that: 1) the BoDW representation is more predictive than the traditional ones; 2) osLDA boosts the performance of topic modeling via the joint discovery of latent topics and the different objective and subjective power hidden in every word; and 3) osLDA has lower computational complexity than supervised LDA, especially under an increasing number of topics.",4
Determination of the Edge of Criticality in Echo State Networks Through Fisher Information Maximization.,"It is a widely accepted fact that the computational capability of recurrent neural networks (RNNs) is maximized on the so-called ""edge of criticality."" Once the network operates in this configuration, it performs efficiently on a specific application both in terms of: 1) low prediction error and 2) high short-term memory capacity. Since the behavior of recurrent networks is strongly influenced by the particular input signal driving the dynamics, a universal, application-independent method for determining the edge of criticality is still missing. In this paper, we aim at addressing this issue by proposing a theoretically motivated, unsupervised method based on Fisher information for determining the edge of criticality in RNNs. It is proved that Fisher information is maximized for (finite-size) systems operating in such critical regions. However, Fisher information is notoriously difficult to compute and requires the analytic form of the probability density function ruling the system behavior. This paper takes advantage of a recently developed nonparametric estimator of the Fisher information matrix and provides a method to determine the critical region of echo state networks (ESNs), a particular class of recurrent networks. The considered control parameters, which indirectly affect the ESN performance, are explored to identify those configurations lying on the edge of criticality and, as such, maximizing Fisher information and computational performance. Experimental results on benchmarks and real-world data demonstrate the effectiveness of the proposed method.",4
Cooperative Adaptive Output Regulation for Second-Order Nonlinear Multiagent Systems With Jointly Connected Switching Networks.,"This paper studies the cooperative global robust output regulation problem for a class of heterogeneous second-order nonlinear uncertain multiagent systems with jointly connected switching networks. The main contributions consist of the following three aspects. First, we generalize the result of the adaptive distributed observer from undirected jointly connected switching networks to directed jointly connected switching networks. Second, by performing a new coordinate and input transformation, we convert our problem into the cooperative global robust stabilization problem of a more complex augmented system via the distributed internal model principle. Third, we solve the stabilization problem by a distributed state feedback control law. Our result is illustrated by the leader-following consensus problem for a group of Van der Pol oscillators.",4
Experienced Gray Wolf Optimization Through Reinforcement Learning and Neural Networks.,"In this paper, a variant of gray wolf optimization (GWO) that uses reinforcement learning principles combined with neural networks to enhance the performance is proposed. The aim is to overcome, by reinforced learning, the common challenge of setting the right parameters for the algorithm. In GWO, a single parameter is used to control the exploration/exploitation rate, which influences the performance of the algorithm. Rather than using a global way to change this parameter for all the agents, we use reinforcement learning to set it on an individual basis. The adaptation of the exploration rate for each agent depends on the agent's own experience and the current terrain of the search space. In order to achieve this, experience repository is built based on the neural network to map a set of agents' states to a set of corresponding actions that specifically influence the exploration rate. The experience repository is updated by all the search agents to reflect experience and to enhance the future actions continuously. The resulted algorithm is called experienced GWO (EGWO) and its performance is assessed on solving feature selection problems and on finding optimal weights for neural networks algorithm. We use a set of performance indicators to evaluate the efficiency of the method. Results over various data sets demonstrate an advance of the EGWO over the original GWO and over other metaheuristics, such as genetic algorithms and particle swarm optimization.",4
Probabilistic Low-Rank Multitask Learning.,"In this paper, we consider the problem of learning multiple related tasks simultaneously with the goal of improving the generalization performance of individual tasks. The key challenge is to effectively exploit the shared information across multiple tasks as well as preserve the discriminative information for each individual task. To address this, we propose a novel probabilistic model for multitask learning (MTL) that can automatically balance between low-rank and sparsity constraints. The former assumes a low-rank structure of the underlying predictive hypothesis space to explicitly capture the relationship of different tasks and the latter learns the incoherent sparse patterns private to each task. We derive and perform inference via variational Bayesian methods. Experimental results on both regression and classification tasks on real-world applications demonstrate the effectiveness of the proposed method in dealing with the MTL problems.",4
Adaptive Reliable $H_\infty $ Static Output Feedback Control Against Markovian Jumping Sensor Failures.,"This paper investigates the adaptive static output feedback (SOF) control problem for continuous-time linear systems with stochastic sensor failures. A multi-Markovian variable is introduced to denote the failure scaling factors for each sensor. Different from the existing results, the failure parameters are stochastically jumping and their bounds of are unknown. An adaptive reliable SOF control method is proposed, where the controller parameters are updated automatically to compensate for the failure effects on systems. A novel cubic absolute Lyapunov function is proposed to design adaptive laws only using measured output with sensor failures, and the convergence of jumping adaptive parameters is ensured by a trajectory initialization approach. The resultant designs can guarantee the asymptotic stability with an adaptive performance of closed-loop systems regardless of sensor failures. Finally, the simulation results on the ""Raptor-90"" helicopter are given to show the effectiveness of the proposed approaches.",4
Multiview Boosting With Information Propagation for Classification.,"Multiview learning has shown promising potential in many applications. However, most techniques are focused on either view consistency, or view diversity. In this paper, we introduce a novel multiview boosting algorithm, called Boost.SH, that computes weak classifiers independently of each view but uses a shared weight distribution to propagate information among the multiple views to ensure consistency. To encourage diversity, we introduce randomized Boost.SH and show its convergence to the greedy Boost.SH solution in the sense of minimizing regret using the framework of adversarial multiarmed bandits. We also introduce a variant of Boost.SH that combines decisions from multiple experts for recommending views for classification. We propose an expert strategy for multiview learning based on inverse variance, which explores both consistency and diversity. Experiments on biometric recognition, document categorization, multilingual text, and yeast genomic multiview data sets demonstrate the advantage of Boost.SH (85%) compared with other boosting algorithms like AdaBoost (82%) using concatenated views and substantially better than a multiview kernel learning algorithm (74%).",4
Self-Taught Low-Rank Coding for Visual Learning.,"The lack of labeled data presents a common challenge in many computer vision and machine learning tasks. Semisupervised learning and transfer learning methods have been developed to tackle this challenge by utilizing auxiliary samples from the same domain or from a different domain, respectively. Self-taught learning, which is a special type of transfer learning, has fewer restrictions on the choice of auxiliary data. It has shown promising performance in visual learning. However, existing self-taught learning methods usually ignore the structure information in data. In this paper, we focus on building a self-taught coding framework, which can effectively utilize the rich low-level pattern information abstracted from the auxiliary domain, in order to characterize the high-level structural information in the target domain. By leveraging a high quality dictionary learned across auxiliary and target domains, the proposed approach learns expressive codings for the samples in the target domain. Since many types of visual data have been proven to contain subspace structures, a low-rank constraint is introduced into the coding objective to better characterize the structure of the given target set. The proposed representation learning framework is called self-taught low-rank (S-Low) coding, which can be formulated as a nonconvex rank-minimization and dictionary learning problem. We devise an efficient majorization-minimization augmented Lagrange multiplier algorithm to solve it. Based on the proposed S-Low coding mechanism, both unsupervised and supervised visual learning algorithms are derived. Extensive experiments on five benchmark data sets demonstrate the effectiveness of our approach.",4
Fine-Grained Image Classification via Low-Rank Sparse Coding With General and Class-Specific Codebooks.,"This paper tries to separate fine-grained images by jointly learning the encoding parameters and codebooks through low-rank sparse coding (LRSC) with general and class-specific codebook generation. Instead of treating each local feature independently, we encode the local features within a spatial region jointly by LRSC. This ensures that the spatially nearby local features with similar visual characters are encoded by correlated parameters. In this way, we can make the encoded parameters more consistent for fine-grained image representation. Besides, we also learn a general codebook and a number of class-specific codebooks in combination with the encoding scheme. Since images of fine-grained classes are visually similar, the difference is relatively small between the general codebook and each class-specific codebook. We impose sparsity constraints to model this relationship. Moreover, the incoherences with different codebooks and class-specific codebooks are jointly considered. We evaluate the proposed method on several public image data sets. The experimental results show that by learning general and class-specific codebooks with the joint encoding of local features, we are able to model the differences among different fine-grained classes than many other fine-grained image classification methods.",4
Global Asymptotic Stability and Stabilization of Neural Networks With General Noise.,"Neural networks (NNs) in the stochastic environment were widely modeled as stochastic differential equations, which were driven by white noise, such as Brown or Wiener process in the existing papers. However, they are not necessarily the best models to describe dynamic characters of NNs disturbed by nonwhite noise in some specific situations. In this paper, general noise disturbance, which may be nonwhite, is introduced to NNs. Since NNs with nonwhite noise cannot be described by Ito integral equation, a novel modeling method of stochastic NNs is utilized. By a framework in light of random field approach and Lyapunov theory, the global asymptotic stability and stabilization in probability or in the mean square of NNs with general noise are analyzed, respectively. Criteria for the concerned systems based on linear matrix inequality are proposed. Some examples are given to illustrate the effectiveness of the obtained results.",4
Robust C-Loss Kernel Classifiers.,"The correntropy-induced loss (C-loss) function has the nice property of being robust to outliers. In this paper, we study the C-loss kernel classifier with the Tikhonov regularization term, which is used to avoid overfitting. After using the half-quadratic optimization algorithm, which converges much faster than the gradient optimization algorithm, we find out that the resulting C-loss kernel classifier is equivalent to an iterative weighted least square support vector machine (LS-SVM). This relationship helps explain the robustness of iterative weighted LS-SVM from the correntropy and density estimation perspectives. On the large-scale data sets which have low-rank Gram matrices, we suggest to use incomplete Cholesky decomposition to speed up the training process. Moreover, we use the representer theorem to improve the sparseness of the resulting C-loss kernel classifier. Experimental results confirm that our methods are more robust to outliers than the existing common classifiers.",4
Supervised Discrete Hashing With Relaxation.,"Data-dependent hashing has recently attracted attention due to being able to support efficient retrieval and storage of high-dimensional data, such as documents, images, and videos. In this paper, we propose a novel learning-based hashing method called ""supervised discrete hashing with relaxation"" (SDHR) based on ""supervised discrete hashing"" (SDH). SDH uses ordinary least squares regression and traditional zero-one matrix encoding of class label information as the regression target (code words), thus fixing the regression target. In SDHR, the regression target is instead optimized. The optimized regression target matrix satisfies a large margin constraint for correct classification of each example. Compared with SDH, which uses the traditional zero-one matrix, SDHR utilizes the learned regression target matrix and, therefore, more accurately measures the classification error of the regression model and is more flexible. As expected, SDHR generally outperforms SDH. Experimental results on two large-scale image data sets (CIFAR-10 and MNIST) and a large-scale and challenging face data set (FRGC) demonstrate the effectiveness and efficiency of SDHR.",4
Kernel-Based Multilayer Extreme Learning Machines for Representation Learning.,"Recently, multilayer extreme learning machine (ML-ELM) was applied to stacked autoencoder (SAE) for representation learning. In contrast to traditional SAE, the training time of ML-ELM is significantly reduced from hours to seconds with high accuracy. However, ML-ELM suffers from several drawbacks: 1) manual tuning on the number of hidden nodes in every layer is an uncertain factor to training time and generalization; 2) random projection of input weights and bias in every layer of ML-ELM leads to suboptimal model generalization; 3) the pseudoinverse solution for output weights in every layer incurs relatively large reconstruction error; and 4) the storage and execution time for transformation matrices in representation learning are proportional to the number of hidden layers. Inspired by kernel learning, a kernel version of ML-ELM is developed, namely, multilayer kernel ELM (ML-KELM), whose contributions are: 1) elimination of manual tuning on the number of hidden nodes in every layer; 2) no random projection mechanism so as to obtain optimal model generalization; 3) exact inverse solution for output weights is guaranteed under invertible kernel matrix, resulting to smaller reconstruction error; and 4) all transformation matrices are unified into two matrices only, so that storage can be reduced and may shorten model execution time. Benchmark data sets of different sizes have been employed for the evaluation of ML-KELM. Experimental results have verified the contributions of the proposed ML-KELM. The improvement in accuracy over benchmark data sets is up to 7%.",4
Terminal Sliding Mode-Based Consensus Tracking Control for Networked Uncertain Mechanical Systems on Digraphs.,This brief investigates the finite-time consensus tracking control problem for networked uncertain mechanical systems on digraphs. A new terminal sliding-mode-based cooperative control scheme is developed to guarantee that the tracking errors converge to an arbitrarily small bound around zero in finite time. All the networked systems can have different dynamics and all the dynamics are unknown. A neural network is used at each node to approximate the local unknown dynamics. The control schemes are implemented in a fully distributed manner. The proposed control method eliminates some limitations in the existing terminal sliding-mode-based consensus control methods and extends the existing analysis methods to the case of directed graphs. Simulation results on networked robot manipulators are provided to show the effectiveness of the proposed control algorithms.,4
Robust DLPP With Nongreedy $\ell _1$ -Norm Minimization and Maximization.,"Recently, discriminant locality preserving projection based on L1-norm (DLPP-L1) was developed for robust subspace learning and image classification. It obtains projection vectors by greedy strategy, i.e., all projection vectors are optimized individually through maximizing the objective function. Thus, the obtained solution does not necessarily best optimize the corresponding trace ratio optimization algorithm, which is the essential objective function for general dimensionality reduction. It results in insufficient recognition accuracy. To tackle this problem, we propose a nongreedy algorithm to solve the trace ratio formula of DLPP-L1, and analyze its convergence. Experimental results on three databases illustrate the effectiveness of our proposed algorithm.",4
Optimal Switching of DC-DC Power Converters Using Approximate Dynamic Programming.,"Optimal switching between different topologies in step-down dc-dc voltage converters, with nonideal inductors and capacitors, is investigated in this paper. Challenges including constraint on the inductor current and voltage leakages across the capacitor (due to switching) are incorporated. The objective is generating the desired voltage with low ripples and high robustness toward line and load disturbances. A previously developed tool, which is based on approximate dynamic programming, is adapted for this application. The scheme leads to tuning a parametric function approximator to provide optimal switching in a feedback form. No fixed cycle time is assumed, as the cycle time and the duty ratio will be adjusted on the fly in an optimal fashion. The controller demonstrates good capabilities in controlling the system even under parameter uncertainties. Finally, some modifications on the scheme are conducted to handle optimal switching problems with state jumps at the switching times.",4
Stability of Rotor Hopfield Neural Networks With Synchronous Mode.,"A complex-valued Hopfield neural network (CHNN) is a model of a Hopfield neural network using multistate neurons. The stability conditions of CHNNs have been widely studied. A CHNN with a synchronous mode will converge to a fixed point or a cycle of length 2. A rotor Hopfield neural network (RHNN) is also a model of a multistate Hopfield neural network. RHNNs have much higher storage capacity and noise tolerance than CHNNs. We extend the theories regarding the stability of CHNNs to RHNNs. In addition, we investigate the stability of RHNNs with the projection rule. Although a CHNN with projection rule can be trapped at a cycle, an RHNN with projection rule converges to a fixed point. This is one of the great advantages of RHNNs.",4
Dissipativity Analysis for Stochastic Memristive Neural Networks With Time-Varying Delays: A Discrete-Time Case.,"In this paper, the dissipativity problem of discrete-time memristive neural networks (DMNNs) with time-varying delays and stochastic perturbation is investigated. A class of logical switched functions are put forward to reflect the memristor-based switched property of connection weights, and the DMNNs are then recast into a tractable model. Based on the tractable model, the robust analysis method and Refined Jensen-based inequalities are applied to establish some sufficient conditions that ensure the of DMNNs. Two numerical examples are presented to illustrate the effectiveness of the obtained results.",4
A Locality-Constrained and Label Embedding Dictionary Learning Algorithm for Image Classification.,"Locality and label information of training samples play an important role in image classification. However, previous dictionary learning algorithms do not take the locality and label information of atoms into account together in the learning process, and thus their performance is limited. In this paper, a discriminative dictionary learning algorithm, called the locality-constrained and label embedding dictionary learning (LCLE-DL) algorithm, was proposed for image classification. First, the locality information was preserved using the graph Laplacian matrix of the learned dictionary instead of the conventional one derived from the training samples. Then, the label embedding term was constructed using the label information of atoms instead of the classification error term, which contained discriminating information of the learned dictionary. The optimal coding coefficients derived by the locality-based and label-based reconstruction were effective for image classification. Experimental results demonstrated that the LCLE-DL algorithm can achieve better performance than some state-of-the-art algorithms.",4
Global Mittag-Leffler Stabilization of Fractional-Order Memristive Neural Networks.,"According to conventional memristive neural network theories, neurodynamic properties are powerful tools for solving many problems in the areas of brain-like associative learning, dynamic information storage or retrieval, etc. However, as have often been noted in most fractional-order systems, system analysis approaches for integral-order systems could not be directly extended and applied to deal with fractional-order systems, and consequently, it raises difficult issues in analyzing and controlling the fractional-order memristive neural networks. By using the set-valued maps and fractional-order differential inclusions, then aided by a newly proposed fractional derivative inequality, this paper investigates the global Mittag-Leffler stabilization for a class of fractional-order memristive neural networks. Two types of control rules (i.e., state feedback stabilizing control and output feedback stabilizing control) are designed for the stabilization of fractional-order memristive neural networks, while a list of stabilization criteria is established. Finally, two numerical examples are given to show the effectiveness and characteristics of the obtained theoretical results.",4
Asymmetric Actuator Backlash Compensation in Quantized Adaptive Control of Uncertain Networked Nonlinear Systems.,"This paper mainly aims at the problem of adaptive quantized control for a class of uncertain nonlinear systems preceded by asymmetric actuator backlash. One challenging problem that blocks the construction of our control scheme is that the real control signal is wrapped in the coupling of quantization effect and nonsmooth backlash nonlinearity. To resolve this challenge, this paper presents a two-stage separation approach established on two new technical components, which are the approximate asymmetric backlash model and the nonlinear decomposition of quantizer, respectively. Then the real control is successfully separated from the coupling dynamics. Furthermore, by employing the neural networks and adaptation method in control design, a quantized controller is developed to guarantee the asymptotic convergence of tracking error to an adjustable region of zero and uniform ultimate boundedness of all closed-loop signals. Eventually, simulations are conducted to support our theoretical results.",4
Value and Policy Iterations in Optimal Control and Adaptive Dynamic Programming.,"In this paper, we consider discrete-time infinite horizon problems of optimal control to a terminal set of states. These are the problems that are often taken as the starting point for adaptive dynamic programming. Under very general assumptions, we establish the uniqueness of the solution of Bellman's equation, and we provide convergence results for value and policy iterations.",4
Asynchronous Dissipative State Estimation for Stochastic Complex Networks With Quantized Jumping Coupling and Uncertain Measurements.,"This paper addresses the problem of state estimation for a class of discrete-time stochastic complex networks with a constrained and randomly varying coupling and uncertain measurements. The randomly varying coupling is governed by a Markov chain, and the capacity constraint is handled by introducing a logarithmic quantizer. The uncertainty of measurements is modeled by a multiplicative noise. An asynchronous estimator is designed to overcome the difficulty that each node cannot access to the coupling information, and an augmented estimation error system is obtained using the Kronecker product. Sufficient conditions are established, which guarantee that the estimation error system is stochastically stable and achieves the strict (Q, S, R)-gamma-dissipativity. Then, the estimator gains are derived using the linear matrix inequality method. Finally, a numerical example is provided to illustrate the effectiveness of the proposed new design techniques.",4
Propagation of Collective Temporal Regularity in Noisy Hierarchical Networks.,"Neuronal communication between different brain areas is achieved in terms of spikes. Consequently, spike-time regularity is closely related to many cognitive tasks and timing precision of neural information processing. A recent experiment on primate parietal cortex reports that spike-time regularity increases consistently from primary sensory to higher cortical regions. This observation conflicts with the influential view that spikes in the neocortex are fundamentally irregular. To uncover the underlying network mechanism, we construct a multilayered feedforward neural information transmission pathway and investigate how spike-time regularity evolves across subsequent layers. Numerical results reveal that despite the obviously irregular spiking patterns in previous several layers, neurons in downstream layers can generate rather regular spikes, which depends on the network topology. In particular, we find that collective temporal regularity in deeper layers exhibits resonance-like behavior with respect to both synaptic connection probability and synaptic weight, i.e., the optimal topology parameter maximizes the spike-timing regularity. Furthermore, it is demonstrated that synaptic properties, including inhibition, synaptic transient dynamics, and plasticity, have significant impacts on spike-timing regularity propagation. The emergence of the increasingly regular spiking (RS) patterns in higher parietal regions can, thus, be viewed as a natural consequence of spiking activity propagation between different brain areas. Finally, we validate an important function served by increased RS: promoting reliable propagation of spike-rate signals across downstream layers.",4
Localized Multiple Kernel Learning With Dynamical Clustering and Matrix Regularization.,"Localized multiple kernel learning (LMKL) is an attractive strategy for combining multiple heterogeneous features with regard to their discriminative power for each individual sample. However, the learning of numerous local solutions may not scale well even for a moderately sized training set, and the independently learned local models may suffer from overfitting. Hence, in existing local methods, the distributed samples are typically assumed to share the same weights, and various unsupervised clustering methods are applied as preprocessing. In this paper, to enable the learner to discover and benefit from the underlying local coherence and diversity of the samples, we incorporate the clustering procedure into the canonical support vector machine-based LMKL framework. Then, to explore the relatedness among different samples, which has been ignored in a vector -norm analysis, we organize the cluster-specific kernel weights into a matrix and introduce a matrix-based extension of the -norm for constraint enforcement. By casting the joint optimization problem as a problem of alternating optimization, we show how the cluster structure is gradually revealed and how the matrix-regularized kernel weights are obtained. A theoretical analysis of such a regularizer is performed using a Rademacher complexity bound, and complementary empirical experiments on real-world data sets demonstrate the effectiveness of our technique.",4
Stabilization of Neural-Network-Based Control Systems via Event-Triggered Control With Nonperiodic Sampled Data.,"This paper focuses on a problem of event-triggered stabilization for a class of nonuniformly sampled neural-network-based control systems (NNBCSs). First, a new event-triggered data transmission mechanism is designed based on the nonperiodic sampled data. Different from the previous works, the proposed triggering scheme enables the NNBCSs design to enjoy the advantages of both nonuniform and event-triggered sampling schemes. Second, under the nonperiodic event-triggered data transmission scheme, the nonperiodic sampled-data three-layer fully connected feedforward neural-network (TLFCFFNN)-based event-triggered controller is constructed, and the resulting closed-loop TLFCFFNN-based event-triggered control system is modeled as a state delay system based on time-delay system modeling approach. Then, the stability criteria for the closed-loop system is formulated using Lyapunov-Krasovskii functional approach. Third, the sufficient conditions for the codesign of the TLFCFFNN-based controller and triggering parameters are given in terms of solvability of matrix inequalities to guarantee the asymptotical stability of the closed-loop system and an upper bound on the given cost function while reducing the updates of the controller. Finally, three numerical examples are provided to illustrate the effectiveness and benefits of the proposed results.",4
A Deep Convolutional Coupling Network for Change Detection Based on Heterogeneous Optical and Radar Images.,"We propose an unsupervised deep convolutional coupling network for change detection based on two heterogeneous images acquired by optical sensors and radars on different dates. Most existing change detection methods are based on homogeneous images. Due to the complementary properties of optical and radar sensors, there is an increasing interest in change detection based on heterogeneous images. The proposed network is symmetric with each side consisting of one convolutional layer and several coupling layers. The two input images connected with the two sides of the network, respectively, are transformed into a feature space where their feature representations become more consistent. In this feature space, the different map is calculated, which then leads to the ultimate detection map by applying a thresholding algorithm. The network parameters are learned by optimizing a coupling function. The learning process is unsupervised, which is different from most existing change detection methods based on heterogeneous images. Experimental results on both homogenous and heterogeneous images demonstrate the promising performance of the proposed network compared with several existing approaches.",4
Synchronization of General Chaotic Neural Networks With Nonuniform Sampling and Packet Missing: A Switched System Approach.,"This paper is concerned with the exponential synchronization issue of general chaotic neural networks subject to nonuniform sampling and control packet missing in the frame of the zero-input strategy. Based on this strategy, we make use of the switched system model to describe the synchronization error system. First, when the missing of control packet does not occur, an exponential stability criterion with less conservatism is established for the resultant synchronization error systems via a superior time-dependent Lyapunov functional and the convex optimization approach. The characteristics induced by nonuniform sampling can be used to the full because of the structure and property of the constructed Lyapunov functional, that is not necessary to be positive definite except sampling times. Then, a criterion is obtained to guarantee that the general chaotic neural networks are synchronous exponentially when the missing of control packet occurs by means of the average dwell-time technique. An explicit expression of the sampled-data static output feedback controller is also gained. Finally, the effectiveness of the proposed new design methods is shown via two examples.",4
Insights Into the Robustness of Minimum Error Entropy Estimation.,"The minimum error entropy (MEE) is an important and highly effective optimization criterion in information theoretic learning (ITL). For regression problems, MEE aims at minimizing the entropy of the prediction error such that the estimated model preserves the information of the data generating system as much as possible. In many real world applications, the MEE estimator can outperform significantly the well-known minimum mean square error (MMSE) estimator and show strong robustness to noises especially when data are contaminated by non-Gaussian (multimodal, heavy tailed, discrete valued, and so on) noises. In this brief, we present some theoretical results on the robustness of MEE. For a one-parameter linear errors-in-variables (EIV) model and under some conditions, we derive a region that contains the MEE solution, which suggests that the MEE estimate can be very close to the true value of the unknown parameter even in presence of arbitrarily large outliers in both input and output variables. Theoretical prediction is verified by an illustrative example.",4
A One-Layer Recurrent Neural Network for Constrained Complex-Variable Convex Optimization.,"In this paper, based on calculus and penalty method, a one-layer recurrent neural network is proposed for solving constrained complex-variable convex optimization. It is proved that for any initial point from a given domain, the state of the proposed neural network reaches the feasible region in finite time and converges to an optimal solution of the constrained complex-variable convex optimization finally. In contrast to existing neural networks for complex-variable convex optimization, the proposed neural network has a lower model complexity and better convergence. Some numerical examples and application are presented to substantiate the effectiveness of the proposed neural network.",4
Nonlinear Process Fault Diagnosis Based on Serial Principal Component Analysis.,"Many industrial processes contain both linear and nonlinear parts, and kernel principal component analysis (KPCA), widely used in nonlinear process monitoring, may not offer the most effective means for dealing with these nonlinear processes. This paper proposes a new hybrid linear-nonlinear statistical modeling approach for nonlinear process monitoring by closely integrating linear principal component analysis (PCA) and nonlinear KPCA using a serial model structure, which we refer to as serial PCA (SPCA). Specifically, PCA is first applied to extract PCs as linear features, and to decompose the data into the PC subspace and residual subspace (RS). Then, KPCA is performed in the RS to extract the nonlinear PCs as nonlinear features. Two monitoring statistics are constructed for fault detection, based on both the linear and nonlinear features extracted by the proposed SPCA. To effectively perform fault identification after a fault is detected, an SPCA similarity factor method is built for fault recognition, which fuses both the linear and nonlinear features. Unlike PCA and KPCA, the proposed method takes into account both linear and nonlinear PCs simultaneously, and therefore, it can better exploit the underlying process's structure to enhance fault diagnosis performance. Two case studies involving a simulated nonlinear process and the benchmark Tennessee Eastman process demonstrate that the proposed SPCA approach is more effective than the existing state-of-the-art approach based on KPCA alone, in terms of nonlinear process fault detection and identification.",4
Decoupled ARX and RBF Neural Network Modeling Using PCA and GA Optimization for Nonlinear Distributed Parameter Systems.,"Modeling of distributed parameter systems is difficult because of their nonlinearity and infinite-dimensional characteristics. Based on principal component analysis (PCA), a hybrid modeling strategy that consists of a decoupled linear autoregressive exogenous (ARX) model and a nonlinear radial basis function (RBF) neural network model are proposed. The spatial-temporal output is first divided into a few dominant spatial basis functions and finite-dimensional temporal series by PCA. Then, a decoupled ARX model is designed to model the linear dynamics of the dominant modes of the time series. The nonlinear residual part is subsequently parameterized by RBFs, where genetic algorithm is utilized to optimize their hidden layer structure and the parameters. Finally, the nonlinear spatial-temporal dynamic system is obtained after the time/space reconstruction. Simulation results of a catalytic rod and a heat conduction equation demonstrate the effectiveness of the proposed strategy compared to several other methods.",4
Forward Stagewise Additive Model for Collaborative Multiview Boosting.,"Multiview assisted learning has gained significant attention in recent years in supervised learning genre. Availability of high-performance computing devices enables learning algorithms to search simultaneously over multiple views or feature spaces to obtain an optimum classification performance. This paper is a pioneering attempt of formulating a mathematical foundation for realizing a multiview aided collaborative boosting architecture for multiclass classification. Most of the present algorithms apply multiview learning heuristically without exploring the fundamental mathematical changes imposed on traditional boosting. Also, most of the algorithms are restricted to two class or view setting. Our proposed mathematical framework enables collaborative boosting across any finite-dimensional view spaces for multiclass learning. The boosting framework is based on a forward stagewise additive model, which minimizes a novel exponential loss function. We show that the exponential loss function essentially captures the difficulty of a training sample space instead of the traditional ""1/0"" loss. The new algorithm restricts a weak view from overlearning and thereby preventing overfitting. The model is inspired by our earlier attempt on collaborative boosting, which was devoid of mathematical justification. The proposed algorithm is shown to converge much nearer to global minimum in the exponential loss space and thus supersedes our previous algorithm. This paper also presents analytical and numerical analyses of convergence and margin bounds for multiview boosting algorithms and we show that our proposed ensemble learning manifests lower error bound and higher margin compared with our previous model. Also, the proposed model is compared with traditional boosting and recent multiview boosting algorithms. In the majority of instances, the new algorithm manifests a faster rate of convergence on training set error and also simultaneously offers better generalization performance. The kappa-error diagram analysis reveals the robustness of the proposed boosting framework to labeling noise.",4
Learning to Predict Eye Fixations via Multiresolution Convolutional Neural Networks.,"Eye movements in the case of freely viewing natural scenes are believed to be guided by local contrast, global contrast, and top-down visual factors. Although a lot of previous works have explored these three saliency cues for several years, there still exists much room for improvement on how to model them and integrate them effectively. This paper proposes a novel computation model to predict eye fixations, which adopts a multiresolution convolutional neural network (Mr-CNN) to infer these three types of saliency cues from raw image data simultaneously. The proposed Mr-CNN is trained directly from fixation and nonfixation pixels with multiresolution input image regions with different contexts. It utilizes image pixels as inputs and eye fixation points as labels. Then, both the local and global contrasts are learned by fusing information in multiple contexts. Meanwhile, various top-down factors are learned in higher layers. Finally, optimal combination of top-down factors and bottom-up contrasts can be learned to predict eye fixations. The proposed approach significantly outperforms the state-of-the-art methods on several publically available benchmark databases, demonstrating the superiority of Mr-CNN. We also apply our method to the RGB-D image saliency detection problem. Through learning saliency cues induced by depth and RGB information on pixel level jointly and their interactions, our model achieves better performance on predicting eye fixations in RGB-D images.",4
Constrained Null Space Component Analysis for Semiblind Source Separation Problem.,"The blind source separation (BSS) problem extracts unknown sources from observations of their unknown mixtures. A current trend in BSS is the semiblind approach, which incorporates prior information on sources or how the sources are mixed. The constrained independent component analysis (ICA) approach has been studied to impose constraints on the famous ICA framework. We introduced an alternative approach based on the null space component (NCA) framework and referred to the approach as the c-NCA approach. We also presented the c-NCA algorithm that uses signal-dependent semidefinite operators, which is a bilinear mapping, as signatures for operator design in the c-NCA approach. Theoretically, we showed that the source estimation of the c-NCA algorithm converges with a convergence rate dependent on the decay of the sequence, obtained by applying the estimated operators on corresponding sources. The c-NCA can be formulated as a deterministic constrained optimization method, and thus, it can take advantage of solvers developed in optimization society for solving the BSS problem. As examples, we demonstrated electroencephalogram interference rejection problems can be solved by the c-NCA with proximal splitting algorithms by incorporating a sparsity-enforcing separation model and considering the case when reference signals are available.",4
Real-Time Decentralized Neural Control via Backstepping for a Robotic Arm Powered by Industrial Servomotors.,"This paper presents a continuous-time decentralized neural control scheme for trajectory tracking of a two degrees of freedom direct drive vertical robotic arm. A decentralized recurrent high-order neural network (RHONN) structure is proposed to identify online, in a series-parallel configuration and using the filtered error learning law, the dynamics of the plant. Based on the RHONN subsystems, a local neural controller is derived via backstepping approach. The effectiveness of the decentralized neural controller is validated on a robotic arm platform, of our own design and unknown parameters, which uses industrial servomotors to drive the joints.",4
Network Unfolding Map by Vertex-Edge Dynamics Modeling.,"The emergence of collective dynamics in neural networks is a mechanism of the animal and human brain for information processing. In this paper, we develop a computational technique using distributed processing elements in a complex network, which are called particles, to solve semisupervised learning problems. Three actions govern the particles' dynamics: generation, walking, and absorption. Labeled vertices generate new particles that compete against rival particles for edge domination. Active particles randomly walk in the network until they are absorbed by either a rival vertex or an edge currently dominated by rival particles. The result from the model evolution consists of sets of edges arranged by the label dominance. Each set tends to form a connected subnetwork to represent a data class. Although the intrinsic dynamics of the model is a stochastic one, we prove that there exists a deterministic version with largely reduced computational complexity; specifically, with linear growth. Furthermore, the edge domination process corresponds to an unfolding map in such way that edges ""stretch"" and ""shrink"" according to the vertex-edge dynamics. Consequently, the unfolding effect summarizes the relevant relationships between vertices and the uncovered data classes. The proposed model captures important details of connectivity patterns over the vertex-edge dynamics evolution, in contrast to the previous approaches, which focused on only vertex or only edge dynamics. Computer simulations reveal that the new model can identify nonlinear features in both real and artificial data, including boundaries between distinct classes and overlapping structures of data.",4
Passivity and Output Synchronization of Complex Dynamical Networks With Fixed and Adaptive Coupling Strength.,"This paper considers a complex dynamical network model, in which the input and output vectors have different dimensions. We, respectively, investigate the passivity and the relationship between output strict passivity and output synchronization of the complex dynamical network with fixed and adaptive coupling strength. First, two new passivity definitions are proposed, which generalize some existing concepts of passivity. By constructing appropriate Lyapunov functional, some sufficient conditions ensuring the passivity, input strict passivity and output strict passivity are derived for the complex dynamical network with fixed coupling strength. In addition, we also reveal the relationship between output strict passivity and output synchronization of the complex dynamical network with fixed coupling strength. By employing the relationship between output strict passivity and output synchronization, a sufficient condition for output synchronization of the complex dynamical network with fixed coupling strength is established. Then, we extend these results to the case when the coupling strength is adaptively adjusted. Finally, two examples with numerical simulations are provided to demonstrate the effectiveness of the proposed criteria.",4
Multivariate Cryptography Based on Clipped Hopfield Neural Network.,"Designing secure and efficient multivariate public key cryptosystems [multivariate cryptography (MVC)] to strengthen the security of RSA and ECC in conventional and quantum computational environment continues to be a challenging research in recent years. In this paper, we will describe multivariate public key cryptosystems based on extended Clipped Hopfield Neural Network (CHNN) and implement it using the MVC (CHNN-MVC) framework operated in space. The Diffie-Hellman key exchange algorithm is extended into the matrix field, which illustrates the feasibility of its new applications in both classic and postquantum cryptography. The efficiency and security of our proposed new public key cryptosystem CHNN-MVC are simulated and found to be NP-hard. The proposed algorithm will strengthen multivariate public key cryptosystems and allows hardware realization practicality.",4
Concept Factorization With Adaptive Neighbors for Document Clustering.,"In this paper, a novel concept factorization (CF) method, called CF with adaptive neighbors (CFANs), is proposed. The idea of CFAN is to integrate an ANs regularization constraint into the CF decomposition. The goal of CFAN is to extract the representation space that maintains geometrical neighborhood structure of the data. Similar to the existing graph-regularized CF, CFAN builds a neighbor graph weights matrix. The key difference is that the CFAN performs dimensionality reduction and finds the neighbor graph weights matrix simultaneously. An efficient algorithm is also derived to solve the proposed problem. We apply the proposed method to the problem of document clustering on the 20 Newsgroups, Reuters-21578, and TDT2 document data sets. Our experiments demonstrate the effectiveness of the method.",4
Multisynchronization of Coupled Heterogeneous Genetic Oscillator Networks via Partial Impulsive Control.,"This paper focuses on the collective dynamics of multisynchronization among heterogeneous genetic oscillators under a partial impulsive control strategy. The coupled nonidentical genetic oscillators are modeled by differential equations with uncertainties. The definition of multisynchronization is proposed to describe some more general synchronization behaviors in the real. Considering that each genetic oscillator consists of a large number of biochemical molecules, we design a more manageable impulsive strategy for dynamic networks to achieve multisynchronization. Not all the molecules but only a small fraction of them in each genetic oscillator are controlled at each impulsive instant. Theoretical analysis of multisynchronization is carried out by the control theory approach, and a sufficient condition of partial impulsive controller for multisynchronization with given error bounds is established. At last, numerical simulations are exploited to demonstrate the effectiveness of our results.",4
A Novel Algorithm for Learning Sparse Spatio-Spectral Patterns for Event-Related Potentials.,"Recent years have witnessed brain-computer interface (BCI) as a promising technology for integrating human intelligence and machine intelligence. Currently, event-related potential (ERP)-based BCI is an important branch of noninvasive electroencephalogram (EEG)-based BCIs. Extracting ERPs from a limited number of trials remains challenging due to their low signal-to-noise ratio (SNR) and low spatial resolution caused by volume conduction. In this paper, we propose a probabilistic model for trial-by-trial concatenated EEG, in which the concatenated ERPs are expressed as a linear combination of a set of discrete sine and cosine bases. The bases are simply determined by the data length of a single trial. A sparse prior on the rank of the spatio-spectral pattern matrix is introduced into the model to allow the number of components to be automatically determined. A maximum posterior estimation algorithm based on cyclic descent is then developed to estimate the spatiospectral patterns. A spatial filter can then be obtained by maximizing the SNR of the ERP components. Experiments on both synthetic data and real N170 ERP from 13 subjects were conducted to test the efficacy and efficiency of the algorithm. The results showed that the proposed algorithm can estimate the ERPs more accurately than the several state-of-the-art algorithms.",4
Neuroadaptive Fault-Tolerant Control of Nonlinear Systems Under Output Constraints and Actuation Faults.,"In this paper, a neuroadaptive fault-tolerant tracking control method is proposed for a class of time-delay pure-feedback systems in the presence of external disturbances and actuation faults. The proposed controller can achieve prescribed transient and steady-state performance, despite uncertain time delays and output constraints as well as actuation faults. By combining a tangent barrier Lyapunov-Krasovskii function with the dynamic surface control technique, the neural network unit in the developed control scheme is able to take its action from the very beginning and play its learning/approximating role safely during the entire system operational envelope, leading to enhanced control performance without the danger of violating compact set precondition. Furthermore, prescribed transient performance and output constraints are strictly ensured in the presence of nonaffine uncertainties, external disturbances, and undetectable actuation faults. The control strategy is also validated by numerical simulation.",4
Deep Logic Networks: Inserting and Extracting Knowledge From Deep Belief Networks.,"Developments in deep learning have seen the use of layerwise unsupervised learning combined with supervised learning for fine-tuning. With this layerwise approach, a deep network can be seen as a more modular system that lends itself well to learning representations. In this paper, we investigate whether such modularity can be useful to the insertion of background knowledge into deep networks, whether it can improve learning performance when it is available, and to the extraction of knowledge from trained deep networks, and whether it can offer a better understanding of the representations learned by such networks. To this end, we use a simple symbolic language-a set of logical rules that we call confidence rules-and show that it is suitable for the representation of quantitative reasoning in deep networks. We show by knowledge extraction that confidence rules can offer a low-cost representation for layerwise networks (or restricted Boltzmann machines). We also show that layerwise extraction can produce an improvement in the accuracy of deep belief networks. Furthermore, the proposed symbolic characterization of deep networks provides a novel method for the insertion of prior knowledge and training of deep networks. With the use of this method, a deep neural-symbolic system is proposed and evaluated, with the experimental results indicating that modularity through the use of confidence rules and knowledge insertion can be beneficial to network performance.",4
Synchronization of an Inertial Neural Network With Time-Varying Delays and Its Application to Secure Communication.,"In this paper, synchronization of an inertial neural network with time-varying delays is investigated. Based on the variable transformation method, we transform the second-order differential equations into the first-order differential equations. Then, using suitable Lyapunov-Krasovskii functionals and Jensen's inequality, the synchronization criteria are established in terms of linear matrix inequalities. Moreover, a feedback controller is designed to attain synchronization between the master and slave models, and to ensure that the error model is globally asymptotically stable. Numerical examples and simulations are presented to indicate the effectiveness of the proposed method. Besides that, an image encryption algorithm is proposed based on the piecewise linear chaotic map and the chaotic inertial neural network. The chaotic signals obtained from the inertial neural network are utilized for the encryption process. Statistical analyses are provided to evaluate the effectiveness of the proposed encryption algorithm. The results ascertain that the proposed encryption algorithm is efficient and reliable for secure communication applications.",4
Hysteretic Noisy Chaotic Neural Networks for Resource Allocation in OFDMA System.,"This paper addresses two-stage resource allocation in the orthogonal frequency division multiplexing access system. In the subcarrier allocation stage, hysteretic noisy chaotic neural network (HNCNN) with a newly established energy function is proposed for subcarrier allocation to improve the optimization performance and reduce the computational complexity. Activation functions with both anticlockwise and clockwise hysteretic loops are applied to the HNCNN. A new energy function is established for an objective function, which can be calculated offline, resulting in a lower computational complexity in solving subcarrier allocation than the previous energy function. In the power allocation stage, the water-filling algorithm is employed to attain optimal power allocation. Simulation results show that the energy function established in this paper can decrease the runtimes of the neural networks, and that the HNCNN with both anticlockwise and clockwise hysteretic-loop activation functions can improve probabilities of feasible and optimal solutions at higher noises. The two-stage algorithm in this paper outperforms the previous algorithms in fairness, system throughput, and resource utilization.",4
Decorrelation of Neutral Vector Variables: Theory and Applications.,"In this paper, we propose novel strategies for neutral vector variable decorrelation. Two fundamental invertible transformations, namely, serial nonlinear transformation and parallel nonlinear transformation, are proposed to carry out the decorrelation. For a neutral vector variable, which is not multivariate-Gaussian distributed, the conventional principal component analysis cannot yield mutually independent scalar variables. With the two proposed transformations, a highly negatively correlated neutral vector can be transformed to a set of mutually independent scalar variables with the same degrees of freedom. We also evaluate the decorrelation performances for the vectors generated from a single Dirichlet distribution and a mixture of Dirichlet distributions. The mutual independence is verified with the distance correlation measurement. The advantages of the proposed decorrelation strategies are intensively studied and demonstrated with synthesized data and practical application evaluations.",4
An Exemplar-Based Multi-View Domain Generalization Framework for Visual Recognition.,"In this paper, we propose a new exemplar-based multi-view domain generalization (EMVDG) framework for visual recognition by learning robust classifier that are able to generalize well to arbitrary target domain based on the training samples with multiple types of features (i.e., multi-view features). In this framework, we aim to address two issues simultaneously. First, the distribution of training samples (i.e., the source domain) is often considerably different from that of testing samples (i.e., the target domain), so the performance of the classifiers learnt on the source domain may drop significantly on the target domain. Moreover, the testing data are often unseen during the training procedure. Second, when the training data are associated with multi-view features, the recognition performance can be further improved by exploiting the relation among multiple types of features. To address the first issue, considering that it has been shown that fusing multiple SVM classifiers can enhance the domain generalization ability, we build our EMVDG framework upon exemplar SVMs (ESVMs), in which a set of ESVM classifiers are learnt with each one trained based on one positive training sample and all the negative training samples. When the source domain contains multiple latent domains, the learnt ESVM classifiers are expected to be grouped into multiple clusters. To address the second issue, we propose two approaches under the EMVDG framework based on the consensus principle and the complementary principle, respectively. Specifically, we propose an EMVDG_CO method by adding a co-regularizer to enforce the cluster structures of ESVM classifiers on different views to be consistent based on the consensus principle. Inspired by multiple kernel learning, we also propose another EMVDG_MK method by fusing the ESVM classifiers from different views based on the complementary principle. In addition, we further extend our EMVDG framework to exemplar-based multi-view domain adaptation (EMVDA) framework when the unlabeled target domain data are available during the training procedure. The effectiveness of our EMVDG and EMVDA frameworks for visual recognition is clearly demonstrated by comprehensive experiments on three benchmark data sets.",4
Face Alignment With Deep Regression.,"In this paper, we present a deep regression approach for face alignment. The deep regressor is a neural network that consists of a global layer and multistage local layers. The global layer estimates the initial face shape from the whole image, while the following local layers iteratively update the shape with local image observations. Combining standard derivations and numerical approximations, we make all layers able to backpropagate error differentials, so that we can apply the standard backpropagation to jointly learn the parameters from all layers. We show that the resulting deep regressor gradually and evenly approaches the true facial landmarks stage by stage, avoiding the tendency that often occurs in the cascaded regression methods and deteriorates the overall performance: yielding early stage regressors with high alignment accuracy gains but later stage regressors with low alignment accuracy gains. Experimental results on standard benchmarks demonstrate that our approach brings significant improvements over previous cascaded regression algorithms.",4
Adaptive Iterative Learning Control for Linear Systems With Binary-Valued Observations.,"This brief presents a novel adaptive iterative learning control (ILC) algorithm for a class of single parameter systems with binary-valued observations. Using the certainty equivalence principle, the adaptive ILC algorithm is designed by employing a projection identification algorithm along the iteration axis. It is shown that, even though the available system information is very limited and the desired trajectory is iteration-varying, the proposed adaptive ILC algorithm can guarantee the convergence of parameter estimation over a finite-time interval along the iterative axis; meanwhile, the tracking error is pointwise convergence asymptotically. Two examples are given to validate the effectiveness of the algorithm.",4
Online Optimization With Costly and Noisy Measurements Using Random Fourier Expansions.,"This paper analyzes data-based online nonlinear extremum-seeker (DONE), an online optimization algorithm that iteratively minimizes an unknown function based on costly and noisy measurements. The algorithm maintains a surrogate of the unknown function in the form of a random Fourier expansion. The surrogate is updated whenever a new measurement is available, and then used to determine the next measurement point. The algorithm is comparable with Bayesian optimization algorithms, but its computational complexity per iteration does not depend on the number of measurements. We derive several theoretical results that provide insight on how the hyperparameters of the algorithm should be chosen. The algorithm is compared with a Bayesian optimization algorithm for an analytic benchmark problem and three applications, namely, optical coherence tomography, optical beam-forming network tuning, and robot arm control. It is found that the DONE algorithm is significantly faster than Bayesian optimization in the discussed problems while achieving a similar or better performance.",4
A Rotational Motion Perception Neural Network Based on Asymmetric Spatiotemporal Visual Information Processing.,"All complex motion patterns can be decomposed into several elements, including translation, expansion/contraction, and rotational motion. In biological vision systems, scientists have found that specific types of visual neurons have specific preferences to each of the three motion elements. There are computational models on translation and expansion/contraction perceptions; however, little has been done in the past to create computational models for rotational motion perception. To fill this gap, we proposed a neural network that utilizes a specific spatiotemporal arrangement of asymmetric lateral inhibited direction selective neural networks (DSNNs) for rotational motion perception. The proposed neural network consists of two parts-presynaptic and postsynaptic parts. In the presynaptic part, there are a number of lateral inhibited DSNNs to extract directional visual cues. In the postsynaptic part, similar to the arrangement of the directional columns in the cerebral cortex, these direction selective neurons are arranged in a cyclic order to perceive rotational motion cues. In the postsynaptic network, the delayed excitation from each direction selective neuron is multiplied by the gathered excitation from this neuron and its unilateral counterparts depending on which rotation, clockwise (cw) or counter-cw (ccw), to perceive. Systematic experiments under various conditions and settings have been carried out and validated the robustness and reliability of the proposed neural network in detecting cw or ccw rotational motion. This research is a critical step further toward dynamic visual information processing.All complex motion patterns can be decomposed into several elements, including translation, expansion/contraction, and rotational motion. In biological vision systems, scientists have found that specific types of visual neurons have specific preferences to each of the three motion elements. There are computational models on translation and expansion/contraction perceptions; however, little has been done in the past to create computational models for rotational motion perception. To fill this gap, we proposed a neural network that utilizes a specific spatiotemporal arrangement of asymmetric lateral inhibited direction selective neural networks (DSNNs) for rotational motion perception. The proposed neural network consists of two parts-presynaptic and postsynaptic parts. In the presynaptic part, there are a number of lateral inhibited DSNNs to extract directional visual cues. In the postsynaptic part, similar to the arrangement of the directional columns in the cerebral cortex, these direction selective neurons are arranged in a cyclic order to perceive rotational motion cues. In the postsynaptic network, the delayed excitation from each direction selective neuron is multiplied by the gathered excitation from this neuron and its unilateral counterparts depending on which rotation, clockwise (cw) or counter-cw (ccw), to perceive. Systematic experiments under various conditions and settings have been carried out and validated the robustness and reliability of the proposed neural network in detecting cw or ccw rotational motion. This research is a critical step further toward dynamic visual information processing.",4
Neural-Network-Based Adaptive Decentralized Fault-Tolerant Control for a Class of Interconnected Nonlinear Systems.,"This paper is concerned with the adaptive decentralized fault-tolerant tracking control problem for a class of uncertain interconnected nonlinear systems with unknown strong interconnections. An algebraic graph theory result is introduced to address the considered interconnections. In addition, to achieve the desirable tracking performance, a neural-network-based robust adaptive decentralized fault-tolerant control (FTC) scheme is given to compensate the actuator faults and system uncertainties. Furthermore, via the Lyapunov analysis method, it is proven that all the signals of the resulting closed-loop system are semiglobally bounded, and the tracking errors of each subsystem exponentially converge to a compact set, whose radius is adjustable by choosing different controller design parameters. Finally, the effectiveness and advantages of the proposed FTC approach are illustrated with two simulated examples.",4
Distinct Variation Pattern Discovery Using Alternating Nonlinear Principal Component Analysis.,"Autoassociative neural networks (ANNs) have been proposed as a nonlinear extension of principal component analysis (PCA), which is commonly used to identify linear variation patterns in high-dimensional data. While principal component scores represent uncorrelated features, standard backpropagation methods for training ANNs provide no guarantee of producing distinct features, which is important for interpretability and for discovering the nature of the variation patterns in the data. Here, we present an alternating nonlinear PCA method, which encourages learning of distinct features in ANNs. A new measure motivated by the condition of orthogonal loadings in PCA is proposed for measuring the extent to which the nonlinear principal components represent distinct variation patterns. We demonstrate the effectiveness of our method using a simulated point cloud data set as well as a subset of the MNIST handwritten digits data. The results show that standard ANNs consistently mix the true variation sources in the low-dimensional representation learned by the model, whereas our alternating method produces solutions where the patterns are better separated in the low-dimensional space.",4
Development of Quantum Local Potential Function Networks Based on Quantum Assimilation and Subspace Division.,"The centers and radii of radial basis functions (RBFs) greatly affect the approximation capability of RBF networks (RBFNs). Traditional statistics-based approaches are widely used, but they may lack adaptivity to different data structures. Quantum clustering (QC), derived from quantum mechanics and the Schrodinger equation, demonstrates excellent capability in finding the structure and conformity toward data distribution. In this paper, a novel neural networks model called quantum local potential function networks (QLPFNs) is proposed. The QLPFN inherits the outstanding properties of QC by constructing the waves and the potential functions, and the level of data concentration can be discovered to obtain the inherent structures of the given data set. The local potential functions form the basic components of the QLPFN structure, which are automatically generated from the subsets of training data following specific subspace division procedures. Therefore, the QLPFN model in fact incorporates the level of data concentration as a computation technique, which is different from the classical RBFN model that exhibits radial symmetry toward specific centers. Some application examples are given in this paper to show the effectiveness of the QLPFN model.",4
A Bi-Criteria Active Learning Algorithm for Dynamic Data Streams.,"Active learning (AL) is a promising way to efficiently build up training sets with minimal supervision. A learner deliberately queries specific instances to tune the classifier's model using as few labels as possible. The challenge for streaming is that the data distribution may evolve over time, and therefore the model must adapt. Another challenge is the sampling bias where the sampled training set does not reflect the underlying data distribution. In the presence of concept drift, sampling bias is more likely to occur as the training set needs to represent the whole evolving data. To tackle these challenges, we propose a novel bi-criteria AL (BAL) approach that relies on two selection criteria, namely, label uncertainty criterion and density-based criterion. While the first criterion selects instances that are the most uncertain in terms of class membership, the latter dynamically curbs the sampling bias by weighting the samples to reflect on the true underlying distribution. To design and implement these two criteria for learning from streams, BAL adopts a Bayesian online learning approach and combines online classification and online clustering through the use of online logistic regression and online growing Gaussian mixture models, respectively. Empirical results obtained on standard synthetic and real-world benchmarks show the high performance of the proposed BAL method compared with the state-of-the-art AL methods.",4
On Global Dissipativity of Nonautonomous Neural Networks With Multiple Proportional Delays.,"This brief addresses the problem of global dissipativity analysis of nonautonomous neural networks with multiple proportional delays. By using a novel constructive approach based on some comparison techniques for differential inequalities, new explicit delay-independent conditions are derived using M-matrix theory to ensure the existence of generalized exponential attracting sets and the global dissipativity of the system. The method presented in this brief is also utilized to derive a generalized exponential estimate for a class of Halanay-type inequalities with proportional delays. Finally, three numerical examples are given to illustrate the effectiveness and improvement of the obtained results.",4
An Efficient Representation-Based Method for Boundary Point and Outlier Detection.,"Detecting boundary points (including outliers) is often more interesting than detecting normal observations, since they represent valid, interesting, and potentially valuable patterns. Since data representation can uncover the intrinsic data structure, we present an efficient representation-based method for detecting such points, which are generally located around the margin of densely distributed data, such as a cluster. For each point, the negative components in its representation generally correspond to the boundary points among its affine combination of points. In the presented method, the reverse unreachability of a point is proposed to evaluate to what degree this observation is a boundary point. The reverse unreachability can be calculated by counting the number of zero and negative components in the representation. The reverse unreachability explicitly takes into account the global data structure and reveals the disconnectivity between a data point and other points. This paper reveals that the reverse unreachability of points with lower density has a higher score. Note that the score of reverse unreachability of an outlier is greater than that of a boundary point. The top- ranked points can thus be identified as outliers. The greater the value of the reverse unreachability, the more likely the point is a boundary point. Compared with related methods, our method better reflects the characteristics of the data, and simultaneously detects outliers and boundary points regardless of their distribution and the dimensionality of the space. Experimental results obtained for a number of synthetic and real-world data sets demonstrate the effectiveness and efficiency of our method.",4
Event-Based Robust Control for Uncertain Nonlinear Systems Using Adaptive Dynamic Programming.,"In this paper, the robust control problem for a class of continuous-time nonlinear system with unmatched uncertainties is investigated using an event-based control method. First, the robust control problem is transformed into a corresponding optimal control problem with an augmented control and an appropriate cost function. Under the event-based mechanism, we prove that the solution of the optimal control problem can asymptotically stabilize the uncertain system with an adaptive triggering condition. That is, the designed event-based controller is robust to the original uncertain system. Note that the event-based controller is updated only when the triggering condition is satisfied, which can save the communication resources between the plant and the controller. Then, a single network adaptive dynamic programming structure with experience replay technique is constructed to approach the optimal control policies. The stability of the closed-loop system with the event-based control policy and the augmented control policy is analyzed using the Lyapunov approach. Furthermore, we prove that the minimal intersample time is bounded by a nonzero positive constant, which excludes Zeno behavior during the learning process. Finally, two simulation examples are provided to demonstrate the effectiveness of the proposed control scheme.",4
A Consistent Model for Lazzaro Winner-Take-All Circuit With Invariant Subthreshold Behavior.,"This paper considers the basic Lazzaro winner-take-all analog computing circuit with N current inputs, N voltage outputs, and a bias current. Motivated by low-power applications, we find a mathematical accurate model of the network when all MOS devices remain inside the subthreshold region all along the transient. This involves analytical inequalities relating the range of admissible input currents to transistor parameters, to supply voltage, and to bias current. The restrictions are sufficiently weak to allow extra demands of functionality or performance. The technical novelty here is that by a slight cut of the maximal subthreshold domain and by choosing proper coordinates, we get a ordinary differential equation invariance problem on a rectangle of Re(N+1) space which is analytically tractable. A more precise localization of the asymptotically stable steady state inside the region of interest is also inferred. Although the work is mainly theoretical, an effort to infer simple, interpretable formulas useful for synthesis has been made. The results are numerically verified and their feasibility is discussed in detail. The subject matter is new and it is worth extending it to larger classes of circuits with regional behavior.",4
Group Component Analysis for Multiblock Data: Common and Individual Feature Extraction.,"Real-world data are often acquired as a collection of matrices rather than as a single matrix. Such multiblock data are naturally linked and typically share some common features while at the same time exhibiting their own individual features, reflecting the underlying data generation mechanisms. To exploit the linked nature of data, we propose a new framework for common and individual feature extraction (CIFE) which identifies and separates the common and individual features from the multiblock data. Two efficient algorithms termed common orthogonal basis extraction (COBE) are proposed to extract common basis is shared by all data, independent on whether the number of common components is known beforehand. Feature extraction is then performed on the common and individual subspaces separately, by incorporating dimensionality reduction and blind source separation techniques. Comprehensive experimental results on both the synthetic and real-world data demonstrate significant advantages of the proposed CIFE method in comparison with the state-of-the-art.",4
Echo State Networks With Orthogonal Pigeon-Inspired Optimization for Image Restoration.,"In this paper, a neurodynamic approach for image restoration is proposed. Image restoration is a process of estimating original images from blurred and/or noisy images. It can be considered as a mapping problem that can be solved by neural networks. Echo state network (ESN) is a recurrent neural network with a simplified training process, which is adopted to estimate the original images in this paper. The parameter selection is important to the performance of the ESN. Thus, the pigeon-inspired optimization (PIO) approach is employed in the training process of the ESN to obtain desired parameters. Moreover, the orthogonal design strategy is utilized in the initialization of PIO to improve the diversity of individuals. The proposed method is tested on several deteriorated images with different sorts and levels of blur and/or noise. Results obtained by the improved ESN are compared with those obtained by several state-of-the-art methods. It is verified experimentally that better image restorations can be obtained for different blurred and/or noisy instances with the proposed neurodynamic method. In addition, the performance of the orthogonal PIO algorithm is compared with that of several existing bioinspired optimization algorithms to confirm its superiority.",4
Asymptotically Stable Adaptive-Optimal Control Algorithm With Saturating Actuators and Relaxed Persistence of Excitation.,"This paper proposes a control algorithm based on adaptive dynamic programming to solve the infinite-horizon optimal control problem for known deterministic nonlinear systems with saturating actuators and nonquadratic cost functionals. The algorithm is based on an actor/critic framework, where a critic neural network (NN) is used to learn the optimal cost, and an actor NN is used to learn the optimal control policy. The adaptive control nature of the algorithm requires a persistence of excitation condition to be a priori validated, but this can be relaxed using previously stored data concurrently with current data in the update of the critic NN. A robustifying control term is added to the controller to eliminate the effect of residual errors, leading to the asymptotically stability of the closed-loop system. Simulation results show the effectiveness of the proposed approach for a controlled Van der Pol oscillator and also for a power system plant.",4
Exponential Stability and Stabilization of Delayed Memristive Neural Networks Based on Quadratic Convex Combination Method.,"This paper is concerned with the exponential stability and stabilization of memristive neural networks (MNNs) with delays. First, we present some generalized double-integral inequalities, which include some existing inequalities as their special cases. Second, combining with quadratic convex combination method, these double-integral inequalities are employed to formulate a delay-dependent stability condition for MNNs with delays. Third, a state-dependent switching control law is obtained for MNNs with delays based on the proposed stability conditions. The desired feedback gain matrices are accomplished by solving a set of linear matrix inequalities. Finally, the feasibility and effectiveness of the proposed results are tested by two numerical examples.",4
Feature Extraction Using Memristor Networks.,"Crossbar arrays of memristive elements are investigated for the implementation of dictionary learning and sparse coding of natural images. A winner-take-all training algorithm, in conjunction with Oja's rule, is used to learn an overcomplete dictionary of feature primitives that resemble Gabor filters. The dictionary is then used in the locally competitive algorithm to form a sparse representation of input images. The impacts of device nonlinearity and parameter variations are evaluated and a compensating procedure is proposed to ensure the robustness of the sparsification. It is shown that, with proper compensation, the memristor crossbar architecture can effectively perform sparse coding with distortion comparable with ideal software implementations at high sparsity, even in the presence of large device-to-device variations in the excess of 100%.",4
Optimizing Single-Trial EEG Classification by Stationary Matrix Logistic Regression in Brain-Computer Interface.,"In addition to the noisy and limited spatial resolution characteristics of the electroencephalography (EEG) signal, the intrinsic nonstationarity in the EEG data makes the single-trial EEG classification an even more challenging problem in brain-computer interface (BCI). Variations of the signal properties within a session often result in deteriorated classification performance. This is mainly attributed to the reason that the routine feature extraction or classification method does not take the changes in the signal into account. Although several extensions to the standard feature extraction method have been proposed to reduce the sensitivity to nonstationarity in data, they optimize different objective functions from that of the subsequent classification model, and thereby, the extracted features may not be optimized for the classification. In this paper, we propose an approach that directly optimizes the classifier's discriminativity and robustness against the within-session nonstationarity of the EEG data through a single optimization paradigm, and show that it can greatly improve the performance, in particular for the subjects who have difficulty in controlling a BCI. Moreover, the experimental results on two benchmark data sets demonstrate that our approach significantly outperforms the compared approaches in reducing classification error rates.",4
Identification of Nonlinear Spatiotemporal Dynamical Systems With Nonuniform Observations Using Reproducing-Kernel-Based Integral Least Square Regulation.,"The identification of nonlinear spatiotemporal dynamical systems given by partial differential equations has attracted a lot of attention in the past decades. Several methods, such as searching principle-based algorithms, partially linear kernel methods, and coupled lattice methods, have been developed to address the identification problems. However, most existing methods have some restrictions on sampling processes in that the sampling intervals should usually be very small and uniformly distributed in spatiotemporal domains. These are actually not applicable for some practical applications. In this paper, to tackle this issue, a novel kernel-based learning algorithm named integral least square regularization regression (ILSRR) is proposed, which can be used to effectively achieve accurate derivative estimation for nonlinear functions in the time domain. With this technique, a discretization method named inverse meshless collocation is then developed to realize the dimensional reduction of the system to be identified. Thereafter, with this novel inverse meshless collocation model, the ILSRR, and a multiple-kernel-based learning algorithm, a multistep identification method is systematically proposed to address the identification problem of spatiotemporal systems with pointwise nonuniform observations. Numerical studies for benchmark systems with necessary discussions are presented to illustrate the effectiveness and the advantages of the proposed method.",4
Multi-AUV Target Search Based on Bioinspired Neurodynamics Model in 3-D Underwater Environments.,"Target search in 3-D underwater environments is a challenge in multiple autonomous underwater vehicles (multi-AUVs) exploration. This paper focuses on an effective strategy for multi-AUV target search in the 3-D underwater environments with obstacles. First, the Dempster-Shafer theory of evidence is applied to extract information of environment from the sonar data to build a grid map of the underwater environments. Second, a topologically organized bioinspired neurodynamics model based on the grid map is constructed to represent the dynamic environment. The target globally attracts the AUVs through the dynamic neural activity landscape of the model, while the obstacles locally push the AUVs away to avoid collision. Finally, the AUVs plan their search path to the targets autonomously by a steepest gradient descent rule. The proposed algorithm deals with various situations, such as static targets search, dynamic targets search, and one or several AUVs break down in the 3-D underwater environments with obstacles. The simulation results show that the proposed algorithm is capable of guiding multi-AUV to achieve search task of multiple targets with higher efficiency and adaptability compared with other algorithms.",4
Detecting Wash Trade in Financial Market Using Digraphs and Dynamic Programming.,"A wash trade refers to the illegal activities of traders who utilize carefully designed limit orders to manually increase the trading volumes for creating a false impression of an active market. As one of the primary formats of market abuse, a wash trade can be extremely damaging to the proper functioning and integrity of capital markets. The existing work focuses on collusive clique detections based on certain assumptions of trading behaviors. Effective approaches for analyzing and detecting wash trade in a real-life market have yet to be developed. This paper analyzes and conceptualizes the basic structures of the trading collusion in a wash trade by using a directed graph of traders. A novel method is then proposed to detect the potential wash trade activities involved in a financial instrument by first recognizing the suspiciously matched orders and then further identifying the collusions among the traders who submit such orders. Both steps are formulated as a simplified form of the knapsack problem, which can be solved by dynamic programming approaches. The proposed approach is evaluated on seven stock data sets from the NASDAQ and the London Stock Exchange. The experimental results show that the proposed approach can effectively detect all primary wash trade scenarios across the selected data sets.",4
Online Learning ARMA Controllers With Guaranteed Closed-Loop Stability.,"This paper presents a novel online block adaptive learning algorithm for autoregressive moving average (ARMA) controller design based on the real data measured from the plant. The method employs ARMA input-output models both for the plant and the resulting closed-loop system. In a sliding window, the plant model parameters are identified first offline using a supervised learning algorithm minimizing an epsilon -insensitive and regularized identification error, which is the window average of the distances between the measured plant output and the model output for the input provided by the controller. The optimal controller parameters are then determined again offline for another sliding window as the solution to a constrained optimization problem, where the cost is the epsilon -insensitive and regularized output tracking error and the constraints that are linear inequalities of the controller parameters are imposed for ensuring the closed-loop system to be Schur stable. Not only the identification phase but also the controller design phase uses the input-output samples measured from the plant during online learning. In the developed online controller design method, the controller parameters can always be kept in a parameter region providing Schur stability for the closed-loop system. The epsilon -insensitiveness provides robustness against disturbances, so does the regularization better generalization performance in the identification and the control. The method is tested on benchmark plants, including the inverted pendulum and dc motor models. The method is also tested on an emulated and also a real dc motor by online block adaptive learning ARMA controllers, in particular, Proportional-Integral-Derivative controllers.",4
Improving on Deterministic Approximate Bayesian Inferences for Mixture Distributions.,"This paper presents the branching approach, which can improve deterministic implementation methods (such as variational Bayesian inference and expectation propagation method) for Bayesian mixture distributions. This proposed approach utilizes a set of artificial conditions defined by using the latent variables of the mixture distribution. This condition set is updated iteratively by branching based on a condition selected from the previous condition set. The target approximate Bayesian inference is obtained by merging the approximate conditional inferences under each condition in the condition set. The proposed approach is compared with several standard implementation methods by using a numerical example and a real-world example.",4
Robust Kernel Low-Rank Representation.,"Recently, low-rank representation (LRR) has shown promising performance in many real-world applications such as face clustering. However, LRR may not achieve satisfactory results when dealing with the data from nonlinear subspaces, since it is originally designed to handle the data from linear subspaces in the input space. Meanwhile, the kernel-based methods deal with the nonlinear data by mapping it from the original input space to a new feature space through a kernel-induced mapping. To effectively cope with the nonlinear data, we first propose the kernelized version of LRR in the clean data case. We also present a closed-form solution for the resultant optimization problem. Moreover, to handle corrupted data, we propose the robust kernel LRR (RKLRR) approach, and develop an efficient optimization algorithm to solve it based on the alternating direction method. In particular, we show that both the subproblems in our optimization algorithm can be efficiently and exactly solved, and it is guaranteed to obtain a globally optimal solution. Besides, our proposed algorithm can also solve the original LRR problem, which is a special case of our RKLRR when using the linear kernel. In addition, based on our new optimization technique, the kernelization of some variants of LRR can be similarly achieved. Comprehensive experiments on synthetic data sets and real-world data sets clearly demonstrate the efficiency of our algorithm, as well as the effectiveness of RKLRR and the kernelization of two variants of LRR.",4
A Comparison of Algorithms for Learning Hidden Variables in Bayesian Factor Graphs in Reduced Normal Form.,"Bayesian-directed acyclic discrete-variable graphs are reduced to a simplified normal form made up of only replicator units (or equal constraint units), source, and single-input/single-output blocks. In this framework, the same adaptation algorithm can be applied to all the parametric blocks. We obtain and compare adaptation rules derived from a constrained maximum likelihood formulation and a minimum Kullback-Leibler divergence criterion using Karush-Kuhn-Tucker conditions. The learning algorithms are compared with two other updating equations based on localized decisions and on a variational approximation, respectively. The performance of the various algorithms is verified on synthetic data sets for various architectures. Factor graphs in reduced normal form provide an appealing framework for rapid deployment of Bayesian-directed graphs in the applications.",4
Efficient $\chi ^{2}$ Kernel Linearization via Random Feature Maps.,"Explicit feature mapping is an appealing way to linearize additive kernels, such as chi(2) kernel for training large-scale support vector machines (SVMs). Although accurate in approximation, feature mapping could pose computational challenges in high-dimensional settings as it expands the original features to a higher dimensional space. To handle this issue in the context of chi(2) kernel SVMs learning, we introduce a simple yet efficient method to approximately linearize chi(2) kernel through random feature maps. The main idea is to use sparse random projection to reduce the dimensionality of feature maps while preserving their approximation capability to the original kernel. We provide approximation error bound for the proposed method. Furthermore, we extend our method to chi(2) multiple kernel SVMs learning. Extensive experiments on large-scale image classification tasks confirm that the proposed approach is able to significantly speed up the training process of the chi(2) kernel SVMs at almost no cost of testing accuracy.",4
Sparse Bayesian Classification of EEG for Brain-Computer Interface.,"Regularization has been one of the most popular approaches to prevent overfitting in electroencephalogram (EEG) classification of brain-computer interfaces (BCIs). The effectiveness of regularization is often highly dependent on the selection of regularization parameters that are typically determined by cross-validation (CV). However, the CV imposes two main limitations on BCIs: 1) a large amount of training data is required from the user and 2) it takes a relatively long time to calibrate the classifier. These limitations substantially deteriorate the system's practicability and may cause a user to be reluctant to use BCIs. In this paper, we introduce a sparse Bayesian method by exploiting Laplace priors, namely, SBLaplace, for EEG classification. A sparse discriminant vector is learned with a Laplace prior in a hierarchical fashion under a Bayesian evidence framework. All required model parameters are automatically estimated from training data without the need of CV. Extensive comparisons are carried out between the SBLaplace algorithm and several other competing methods based on two EEG data sets. The experimental results demonstrate that the SBLaplace algorithm achieves better overall performance than the competing algorithms for EEG classification.",4
RBoost: Label Noise-Robust Boosting Algorithm Based on a Nonconvex Loss Function and the Numerically Stable Base Learners.,"AdaBoost has attracted much attention in the machine learning community because of its excellent performance in combining weak classifiers into strong classifiers. However, AdaBoost tends to overfit to the noisy data in many applications. Accordingly, improving the antinoise ability of AdaBoost plays an important role in many applications. The sensitiveness to the noisy data of AdaBoost stems from the exponential loss function, which puts unrestricted penalties to the misclassified samples with very large margins. In this paper, we propose two boosting algorithms, referred to as RBoost1 and RBoost2, which are more robust to the noisy data compared with AdaBoost. RBoost1 and RBoost2 optimize a nonconvex loss function of the classification margin. Because the penalties to the misclassified samples are restricted to an amount less than one, RBoost1 and RBoost2 do not overfocus on the samples that are always misclassified by the previous base learners. Besides the loss function, at each boosting iteration, RBoost1 and RBoost2 use numerically stable ways to compute the base learners. These two improvements contribute to the robustness of the proposed algorithms to the noisy training and testing samples. Experimental results on the synthetic Gaussian data set, the UCI data sets, and a real malware behavior data set illustrate that the proposed RBoost1 and RBoost2 algorithms perform better when the training data sets contain noisy data.",4
Decomposition Techniques for Multilayer Perceptron Training.,"In this paper, we consider the learning problem of multilayer perceptrons (MLPs) formulated as the problem of minimizing a smooth error function. As well known, the learning problem of MLPs can be a difficult nonlinear nonconvex optimization problem. Typical difficulties can be the presence of extensive flat regions and steep sided valleys in the error surface, and the possible large number of training data and of free network parameters. We define a wide class of batch learning algorithms for MLP, based on the use of block decomposition techniques in the minimization of the error function. The learning problem is decomposed into a sequence of smaller and structured minimization problems in order to advantageously exploit the structure of the objective function. Theoretical convergence results are established, and a specific algorithm is constructed and evaluated through an extensive numerical experimentation. The comparisons with the state-of-the-art learning algorithms show the effectiveness of the proposed techniques.",4
Estimating Sensorimotor Mapping From Stimuli to Behaviors to Infer C. elegans Movements by Neural Transmission Ability Through Connectome Databases.,"One of the ultimate goals of computational neuroscience is to quantitatively connect between complex neural circuits and behaviors. In the past decades, the touch response circuit in Caenorhabditis elegans (C. elegans) has extensively been investigated in studies using genetically modified or laser-ablated worms. Synaptic connections, including chemical and electrical synapses, have been identified for most neurons in the C. elegans. However, we still do not know whether the empirically observed touch responses can be derived from connectome reconstructed from databases. To address this issue, we defined the transmission abilities (or levels) of neurons in a rate model in order to infer the behaviors of wild-type and ablated worms in response to posterior/nose/anterior touch stimuli. Our analysis showed that transmission abilities can be used to identify sensorimotor mapping from stimuli to movements and then to infer the C. elegans behaviors under simulations based on the perspective of decision-making, and provide useful information about how chemical and electronic synapses should be combined in the neural network movement analysis. This paper reveals an efficient tool that provided insights into the functions of complex neural circuits.",4
Multiple Representations-Based Face Sketch-Photo Synthesis.,"Face sketch-photo synthesis plays an important role in law enforcement and digital entertainment. Most of the existing methods only use pixel intensities as the feature. Since face images can be described using features from multiple aspects, this paper presents a novel multiple representations-based face sketch-photo-synthesis method that adaptively combines multiple representations to represent an image patch. In particular, it combines multiple features from face images processed using multiple filters and deploys Markov networks to exploit the interacting relationships between the neighboring image patches. The proposed framework could be solved using an alternating optimization strategy and it normally converges in only five outer iterations in the experiments. Our experimental results on the Chinese University of Hong Kong (CUHK) face sketch database, celebrity photos, CUHK Face Sketch FERET Database, IIIT-D Viewed Sketch Database, and forensic sketches demonstrate the effectiveness of our method for face sketch-photo synthesis. In addition, cross-database and database-dependent style-synthesis evaluations demonstrate the generalizability of this novel method and suggest promising solutions for face identification in forensic science.",4
Learning Transferred Weights From Co-Occurrence Data for Heterogeneous Transfer Learning.,"One of the main research problems in heterogeneous transfer learning is to determine whether a given source domain is effective in transferring knowledge to a target domain, and then to determine how much of the knowledge should be transferred from a source domain to a target domain. The main objective of this paper is to solve this problem by evaluating the relatedness among given domains through transferred weights. We propose a novel method to learn such transferred weights with the aid of co-occurrence data, which contain the same set of instances but in different feature spaces. Because instances with the same category should have similar features, our method is to compute their principal components in each feature space such that co-occurrence data can be rerepresented by these principal components. The principal component coefficients from different feature spaces for the same instance in the co-occurrence data have the same order of significance for describing the category information. By using these principal component coefficients, the Markov Chain Monte Carlo method is employed to construct a directed cyclic network where each node is a domain and each edge weight is the conditional dependence from one domain to another domain. Here, the edge weight of the network can be employed as the transferred weight from a source domain to a target domain. The weight values can be taken as a prior for setting parameters in the existing heterogeneous transfer learning methods to control the amount of knowledge transferred from a source domain to a target domain. The experimental results on synthetic and real-world data sets are reported to illustrate the effectiveness of the proposed method that can capture strong or weak relations among feature spaces, and enhance the learning performance of heterogeneous transfer learning.",4
Decentralized Dimensionality Reduction for Distributed Tensor Data Across Sensor Networks.,"This paper develops a novel decentralized dimensionality reduction algorithm for the distributed tensor data across sensor networks. The main contributions of this paper are as follows. First, conventional centralized methods, which utilize entire data to simultaneously determine all the vectors of the projection matrix along each tensor mode, are not suitable for the network environment. Here, we relax the simultaneous processing manner into the one-vector-by-one-vector (OVBOV) manner, i.e., determining the projection vectors (PVs) related to each tensor mode one by one. Second, we prove that in the OVBOV manner each PV can be determined without modifying any tensor data, which simplifies corresponding computations. Third, we cast the decentralized PV determination problem as a set of subproblems with consensus constraints, so that it can be solved in the network environment only by local computations and information communications among neighboring nodes. Fourth, we introduce the null space and transform the PV determination problem with complex orthogonality constraints into an equivalent hidden convex one without any orthogonality constraint, which can be solved by the Lagrange multiplier method. Finally, experimental results are given to show that the proposed algorithm is an effective dimensionality reduction scheme for the distributed tensor data across the sensor networks.",4
Synchronization Control of Neural Networks With State-Dependent Coefficient Matrices.,"This brief is concerned with synchronization control of a class of neural networks with state-dependent coefficient matrices. Being different from the existing drive-response neural networks in the literature, a novel model of drive-response neural networks is established. The concepts of uniformly ultimately bounded (UUB) synchronization and convex hull Lyapunov function are introduced. Then, by using the convex hull Lyapunov function approach, the UUB synchronization design of the drive-response neural networks is proposed, and a delay-independent control law guaranteeing the bounded synchronization of the neural networks is constructed. All present conditions are formulated in terms of bilinear matrix inequalities. By comparison, it is shown that the neural networks obtained in this brief are less conservative than those ones in the literature, and the bounded synchronization is suitable for the novel drive-response neural networks. Finally, an illustrative example is given to verify the validity of the obtained results.",4
Learning Robust and Discriminative Subspace With Low-Rank Constraints.,"In this paper, we aim at learning robust and discriminative subspaces from noisy data. Subspace learning is widely used in extracting discriminative features for classification. However, when data are contaminated with severe noise, the performance of most existing subspace learning methods would be limited. Recent advances in low-rank modeling provide effective solutions for removing noise or outliers contained in sample sets, which motivates us to take advantage of low-rank constraints in order to exploit robust and discriminative subspace for classification. In particular, we present a discriminative subspace learning method called the supervised regularization-based robust subspace (SRRS) approach, by incorporating the low-rank constraint. SRRS seeks low-rank representations from the noisy data, and learns a discriminative subspace from the recovered clean data jointly. A supervised regularization function is designed to make use of the class label information, and therefore to enhance the discriminability of subspace. Our approach is formulated as a constrained rank-minimization problem. We design an inexact augmented Lagrange multiplier optimization algorithm to solve it. Unlike the existing sparse representation and low-rank learning methods, our approach learns a low-dimensional subspace from recovered data, and explicitly incorporates the supervised information. Our approach and some baselines are evaluated on the COIL-100, ALOI, Extended YaleB, FERET, AR, and KinFace databases. The experimental results demonstrate the effectiveness of our approach, especially when the data contain considerable noise or variations.",4
A Novel Unified and Self-Stabilizing Algorithm for Generalized Eigenpairs Extraction.,"Generalized eigendecomposition problem has been widely employed in many signal processing applications. In this paper, we propose a unified and self-stabilizing algorithm, which is able to extract the first principal and minor generalized eigenvectors of a matrix pencil of two vector sequences adaptively. Furthermore, we extend the proposed algorithm to extract multiple generalized eigenvectors. The performance analysis shows that only the desired equilibrium point of the proposed algorithm is stable and all others are (unstable) repellers or saddle points. Convergence analysis based on the deterministic discrete-time approach shows that, for a step size within a certain range, the norm of the principal/minor state vector converges to a fixed value that relates to the corresponding principal/minor generalized eigenvalue. Thus, the proposed algorithm is a generalized eigenpairs (eigenvectors and eigenvalues) extraction algorithm. Finally, the simulation experiments are carried to further demonstrate the efficiency of the proposed algorithm.",4
An Improved Result on Dissipativity and Passivity Analysis of Markovian Jump Stochastic Neural Networks With Two Delay Components.,"In this paper, we investigate the dissipativity and passivity of Markovian jump stochastic neural networks involving two additive time-varying delays. Using a Lyapunov-Krasovskii functional with triple and quadruple integral terms, we obtain delay-dependent passivity and dissipativity criteria for the system. Using a generalized Finsler lemma (GFL), a set of slack variables with special structure are introduced to reduce design conservatism. The dissipativity and passivity criteria depend on the upper bounds of the discrete time-varying delay and its derivative are given in terms of linear matrix inequalities, which can be efficiently solved through the standard numerical software. Finally, our illustrative examples show that the proposed method performs well and is successful in problems where existing methods fail.",4
Evolutionary Cost-Sensitive Extreme Learning Machine.,"Conventional extreme learning machines (ELMs) solve a Moore-Penrose generalized inverse of hidden layer activated matrix and analytically determine the output weights to achieve generalized performance, by assuming the same loss from different types of misclassification. The assumption may not hold in cost-sensitive recognition tasks, such as face recognition-based access control system, where misclassifying a stranger as a family member may result in more serious disaster than misclassifying a family member as a stranger. Though recent cost-sensitive learning can reduce the total loss with a given cost matrix that quantifies how severe one type of mistake against another, in many realistic cases, the cost matrix is unknown to users. Motivated by these concerns, this paper proposes an evolutionary cost-sensitive ELM, with the following merits: 1) to the best of our knowledge, it is the first proposal of ELM in evolutionary cost-sensitive classification scenario; 2) it well addresses the open issue of how to define the cost matrix in cost-sensitive learning tasks; and 3) an evolutionary backtracking search algorithm is induced for adaptive cost matrix optimization. Experiments in a variety of cost-sensitive tasks well demonstrate the effectiveness of the proposed approaches, with about 5%-10% improvements.",4
"Mapping, Learning, Visualization, Classification, and Understanding of fMRI Data in the NeuCube Evolving Spatiotemporal Data Machine of Spiking Neural Networks.","This paper introduces a new methodology for dynamic learning, visualization, and classification of functional magnetic resonance imaging (fMRI) as spatiotemporal brain data. The method is based on an evolving spatiotemporal data machine of evolving spiking neural networks (SNNs) exemplified by the NeuCube architecture [1]. The method consists of several steps: mapping spatial coordinates of fMRI data into a 3-D SNN cube (SNNc) that represents a brain template; input data transformation into trains of spikes; deep, unsupervised learning in the 3-D SNNc of spatiotemporal patterns from data; supervised learning in an evolving SNN classifier; parameter optimization; and 3-D visualization and model interpretation. Two benchmark case study problems and data are used to illustrate the proposed methodology-fMRI data collected from subjects when reading affirmative or negative sentences and another one-on reading a sentence or seeing a picture. The learned connections in the SNNc represent dynamic spatiotemporal relationships derived from the fMRI data. They can reveal new information about the brain functions under different conditions. The proposed methodology allows for the first time to analyze dynamic functional and structural connectivity of a learned SNN model from fMRI data. This can be used for a better understanding of brain activities and also for online generation of appropriate neurofeedback to subjects for improved brain functions. For example, in this paper, tracing the 3-D SNN model connectivity enabled us for the first time to capture prominent brain functional pathways evoked in language comprehension. We found stronger spatiotemporal interaction between left dorsolateral prefrontal cortex and left temporal while reading a negated sentence. This observation is obviously distinguishable from the patterns generated by either reading affirmative sentences or seeing pictures. The proposed NeuCube-based methodology offers also a superior classification accuracy when compared with traditional AI and statistical methods. The created NeuCube-based models of fMRI data are directly and efficiently implementable on high performance and low energy consumption neuromorphic platforms for real-time applications.",4
Connections Between Nuclear-Norm and Frobenius-Norm-Based Representations.,"A lot of works have shown that frobenius-norm-based representation (FNR) is competitive to sparse representation and nuclear-norm-based representation (NNR) in numerous tasks such as subspace clustering. Despite the success of FNR in experimental studies, less theoretical analysis is provided to understand its working mechanism. In this brief, we fill this gap by building the theoretical connections between FNR and NNR. More specially, we prove that: 1) when the dictionary can provide enough representative capacity, FNR is exactly NNR even though the data set contains the Gaussian noise, Laplacian noise, or sample-specified corruption and 2) otherwise, FNR and NNR are two solutions on the column space of the dictionary.",4
The Twist Tensor Nuclear Norm for Video Completion.,"In this paper, we propose a new low-rank tensor model based on the circulant algebra, namely, twist tensor nuclear norm (t-TNN). The twist tensor denotes a three-way tensor representation to laterally store 2-D data slices in order. On one hand, t-TNN convexly relaxes the tensor multirank of the twist tensor in the Fourier domain, which allows an efficient computation using fast Fourier transform. On the other, t-TNN is equal to the nuclear norm of block circulant matricization of the twist tensor in the original domain, which extends the traditional matrix nuclear norm in a block circulant way. We test the t-TNN model on a video completion application that aims to fill missing values and the experiment results validate its effectiveness, especially when dealing with video recorded by a nonstationary panning camera. The block circulant matricization of the twist tensor can be transformed into a circulant block representation with nuclear norm invariance. This representation, after transformation, exploits the horizontal translation relationship between the frames in a video, and endows the t-TNN model with a more powerful ability to reconstruct panning videos than the existing state-of-the-art low-rank models.",4
Delay-Dependent Global Exponential Stability for Delayed Recurrent Neural Networks.,"This paper deals with the global exponential stability for delayed recurrent neural networks (DRNNs). By constructing an augmented Lyapunov-Krasovskii functional and adopting the reciprocally convex combination approach and Wirtinger-based integral inequality, delay-dependent global exponential stability criteria are derived in terms of linear matrix inequalities. Meanwhile, a general and effective method on global exponential stability analysis for DRNNs is given through a lemma, where the exponential convergence rate can be estimated. With this lemma, some global asymptotic stability criteria of DRNNs acquired in previous studies can be generalized to global exponential stability ones. Finally, a frequently utilized numerical example is carried out to illustrate the effectiveness and merits of the proposed theoretical results.",4
Model-Driven Analysis of Eyeblink Classical Conditioning Reveals the Underlying Structure of Cerebellar Plasticity and Neuronal Activity.,"The cerebellum plays a critical role in sensorimotor control. However, how the specific circuits and plastic mechanisms of the cerebellum are engaged in closed-loop processing is still unclear. We developed an artificial sensorimotor control system embedding a detailed spiking cerebellar microcircuit with three bidirectional plasticity sites. This proved able to reproduce a cerebellar-driven associative paradigm, the eyeblink classical conditioning (EBCC), in which a precise time relationship between an unconditioned stimulus (US) and a conditioned stimulus (CS) is established. We challenged the spiking model to fit an experimental data set from human subjects. Two subsequent sessions of EBCC acquisition and extinction were recorded and transcranial magnetic stimulation (TMS) was applied on the cerebellum to alter circuit function and plasticity. Evolutionary algorithms were used to find the near-optimal model parameters to reproduce the behaviors of subjects in the different sessions of the protocol. The main finding is that the optimized cerebellar model was able to learn to anticipate (predict) conditioned responses with accurate timing and success rate, demonstrating fast acquisition, memory stabilization, rapid extinction, and faster reacquisition as in EBCC in humans. The firing of Purkinje cells (PCs) and deep cerebellar nuclei (DCN) changed during learning under the control of synaptic plasticity, which evolved at different rates, with a faster acquisition in the cerebellar cortex than in DCN synapses. Eventually, a reduced PC activity released DCN discharge just after the CS, precisely anticipating the US and causing the eyeblink. Moreover, a specific alteration in cortical plasticity explained the EBCC changes induced by cerebellar TMS in humans. In this paper, for the first time, it is shown how closed-loop simulations, using detailed cerebellar microcircuit models, can be successfully used to fit real experimental data sets. Thus, the changes of the model parameters in the different sessions of the protocol unveil how implicit microcircuit mechanisms can generate normal and altered associative behaviors.The cerebellum plays a critical role in sensorimotor control. However, how the specific circuits and plastic mechanisms of the cerebellum are engaged in closed-loop processing is still unclear. We developed an artificial sensorimotor control system embedding a detailed spiking cerebellar microcircuit with three bidirectional plasticity sites. This proved able to reproduce a cerebellar-driven associative paradigm, the eyeblink classical conditioning (EBCC), in which a precise time relationship between an unconditioned stimulus (US) and a conditioned stimulus (CS) is established. We challenged the spiking model to fit an experimental data set from human subjects. Two subsequent sessions of EBCC acquisition and extinction were recorded and transcranial magnetic stimulation (TMS) was applied on the cerebellum to alter circuit function and plasticity. Evolutionary algorithms were used to find the near-optimal model parameters to reproduce the behaviors of subjects in the different sessions of the protocol. The main finding is that the optimized cerebellar model was able to learn to anticipate (predict) conditioned responses with accurate timing and success rate, demonstrating fast acquisition, memory stabilization, rapid extinction, and faster reacquisition as in EBCC in humans. The firing of Purkinje cells (PCs) and deep cerebellar nuclei (DCN) changed during learning under the control of synaptic plasticity, which evolved at different rates, with a faster acquisition in the cerebellar cortex than in DCN synapses. Eventually, a reduced PC activity released DCN discharge just after the CS, precisely anticipating the US and causing the eyeblink. Moreover, a specific alteration in cortical plasticity explained the EBCC changes induced by cerebellar TMS in humans. In this paper, for the first time, it is shown how closed-loop simulations, using detailed cerebellar microcircuit models, can be successfully used to fit real experimental data sets. Thus, the changes of the model parameters in the different sessions of the protocol unveil how implicit microcircuit mechanisms can generate normal and altered associative behaviors.",4
Evaluating the Visualization of What a Deep Neural Network Has Learned.,"Deep neural networks (DNNs) have demonstrated impressive performance in complex machine learning tasks such as image classification or speech recognition. However, due to their multilayer nonlinear structure, they are not transparent, i.e., it is hard to grasp what makes them arrive at a particular classification or recognition decision, given a new unseen data sample. Recently, several approaches have been proposed enabling one to understand and interpret the reasoning embodied in a DNN for a single test image. These methods quantify the ""importance"" of individual pixels with respect to the classification decision and allow a visualization in terms of a heatmap in pixel/input space. While the usefulness of heatmaps can be judged subjectively by a human, an objective quality measure is missing. In this paper, we present a general methodology based on region perturbation for evaluating ordered collections of pixels such as heatmaps. We compare heatmaps computed by three different methods on the SUN397, ILSVRC2012, and MIT Places data sets. Our main result is that the recently proposed layer-wise relevance propagation algorithm qualitatively and quantitatively provides a better explanation of what made a DNN arrive at a particular classification decision than the sensitivity-based approach or the deconvolution method. We provide theoretical arguments to explain this result and discuss its practical implications. Finally, we investigate the use of heatmaps for unsupervised assessment of the neural network performance.Deep neural networks (DNNs) have demonstrated impressive performance in complex machine learning tasks such as image classification or speech recognition. However, due to their multilayer nonlinear structure, they are not transparent, i.e., it is hard to grasp what makes them arrive at a particular classification or recognition decision, given a new unseen data sample. Recently, several approaches have been proposed enabling one to understand and interpret the reasoning embodied in a DNN for a single test image. These methods quantify the ""importance"" of individual pixels with respect to the classification decision and allow a visualization in terms of a heatmap in pixel/input space. While the usefulness of heatmaps can be judged subjectively by a human, an objective quality measure is missing. In this paper, we present a general methodology based on region perturbation for evaluating ordered collections of pixels such as heatmaps. We compare heatmaps computed by three different methods on the SUN397, ILSVRC2012, and MIT Places data sets. Our main result is that the recently proposed layer-wise relevance propagation algorithm qualitatively and quantitatively provides a better explanation of what made a DNN arrive at a particular classification decision than the sensitivity-based approach or the deconvolution method. We provide theoretical arguments to explain this result and discuss its practical implications. Finally, we investigate the use of heatmaps for unsupervised assessment of the neural network performance.",4
Adaptive Neural Networks Decentralized FTC Design for Nonstrict-Feedback Nonlinear Interconnected Large-Scale Systems Against Actuator Faults.,"The problem of active fault-tolerant control (FTC) is investigated for the large-scale nonlinear systems in nonstrict-feedback form. The nonstrict-feedback nonlinear systems considered in this paper consist of unstructured uncertainties, unmeasured states, unknown interconnected terms, and actuator faults (e.g., bias fault and gain fault). A state observer is designed to solve the unmeasurable state problem. Neural networks (NNs) are used to identify the unknown lumped nonlinear functions so that the problems of unstructured uncertainties and unknown interconnected terms can be solved. By combining the adaptive backstepping design principle with the combination Nussbaum gain function property, a novel NN adaptive output-feedback FTC approach is developed. The proposed FTC controller can guarantee that all signals in all subsystems are bounded, and the tracking errors for each subsystem converge to a small neighborhood of zero. Finally, numerical results of practical examples are presented to further demonstrate the effectiveness of the proposed control strategy.The problem of active fault-tolerant control (FTC) is investigated for the large-scale nonlinear systems in nonstrict-feedback form. The nonstrict-feedback nonlinear systems considered in this paper consist of unstructured uncertainties, unmeasured states, unknown interconnected terms, and actuator faults (e.g., bias fault and gain fault). A state observer is designed to solve the unmeasurable state problem. Neural networks (NNs) are used to identify the unknown lumped nonlinear functions so that the problems of unstructured uncertainties and unknown interconnected terms can be solved. By combining the adaptive backstepping design principle with the combination Nussbaum gain function property, a novel NN adaptive output-feedback FTC approach is developed. The proposed FTC controller can guarantee that all signals in all subsystems are bounded, and the tracking errors for each subsystem converge to a small neighborhood of zero. Finally, numerical results of practical examples are presented to further demonstrate the effectiveness of the proposed control strategy.",4
Lower Bounds on the Proportion of Leaders Needed for Expected Consensus of 3-D Flocks.,"This paper considers the consensus behavior of a spatially distributed 3-D dynamical network composed of heterogeneous agents: leaders and followers, in which the leaders have the preferred information about the destination, while the followers do not have. All followers move in a 3-D Euclidean space with a given speed and with their headings updated according to the average velocity of the corresponding neighbors. Compared with the 2-D model, a key point lies in how to analyze the dynamical behavior of a ""linear"" nonhomogeneous equation where the nonhomogeneous term strongly nonlinearly depends on the states of all agents. Using the network structure and the estimation of some characteristics for the initial states, we present a proper decaying rate for the nonhomogeneous term and then establish lower bounds on the ratio of the number of leaders to the number of followers that is needed for the expected consensus by considering two cases: 1) fixed speed and neighborhood radius and 2) variable speed and neighborhood radius with respect to the population size. Some simulation examples are given to justify the theoretical results.This paper considers the consensus behavior of a spatially distributed 3-D dynamical network composed of heterogeneous agents: leaders and followers, in which the leaders have the preferred information about the destination, while the followers do not have. All followers move in a 3-D Euclidean space with a given speed and with their headings updated according to the average velocity of the corresponding neighbors. Compared with the 2-D model, a key point lies in how to analyze the dynamical behavior of a ""linear"" nonhomogeneous equation where the nonhomogeneous term strongly nonlinearly depends on the states of all agents. Using the network structure and the estimation of some characteristics for the initial states, we present a proper decaying rate for the nonhomogeneous term and then establish lower bounds on the ratio of the number of leaders to the number of followers that is needed for the expected consensus by considering two cases: 1) fixed speed and neighborhood radius and 2) variable speed and neighborhood radius with respect to the population size. Some simulation examples are given to justify the theoretical results.",4
A Squeezed Artificial Neural Network for the Symbolic Network Reliability Functions of Binary-State Networks.,"Network reliability is an important index to the provision of useful information for decision support in the modern world. There is always a need to calculate symbolic network reliability functions (SNRFs) due to dynamic and rapid changes in network parameters. In this brief, the proposed squeezed artificial neural network (SqANN) approach uses the Monte Carlo simulation to estimate the corresponding reliability of a given designed matrix from the Box-Behnken design, and then the Taguchi method is implemented to find the appropriate number of neurons and activation functions of the hidden layer and the output layer in ANN to evaluate SNRFs. According to the experimental results of the benchmark networks, the comparison appears to support the superiority of the proposed SqANN method over the traditional ANN-based approach with at least 16.6% improvement in the median absolute deviation in the cost of extra 2 s on average for all experiments.Network reliability is an important index to the provision of useful information for decision support in the modern world. There is always a need to calculate symbolic network reliability functions (SNRFs) due to dynamic and rapid changes in network parameters. In this brief, the proposed squeezed artificial neural network (SqANN) approach uses the Monte Carlo simulation to estimate the corresponding reliability of a given designed matrix from the Box-Behnken design, and then the Taguchi method is implemented to find the appropriate number of neurons and activation functions of the hidden layer and the output layer in ANN to evaluate SNRFs. According to the experimental results of the benchmark networks, the comparison appears to support the superiority of the proposed SqANN method over the traditional ANN-based approach with at least 16.6% improvement in the median absolute deviation in the cost of extra 2 s on average for all experiments.",4
Sampled-Data Consensus of Linear Multi-agent Systems With Packet Losses.,"In this paper, the consensus problem is studied for a class of multi-agent systems with sampled data and packet losses, where random and deterministic packet losses are considered, respectively. For random packet losses, a Bernoulli-distributed white sequence is used to describe packet dropouts among agents in a stochastic way. For deterministic packet losses, a switched system with stable and unstable subsystems is employed to model packet dropouts in a deterministic way. The purpose of this paper is to derive consensus criteria, such that linear multi-agent systems with sampled-data and packet losses can reach consensus. By means of the Lyapunov function approach and the decomposition method, the design problem of a distributed controller is solved in terms of convex optimization. The interplay among the allowable bound of the sampling interval, the probability of random packet losses, and the rate of deterministic packet losses are explicitly derived to characterize consensus conditions. The obtained criteria are closely related to the maximum eigenvalue of the Laplacian matrix versus the second minimum eigenvalue of the Laplacian matrix, which reveals the intrinsic effect of communication topologies on consensus performance. Finally, simulations are given to show the effectiveness of the proposed results.In this paper, the consensus problem is studied for a class of multi-agent systems with sampled data and packet losses, where random and deterministic packet losses are considered, respectively. For random packet losses, a Bernoulli-distributed white sequence is used to describe packet dropouts among agents in a stochastic way. For deterministic packet losses, a switched system with stable and unstable subsystems is employed to model packet dropouts in a deterministic way. The purpose of this paper is to derive consensus criteria, such that linear multi-agent systems with sampled-data and packet losses can reach consensus. By means of the Lyapunov function approach and the decomposition method, the design problem of a distributed controller is solved in terms of convex optimization. The interplay among the allowable bound of the sampling interval, the probability of random packet losses, and the rate of deterministic packet losses are explicitly derived to characterize consensus conditions. The obtained criteria are closely related to the maximum eigenvalue of the Laplacian matrix versus the second minimum eigenvalue of the Laplacian matrix, which reveals the intrinsic effect of communication topologies on consensus performance. Finally, simulations are given to show the effectiveness of the proposed results.",4
Pair- ${v}$ -SVR: A Novel and Efficient Pairing nu-Support Vector Regression Algorithm.,"This paper proposes a novel and efficient pairing nu-support vector regression (pair--SVR) algorithm that combines successfully the superior advantages of twin support vector regression (TSVR) and classical -SVR algorithms. In spirit of TSVR, the proposed pair--SVR solves two quadratic programming problems (QPPs) of smaller size rather than a single larger QPP, and thus has faster learning speed than classical -SVR. The significant advantage of our pair--SVR over TSVR is the improvement in the prediction speed and generalization ability by introducing the concepts of the insensitive zone and the regularization term that embodies the essence of statistical learning theory. Moreover, pair--SVR has additional advantage of using parameter for controlling the bounds on fractions of SVs and errors. Furthermore, the upper bound and lower bound functions of the regression model estimated by pair--SVR capture well the characteristics of data distributions, thus facilitating automatic estimation of the conditional mean and predictive variance simultaneously. This may be useful in many cases, especially when the noise is heteroscedastic and depends strongly on the input values. The experimental results validate the superiority of our pair--SVR in both training/prediction speed and generalization ability.This paper proposes a novel and efficient pairing nu-support vector regression (pair--SVR) algorithm that combines successfully the superior advantages of twin support vector regression (TSVR) and classical -SVR algorithms. In spirit of TSVR, the proposed pair--SVR solves two quadratic programming problems (QPPs) of smaller size rather than a single larger QPP, and thus has faster learning speed than classical -SVR. The significant advantage of our pair--SVR over TSVR is the improvement in the prediction speed and generalization ability by introducing the concepts of the insensitive zone and the regularization term that embodies the essence of statistical learning theory. Moreover, pair--SVR has additional advantage of using parameter for controlling the bounds on fractions of SVs and errors. Furthermore, the upper bound and lower bound functions of the regression model estimated by pair--SVR capture well the characteristics of data distributions, thus facilitating automatic estimation of the conditional mean and predictive variance simultaneously. This may be useful in many cases, especially when the noise is heteroscedastic and depends strongly on the input values. The experimental results validate the superiority of our pair--SVR in both training/prediction speed and generalization ability.",4
"Needs, Pains, and Motivations in Autonomous Agents.","This paper presents the development of a motivated learning (ML) agent with symbolic I/O. Our earlier work on the ML agent was enhanced, giving it autonomy for interaction with other agents. Specifically, we equipped the agent with drives and pains that establish its motivations to learn how to respond to desired and undesired events and create related abstract goals. The purpose of this paper is to explore the autonomous development of motivations and memory in agents within a simulated environment. The ML agent has been implemented in a virtual environment created within the NeoAxis game engine. Additionally, to illustrate the benefits of an ML-based agent, we compared the performance of our algorithm against various reinforcement learning (RL) algorithms in a dynamic test scenario, and demonstrated that our ML agent learns better than any of the tested RL agents.This paper presents the development of a motivated learning (ML) agent with symbolic I/O. Our earlier work on the ML agent was enhanced, giving it autonomy for interaction with other agents. Specifically, we equipped the agent with drives and pains that establish its motivations to learn how to respond to desired and undesired events and create related abstract goals. The purpose of this paper is to explore the autonomous development of motivations and memory in agents within a simulated environment. The ML agent has been implemented in a virtual environment created within the NeoAxis game engine. Additionally, to illustrate the benefits of an ML-based agent, we compared the performance of our algorithm against various reinforcement learning (RL) algorithms in a dynamic test scenario, and demonstrated that our ML agent learns better than any of the tested RL agents.",4
Discrete-Time Local Value Iteration Adaptive Dynamic Programming: Admissibility and Termination Analysis.,"In this paper, a novel local value iteration adaptive dynamic programming (ADP) algorithm is developed to solve infinite horizon optimal control problems for discrete-time nonlinear systems. The focuses of this paper are to study admissibility properties and the termination criteria of discrete-time local value iteration ADP algorithms. In the discrete-time local value iteration ADP algorithm, the iterative value functions and the iterative control laws are both updated in a given subset of the state space in each iteration, instead of the whole state space. For the first time, admissibility properties of iterative control laws are analyzed for the local value iteration ADP algorithm. New termination criteria are established, which terminate the iterative local ADP algorithm with an admissible approximate optimal control law. Finally, simulation results are given to illustrate the performance of the developed algorithm.In this paper, a novel local value iteration adaptive dynamic programming (ADP) algorithm is developed to solve infinite horizon optimal control problems for discrete-time nonlinear systems. The focuses of this paper are to study admissibility properties and the termination criteria of discrete-time local value iteration ADP algorithms. In the discrete-time local value iteration ADP algorithm, the iterative value functions and the iterative control laws are both updated in a given subset of the state space in each iteration, instead of the whole state space. For the first time, admissibility properties of iterative control laws are analyzed for the local value iteration ADP algorithm. New termination criteria are established, which terminate the iterative local ADP algorithm with an admissible approximate optimal control law. Finally, simulation results are given to illustrate the performance of the developed algorithm.",4
A New Local Bipolar Autoassociative Memory Based on External Inputs of Discrete Recurrent Neural Networks With Time Delay.,"In this paper, local bipolar auto-associative memories are presented based on discrete recurrent neural networks with a class of gain type activation function. The weight parameters of neural networks are acquired by a set of inequalities without the learning procedure. The global exponential stability criteria are established to ensure the accuracy of the restored patterns by considering time delays and external inputs. The proposed methodology is capable of effectively overcoming spurious memory patterns and achieving memory capacity. The effectiveness, robustness, and fault-tolerant capability are validated by simulated experiments.In this paper, local bipolar auto-associative memories are presented based on discrete recurrent neural networks with a class of gain type activation function. The weight parameters of neural networks are acquired by a set of inequalities without the learning procedure. The global exponential stability criteria are established to ensure the accuracy of the restored patterns by considering time delays and external inputs. The proposed methodology is capable of effectively overcoming spurious memory patterns and achieving memory capacity. The effectiveness, robustness, and fault-tolerant capability are validated by simulated experiments.",4
LMI Conditions for Global Stability of Fractional-Order Neural Networks.,"Fractional-order neural networks play a vital role in modeling the information processing of neuronal interactions. It is still an open and necessary topic for fractional-order neural networks to investigate their global stability. This paper proposes some simplified linear matrix inequality (LMI) stability conditions for fractional-order linear and nonlinear systems. Then, the global stability analysis of fractional-order neural networks employs the results from the obtained LMI conditions. In the LMI form, the obtained results include the existence and uniqueness of equilibrium point and its global stability, which simplify and extend some previous work on the stability analysis of the fractional-order neural networks. Moreover, a generalized projective synchronization method between such neural systems is given, along with its corresponding LMI condition. Finally, two numerical examples are provided to illustrate the effectiveness of the established LMI conditions.",4
Randomized Prediction Games for Adversarial Machine Learning.,"In spam and malware detection, attackers exploit randomization to obfuscate malicious data and increase their chances of evading detection at test time, e.g., malware code is typically obfuscated using random strings or byte sequences to hide known exploits. Interestingly, randomization has also been proposed to improve security of learning algorithms against evasion attacks, as it results in hiding information about the classifier to the attacker. Recent work has proposed game-theoretical formulations to learn secure classifiers, by simulating different evasion attacks and modifying the classification function accordingly. However, both the classification function and the simulated data manipulations have been modeled in a deterministic manner, without accounting for any form of randomization. In this paper, we overcome this limitation by proposing a randomized prediction game, namely, a noncooperative game-theoretic formulation in which the classifier and the attacker make randomized strategy selections according to some probability distribution defined over the respective strategy set. We show that our approach allows one to improve the tradeoff between attack detection and false alarms with respect to the state-of-the-art secure classifiers, even against attacks that are different from those hypothesized during design, on application examples including handwritten digit recognition, spam, and malware detection.In spam and malware detection, attackers exploit randomization to obfuscate malicious data and increase their chances of evading detection at test time, e.g., malware code is typically obfuscated using random strings or byte sequences to hide known exploits. Interestingly, randomization has also been proposed to improve security of learning algorithms against evasion attacks, as it results in hiding information about the classifier to the attacker. Recent work has proposed game-theoretical formulations to learn secure classifiers, by simulating different evasion attacks and modifying the classification function accordingly. However, both the classification function and the simulated data manipulations have been modeled in a deterministic manner, without accounting for any form of randomization. In this paper, we overcome this limitation by proposing a randomized prediction game, namely, a noncooperative game-theoretic formulation in which the classifier and the attacker make randomized strategy selections according to some probability distribution defined over the respective strategy set. We show that our approach allows one to improve the tradeoff between attack detection and false alarms with respect to the state-of-the-art secure classifiers, even against attacks that are different from those hypothesized during design, on application examples including handwritten digit recognition, spam, and malware detection.",4
Hierarchical Address Event Routing for Reconfigurable Large-Scale Neuromorphic Systems.,"We present a hierarchical address-event routing (HiAER) architecture for scalable communication of neural and synaptic spike events between neuromorphic processors, implemented with five Xilinx Spartan-6 field-programmable gate arrays and four custom analog neuromophic integrated circuits serving 262k neurons and 262M synapses. The architecture extends the single-bus address-event representation protocol to a hierarchy of multiple nested buses, routing events across increasing scales of spatial distance. The HiAER protocol provides individually programmable axonal delay in addition to strength for each synapse, lending itself toward biologically plausible neural network architectures, and scales across a range of hierarchies suitable for multichip and multiboard systems in reconfigurable large-scale neuromorphic systems. We show approximately linear scaling of net global synaptic event throughput with number of routing nodes in the network, at 3.6x10(7) synaptic events per second per 16k-neuron node in the hierarchy.",4
A Binaural Neuromorphic Auditory Sensor for FPGA: A Spike Signal Processing Approach.,"This paper presents a new architecture, design flow, and field-programmable gate array (FPGA) implementation analysis of a neuromorphic binaural auditory sensor, designed completely in the spike domain. Unlike digital cochleae that decompose audio signals using classical digital signal processing techniques, the model presented in this paper processes information directly encoded as spikes using pulse frequency modulation and provides a set of frequency-decomposed audio information using an address-event representation interface. In this case, a systematic approach to design led to a generic process for building, tuning, and implementing audio frequency decomposers with different features, facilitating synthesis with custom features. This allows researchers to implement their own parameterized neuromorphic auditory systems in a low-cost FPGA in order to study the audio processing and learning activity that takes place in the brain. In this paper, we present a 64-channel binaural neuromorphic auditory system implemented in a Virtex-5 FPGA using a commercial development board. The system was excited with a diverse set of audio signals in order to analyze its response and characterize its features. The neuromorphic auditory system response times and frequencies are reported. The experimental results of the proposed system implementation with 64-channel stereo are: a frequency range between 9.6 Hz and 14.6 kHz (adjustable), a maximum output event rate of 2.19 Mevents/s, a power consumption of 29.7 mW, the slices requirements of 11141, and a system clock frequency of 27 MHz.",4
Lagrange Programming Neural Network for Nondifferentiable Optimization Problems in Sparse Approximation.,"The major limitation of the Lagrange programming neural network (LPNN) approach is that the objective function and the constraints should be twice differentiable. Since sparse approximation involves nondifferentiable functions, the original LPNN approach is not suitable for recovering sparse signals. This paper proposes a new formulation of the LPNN approach based on the concept of the locally competitive algorithm (LCA). Unlike the classical LCA approach which is able to solve unconstrained optimization problems only, the proposed LPNN approach is able to solve the constrained optimization problems. Two problems in sparse approximation are considered. They are basis pursuit (BP) and constrained BP denoise (CBPDN). We propose two LPNN models, namely, BP-LPNN and CBPDN-LPNN, to solve these two problems. For these two models, we show that the equilibrium points of the models are the optimal solutions of the two problems, and that the optimal solutions of the two problems are the equilibrium points of the two models. Besides, the equilibrium points are stable. Simulations are carried out to verify the effectiveness of these two LPNN models.",4
A Biologically Inspired Appearance Model for Robust Visual Tracking.,"In this paper, we propose a biologically inspired appearance model for robust visual tracking. Motivated in part by the success of the hierarchical organization of the primary visual cortex (area V1), we establish an architecture consisting of five layers: whitening, rectification, normalization, coding, and pooling. The first three layers stem from the models developed for object recognition. In this paper, our attention focuses on the coding and pooling layers. In particular, we use a discriminative sparse coding method in the coding layer along with spatial pyramid representation in the pooling layer, which makes it easier to distinguish the target to be tracked from its background in the presence of appearance variations. An extensive experimental study shows that the proposed method has higher tracking accuracy than several state-of-the-art trackers.",4
Off-Policy Integral Reinforcement Learning Method to Solve Nonlinear Continuous-Time Multiplayer Nonzero-Sum Games.,This paper establishes an off-policy integral reinforcement learning (IRL) method to solve nonlinear continuous-time (CT) nonzero-sum (NZS) games with unknown system dynamics. The IRL algorithm is presented to obtain the iterative control and off-policy learning is used to allow the dynamics to be completely unknown. Off-policy IRL is designed to do policy evaluation and policy improvement in the policy iteration algorithm. Critic and action networks are used to obtain the performance index and control for each player. The gradient descent algorithm makes the update of critic and action weights simultaneously. The convergence analysis of the weights is given. The asymptotic stability of the closed-loop system and the existence of Nash equilibrium are proved. The simulation study demonstrates the effectiveness of the developed method for nonlinear CT NZS games with unknown system dynamics.,4
Event-Based $H_\infty $ State Estimation for Time-Varying Stochastic Dynamical Networks With State- and Disturbance-Dependent Noises.,"In this paper, the event-based finite-horizon Hinfinity state estimation problem is investigated for a class of discrete time-varying stochastic dynamical networks with state- and disturbance-dependent noises [also called (x,v) -dependent noises]. An event-triggered scheme is proposed to decrease the frequency of the data transmission between the sensors and the estimator, where the signal is transmitted only when certain conditions are satisfied. The purpose of the problem addressed is to design a time-varying state estimator in order to estimate the network states through available output measurements. By employing the completing-the-square technique and the stochastic analysis approach, sufficient conditions are established to ensure that the error dynamics of the state estimation satisfies a prescribed Hinfinity performance constraint over a finite horizon. The desired estimator parameters can be designed via solving coupled backward recursive Riccati difference equations. Finally, a numerical example is exploited to demonstrate the effectiveness of the developed state estimation scheme.",4
Stability of Recurrent Neural Networks With Time-Varying Delay via Flexible Terminal Method.,"This brief is concerned with the stability criteria for recurrent neural networks with time-varying delay. First, based on convex combination technique, a delay interval with fixed terminals is changed into the one with flexible terminals, which is called flexible terminal method (FTM). Second, based on the FTM, a novel Lyapunov-Krasovskii functional is constructed, in which the integral interval associated with delayed variables is not fixed. Thus, the FTM can achieve the same effect as that of delay-partitioning method, while their implementary ways are different. Guided by FTM, Wirtinger-based integral inequality and free-weight matrix method are employed to develop several stability criteria, respectively. Finally, the feasibility and the effectiveness of the proposed results are tested by two numerical examples.",4
Optimized Structure of the Traffic Flow Forecasting Model With a Deep Learning Approach.,"Forecasting accuracy is an important issue for successful intelligent traffic management, especially in the domain of traffic efficiency and congestion reduction. The dawning of the big data era brings opportunities to greatly improve prediction accuracy. In this paper, we propose a novel model, stacked autoencoder Levenberg-Marquardt model, which is a type of deep architecture of neural network approach aiming to improve forecasting accuracy. The proposed model is designed using the Taguchi method to develop an optimized structure and to learn traffic flow features through layer-by-layer feature granulation with a greedy layerwise unsupervised learning algorithm. It is applied to real-world data collected from the M6 freeway in the U.K. and is compared with three existing traffic predictors. To the best of our knowledge, this is the first time that an optimized structure of the traffic flow forecasting model with a deep learning approach is presented. The evaluation results demonstrate that the proposed model with an optimized structure has superior performance in traffic flow forecasting.",4
Fractional Hopfield Neural Networks: Fractional Dynamic Associative Recurrent Neural Networks.,"This paper mainly discusses a novel conceptual framework: fractional Hopfield neural networks (FHNN). As is commonly known, fractional calculus has been incorporated into artificial neural networks, mainly because of its long-term memory and nonlocality. Some researchers have made interesting attempts at fractional neural networks and gained competitive advantages over integer-order neural networks. Therefore, it is naturally makes one ponder how to generalize the first-order Hopfield neural networks to the fractional-order ones, and how to implement FHNN by means of fractional calculus. We propose to introduce a novel mathematical method: fractional calculus to implement FHNN. First, we implement fractor in the form of an analog circuit. Second, we implement FHNN by utilizing fractor and the fractional steepest descent approach, construct its Lyapunov function, and further analyze its attractors. Third, we perform experiments to analyze the stability and convergence of FHNN, and further discuss its applications to the defense against chip cloning attacks for anticounterfeiting. The main contribution of our work is to propose FHNN in the form of an analog circuit by utilizing a fractor and the fractional steepest descent approach, construct its Lyapunov function, prove its Lyapunov stability, analyze its attractors, and apply FHNN to the defense against chip cloning attacks for anticounterfeiting. A significant advantage of FHNN is that its attractors essentially relate to the neuron's fractional order. FHNN possesses the fractional-order-stability and fractional-order-sensitivity characteristics.",4
A Collective Neurodynamic Optimization Approach to Nonnegative Matrix Factorization.,"Nonnegative matrix factorization (NMF) is an advanced method for nonnegative feature extraction, with widespread applications. However, the NMF solution often entails to solve a global optimization problem with a nonconvex objective function and nonnegativity constraints. This paper presents a collective neurodynamic optimization (CNO) approach to this challenging problem. The proposed collective neurodynamic system consists of a population of recurrent neural networks (RNNs) at the lower level and a particle swarm optimization (PSO) algorithm with wavelet mutation at the upper level. The RNNs act as search agents carrying out precise local searches according to their neurodynamics and initial conditions. The PSO algorithm coordinates and guides the RNNs with updated initial states toward global optimal solution(s). A wavelet mutation operator is added to enhance PSO exploration diversity. Through iterative interaction and improvement of the locally best solutions of RNNs and global best positions of the whole population, the population-based neurodynamic systems are almost sure able to achieve the global optimality for the NMF problem. It is proved that the convergence of the group-best state to the global optimal solution with probability one. The experimental results substantiate the efficacy and superiority of the CNO approach to bound-constrained global optimization with several benchmark nonconvex functions and NMF-based clustering with benchmark data sets in comparison with the state-of-the-art algorithms.",4
Synchronization of Switched Neural Networks With Communication Delays via the Event-Triggered Control.,"This paper addresses the issue of synchronization of switched delayed neural networks with communication delays via event-triggered control. For synchronizing coupled switched neural networks, we propose a novel event-triggered control law which could greatly reduce the number of control updates for synchronization tasks of coupled switched neural networks involving embedded microprocessors with limited on-board resources. The control signals are driven by properly defined events, which depend on the measurement errors and current-sampled states. By using a delay system method, a novel model of synchronization error system with delays is proposed with the communication delays and event-triggered control in the unified framework for coupled switched neural networks. The criteria are derived for the event-triggered synchronization analysis and control synthesis of switched neural networks via the Lyapunov-Krasovskii functional method and free weighting matrix approach. A numerical example is elaborated on to illustrate the effectiveness of the derived results.",4
Model-Free Optimal Tracking Control via Critic-Only Q-Learning.,"Model-free control is an important and promising topic in control fields, which has attracted extensive attention in the past few years. In this paper, we aim to solve the model-free optimal tracking control problem of nonaffine nonlinear discrete-time systems. A critic-only Q-learning (CoQL) method is developed, which learns the optimal tracking control from real system data, and thus avoids solving the tracking Hamilton-Jacobi-Bellman equation. First, the Q-learning algorithm is proposed based on the augmented system, and its convergence is established. Using only one neural network for approximating the Q-function, the CoQL method is developed to implement the Q-learning algorithm. Furthermore, the convergence of the CoQL method is proved with the consideration of neural network approximation error. With the convergent Q-function obtained from the CoQL method, the adaptive optimal tracking control is designed based on the gradient descent scheme. Finally, the effectiveness of the developed CoQL method is demonstrated through simulation studies. The developed CoQL method learns with off-policy data and implements with a critic-only structure, thus it is easy to realize and overcome the inadequate exploration problem.",4
A New Powered Lower Limb Prosthesis Control Framework Based on Adaptive Dynamic Programming.,"This brief presents a novel application of adaptive dynamic programming (ADP) for optimal adaptive control of powered lower limb prostheses, a type of wearable robots to assist the motor function of the limb amputees. Current control of these robotic devices typically relies on finite state impedance control (FS-IC), which lacks adaptability to the user's physical condition. As a result, joint impedance settings are often customized manually and heuristically in clinics, which greatly hinder the wide use of these advanced medical devices. This simulation study aimed at demonstrating the feasibility of ADP for automatic tuning of the twelve knee joint impedance parameters during a complete gait cycle to achieve balanced walking. Given that the accurate models of human walking dynamics are difficult to obtain, the model-free ADP control algorithms were considered. First, direct heuristic dynamic programming (dHDP) was applied to the control problem, and its performance was evaluated on OpenSim, an often-used dynamic walking simulator. For the comparison purposes, we selected another established ADP algorithm, the neural fitted Q with continuous action (NFQCA). In both cases, the ADP controllers learned to control the right knee joint and achieved balanced walking, but dHDP outperformed NFQCA in this application during a 200 gait cycle-based testing.",4
Multiobjective Deep Belief Networks Ensemble for Remaining Useful Life Estimation in Prognostics.,"In numerous industrial applications where safety, efficiency, and reliability are among primary concerns, condition-based maintenance (CBM) is often the most effective and reliable maintenance policy. Prognostics, as one of the key enablers of CBM, involves the core task of estimating the remaining useful life (RUL) of the system. Neural networks-based approaches have produced promising results on RUL estimation, although their performances are influenced by handcrafted features and manually specified parameters. In this paper, we propose a multiobjective deep belief networks ensemble (MODBNE) method. MODBNE employs a multiobjective evolutionary algorithm integrated with the traditional DBN training technique to evolve multiple DBNs simultaneously subject to accuracy and diversity as two conflicting objectives. The eventually evolved DBNs are combined to establish an ensemble model used for RUL estimation, where combination weights are optimized via a single-objective differential evolution algorithm using a task-oriented objective function. We evaluate the proposed method on several prognostic benchmarking data sets and also compare it with some existing approaches. Experimental results demonstrate the superiority of our proposed method.",4
LSTM: A Search Space Odyssey.,"Several variants of the long short-term memory (LSTM) architecture for recurrent neural networks have been proposed since its inception in 1995. In recent years, these networks have become the state-of-the-art models for a variety of machine learning problems. This has led to a renewed interest in understanding the role and utility of various computational components of typical LSTM variants. In this paper, we present the first large-scale analysis of eight LSTM variants on three representative tasks: speech recognition, handwriting recognition, and polyphonic music modeling. The hyperparameters of all LSTM variants for each task were optimized separately using random search, and their importance was assessed using the powerful functional ANalysis Of VAriance framework. In total, we summarize the results of 5400 experimental runs ( approximately 15 years of CPU time), which makes our study the largest of its kind on LSTM networks. Our results show that none of the variants can improve upon the standard LSTM architecture significantly, and demonstrate the forget gate and the output activation function to be its most critical components. We further observe that the studied hyperparameters are virtually independent and derive guidelines for their efficient adjustment.",4
Semisupervised Feature Analysis by Mining Correlations Among Multiple Tasks.,"In this paper, we propose a novel semisupervised feature selection framework by mining correlations among multiple tasks and apply it to different multimedia applications. Instead of independently computing the importance of features for each task, our algorithm leverages shared knowledge from multiple related tasks, thus improving the performance of feature selection. Note that the proposed algorithm is built upon an assumption that different tasks share some common structures. The proposed algorithm selects features in a batch mode, by which the correlations between various features are taken into consideration. Besides, considering the fact that labeling a large amount of training data in real world is both time-consuming and tedious, we adopt manifold learning, which exploits both labeled and unlabeled training data for a feature space analysis. Since the objective function is nonsmooth and difficult to solve, we propose an iteractive algorithm with fast convergence. Extensive experiments on different applications demonstrate that our algorithm outperforms the other state-of-the-art feature selection algorithms.",4
An Online Unsupervised Structural Plasticity Algorithm for Spiking Neural Networks.,"In this paper, we propose a novel winner-take-all (WTA) architecture employing neurons with nonlinear dendrites and an online unsupervised structural plasticity rule for training it. Furthermore, to aid hardware implementations, our network employs only binary synapses. The proposed learning rule is inspired by spike-timing-dependent plasticity but differs for each dendrite based on its activation level. It trains the WTA network through formation and elimination of connections between inputs and synapses. To demonstrate the performance of the proposed network and learning rule, we employ it to solve two-class, four-class, and six-class classification of random Poisson spike time inputs. The results indicate that by proper tuning of the inhibitory time constant of the WTA, a tradeoff between specificity and sensitivity of the network can be achieved. We use the inhibitory time constant to set the number of subpatterns per pattern we want to detect. We show that while the percentages of successful trials are 92%, 88%, and 82% for two-class, four-class, and six-class classification when no pattern subdivisions are made, it increases to 100% when each pattern is subdivided into 5 or 10 subpatterns. However, the former scenario of no pattern subdivision is more jitter resilient than the later ones.",4
Resolution of Singularities Introduced by Hierarchical Structure in Deep Neural Networks.,"We present a theoretical analysis of singular points of artificial deep neural networks, resulting in providing deep neural network models having no critical points introduced by a hierarchical structure. It is considered that such deep neural network models have good nature for gradient-based optimization. First, we show that there exist a large number of critical points introduced by a hierarchical structure in deep neural networks as straight lines, depending on the number of hidden layers and the number of hidden neurons. Second, we derive a sufficient condition for deep neural networks having no critical points introduced by a hierarchical structure, which can be applied to general deep neural networks. It is also shown that the existence of critical points introduced by a hierarchical structure is determined by the rank and the regularity of weight matrices for a specific class of deep neural networks. Finally, two kinds of implementation methods of the sufficient conditions to have no critical points are provided. One is a learning algorithm that can avoid critical points introduced by the hierarchical structure during learning (called avoidant learning algorithm). The other is a neural network that does not have some critical points introduced by the hierarchical structure as an inherent property (called avoidant neural network).",4
Improving Neural-Network Classifiers Using Nearest Neighbor Partitioning.,"This paper presents a nearest neighbor partitioning method designed to improve the performance of a neural-network classifier. For neural-network classifiers, usually the number, positions, and labels of centroids are fixed in partition space before training. However, that approach limits the search for potential neural networks during optimization; the quality of a neural network classifier is based on how clear the decision boundaries are between classes. Although attempts have been made to generate floating centroids automatically, these methods still tend to generate sphere-like partitions and cannot produce flexible decision boundaries. We propose the use of nearest neighbor classification in conjunction with a neural-network classifier. Instead of being bound by sphere-like boundaries (such as the case with centroid-based methods), the flexibility of nearest neighbors increases the chance of finding potential neural networks that have arbitrarily shaped boundaries in partition space. Experimental results demonstrate that the proposed method exhibits superior performance on accuracy and average f-measure.",4
Methodology of Recurrent Laguerre-Volterra Network for Modeling Nonlinear Dynamic Systems.,"In this paper, we have introduced a general modeling approach for dynamic nonlinear systems that utilizes a variant of the simulated annealing algorithm for training the Laguerre-Volterra network (LVN) to overcome the local minima and convergence problems and employs a pruning technique to achieve sparse LVN representations with l1 regularization. We tested this new approach with computer simulated systems and extended it to autoregressive sparse LVN (ASLVN) model structures that are suitable for input-output modeling of nonlinear systems that exhibit transitions in dynamic states, such as the Hodgkin-Huxley (H-H) equations of neuronal firing. Application of the proposed ASLVN to the H-H equations yields a more parsimonious input-output model with improved predictive capability that is amenable to more insightful physiological/biological interpretation.",4
A New Discriminative Sparse Representation Method for Robust Face Recognition via l(2) Regularization.,"Sparse representation has shown an attractive performance in a number of applications. However, the available sparse representation methods still suffer from some problems, and it is necessary to design more efficient methods. Particularly, to design a computationally inexpensive, easily solvable, and robust sparse representation method is a significant task. In this paper, we explore the issue of designing the simple, robust, and powerfully efficient sparse representation methods for image classification. The contributions of this paper are as follows. First, a novel discriminative sparse representation method is proposed and its noticeable performance in image classification is demonstrated by the experimental results. More importantly, the proposed method outperforms the existing state-of-the-art sparse representation methods. Second, the proposed method is not only very computationally efficient but also has an intuitive and easily understandable idea. It exploits a simple algorithm to obtain a closed-form solution and discriminative representation of the test sample. Third, the feasibility, computational efficiency, and remarkable classification accuracy of the proposed l(2) regularization-based representation are comprehensively shown by extensive experiments and analysis. The code of the proposed method is available at http://www.yongxu.org/lunwen.html.",4
Smooth Neuroadaptive PI Tracking Control of Nonlinear Systems With Unknown and Nonsmooth Actuation Characteristics.,"This paper considers the tracking control problem for a class of multi-input multi-output nonlinear systems subject to unknown actuation characteristics and external disturbances. Neuroadaptive proportional-integral (PI) control with self-tuning gains is proposed, which is structurally simple and computationally inexpensive. Different from traditional PI control, the proposed one is able to online adjust its PI gains using stability-guaranteed analytic algorithms without involving manual tuning or trial and error process. It is shown that the proposed neuroadaptive PI control is continuous and smooth everywhere and ensures the uniformly ultimately boundedness of all the signals of the closed-loop system. Furthermore, the crucial compact set precondition for a neural network (NN) to function properly is guaranteed with the barrier Lyapunov function, allowing the NN unit to play its learning/approximating role during the entire system operation. The salient feature also lies in its low complexity in computation and effectiveness in dealing with modeling uncertainties and nonlinearities. Both square and nonsquare nonlinear systems are addressed. The benefits and the feasibility of the developed control are also confirmed by simulations.",4
Kinematic Control of Redundant Manipulators Using Neural Networks.,"Redundancy resolution is a critical problem in the control of robotic manipulators. Recurrent neural networks (RNNs), as inherently parallel processing models for time-sequence processing, are potentially applicable for the motion control of manipulators. However, the development of neural models for high-accuracy and real-time control is a challenging problem. This paper identifies two limitations of the existing RNN solutions for manipulator control, i.e., position error accumulation and the convex restriction on the projection set, and overcomes them by proposing two modified neural network models. Our method allows nonconvex sets for projection operations, and control error does not accumulate over time in the presence of noise. Unlike most works in which RNNs are used to process time sequences, the proposed approach is model-based and training-free, which makes it possible to achieve fast tracking of reference signals with superior robustness and accuracy. Theoretical analysis reveals the global stability of a system under the control of the proposed neural networks. Simulation results confirm the effectiveness of the proposed control method in both the position regulation and tracking control of redundant PUMA 560 manipulators.",4
Predictor-Based Neural Dynamic Surface Control for Uncertain Nonlinear Systems in Strict-Feedback Form.,"This paper presents a predictor-based neural dynamic surface control (PNDSC) design method for a class of uncertain nonlinear systems in a strict-feedback form. In contrast to existing NDSC approaches where the tracking errors are commonly used to update neural network weights, a predictor is proposed for every subsystem, and the prediction errors are employed to update the neural adaptation laws. The proposed scheme enables smooth and fast identification of system dynamics without incurring high-frequency oscillations, which are unavoidable using classical NDSC methods. Furthermore, the result is extended to the PNDSC with observer feedback, and its robustness against measurement noise is analyzed. Numerical and experimental results are given to demonstrate the efficacy of the proposed PNDSC architecture.",4
Containment Control for Second-Order Multiagent Systems Communicating Over Heterogeneous Networks.,"The containment control is studied for the second-order multiagent systems over a heterogeneous network where the position and velocity interactions are different. We consider three cases that multiple leaders are stationary, moving at the same constant speed, and moving at the same time-varying speed, and develop different containment control algorithms for each case. In particular, for the former two cases, we first propose the containment algorithms based on the well-established ones for the homogeneous network, for which the position interaction topology is required to be undirected. Then, we extend the results to the general setting with the directed position and velocity interaction topologies by developing a novel algorithm. For the last case with time-varying velocities, we introduce two algorithms to address the containment control problem under, respectively, the directed and undirected interaction topologies. For most cases, sufficient conditions with regard to the interaction topologies are derived for guaranteeing the containment behavior and, thus, are easy to verify. Finally, six simulation examples are presented to illustrate the validity of the theoretical findings.",4
Large-Cone Nonnegative Matrix Factorization.,"Nonnegative matrix factorization (NMF) has been greatly popularized by its parts-based interpretation and the effective multiplicative updating rule for searching local solutions. In this paper, we study the problem of how to obtain an attractive local solution for NMF, which not only fits the given training data well but also generalizes well on the unseen test data. Based on the geometric interpretation of NMF, we introduce two large-cone penalties for NMF and propose large-cone NMF (LCNMF) algorithms. Compared with NMF, LCNMF will obtain bases comprising a larger simplicial cone, and therefore has three advantages. 1) the empirical reconstruction error of LCNMF could mostly be smaller; (2) the generalization ability of the proposed algorithm is much more powerful; and (3) the obtained bases of LCNMF have a low-overlapping property, which enables the bases to be sparse and makes the proposed algorithms very robust. Experiments on synthetic and real-world data sets confirm the efficiency of LCNMF.",4
Online Regression for Data With Changepoints Using Gaussian Processes and Reusable Models.,"Many prediction, decision-making, and control architectures rely on online learned Gaussian process (GP) models. However, most existing GP regression algorithms assume a single generative model, leading to poor predictive performance when the data are nonstationary, i.e., generated from multiple switching processes. Furthermore, existing methods for GP regression over nonstationary data require significant computation, do not come with provable guarantees on correctness and speed, and many only work in batch settings, making them ill-suited for real-time prediction. We present an efficient online GP framework, GP-non-Bayesian clustering (GP-NBC), which addresses these computational and theoretical issues, allowing for real-time changepoint detection and regression using GPs. Our empirical results on two real-world data sets and two synthetic data set show that GP-NBC outperforms state-of-the-art methods for nonstationary regression in terms of both regression error and computation. For example, it outperforms Dirichlet process GP clustering with Gibbs sampling by 98% in computation time reduction while the mean absolute error is comparable.",4
Budget Online Learning Algorithm for Least Squares SVM.,"Batch-mode least squares support vector machine (LSSVM) is often associated with unbounded number of support vectors (SVs'), making it unsuitable for applications involving large-scale streaming data. Limited-scale LSSVM, which allows efficient updating, seems to be a good solution to tackle this issue. In this paper, to train the limited-scale LSSVM dynamically, we present a budget online LSSVM (BOLSSVM) algorithm. Methodologically, by setting a fixed budget for SVs', we are able to update the LSSVM model according to the updated SVs' set dynamically without retraining from scratch. In particular, when a new small chunk of SVs' substitute for the old ones, the proposed algorithm employs a low rank correction technology and the Sherman-Morrison-Woodbury formula to compute the inverse of saddle point matrix derived from the LSSVM's Karush-Kuhn-Tucker (KKT) system, which, in turn, updates the LSSVM model efficiently. In this way, the proposed BOLSSVM algorithm is especially useful for online prediction tasks. Another merit of the proposed BOLSSVM is that it can be used for k -fold cross validation. Specifically, compared with batch-mode learning methods, the computational complexity of the proposed BOLSSVM method is significantly reduced from O(n(4)) to O(n(3)) for leave-one-out cross validation with n training samples. The experimental results of classification and regression on benchmark data sets and real-world applications show the validity and effectiveness of the proposed BOLSSVM algorithm.",4
Neural Network-Based Passive Filtering for Delayed Neutral-Type Semi-Markovian Jump Systems.,"This paper investigates the problem of exponential passive filtering for a class of stochastic neutral-type neural networks with both semi-Markovian jump parameters and mixed time delays. Our aim is to estimate the states by designing a Luenberger-type observer, such that the filter error dynamics are mean-square exponentially stable with an expected decay rate and an attenuation level. Sufficient conditions for the existence of passive filters are obtained, and a convex optimization algorithm for the filter design is given. In addition, a cone complementarity linearization procedure is employed to cast the nonconvex feasibility problem into a sequential minimization problem, which can be readily solved by the existing optimization techniques. Numerical examples are given to demonstrate the effectiveness of the proposed techniques.",4
A Novel Neural Network for Generally Constrained Variational Inequalities.,"This paper presents a novel neural network for solving generally constrained variational inequality problems by constructing a system of double projection equations. By defining proper convex energy functions, the proposed neural network is proved to be stable in the sense of Lyapunov and converges to an exact solution of the original problem for any starting point under the weaker cocoercivity condition or the monotonicity condition of the gradient mapping on the linear equation set. Furthermore, two sufficient conditions are provided to ensure the stability of the proposed neural network for a special case. The proposed model overcomes some shortcomings of existing continuous-time neural networks for constrained variational inequality, and its stability only requires some monotonicity conditions of the underlying mapping and the concavity of nonlinear inequality constraints on the equation set. The validity and transient behavior of the proposed neural network are demonstrated by some simulation results.",4
Online Learning of Hierarchical Pitman-Yor Process Mixture of Generalized Dirichlet Distributions With Feature Selection.,"In this paper, a novel statistical generative model based on hierarchical Pitman-Yor process and generalized Dirichlet distributions (GDs) is presented. The proposed model allows us to perform joint clustering and feature selection thanks to the interesting properties of the GD distribution. We develop an online variational inference algorithm, formulated in terms of the minimization of a Kullback-Leibler divergence, of our resulting model that tackles the problem of learning from high-dimensional examples. This variational Bayes formulation allows simultaneously estimating the parameters, determining the model's complexity, and selecting the appropriate relevant features for the clustering structure. Moreover, the proposed online learning algorithm allows data instances to be processed in a sequential manner, which is critical for large-scale and real-time applications. Experiments conducted using challenging applications, namely, scene recognition and video segmentation, where our approach is viewed as an unsupervised technique for visual learning in high-dimensional spaces, showed that the proposed approach is suitable and promising.",4
Descriptor Learning via Supervised Manifold Regularization for Multioutput Regression.,"Multioutput regression has recently shown great ability to solve challenging problems in both computer vision and medical image analysis. However, due to the huge image variability and ambiguity, it is fundamentally challenging to handle the highly complex input-target relationship of multioutput regression, especially with indiscriminate high-dimensional representations. In this paper, we propose a novel supervised descriptor learning (SDL) algorithm for multioutput regression, which can establish discriminative and compact feature representations to improve the multivariate estimation performance. The SDL is formulated as generalized low-rank approximations of matrices with a supervised manifold regularization. The SDL is able to simultaneously extract discriminative features closely related to multivariate targets and remove irrelevant and redundant information by transforming raw features into a new low-dimensional space aligned to targets. The achieved discriminative while compact descriptor largely reduces the variability and ambiguity for multioutput regression, which enables more accurate and efficient multivariate estimation. We conduct extensive evaluation of the proposed SDL on both synthetic data and real-world multioutput regression tasks for both computer vision and medical image analysis. Experimental results have shown that the proposed SDL can achieve high multivariate estimation accuracy on all tasks and largely outperforms the algorithms in the state of the arts. Our method establishes a novel SDL framework for multioutput regression, which can be widely used to boost the performance in different applications.",4
An Approach to Stable Gradient-Descent Adaptation of Higher Order Neural Units.,"Stability evaluation of a weight-update system of higher order neural units (HONUs) with polynomial aggregation of neural inputs (also known as classes of polynomial neural networks) for adaptation of both feedforward and recurrent HONUs by a gradient descent method is introduced. An essential core of the approach is based on the spectral radius of a weight-update system, and it allows stability monitoring and its maintenance at every adaptation step individually. Assuring the stability of the weight-update system (at every single adaptation step) naturally results in the adaptation stability of the whole neural architecture that adapts to the target data. As an aside, the used approach highlights the fact that the weight optimization of HONU is a linear problem, so the proposed approach can be generally extended to any neural architecture that is linear in its adaptable parameters.",4
Dynamic Surface Control for a Class of Nonlinear Feedback Linearizable Systems With Actuator Failures.,"In this brief, we propose a dynamic surface control with actuator failure compensation for a class of feedback linearizable systems with locally Lipschitz nonlinearities. First, a dynamic surface state feedback control scheme is designed, which incorporates radial basis function networks in a novel approach, to compensate system uncertainties and dynamic changes induced by actuator failures. Then, an output feedback controller is obtained by means of high-gain observers. It is proved that our control schemes guarantee the uniform ultimate boundedness of the system, and that the output tracking error converges to an arbitrarily small residual set. Finally, a simulation is carried out to illustrate the performance of the designed control schemes.",4
A Novel Locally Linear KNN Method With Applications to Visual Recognition.,"A locally linear K Nearest Neighbor (LLK) method is presented in this paper with applications to robust visual recognition. Specifically, the concept of an ideal representation is first presented, which improves upon the traditional sparse representation in many ways. The objective function based on a host of criteria for sparsity, locality, and reconstruction is then optimized to derive a novel representation, which is an approximation to the ideal representation. The novel representation is further processed by two classifiers, namely, an LLK-based classifier and a locally linear nearest mean-based classifier, for visual recognition. The proposed classifiers are shown to connect to the Bayes decision rule for minimum error. Additional new theoretical analysis is presented, such as the nonnegative constraint, the group regularization, and the computational efficiency of the proposed LLK method. New methods such as a shifted power transformation for improving reliability, a coefficients' truncating method for enhancing generalization, and an improved marginal Fisher analysis method for feature extraction are proposed to further improve visual recognition performance. Extensive experiments are implemented to evaluate the proposed LLK method for robust visual recognition. In particular, eight representative data sets are applied for assessing the performance of the LLK method for various visual recognition applications, such as action recognition, scene recognition, object recognition, and face recognition.",4
Design of Probabilistic Boolean Networks Based on Network Structure and Steady-State Probabilities.,"In this brief, we consider the problem of finding a probabilistic Boolean network (PBN) based on a network structure and desired steady-state properties. In systems biology and synthetic biology, such problems are important as an inverse problem. Using a matrix-based representation of PBNs, a solution method for this problem is proposed. The problem of finding a BN has been studied so far. In the problem of finding a PBN, we must calculate not only the Boolean functions, but also the probabilities of selecting a Boolean function and the number of candidates of the Boolean functions. Hence, the problem of finding a PBN is more difficult than that of finding a BN. The effectiveness of the proposed method is presented by numerical examples.",4
The Growing Hierarchical Neural Gas Self-Organizing Neural Network.,"The growing neural gas (GNG) self-organizing neural network stands as one of the most successful examples of unsupervised learning of a graph of processing units. Despite its success, little attention has been devoted to its extension to a hierarchical model, unlike other models such as the self-organizing map, which has many hierarchical versions. Here, a hierarchical GNG is presented, which is designed to learn a tree of graphs. Moreover, the original GNG algorithm is improved by a distinction between a growth phase where more units are added until no significant improvement in the quantization error is obtained, and a convergence phase where no unit creation is allowed. This means that a principled mechanism is established to control the growth of the structure. Experiments are reported, which demonstrate the self-organization and hierarchy learning abilities of our approach and its performance for vector quantization applications.",4
Visual Recognition by Learning From Web Data via Weakly Supervised Domain Generalization.,"In this paper, a weakly supervised domain generalization (WSDG) method is proposed for real-world visual recognition tasks, in which we train classifiers by using Web data (e.g., Web images and Web videos) with noisy labels. In particular, two challenging problems need to be solved when learning robust classifiers, in which the first issue is to cope with the label noise of training Web data from the source domain, while the second issue is to enhance the generalization capability of learned classifiers to an arbitrary target domain. In order to handle the first problem, the training samples within each category are partitioned into clusters, where we use one bag to denote each cluster and instances to denote the samples in each cluster. Then, we identify a proportion of good training samples in each bag and train robust classifiers by using the good training samples, which leads to a multi-instance learning (MIL) problem. In order to handle the second problem, we assume that the training samples possibly form a set of hidden domains, with each hidden domain associated with a distinctive data distribution. Then, for each category and each hidden latent domain, we propose to learn one classifier by extending our MIL formulation, which leads to our WSDG approach. In the testing stage, our approach can obtain better generalization capability by effectively integrating multiple classifiers from different latent domains in each category. Moreover, our WSDG approach is further extended to utilize additional textual descriptions associated with Web data as privileged information (PI), although testing data do not have such PI. Extensive experiments on three benchmark data sets indicate that our newly proposed methods are effective for real-world visual recognition tasks by learning from Web data.",4
Iterative Adaptive Dynamic Programming for Solving Unknown Nonlinear Zero-Sum Game Based on Online Data.,"Hinfinity control is a powerful method to solve the disturbance attenuation problems that occur in some control systems. The design of such controllers relies on solving the zero-sum game (ZSG). But in practical applications, the exact dynamics is mostly unknown. Identification of dynamics also produces errors that are detrimental to the control performance. To overcome this problem, an iterative adaptive dynamic programming algorithm is proposed in this paper to solve the continuous-time, unknown nonlinear ZSG with only online data. A model-free approach to the Hamilton-Jacobi-Isaacs equation is developed based on the policy iteration method. Control and disturbance policies and value are approximated by neural networks (NNs) under the critic-actor-disturber structure. The NN weights are solved by the least-squares method. According to the theoretical analysis, our algorithm is equivalent to a Gauss-Newton method solving an optimization problem, and it converges uniformly to the optimal solution. The online data can also be used repeatedly, which is highly efficient. Simulation results demonstrate its feasibility to solve the unknown nonlinear ZSG. When compared with other algorithms, it saves a significant amount of online measurement time.",4
Dynamical Analysis of the Hindmarsh-Rose Neuron With Time Delays.,"This brief is mainly concerned with a series of dynamical analyses of the Hindmarsh-Rose (HR) neuron with state-dependent time delays. The dynamical analyses focus on stability, Hopf bifurcation, as well as chaos and chaos control. Through the stability and bifurcation analysis, we determine that increasing the external current causes the excitable HR neuron to exhibit periodic or chaotic bursting/spiking behaviors and emit subcritical Hopf bifurcation. Furthermore, by choosing a fixed external current and varying the time delay, the stability of the HR neuron is affected. We analyze the chaotic behaviors of the HR neuron under a fixed external current through time series, bifurcation diagram, Lyapunov exponents, and Lyapunov dimension. We also analyze the synchronization of the chaotic time-delayed HR neuron through nonlinear control. Based on an appropriate Lyapunov-Krasovskii functional with triple integral terms, a nonlinear feedback control scheme is designed to achieve synchronization between the uncontrolled and controlled models. The proposed synchronization criteria are derived in terms of linear matrix inequalities to achieve the global asymptotical stability of the considered error model under the designed control scheme. Finally, numerical simulations pertaining to stability, Hopf bifurcation, periodic, chaotic, and synchronized models are provided to demonstrate the effectiveness of the derived theoretical results.",4
An Adaptive NN-Based Approach for Fault-Tolerant Control of Nonlinear Time-Varying Delay Systems With Unmodeled Dynamics.,"This paper presents an adaptive neural network (NN)-based fault-tolerant control approach for the compensation of actuator failures in nonlinear systems with time-varying delay. The novelty of this paper lies in the fact that both the lock in place and loss of effectiveness faults, unmodeled dynamics, and dynamic disturbances are catered for simultaneously. Furthermore, this is achieved by the adaptation of only one parameter, which simplifies the computation of the control effort, and therefore extends its applicability. In the approach, the Razumikhin lemma and a dynamic signal are employed. It is shown that the output of the system converges to a neighborhood of the reference signal and the semiglobal boundedness of all signals is guaranteed. A simulation example is used to illustrate the validity and efficacy of the approach.",4
Dissimilarity-Based Ensembles for Multiple Instance Learning.,"In multiple instance learning, objects are sets (bags) of feature vectors (instances) rather than individual feature vectors. In this paper, we address the problem of how these bags can best be represented. Two standard approaches are to use (dis)similarities between bags and prototype bags, or between bags and prototype instances. The first approach results in a relatively low-dimensional representation, determined by the number of training bags, whereas the second approach results in a relatively high-dimensional representation, determined by the total number of instances in the training set. However, an advantage of the latter representation is that the informativeness of the prototype instances can be inferred. In this paper, a third, intermediate approach is proposed, which links the two approaches and combines their strengths. Our classifier is inspired by a random subspace ensemble, and considers subspaces of the dissimilarity space, defined by subsets of instances, as prototypes. We provide insight into the structure of some popular multiple instance problems and show state-of-the-art performances on these data sets.",4
Improving Visual Saliency Computing With Emotion Intensity.,"Saliency maps that integrate individual feature maps into a global measure of visual attention are widely used to estimate human gaze density. Most of the existing methods consider low-level visual features and locations of objects, and/or emphasize the spatial position with center prior. Recent psychology research suggests that emotions strongly influence human visual attention. In this paper, we explore the influence of emotional content on visual attention. On top of the traditional bottom-up saliency map generation, our saliency map is generated in cooperation with three emotion factors, i.e., general emotional content, facial expression intensity, and emotional object locations. Experiments, carried out on National University of Singapore Eye Fixation (a public eye tracking data set), demonstrate that incorporating emotion does improve the quality of visual saliency maps computed by bottom-up approaches for the gaze density estimation. Our method increases about 0.1 on an average of area under the curve of receiver operation characteristic curve, compared with the four baseline bottom-up approaches (Itti's, attention based on information maximization, saliency using natural, and graph-based vision saliency).",4
Exponential Synchronization of Memristive Neural Networks With Delays: Interval Matrix Method.,"This paper considers the global exponential synchronization of drive-response memristive neural networks (MNNs) with heterogeneous time-varying delays. Because the parameters of MNNs are state-dependent, the MNNs may exhibit unexpected parameter mismatch when different initial conditions are chosen. Therefore, traditional robust control scheme cannot guarantee the synchronization of MNNs. Under the framework of Filippov solution, the drive and response MNNs are first transformed into systems with interval parameters. Then suitable controllers are designed to overcome the problem of mismatched parameters and synchronize the coupled MNNs. Based on some novel Lyapunov functionals and interval matrix inequalities, several sufficient conditions are derived to guarantee the exponential synchronization. Moreover, adaptive control is also investigated for the exponential synchronization. Numerical simulations are provided to illustrate the effectiveness of the theoretical analysis.",4
Extending the Peak Bandwidth of Parameters for Softmax Selection in Reinforcement Learning.,"Softmax selection is one of the most popular methods for action selection in reinforcement learning. Although various recently proposed methods may be more effective with full parameter tuning, implementing a complicated method that requires the tuning of many parameters can be difficult. Thus, softmax selection is still worth revisiting, considering the cost savings of its implementation and tuning. In fact, this method works adequately in practice with only one parameter appropriately set for the environment. The aim of this paper is to improve the variable setting of this method to extend the bandwidth of good parameters, thereby reducing the cost of implementation and parameter tuning. To achieve this, we take advantage of the asymptotic equipartition property in a Markov decision process to extend the peak bandwidth of softmax selection. Using a variety of episodic tasks, we show that our setting is effective in extending the bandwidth and that it yields a better policy in terms of stability. The bandwidth is quantitatively assessed in a series of statistical tests.",4
A Memristive Multilayer Cellular Neural Network With Applications to Image Processing.,"The memristor has been extensively studied in electrical engineering and biological sciences as a means to compactly implement the synaptic function in neural networks. The cellular neural network (CNN) is one of the most implementable artificial neural network models and capable of massively parallel analog processing. In this paper, a novel memristive multilayer CNN (Mm-CNN) model is presented along with its performance analysis and applications. In this new CNN design, the memristor crossbar circuit acts as the synapse, which realizes one signed synaptic weight with a pair of memristors and performs the synaptic weighting compactly and linearly. Moreover, the complex weighted summation is executed in an efficient way with a proper design of Mm-CNN cell circuits. The proposed Mm-CNN has several merits, such as compactness, nonvolatility, versatility, and programmability of synaptic weights. Its performance in several image processing applications is illustrated through simulations.",4
Passivity of Directed and Undirected Complex Dynamical Networks With Adaptive Coupling Weights.,"A complex dynamical network consisting of N identical neural networks with reaction-diffusion terms is considered in this paper. First, several passivity definitions for the systems with different dimensions of input and output are given. By utilizing some inequality techniques, several criteria are presented, ensuring the passivity of the complex dynamical network under the designed adaptive law. Then, we discuss the relationship between the synchronization and output strict passivity of the proposed network model. Furthermore, these results are extended to the case when the topological structure of the network is undirected. Finally, two examples with numerical simulations are provided to illustrate the correctness and effectiveness of the proposed results.",4
Understanding Social Causalities Behind Human Action Sequences.,"Social causality study on human action sequences is useful and important to improve our understandings to human behaviors on online social networks. The redundant indirect causalities and unobserved confounding factors, such as homophily and simultaneity phenomena, contribute to the huge challenges on accurate causal discovery on such human actions. A causal relationship exists between two persons, if the actions of one person are significantly affected by the actions of the other person, while fairly independent of her/his own prior actions. In this paper, we design a systematic approach based on conditional independence testing to detect such asymmetric relations, even when there are latent confounders underneath the observational action sequences. Technically, a group of asymmetric independence tests are conducted to infer the loose causal directions between action sequence pairs, followed by another group of tests to distinguish different types of relationships, e.g., homophily and simultaneity. Finally, a causal structure learning method is employed to output pairwise causalities with redundant indirect causalities eliminated. Empirical evaluations on simulated data verify the effectiveness and scalability of our proposals. We also present four interesting patterns of causal relations found by our algorithm, on real Sina Weibo feeds, including two new patterns never reported in previous studies.",4
Tensor LRR and Sparse Coding-Based Subspace Clustering.,"Subspace clustering groups a set of samples from a union of several linear subspaces into clusters, so that the samples in the same cluster are drawn from the same linear subspace. In the majority of the existing work on subspace clustering, clusters are built based on feature information, while sample correlations in their original spatial structure are simply ignored. Besides, original high-dimensional feature vector contains noisy/redundant information, and the time complexity grows exponentially with the number of dimensions. To address these issues, we propose a tensor low-rank representation (TLRR) and sparse coding-based (TLRRSC) subspace clustering method by simultaneously considering feature information and spatial structures. TLRR seeks the lowest rank representation over original spatial structures along all spatial directions. Sparse coding learns a dictionary along feature spaces, so that each sample can be represented by a few atoms of the learned dictionary. The affinity matrix used for spectral clustering is built from the joint similarities in both spatial and feature spaces. TLRRSC can well capture the global structure and inherent feature information of data and provide a robust subspace segmentation from corrupted data. Experimental results on both synthetic and real-world data sets show that TLRRSC outperforms several established stateof- the-art methods.",4
A Survey of Memristive Threshold Logic Circuits.,"In this paper, we review different memristive threshold logic (MTL) circuits that are inspired from the synaptic action of the flow of neurotransmitters in the biological brain. The brainlike generalization ability and the area minimization of these threshold logic circuits aim toward crossing Moore's law boundaries at device, circuits, and systems levels. Fast switching memory, signal processing, control systems, programmable logic, image processing, reconfigurable computing, and pattern recognition are identified as some of the potential applications of MTL systems. The physical realization of nanoscale devices with memristive behavior from materials, such as TiO2, ferroelectrics, silicon, and polymers, has accelerated research effort in these application areas, inspiring the scientific community to pursue the design of high-speed, low-cost, low-power, and high-density neuromorphic architectures.",4
Bridging the Gap Between Imitation Learning and Inverse Reinforcement Learning.,"Learning from demonstrations is a paradigm by which an apprentice agent learns a control policy for a dynamic environment by observing demonstrations delivered by an expert agent. It is usually implemented as either imitation learning (IL) or inverse reinforcement learning (IRL) in the literature. On the one hand, IRL is a paradigm relying on the Markov decision processes, where the goal of the apprentice agent is to find a reward function from the expert demonstrations that could explain the expert behavior. On the other hand, IL consists in directly generalizing the expert strategy, observed in the demonstrations, to unvisited states (and it is therefore close to classification, when there is a finite set of possible decisions). While these two visions are often considered as opposite to each other, the purpose of this paper is to exhibit a formal link between these approaches from which new algorithms can be derived. We show that IL and IRL can be redefined in a way that they are equivalent, in the sense that there exists an explicit bijective operator (namely, the inverse optimal Bellman operator) between their respective spaces of solutions. To do so, we introduce the set-policy framework that creates a clear link between the IL and the IRL. As a result, the IL and IRL solutions making the best of both worlds are obtained. In addition, it is a unifying framework from which existing IL and IRL algorithms can be derived and which opens the way for the IL methods able to deal with the environment's dynamics. Finally, the IRL algorithms derived from the set-policy framework are compared with the algorithms belonging to the more common trajectory-matching family. Experiments demonstrate that the set-policy-based algorithms outperform both the standard IRL and IL ones and result in more robust solutions.",4
Switched-Observer-Based Adaptive Neural Control of MIMO Switched Nonlinear Systems With Unknown Control Gains.,"In this paper, the problem of adaptive neural output-feedback control is addressed for a class of multi-input multioutput (MIMO) switched uncertain nonlinear systems with unknown control gains. Neural networks (NNs) are used to approximate unknown nonlinear functions. In order to avoid the conservativeness caused by adoption of a common observer for all subsystems, an MIMO NN switched observer is designed to estimate unmeasurable states. A new switched observer-based adaptive neural control technique for the problem studied is then provided by exploiting the classical average dwell time (ADT) method and the backstepping method and the Nussbaum gain technique. It effectively handles the obstacle about the coexistence of multiple Nussbaum-type function terms, and improves the classical ADT method, since the exponential decline property of Lyapunov functions for individual subsystems is no longer satisfied. It is shown that the technique proposed is able to guarantee semiglobal uniformly ultimately boundedness of all the signals in the closed-loop system under a class of switching signals with ADT, and the tracking errors converge to a small neighborhood of the origin. The effectiveness of the approach proposed is illustrated by its application to a two inverted pendulum system.",4
Railway Track Circuit Fault Diagnosis Using Recurrent Neural Networks.,"Timely detection and identification of faults in railway track circuits are crucial for the safety and availability of railway networks. In this paper, the use of the long-short-term memory (LSTM) recurrent neural network is proposed to accomplish these tasks based on the commonly available measurement signals. By considering the signals from multiple track circuits in a geographic area, faults are diagnosed from their spatial and temporal dependences. A generative model is used to show that the LSTM network can learn these dependences directly from the data. The network correctly classifies 99.7% of the test input sequences, with no false positive fault detections. In addition, the t-Distributed Stochastic Neighbor Embedding (t-SNE) method is used to examine the resulting network, further showing that it has learned the relevant dependences in the data. Finally, we compare our LSTM network with a convolutional network trained on the same task. From this comparison, we conclude that the LSTM network architecture is better suited for the railway track circuit fault detection and identification tasks than the convolutional network.",4
The Proximal Trajectory Algorithm in SVM Cross Validation.,"We propose a bilevel cross-validation scheme for support vector machine (SVM) model selection based on the construction of the entire regularization path. Since such path is a particular case of the more general proximal trajectory concept from nonsmooth optimization, we propose for its construction an algorithm based on solving a finite number of structured linear programs. Our methodology, differently from other approaches, works directly on the primal form of SVM. Numerical results are presented on binary data sets drawn from literature.",4
Hybrid Sampling-Based Clustering Ensemble With Global and Local Constitutions.,"Among a number of ensemble learning techniques, boosting and bagging are the most popular sampling-based ensemble approaches for classification problems. Boosting is considered stronger than bagging on noise-free data set with complex class structures, whereas bagging is more robust than boosting in cases where noise data are present. In this paper, we extend both ensemble approaches to clustering tasks, and propose a novel hybrid sampling-based clustering ensemble by combining the strengths of boosting and bagging. In our approach, the input partitions are iteratively generated via a hybrid process inspired by both boosting and bagging. Then, a novel consensus function is proposed to encode the local and global cluster structure of input partitions into a single representation, and applies a single clustering algorithm to such representation to obtain the consolidated consensus partition. Our approach has been evaluated on 2-D-synthetic data, collection of benchmarks, and real-world facial recognition data sets, which show that the proposed technique outperforms the existing benchmarks for a variety of clustering tasks.",4
Storing Sequences in Binary Tournament-Based Neural Networks.,"An extension to a recently introduced architecture of clique-based neural networks is presented. This extension makes it possible to store sequences with high efficiency. To obtain this property, network connections are provided with orientation and with flexible redundancy carried by both spatial and temporal redundancies, a mechanism of anticipation being introduced in the model. In addition to the sequence storage with high efficiency, this new scheme also offers biological plausibility. In order to achieve accurate sequence retrieval, a double-layered structure combining heteroassociation and autoassociation is also proposed.",4
Learning With Jensen-Tsallis Kernels.,"Jensen-type [Jensen-Shannon (JS) and Jensen-Tsallis] kernels were first proposed by Martins et al. (2009). These kernels are based on JS divergences that originated in the information theory. In this paper, we extend the Jensen-type kernels on probability measures to define positive-definite kernels on Euclidean space. We show that the special cases of these kernels include dot-product kernels. Since Jensen-type divergences are multidistribution divergences, we propose their multipoint variants, and study spectral clustering and kernel methods based on these. We also provide experimental studies on benchmark image database and gene expression database that show the benefits of the proposed kernels compared with the existing kernels. The experiments on clustering also demonstrate the use of constructing multipoint similarities.",4
Adaptation to New Microphones Using Artificial Neural Networks With Trainable Activation Functions.,"Model adaptation is a key technique that enables a modern automatic speech recognition (ASR) system to adjust its parameters, using a small amount of enrolment data, to the nuances in the speech spectrum due to microphone mismatch in the training and test data. In this brief, we investigate four different adaptation schemes for connectionist (also known as hybrid) ASR systems that learn microphone-specific hidden unit contributions, given some adaptation material. This solution is made possible adopting one of the following schemes: 1) the use of Hermite activation functions; 2) the introduction of bias and slope parameters in the sigmoid activation functions; 3) the injection of an amplitude parameter specific for each sigmoid unit; or 4) the combination of 2) and 3). Such a simple yet effective solution allows the adapted model to be stored in a small-sized storage space, a highly desirable property of adaptation algorithms for deep neural networks that are suitable for large-scale online deployment. Experimental results indicate that the investigated approaches reduce word error rates on the standard Spoke 6 task of the Wall Street Journal corpus compared with unadapted ASR systems. Moreover, the proposed adaptation schemes all perform better than simple multicondition training and comparable favorably against conventional linear regression-based approaches while using up to 15 orders of magnitude fewer parameters. The proposed adaptation strategies are also effective when a single adaptation sentence is available.",4
Global Synchronization of Multiple Recurrent Neural Networks With Time Delays via Impulsive Interactions.,"In this paper, new results on the global synchronization of multiple recurrent neural networks (NNs) with time delays via impulsive interactions are presented. Impulsive interaction means that a number of NNs communicate with each other at impulse instants only, while they are independent at the remaining time. The communication topology among NNs is not required to be always connected and can switch ON and OFF at different impulse instants. By using the concept of sequential connectivity and the properties of stochastic matrices, a set of sufficient conditions depending on time delays is derived to ascertain global synchronization of multiple continuous-time recurrent NNs. In addition, a counterpart on the global synchronization of multiple discrete-time NNs is also discussed. Finally, two examples are presented to illustrate the results.",4
A Collective Neurodynamic Approach to Distributed Constrained Optimization.,"This paper presents a collective neurodynamic approach with multiple interconnected recurrent neural networks (RNNs) for distributed constrained optimization. The objective function of the distributed optimization problems to be solved is a sum of local convex objective functions, which may be nonsmooth. Subject to its local constraints, each local objective function is minimized individually by using an RNN, with consensus among others. In contrast to existing continuous-time distributed optimization methods, the proposed collective neurodynamic approach is capable of solving more general distributed optimization problems. Simulation results on three numerical examples are discussed to substantiate the effectiveness and characteristics of the proposed approach. In addition, an application to the optimal placement problem is delineated to demonstrate the viability of the approach.",4
Assessing the Influence of an Individual Event in Complex Fault Spreading Network Based on Dynamic Uncertain Causality Graph.,"Identifying the pivotal causes and highly influential spreaders in fault propagation processes is crucial for improving the maintenance decision making for complex systems under abnormal and emergency situations. A dynamic uncertain causality graph-based method is introduced in this paper to explicitly model the uncertain causalities among system components, identify fault conditions, locate the fault origins, and predict the spreading tendency by means of probabilistic reasoning. A new algorithm is proposed to assess the impacts of an individual event by investigating the corresponding node's time-variant betweenness centrality and the strength of global causal influence in the fault propagation network. The algorithm does not depend on the whole original and static network but on the real-time spreading behaviors and dynamics, which makes the algorithm to be specifically targeted and more efficient. Experiments on both simulated networks and real-world systems demonstrate the accuracy, effectiveness, and comprehensibility of the proposed method for the fault management of power grids and other complex networked systems.",4
Structural Minimax Probability Machine.,"Minimax probability machine (MPM) is an interesting discriminative classifier based on generative prior knowledge. It can directly estimate the probabilistic accuracy bound by minimizing the maximum probability of misclassification. The structural information of data is an effective way to represent prior knowledge, and has been found to be vital for designing classifiers in real-world problems. However, MPM only considers the prior probability distribution of each class with a given mean and covariance matrix, which does not efficiently exploit the structural information of data. In this paper, we use two finite mixture models to capture the structural information of the data from binary classification. For each subdistribution in a finite mixture model, only its mean and covariance matrix are assumed to be known. Based on the finite mixture models, we propose a structural MPM (SMPM). SMPM can be solved effectively by a sequence of the second-order cone programming problems. Moreover, we extend a linear model of SMPM to a nonlinear model by exploiting kernelization techniques. We also show that the SMPM can be interpreted as a large margin classifier and can be transformed to support vector machine and maxi-min margin machine under certain special conditions. Experimental results on both synthetic and real-world data sets demonstrate the effectiveness of SMPM.",4
An Alternating Identification Algorithm for a Class of Nonlinear Dynamical Systems.,"While modeling nonlinear systems by combining a linear model with a nonlinear compensation term, namely, virtual unmodeled dynamics (VUD), the parameter estimation of the linear model and the learning-based VUD estimate influences and interacts with each other simultaneously. This paper aims to develop an alternating identification scheme for resolving such a challenging problem, where a projection algorithm is employed to identify the linear model and a feedforward neural network is used to model the VUD of a class of nonlinear dynamical systems. An open-loop estimation algorithm on the VUD is first presented under the known linear model, followed by an alternating identification algorithm for completely unknown nonlinear systems. Algorithm description is given and some simulation studies on multiple input and multiple output nonlinear systems are carried out to illustrate the effectiveness of our proposed modeling techniques.",4
Import Vector Domain Description: A Kernel Logistic One-Class Learning Algorithm.,"Recognizing the samples belonging to one class in a heterogeneous data set is a very interesting but tough machine learning task. Some samples of the data set can be actual outliers or members of other classes for which training examples are lacking. In contrast to other kernel approaches present in the literature, in this work, the problem is faced defining a one-class kernel machine that delivers the probability for a sample to belong to the support of the distribution and that can be efficiently trained by a hybrid sequential minimal optimization-expectation maximization algorithm. Due to the analogy to the import vector machine and to the one-class approach, we named the method import vector domain description (IVDD). IVDD was tested on a toy 2-D data set in order to characterize its behavior on a set of widely used benchmarking UCI data sets and, lastly, challenged against a real world outlier detection data set. All the results were compared against state-of-the-art closely related methods such as one-class-SVM and Support Vector Domain Description, proving that the algorithm is equally accurate with the additional advantage of delivering the probability estimate for each sample. Finally, a few variants aimed at providing memory savings and/or computational speed-up in the light of big data analysis are briefly sketched.",4
Exponential Synchronization for Markovian Stochastic Coupled Neural Networks of Neutral-Type via Adaptive Feedback Control.,"In this paper, we investigate the adaptive exponential synchronization in both the mean square and the almost sure senses for an array of N identical Markovian stochastic coupled neural networks of neutral-type with time-varying delay and random coupling strength. The generalized Lyapunov theorem of the exponential stability in the mean square for the neutral stochastic Markov system with the time-varying delay is first established. The time-varying delay in the system is assumed to be a bounded measurable function. Then, sufficient conditions to guarantee the exponential synchronization in the mean square for the underlying system are developed under an adaptive feedback controller, which are given in terms of the M -matrix and the algebraic inequalities. Under the same conditions, the almost sure exponential synchronization is also presented. A numerical example is given to show the effectiveness and potential of the proposed theoretical results.",4
Observer-Based Adaptive Neural Network Trajectory Tracking Control for Remotely Operated Vehicle.,"This paper focuses on the adaptive trajectory tracking control for a remotely operated vehicle (ROV) with an unknown dynamic model and the unmeasured states. Unlike most previous trajectory tracking control approaches, in this paper, the velocity states and the angular velocity states in the body-fixed frame are unmeasured, and the thrust model is inaccurate. Obviously, it is more in line with the actual ROV systems. Since the dynamic model is unknown, a new local recurrent neural network (local RNN) structure with fast learning speed is proposed for online identification. To estimate the unmeasured states, an adaptive terminal sliding-mode state observer based on the local RNN is proposed, so that the finite-time convergence of the trajectory tracking error can be guaranteed. Considering the problem of inaccurate thrust model, an adaptive scale factor is introduced into thrust model, and the thruster control signal is considered as the input of the trajectory tracking system directly. Based on the local RNN output, the adaptive scale factor, and the state estimation values, an adaptive trajectory tracking control law is constructed. The stability of the trajectory tracking control system is analyzed by the Lyapunov theorem. The effectiveness of the proposed control scheme is illustrated by simulations.",4
Characterization of Linearly Separable Boolean Functions: A Graph-Theoretic Perspective.,"In this paper, we present a novel approach for studying Boolean function in a graph-theoretic perspective. In particular, we first transform a Boolean function f of n variables into an induced subgraph Hf of the n -dimensional hypercube, and then, we show the properties of linearly separable Boolean functions on the basis of the analysis of the structure of Hf . We define a new class of graphs, called hyperstar, and prove that the induced subgraph Hf of any linearly separable Boolean function f is a hyperstar. The proposal of hyperstar helps us uncover a number of fundamental properties of linearly separable Boolean functions in this paper.",4
Label Propagation via Teaching-to-Learn and Learning-to-Teach.,"How to propagate label information from labeled examples to unlabeled examples over a graph has been intensively studied for a long time. Existing graph-based propagation algorithms usually treat unlabeled examples equally, and transmit seed labels to the unlabeled examples that are connected to the labeled examples in a neighborhood graph. However, such a popular propagation scheme is very likely to yield inaccurate propagation, because it falls short of tackling ambiguous but critical data points (e.g., outliers). To this end, this paper treats the unlabeled examples in different levels of difficulties by assessing their reliability and discriminability, and explicitly optimizes the propagation quality by manipulating the propagation sequence to move from simple to difficult examples. In particular, we propose a novel iterative label propagation algorithm in which each propagation alternates between two paradigms, teaching-to-learn and learning-to-teach (TLLT). In the teaching-to-learn step, the learner conducts the propagation on the simplest unlabeled examples designated by the teacher. In the learning-to-teach step, the teacher incorporates the learner's feedback to adjust the choice of the subsequent simplest examples. The proposed TLLT strategy critically improves the accuracy of label propagation, making our algorithm substantially robust to the values of tuning parameters, such as the Gaussian kernel width used in graph construction. The merits of our algorithm are theoretically justified and empirically demonstrated through experiments performed on both synthetic and real-world data sets.",4
Adaptive Neural Network Nonparametric Identifier With Normalized Learning Laws.,"This paper addresses the design of a normalized convergent learning law for neural networks (NNs) with continuous dynamics. The NN is used here to obtain a nonparametric model for uncertain systems described by a set of ordinary differential equations. The source of uncertainties is the presence of some external perturbations and poor knowledge of the nonlinear function describing the system dynamics. A new adaptive algorithm based on normalized algorithms was used to adjust the weights of the NN. The adaptive algorithm was derived by means of a nonstandard logarithmic Lyapunov function (LLF). Two identifiers were designed using two variations of LLFs leading to a normalized learning law for the first identifier and a variable gain normalized learning law. In the case of the second identifier, the inclusion of normalized learning laws yields to reduce the size of the convergence region obtained as solution of the practical stability analysis. On the other hand, the velocity of convergence for the learning laws depends on the norm of errors in inverse form. This fact avoids the peaking transient behavior in the time evolution of weights that accelerates the convergence of identification error. A numerical example demonstrates the improvements achieved by the algorithm introduced in this paper compared with classical schemes with no-normalized continuous learning methods. A comparison of the identification performance achieved by the no-normalized identifier and the ones developed in this paper shows the benefits of the learning law proposed in this paper.",4
Solution Path for Pin-SVM Classifiers With Positive and Negative $\tau $ Values.,"Applying the pinball loss in a support vector machine (SVM) classifier results in pin-SVM. The pinball loss is characterized by a parameter tau . Its value is related to the quantile level and different tau values are suitable for different problems. In this paper, we establish an algorithm to find the entire solution path for pin-SVM with different tau values. This algorithm is based on the fact that the optimal solution to pin-SVM is continuous and piecewise linear with respect to tau . We also show that the nonnegativity constraint on tau is not necessary, i.e., tau can be extended to negative values. First, in some applications, a negative tau leads to better accuracy. Second, tau = -1 corresponds to a simple solution that links SVM and the classical kernel rule. The solution for tau = -1 can be obtained directly and then be used as a starting point of the solution path. The proposed method efficiently traverses tau values through the solution path, and then achieves good performance by a suitable tau . In particular, tau = 0 corresponds to C-SVM, meaning that the traversal algorithm can output a result at least as good as C-SVM with respect to validation error.",4
Learning With Auxiliary Less-Noisy Labels.,"Obtaining a sufficient number of accurate labels to form a training set for learning a classifier can be difficult due to the limited access to reliable label resources. Instead, in real-world applications, less-accurate labels, such as labels from nonexpert labelers, are often used. However, learning with less-accurate labels can lead to serious performance deterioration because of the high noise rate. Although several learning methods (e.g., noise-tolerant classifiers) have been advanced to increase classification performance in the presence of label noise, only a few of them take the noise rate into account and utilize both noisy but easily accessible labels and less-noisy labels, a small amount of which can be obtained with an acceptable added time cost and expense. In this brief, we propose a learning method, in which not only noisy labels but also auxiliary less-noisy labels, which are available in a small portion of the training data, are taken into account. Based on a flipping probability noise model and a logistic regression classifier, this method estimates the noise rate parameters, infers ground-truth labels, and learns the classifier simultaneously in a maximum likelihood manner. The proposed method yields three learning algorithms, which correspond to three prior knowledge states regarding the less-noisy labels. The experiments show that the proposed method is tolerant to label noise, and outperforms classifiers that do not explicitly consider the auxiliary less-noisy labels.",4
Embedded Streaming Deep Neural Networks Accelerator With Applications.,"Deep convolutional neural networks (DCNNs) have become a very powerful tool in visual perception. DCNNs have applications in autonomous robots, security systems, mobile phones, and automobiles, where high throughput of the feedforward evaluation phase and power efficiency are important. Because of this increased usage, many field-programmable gate array (FPGA)-based accelerators have been proposed. In this paper, we present an optimized streaming method for DCNNs' hardware accelerator on an embedded platform. The streaming method acts as a compiler, transforming a high-level representation of DCNNs into operation codes to execute applications in a hardware accelerator. The proposed method utilizes maximum computational resources available based on a novel-scheduled routing topology that combines data reuse and data concatenation. It is tested with a hardware accelerator implemented on the Xilinx Kintex-7 XC7K325T FPGA. The system fully explores weight-level and node-level parallelizations of DCNNs and achieves a peak performance of 247 G-ops while consuming less than 4 W of power. We test our system with applications on object classification and object detection in real-world scenarios. Our results indicate high-performance efficiency, outperforming all other presented platforms while running these applications.",4
Impulsive Multisynchronization of Coupled Multistable Neural Networks With Time-Varying Delay.,"This paper studies the synchronization problem of coupled delayed multistable neural networks (NNs) with directed topology. To begin with, several sufficient conditions are developed in terms of algebraic inequalities such that every subnetwork has multiple locally exponentially stable periodic orbits or equilibrium points. Then two new concepts named dynamical multisynchronization (DMS) and static multisynchronization (SMS) are introduced to describe the two novel kinds of synchronization manifolds. Using the impulsive control strategy and the Razumikhin-type technique, some sufficient conditions for both the DMS and the SMS of the controlled coupled delayed multistable NNs with fixed and switching topologies are derived, respectively. Simulation examples are presented to illustrate the effectiveness of the proposed results.",4
Adaptive Event-Triggered Control Based on Heuristic Dynamic Programming for Nonlinear Discrete-Time Systems.,"This paper presents the design of a novel adaptive event-triggered control method based on the heuristic dynamic programming (HDP) technique for nonlinear discrete-time systems with unknown system dynamics. In the proposed method, the control law is only updated when the event-triggered condition is violated. Compared with the periodic updates in the traditional adaptive dynamic programming (ADP) control, the proposed method can reduce the computation and transmission cost. An actor-critic framework is used to learn the optimal event-triggered control law and the value function. Furthermore, a model network is designed to estimate the system state vector. The main contribution of this paper is to design a new trigger threshold for discrete-time systems. A detailed Lyapunov stability analysis shows that our proposed event-triggered controller can asymptotically stabilize the discrete-time systems. Finally, we test our method on two different discrete-time systems, and the simulation results are included.",4
Approximate Optimal Control of Affine Nonlinear Continuous-Time Systems Using Event-Sampled Neurodynamic Programming.,"This paper presents an approximate optimal control of nonlinear continuous-time systems in affine form by using the adaptive dynamic programming (ADP) with event-sampled state and input vectors. The knowledge of the system dynamics is relaxed by using a neural network (NN) identifier with event-sampled inputs. The value function, which becomes an approximate solution to the Hamilton-Jacobi-Bellman equation, is generated by using event-sampled NN approximator. Subsequently, the NN identifier and the approximated value function are utilized to obtain the optimal control policy. Both the identifier and value function approximator weights are tuned only at the event-sampled instants leading to an aperiodic update scheme. A novel adaptive event sampling condition is designed to determine the sampling instants, such that the approximation accuracy and the stability are maintained. A positive lower bound on the minimum inter-sample time is guaranteed to avoid accumulation point, and the dependence of inter-sample time upon the NN weight estimates is analyzed. A local ultimate boundedness of the resulting nonlinear impulsive dynamical closed-loop system is shown. Finally, a numerical example is utilized to evaluate the performance of the near-optimal design. The net result is the design of an event-sampled ADP-based controller for nonlinear continuous-time systems.",4
Sparseness Analysis in the Pretraining of Deep Neural Networks.,"A major progress in deep multilayer neural networks (DNNs) is the invention of various unsupervised pretraining methods to initialize network parameters which lead to good prediction accuracy. This paper presents the sparseness analysis on the hidden unit in the pretraining process. In particular, we use the L1 -norm to measure sparseness and provide some sufficient conditions for that pretraining leads to sparseness with respect to the popular pretraining models-such as denoising autoencoders (DAEs) and restricted Boltzmann machines (RBMs). Our experimental results demonstrate that when the sufficient conditions are satisfied, the pretraining models lead to sparseness. Our experiments also reveal that when using the sigmoid activation functions, pretraining plays an important sparseness role in DNNs with sigmoid (Dsigm), and when using the rectifier linear unit (ReLU) activation functions, pretraining becomes less effective for DNNs with ReLU (Drelu). Luckily, Drelu can reach a higher recognition accuracy than DNNs with pretraining (DAEs and RBMs), as it can capture the main benefit (such as sparseness-encouraging) of pretraining in Dsigm. However, ReLU is not adapted to the different firing rates in biological neurons, because the firing rate actually changes along with the varying membrane resistances. To address this problem, we further propose a family of rectifier piecewise linear units (RePLUs) to fit the different firing rates. The experimental results show that the performance of RePLU is better than ReLU, and is comparable with those with some pretraining techniques, such as RBMs and DAEs.",4
A Collective Neurodynamic Approach to Constrained Global Optimization.,"Global optimization is a long-lasting research topic in the field of optimization, posting many challenging theoretic and computational issues. This paper presents a novel collective neurodynamic method for solving constrained global optimization problems. At first, a one-layer recurrent neural network (RNN) is presented for searching the Karush-Kuhn-Tucker points of the optimization problem under study. Next, a collective neuroydnamic optimization approach is developed by emulating the paradigm of brainstorming. Multiple RNNs are exploited cooperatively to search for the global optimal solutions in a framework of particle swarm optimization. Each RNN carries out a precise local search and converges to a candidate solution according to its own neurodynamics. The neuronal state of each neural network is repetitively reset by exchanging historical information of each individual network and the entire group. Wavelet mutation is performed to avoid prematurity, add diversity, and promote global convergence. It is proved in the framework of stochastic optimization that the proposed collective neurodynamic approach is capable of computing the global optimal solutions with probability one provided that a sufficiently large number of neural networks are utilized. The essence of the collective neurodynamic optimization approach lies in its potential to solve constrained global optimization problems in real time. The effectiveness and characteristics of the proposed approach are illustrated by using benchmark optimization problems.",4
CONE: Convex-Optimized-Synaptic Efficacies for Temporally Precise Spike Mapping.,"Spiking neural networks are well suited to perform time-dependent pattern recognition problems by encoding the temporal dimension in precise spike times. With an appropriate set of weights, a spiking neuron can emit precisely timed action potentials in response to spatiotemporal input spikes. However, deriving supervised learning rules for spike mapping is nontrivial due to the increased complexity. Existing methods rely on heuristic approaches that do not guarantee a convex objective function and, therefore, may not converge to a global minimum. In this paper, we present a novel technique to obtain the weights of spiking neurons by formulating the problem in a convex optimization framework, rendering it be compatible with the established methods. We introduce techniques to influence the weight distribution and membrane trajectory, and then study how these factors affect robustness in the presence of noise. In addition, we show how the existence of a solution can be determined and assess memory capacity limits of a neuron model using synthetic examples. The practical utility of our technique is further assessed by its application to gait-event detection using the experimental data.",4
Dual Low-Rank Pursuit: Learning Salient Features for Saliency Detection.,"Saliency detection is an important procedure for machines to understand visual world as humans do. In this paper, we consider a specific saliency detection problem of predicting human eye fixations when they freely view natural images, and propose a novel dual low-rank pursuit (DLRP) method. DLRP learns saliency-aware feature transformations by utilizing available supervision information and constructs discriminative bases for effectively detecting human fixation points under the popular low-rank and sparsity-pursuit framework. Benefiting from the embedded high-level information in the supervised learning process, DLRP is able to predict fixations accurately without performing the expensive object segmentation as in the previous works. Comprehensive experiments clearly show the superiority of the proposed DLRP method over the established state-of-the-art methods. We also empirically demonstrate that DLRP provides stronger generalization performance across different data sets and inherits the advantages of both the bottom-up- and top-down-based saliency detection methods.",4
Adaptive Neural Control of Uncertain MIMO Nonlinear Systems With State and Input Constraints.,"An adaptive neural control strategy for multiple input multiple output nonlinear systems with various constraints is presented in this paper. To deal with the nonsymmetric input nonlinearity and the constrained states, the proposed adaptive neural control is combined with the backstepping method, radial basis function neural network, barrier Lyapunov function (BLF), and disturbance observer. By ensuring the boundedness of the BLF of the closed-loop system, it is demonstrated that the output tracking is achieved with all states remaining in the constraint sets and the general assumption on nonsingularity of unknown control coefficient matrices has been eliminated. The constructed adaptive neural control has been rigorously proved that it can guarantee the semiglobally uniformly ultimate boundedness of all signals in the closed-loop system. Finally, the simulation studies on a 2-DOF robotic manipulator system indicate that the designed adaptive control is effective.",4
Salient Band Selection for Hyperspectral Image Classification via Manifold Ranking.,"Saliency detection has been a hot topic in recent years, and many efforts have been devoted in this area. Unfortunately, the results of saliency detection can hardly be utilized in general applications. The primary reason, we think, is unspecific definition of salient objects, which makes that the previously published methods cannot extend to practical applications. To solve this problem, we claim that saliency should be defined in a context and the salient band selection in hyperspectral image (HSI) is introduced as an example. Unfortunately, the traditional salient band selection methods suffer from the problem of inappropriate measurement of band difference. To tackle this problem, we propose to eliminate the drawbacks of traditional salient band selection methods by manifold ranking. It puts the band vectors in the more accurate manifold space and treats the saliency problem from a novel ranking perspective, which is considered to be the main contributions of this paper. To justify the effectiveness of the proposed method, experiments are conducted on three HSIs, and our method is compared with the six existing competitors. Results show that the proposed method is very effective and can achieve the best performance among the competitors.",4
"Mapping Temporal Variables Into the NeuCube for Improved Pattern Recognition, Predictive Modeling, and Understanding of Stream Data.","This paper proposes a new method for an optimized mapping of temporal variables, describing a temporal stream data, into the recently proposed NeuCube spiking neural network (SNN) architecture. This optimized mapping extends the use of the NeuCube, which was initially designed for spatiotemporal brain data, to work on arbitrary stream data and to achieve a better accuracy of temporal pattern recognition, a better and earlier event prediction, and a better understanding of complex temporal stream data through visualization of the NeuCube connectivity. The effect of the new mapping is demonstrated on three benchmark problems. The first one is the early prediction of patient sleep stage event from temporal physiological data. The second one is the pattern recognition of dynamic temporal patterns of traffic in the Bay Area of California and the last one is the Challenge 2012 contest data set. In all the cases, the use of the proposed mapping leads to an improved accuracy of pattern recognition and event prediction and a better understanding of the data when compared with traditional machine learning techniques or SNN reservoirs with an arbitrary mapping of the variables.",4
Objective Function and Learning Algorithm for the General Node Fault Situation.,"Fault tolerance is one interesting property of artificial neural networks. However, the existing fault models are able to describe limited node fault situations only, such as stuck-at-zero and stuck-at-one. There is no general model that is able to describe a large class of node fault situations. This paper studies the performance of faulty radial basis function (RBF) networks for the general node fault situation. We first propose a general node fault model that is able to describe a large class of node fault situations, such as stuck-at-zero, stuck-at-one, and the stuck-at level being with arbitrary distribution. Afterward, we derive an expression to describe the performance of faulty RBF networks. An objective function is then identified from the formula. With the objective function, a training algorithm for the general node situation is developed. Finally, a mean prediction error (MPE) formula that is able to estimate the test set error of faulty networks is derived. The application of the MPE formula in the selection of basis width is elucidated. Simulation experiments are then performed to demonstrate the effectiveness of the proposed method.",4
Sequential Nonlinear Learning for Distributed Multiagent Systems via Extreme Learning Machines.,"We study online nonlinear learning over distributed multiagent systems, where each agent employs a single hidden layer feedforward neural network (SLFN) structure to sequentially minimize arbitrary loss functions. In particular, each agent trains its own SLFN using only the data that is revealed to itself. On the other hand, the aim of the multiagent system is to train the SLFN at each agent as well as the optimal centralized batch SLFN that has access to all the data, by exchanging information between neighboring agents. We address this problem by introducing a distributed subgradient-based extreme learning machine algorithm. The proposed algorithm provides guaranteed upper bounds on the performance of the SLFN at each agent and shows that each of these individual SLFNs asymptotically achieves the performance of the optimal centralized batch SLFN. Our performance guarantees explicitly distinguish the effects of data- and network-dependent parameters on the convergence rate of the proposed algorithm. The experimental results illustrate that the proposed algorithm achieves the oracle performance significantly faster than the state-of-the-art methods in the machine learning and signal processing literature. Hence, the proposed method is highly appealing for the applications involving big data.",4
Holographic Graph Neuron: A Bioinspired Architecture for Pattern Processing.,"In this paper, we propose a new approach to implementing hierarchical graph neuron (HGN), an architecture for memorizing patterns of generic sensor stimuli, through the use of vector symbolic architectures. The adoption of a vector symbolic representation ensures a single-layer design while retaining the existing performance characteristics of HGN. This approach significantly improves the noise resistance of the HGN architecture, and enables a linear (with respect to the number of stored entries) time search for an arbitrary subpattern.",4
$\mu $ -Stability of Nonlinear Positive Systems With Unbounded Time-Varying Delays.,"The stability of the zero solution plays an important role in the investigation of positive systems. In this brief, we discuss the mu -stability of positive nonlinear systems with unbounded time-varying delays. The system is modeled by the continuous-time ordinary differential equation. Under some assumptions on the nonlinear functions, such as homogeneous, cooperative, and nondecreasing, we propose a novel transform, by which the nonlinear system reduces to a new system. Thus, we analyze its dynamics, which can simplify the nonlinear homogenous functions with respect to the arbitrary dilation map to those with respect to the standard dilation map. We finally get some new criteria for the global mu -stability taking the degree into consideration. A numerical example is given to demonstrate the validity of obtained results.",4
Action and Event Recognition in Videos by Learning From Heterogeneous Web Sources.,"In this paper, we propose new approaches for action and event recognition by leveraging a large number of freely available Web videos (e.g., from Flickr video search engine) and Web images (e.g., from Bing and Google image search engines). We address this problem by formulating it as a new multi-domain adaptation problem, in which heterogeneous Web sources are provided. Specifically, we are given different types of visual features (e.g., the DeCAF features from Bing/Google images and the trajectory-based features from Flickr videos) from heterogeneous source domains and all types of visual features from the target domain. Considering the target domain is more relevant to some source domains, we propose a new approach named multi-domain adaptation with heterogeneous sources (MDA-HS) to effectively make use of the heterogeneous sources. In MDA-HS, we simultaneously seek for the optimal weights of multiple source domains, infer the labels of target domain samples, and learn an optimal target classifier. Moreover, as textual descriptions are often available for both Web videos and images, we propose a novel approach called MDA-HS using privileged information (MDA-HS+) to effectively incorporate the valuable textual information into our MDA-HS method, based on the recent learning using privileged information paradigm. MDA-HS+ can be further extended by using a new elastic-net-like regularization. We solve our MDA-HS and MDA-HS+ methods by using the cutting-plane algorithm, in which a multiple kernel learning problem is derived and solved. Extensive experiments on three benchmark data sets demonstrate that our proposed approaches are effective for action and event recognition without requiring any labeled samples from the target domain.",4
Neural Network Control-Based Adaptive Learning Design for Nonlinear Systems With Full-State Constraints.,"In order to stabilize a class of uncertain nonlinear strict-feedback systems with full-state constraints, an adaptive neural network control method is investigated in this paper. The state constraints are frequently emerged in the real-life plants and how to avoid the violation of state constraints is an important task. By introducing a barrier Lyapunov function (BLF) to every step in a backstepping procedure, a novel adaptive backstepping design is well developed to ensure that the full-state constraints are not violated. At the same time, one remarkable feature is that the minimal learning parameters are employed in BLF backstepping design. By making use of Lyapunov analysis, we can prove that all the signals in the closed-loop system are semiglobal uniformly ultimately bounded and the output is well driven to follow the desired output. Finally, a simulation is given to verify the effectiveness of the method.",4
Quantized Iterative Learning Consensus Tracking of Digital Networks With Limited Information Communication.,"This brief investigates the quantized iterative learning problem for digital networks with time-varying topologies. The information is first encoded as symbolic data and then transmitted. After the data are received, a decoder is used by the receiver to get an estimate of the sender's state. Iterative learning quantized communication is considered in the process of encoding and decoding. A sufficient condition is then presented to achieve the consensus tracking problem in a finite interval using the quantized iterative learning controllers. Finally, simulation results are given to illustrate the usefulness of the developed criterion.",4
Rate of Convergence of the FOCUSS Algorithm.,"Focal underdetermined system solver (FOCUSS) is a powerful method for basis selection and sparse representation, where it employs the [Formula: see text]-norm with p in (0,2) to measure the sparsity of solutions. In this paper, we give a systematical analysis on the rate of convergence of the FOCUSS algorithm with respect to p in (0,2) . We prove that the FOCUSS algorithm converges superlinearly for and linearly for usually, but may superlinearly in some very special scenarios. In addition, we verify its rates of convergence with respect to p by numerical experiments.",4
Robust Joint Graph Sparse Coding for Unsupervised Spectral Feature Selection.,"In this paper, we propose a new unsupervised spectral feature selection model by embedding a graph regularizer into the framework of joint sparse regression for preserving the local structures of data. To do this, we first extract the bases of training data by previous dictionary learning methods and, then, map original data into the basis space to generate their new representations, by proposing a novel joint graph sparse coding (JGSC) model. In JGSC, we first formulate its objective function by simultaneously taking subspace learning and joint sparse regression into account, then, design a new optimization solution to solve the resulting objective function, and further prove the convergence of the proposed solution. Furthermore, we extend JGSC to a robust JGSC (RJGSC) via replacing the least square loss function with a robust loss function, for achieving the same goals and also avoiding the impact of outliers. Finally, experimental results on real data sets showed that both JGSC and RJGSC outperformed the state-of-the-art algorithms in terms of k -nearest neighbor classification performance.",4
Optimized Kernel Entropy Components.,"This brief addresses two main issues of the standard kernel entropy component analysis (KECA) algorithm: the optimization of the kernel decomposition and the optimization of the Gaussian kernel parameter. KECA roughly reduces to a sorting of the importance of kernel eigenvectors by entropy instead of variance, as in the kernel principal components analysis. In this brief, we propose an extension of the KECA method, named optimized KECA (OKECA), that directly extracts the optimal features retaining most of the data entropy by means of compacting the information in very few features (often in just one or two). The proposed method produces features which have higher expressive power. In particular, it is based on the independent component analysis framework, and introduces an extra rotation to the eigen decomposition, which is optimized via gradient-ascent search. This maximum entropy preservation suggests that OKECA features are more efficient than KECA features for density estimation. In addition, a critical issue in both the methods is the selection of the kernel parameter, since it critically affects the resulting performance. Here, we analyze the most common kernel length-scale selection criteria. The results of both the methods are illustrated in different synthetic and real problems. Results show that OKECA returns projections with more expressive power than KECA, the most successful rule for estimating the kernel parameter is based on maximum likelihood, and OKECA is more robust to the selection of the length-scale parameter in kernel density estimation.",4
Fair Energy Scheduling for Vehicle-to-Grid Networks Using Adaptive Dynamic Programming.,"Research on the smart grid is being given enormous supports worldwide due to its great significance in solving environmental and energy crises. Electric vehicles (EVs), which are powered by clean energy, are adopted increasingly year by year. It is predictable that the huge charge load caused by high EV penetration will have a considerable impact on the reliability of the smart grid. Therefore, fair energy scheduling for EV charge and discharge is proposed in this paper. By using the vehicle-to-grid technology, the scheduler controls the electricity loads of EVs considering fairness in the residential distribution network. We propose contribution-based fairness, in which EVs with high contributions have high priorities to obtain charge energy. The contribution value is defined by both the charge/discharge energy and the timing of the action. EVs can achieve higher contribution values when discharging during the load peak hours. However, charging during this time will decrease the contribution values seriously. We formulate the fair energy scheduling problem as an infinite-horizon Markov decision process. The methodology of adaptive dynamic programming is employed to maximize the long-term fairness by processing online network training. The numerical results illustrate that the proposed EV energy scheduling is able to mitigate and flatten the peak load in the distribution network. Furthermore, contribution-based fairness achieves a fast recovery of EV batteries that have deeply discharged and guarantee fairness in the full charge time of all EVs.",4
A Robust Regularization Path Algorithm for $\nu $ -Support Vector Classification.,"The nu -support vector classification has the advantage of using a regularization parameter nu to control the number of support vectors and margin errors. Recently, a regularization path algorithm for nu -support vector classification ( nu -SvcPath) suffers exceptions and singularities in some special cases. In this brief, we first present a new equivalent dual formulation for nu -SVC and, then, propose a robust nu -SvcPath, based on lower upper decomposition with partial pivoting. Theoretical analysis and experimental results verify that our proposed robust regularization path algorithm can avoid the exceptions completely, handle the singularities in the key matrix, and fit the entire solution path in a finite number of steps. Experimental results also show that our proposed algorithm fits the entire solution path with fewer steps and less running time than original one does.",4
A Note on the Unification of Adaptive Online Learning.,"In online convex optimization, adaptive algorithms, which can utilize the second-order information of the loss function's (sub)gradient, have shown improvements over standard gradient methods. This paper presents a framework Follow the Bregman Divergence Leader that unifies various existing adaptive algorithms from which new insights are revealed. Under the proposed framework, two simple adaptive online algorithms with improvable performance guarantee are derived. Furthermore, a general equation derived from a matrix analysis generalizes the adaptive learning to nonlinear case with kernel trick.",4
LIF and Simplified SRM Neurons Encode Signals Into Spikes via a Form of Asynchronous Pulse Sigma-Delta Modulation.,"We show how two spiking neuron models encode continuous-time signals into spikes (action potentials, time-encoded pulses, or point processes) using a special form of sigma-delta modulation (SDM). In particular, we show that the well-known leaky integrate-and-fire (LIF) neuron and the simplified spike response model (SRM0) neuron encode the continuous-time signals into spikes via a proposed asynchronous pulse SDM (APSDM) scheme. The encoder is clock free using level-crossing sampling with a single-level quantizer, unipolar signaling, differential coding, and pulse-shaping filters. The decoder, in the form of a low-pass filter or bandpass smoothing filter, can be fed with the spikes to reconstruct an estimate of the signal. The density of the spikes reflects the amplitude of the encoded signal. Numerical examples illustrating the concepts and the signaling efficiency of APSDM vis-a-vis SDM for comparable reconstruction accuracies are presented. We anticipate these results will facilitate the design of spiking neurons and spiking neural networks as well as cross fertilizations between the fields of neural coding and the SDM.",4
Modeling Disease Progression via Multisource Multitask Learners: A Case Study With Alzheimer's Disease.,"Understanding the progression of chronic diseases can empower the sufferers in taking proactive care. To predict the disease status in the future time points, various machine learning approaches have been proposed. However, a few of them jointly consider the dual heterogeneities of chronic disease progression. In particular, the predicting task at each time point has features from multiple sources, and multiple tasks are related to each other in chronological order. To tackle this problem, we propose a novel and unified scheme to coregularize the prior knowledge of source consistency and temporal smoothness. We theoretically prove that our proposed model is a linear model. Before training our model, we adopt the matrix factorization approach to address the data missing problem. Extensive evaluations on real-world Alzheimer's disease data set have demonstrated the effectiveness and efficiency of our model. It is worth mentioning that our model is generally applicable to a rich range of chronic diseases.",4
A Semisupervised Approach to the Detection and Characterization of Outliers in Categorical Data.,"In this paper, we introduce a new approach of semisupervised anomaly detection that deals with categorical data. Given a training set of instances (all belonging to the normal class), we analyze the relationship among features for the extraction of a discriminative characterization of the anomalous instances. Our key idea is to build a model that characterizes the features of the normal instances and then use a set of distance-based techniques for the discrimination between the normal and the anomalous instances. We compare our approach with the state-of-the-art methods for semisupervised anomaly detection. We empirically show that a specifically designed technique for the management of the categorical data outperforms the general-purpose approaches. We also show that, in contrast with other approaches that are opaque because their decision cannot be easily understood, our proposed approach produces a discriminative model that can be easily interpreted and used for the exploration of the data.",4
State Estimation for Discrete-Time Dynamical Networks With Time-Varying Delays and Stochastic Disturbances Under the Round-Robin Protocol.,"This paper is concerned with the state estimation problem for a class of nonlinear dynamical networks with time-varying delays subject to the round-robin protocol. The communication between the state estimator and the nodes of the dynamical networks is implemented through a shared constrained network, in which only one node is allowed to send data at each time instant. The round-robin protocol is utilized to orchestrate the transmission order of nodes. By using a switch-based approach, the dynamics of the estimation error is modeled by a periodic parameter-switching system with time-varying delays. The purpose of the problem addressed is to design an estimator, such that the estimation error is exponentially ultimately bounded with a certain asymptotic upper bound in mean square subject to the process noise and exogenous disturbance. Furthermore, such a bound is subsequently minimized by the designed estimator parameters. A novel Lyapunov-like functional is employed to deal with the dynamics analysis issue of the estimation error. Sufficient conditions are established to guarantee the ultimate boundedness of the estimation error in mean square by applying the stochastic analysis approach. Then, the desired estimator gains are characterized by solving a convex problem. Finally, a numerical example is given to illustrate the effectiveness of the estimator design scheme.",4
Dual RBFNNs-Based Model-Free Adaptive Control With Aspen HYSYS Simulation.,"In this brief, we propose a new data-driven model-free adaptive control (MFAC) method with dual radial basis function neural networks (RBFNNs) for a class of discrete-time nonlinear systems. The main novelty lies in that it provides a systematic design method for controller structure by the direct usage of I/O data, rather than using the first-principle model or offline identified plant model. The controller structure is determined by equivalent-dynamic-linearization representation of the ideal nonlinear controller, and the controller parameters are tuned by the pseudogradient information extracted from the I/O data of the plant, which can deal with the unknown nonlinear system. The stability of the closed-loop control system and the stability of the training process for RBFNNs are guaranteed by rigorous theoretical analysis. Meanwhile, the effectiveness and the applicability of the proposed method are further demonstrated by the numerical example and Aspen HYSYS simulation of distillation column in crude styrene produce process.",4
Event-Triggered State Estimation for Discrete-Time Multidelayed Neural Networks With Stochastic Parameters and Incomplete Measurements.,"In this paper, the event-triggered state estimation problem is investigated for a class of discrete-time multidelayed neural networks with stochastic parameters and incomplete measurements. In order to cater for more realistic transmission process of the neural signals, we make the first attempt to introduce a set of stochastic variables to characterize the random fluctuations of system parameters. In the addressed neural network model, the delays among the interconnections are allowed to be different, which are more general than those in the existing literature. The incomplete information under consideration includes randomly occurring sensor saturations and quantizations. For the purpose of energy saving, an event-triggered state estimator is constructed and a sufficient condition is given under which the estimation error dynamics is exponentially ultimately bounded in the mean square. It is worth noting that the ultimate boundedness of the error dynamics is explicitly estimated. The characterization of the desired estimator gain is designed in terms of the solution to a certain matrix inequality. Finally, a numerical simulation example is presented to illustrate the effectiveness of the proposed event-triggered state estimation scheme.",4
On Deep Learning for Trust-Aware Recommendations in Social Networks.,"With the emergence of online social networks, the social network-based recommendation approach is popularly used. The major benefit of this approach is the ability of dealing with the problems with cold-start users. In addition to social networks, user trust information also plays an important role to obtain reliable recommendations. Although matrix factorization (MF) becomes dominant in recommender systems, the recommendation largely relies on the initialization of the user and item latent feature vectors. Aiming at addressing these challenges, we develop a novel trust-based approach for recommendation in social networks. In particular, we attempt to leverage deep learning to determinate the initialization in MF for trust-aware social recommendations and to differentiate the community effect in user's trusted friendships. A two-phase recommendation process is proposed to utilize deep learning in initialization and to synthesize the users' interests and their trusted friends' interests together with the impact of community effect for recommendations. We perform extensive experiments on real-world social network data to demonstrate the accuracy and effectiveness of our proposed approach in comparison with other state-of-the-art methods.",4
"Affinity and Penalty Jointly Constrained Spectral Clustering With All-Compatibility, Flexibility, and Robustness.","The existing, semisupervised, spectral clustering approaches have two major drawbacks, i.e., either they cannot cope with multiple categories of supervision or they sometimes exhibit unstable effectiveness. To address these issues, two normalized affinity and penalty jointly constrained spectral clustering frameworks as well as their corresponding algorithms, referred to as type-I affinity and penalty jointly constrained spectral clustering (TI-APJCSC) and type-II affinity and penalty jointly constrained spectral clustering (TII-APJCSC), respectively, are proposed in this paper. TI refers to type-I and TII to type-II. The significance of this paper is fourfold. First, benefiting from the distinctive affinity and penalty jointly constrained strategies, both TI-APJCSC and TII-APJCSC are substantially more effective than the existing methods. Second, both TI-APJCSC and TII-APJCSC are fully compatible with the three well-known categories of supervision, i.e., class labels, pairwise constraints, and grouping information. Third, owing to the delicate framework normalization, both TI-APJCSC and TII-APJCSC are quite flexible. With a simple tradeoff factor varying in the small fixed interval (0, 1], they can self-adapt to any semisupervised scenario. Finally, both TI-APJCSC and TII-APJCSC demonstrate strong robustness, not only to the number of pairwise constraints but also to the parameter for affinity measurement. As such, the novel TI-APJCSC and TII-APJCSC algorithms are very practical for medium- and small-scale semisupervised data sets. The experimental studies thoroughly evaluated and demonstrated these advantages on both synthetic and real-life semisupervised data sets.",4
Coarse-to-Fine Learning for Single-Image Super-Resolution.,"This paper develops a coarse-to-fine framework for single-image super-resolution (SR) reconstruction. The coarse-to-fine approach achieves high-quality SR recovery based on the complementary properties of both example learning-and reconstruction-based algorithms: example learning-based SR approaches are useful for generating plausible details from external exemplars but poor at suppressing aliasing artifacts, while reconstruction-based SR methods are propitious for preserving sharp edges yet fail to generate fine details. In the coarse stage of the method, we use a set of simple yet effective mapping functions, learned via correlative neighbor regression of grouped low-resolution (LR) to high-resolution (HR) dictionary atoms, to synthesize an initial SR estimate with particularly low computational cost. In the fine stage, we devise an effective regularization term that seamlessly integrates the properties of local structural regularity, nonlocal self-similarity, and collaborative representation over relevant atoms in a learned HR dictionary, to further improve the visual quality of the initial SR estimation obtained in the coarse stage. The experimental results indicate that our method outperforms other state-of-the-art methods for producing high-quality images despite that both the initial SR estimation and the followed enhancement are cheap to implement.",4
Learning Discriminative Subspaces on Random Contrasts for Image Saliency Analysis.,"In visual saliency estimation, one of the most challenging tasks is to distinguish targets and distractors that share certain visual attributes. With the observation that such targets and distractors can sometimes be easily separated when projected to specific subspaces, we propose to estimate image saliency by learning a set of discriminative subspaces that perform the best in popping out targets and suppressing distractors. Toward this end, we first conduct principal component analysis on massive randomly selected image patches. The principal components, which correspond to the largest eigenvalues, are selected to construct candidate subspaces since they often demonstrate impressive abilities to separate targets and distractors. By projecting images onto various subspaces, we further characterize each image patch by its contrasts against randomly selected neighboring and peripheral regions. In this manner, the probable targets often have the highest responses, while the responses at background regions become very low. Based on such random contrasts, an optimization framework with pairwise binary terms is adopted to learn the saliency model that best separates salient targets and distractors by optimally integrating the cues from various subspaces. Experimental results on two public benchmarks show that the proposed approach outperforms 16 state-of-the-art methods in human fixation prediction.",4
Learning Kernel Extended Dictionary for Face Recognition.,"A sparse representation classifier (SRC) and a kernel discriminant analysis (KDA) are two successful methods for face recognition. An SRC is good at dealing with occlusion, while a KDA does well in suppressing intraclass variations. In this paper, we propose kernel extended dictionary (KED) for face recognition, which provides an efficient way for combining KDA and SRC. We first learn several kernel principal components of occlusion variations as an occlusion model, which can represent the possible occlusion variations efficiently. Then, the occlusion model is projected by KDA to get the KED, which can be computed via the same kernel trick as new testing samples. Finally, we use structured SRC for classification, which is fast as only a small number of atoms are appended to the basic dictionary, and the feature dimension is low. We also extend KED to multikernel space to fuse different types of features at kernel level. Experiments are done on several large-scale data sets, demonstrating that not only does KED get impressive results for nonoccluded samples, but it also handles the occlusion well without overfitting, even with a single gallery sample per subject.",4
Deep Neural Network for Structural Prediction and Lane Detection in Traffic Scene.,"Hierarchical neural networks have been shown to be effective in learning representative image features and recognizing object classes. However, most existing networks combine the low/middle level cues for classification without accounting for any spatial structures. For applications such as understanding a scene, how the visual cues are spatially distributed in an image becomes essential for successful analysis. This paper extends the framework of deep neural networks by accounting for the structural cues in the visual signals. In particular, two kinds of neural networks have been proposed. First, we develop a multitask deep convolutional network, which simultaneously detects the presence of the target and the geometric attributes (location and orientation) of the target with respect to the region of interest. Second, a recurrent neuron layer is adopted for structured visual detection. The recurrent neurons can deal with the spatial distribution of visible cues belonging to an object whose shape or structure is difficult to explicitly define. Both the networks are demonstrated by the practical task of detecting lane boundaries in traffic scenes. The multitask convolutional neural network provides auxiliary geometric information to help the subsequent modeling of the given lane structures. The recurrent neural network automatically detects lane boundaries, including those areas containing no marks, without any explicit prior knowledge or secondary modeling.",4
Deep Direct Reinforcement Learning for Financial Signal Representation and Trading.,"Can we train the computer to beat experienced traders for financial assert trading? In this paper, we try to address this challenge by introducing a recurrent deep neural network (NN) for real-time financial signal representation and trading. Our model is inspired by two biological-related learning concepts of deep learning (DL) and reinforcement learning (RL). In the framework, the DL part automatically senses the dynamic market condition for informative feature learning. Then, the RL module interacts with deep representations and makes trading decisions to accumulate the ultimate rewards in an unknown environment. The learning system is implemented in a complex NN that exhibits both the deep and recurrent structures. Hence, we propose a task-aware backpropagation through time method to cope with the gradient vanishing issue in deep training. The robustness of the neural system is verified on both the stock and the commodity future markets under broad testing conditions.",4
Mixtures of Conditional Random Fields for Improved Structured Output Prediction.,"The conditional random field (CRF) is a successful probabilistic model for structured output prediction problems. In this brief, we consider to enlarge the representational capacity of CRF via mixture modeling. The motivation is that a single CRF can perform well if the data conform to the statistical dependence assumption imposed by the CRF model structure, whereas it may potentially fail to model the data that come from multiple different sources or domains. For the conventional conditional likelihood objective, we derive the expectation-maximization algorithm in conjunction with the direct gradient ascent method for learning a CRF mixture with sequence or image-structured data. In addition, we provide alternative mixture learning algorithms that aim to maximize either the classification margin or the sitewise conditional likelihood, which were previously shown to outperform the conventional estimator for single CRF models in a variety of situations. We demonstrate the improved prediction accuracy of the proposed mixture learning algorithms on several important sequence labeling problems.",4
Robust Recurrent Kernel Online Learning.,"We propose a robust recurrent kernel online learning (RRKOL) algorithm based on the celebrated real-time recurrent learning approach that exploits the kernel trick in a recurrent online training manner. The novel RRKOL algorithm guarantees weight convergence with regularized risk management through the use of adaptive recurrent hyperparameters for superior generalization performance. Based on a new concept of the structure update error with a variable parameter length, we are the first one to propose the detailed structure update error, such that the weight convergence and robust stability proof can be integrated with a kernel sparsification scheme based on a solid theoretical ground. The RRKOL algorithm automatically weighs the regularized term in the recurrent loss function, such that we not only minimize the estimation error but also improve the generalization performance through sparsification with simulation support.",4
High-Performance Consensus Control in Networked Systems With Limited Bandwidth Communication and Time-Varying Directed Topologies.,"Communication data rates and energy constraints are two important factors that have to be considered in the coordination control of multiagent networks. Although some encoder-decoder-based consensus protocols are available, there still exists a fundamental theoretical problem: how can we further reduce the update rate of control input for each agent without the changing consensus performance? In this paper, we consider the problem of average consensus over directed and time-varying digital networks of discrete-time first-order multiagent systems with limited communication data transmission rates. Each agent has a real-valued state but can only exchange binary symbolic sequence with its neighbors due to bandwidth constraints. A class of novel event-triggered dynamic encoding and decoding algorithms is proposed, based on which a kind of consensus protocol is presented. Moreover, we develop a scheme to select the numbers of time-varying quantization levels for each connected communication channel in the time-varying directed topologies at each time step. The analytical relation among system and network parameters is characterized explicitly. It is shown that the asymptotic convergence rate is related to the scale of the network, the number of quantization levels, the system parameter, and the network structure. It is also found that under the designed event-triggered protocol, for a directed and time-varying digital network, which uniformly contains a spanning tree over a time interval, the average consensus can be achieved with an exponential convergence rate based on merely 1-b information exchange between each pair of adjacent agents at each time step.",4
Pinning Impulsive Synchronization of Reaction-Diffusion Neural Networks With Time-Varying Delays.,"This paper investigates the exponential synchronization of reaction-diffusion neural networks with time-varying delays subject to Dirichlet boundary conditions. A novel type of pinning impulsive controllers is proposed to synchronize the reaction-diffusion neural networks with time-varying delays. By applying the Lyapunov functional method, sufficient verifiable conditions are constructed for the exponential synchronization of delayed reaction-diffusion neural networks with large and small delay sizes. It is shown that synchronization can be realized by pinning impulsive control of a small portion of neurons of the network; the technique used in this paper is also applicable to reaction-diffusion networks with Neumann boundary conditions. Numerical examples are presented to demonstrate the effectiveness of the theoretical results.",4
Max-Margin-Based Discriminative Feature Learning.,"In this brief, we propose a new max-margin-based discriminative feature learning method. In particular, we aim at learning a low-dimensional feature representation, so as to maximize the global margin of the data and make the samples from the same class as close as possible. In order to enhance the robustness to noise, we leverage a regularization term to make the transformation matrix sparse in rows. In addition, we further learn and leverage the correlations among multiple categories for assisting in learning discriminative features. The experimental results demonstrate the power of the proposed method against the related state-of-the-art methods.",4
Scalable Algorithms for Multi-Instance Learning.,"Multi-instance learning (MIL) has been widely applied to diverse applications involving complicated data objects, such as images and genes. However, most existing MIL algorithms can only handle small- or moderate-sized data. In order to deal with large-scale MIL problems, we propose MIL based on the vector of locally aggregated descriptors representation (miVLAD) and MIL based on the Fisher vector representation (miFV), two efficient and scalable MIL algorithms. They map the original MIL bags into new vector representations using their corresponding mapping functions. The new feature representations keep essential bag-level information, and at the same time lead to excellent MIL performances even when linear classifiers are used. Thanks to the low computational cost in the mapping step and the scalability of linear classifiers, miVLAD and miFV can handle large-scale MIL data efficiently and effectively. Experiments show that miVLAD and miFV not only achieve comparable accuracy rates with the state-of-the-art MIL algorithms, but also have hundreds of times faster speed. Moreover, we can regard the new miVLAD and miFV representations as multiview data, which improves the accuracy rates in most cases. In addition, our algorithms perform well even when they are used without parameter tuning (i.e., adopting the default parameters), which is convenient for practical MIL applications.",4
An Adaptable Continuous Restricted Boltzmann Machine in VLSI for Fusing the Sensory Data of an Electronic Nose.,"An embedded system capable of fusing sensory data is demanded for many portable or implantable microsystems. The continuous restricted Boltzmann machine (CRBM) is a probabilistic neural network not only capable of classifying data reliably but also amenable to very-large-scale-integration (VLSI) implementation. Although the embedded system based on the CRBM has been demonstrated with analog VLSI, the precision required by the learning algorithm is hardly achievable with analog circuits. Therefore, this paper investigates the feasibility of realizing the CRBM as a digital embedded system for fusing the sensory data of an electronic nose (eNose). The fusion here refers to data clustering and dimensional reduction that facilitates reliable classification. The capability of the CRBM to model different types of eNose data is first examined by MATLAB simulation. Afterward, the CRBM algorithm is customdesigned as a digital embedded system within an eNose microsystem. The functionality of the embedded CRBM system is then tested and discussed. With on-chip learning ability, the CRBM-embedded eNose is able to adapt its parameters in response to new data inputs or environmental changes.",4
Air-Breathing Hypersonic Vehicle Tracking Control Based on Adaptive Dynamic Programming.,"In this paper, we propose a data-driven supplementary control approach with adaptive learning capability for air-breathing hypersonic vehicle tracking control based on action-dependent heuristic dynamic programming (ADHDP). The control action is generated by the combination of sliding mode control (SMC) and the ADHDP controller to track the desired velocity and the desired altitude. In particular, the ADHDP controller observes the differences between the actual velocity/altitude and the desired velocity/altitude, and then provides a supplementary control action accordingly. The ADHDP controller does not rely on the accurate mathematical model function and is data driven. Meanwhile, it is capable to adjust its parameters online over time under various working conditions, which is very suitable for hypersonic vehicle system with parameter uncertainties and disturbances. We verify the adaptive supplementary control approach versus the traditional SMC in the cruising flight, and provide three simulation studies to illustrate the improved performance with the proposed approach.",4
Multiscale Support Vector Learning With Projection Operator Wavelet Kernel for Nonlinear Dynamical System Identification.,"A giant leap has been made in the past couple of decades with the introduction of kernel-based learning as a mainstay for designing effective nonlinear computational learning algorithms. In view of the geometric interpretation of conditional expectation and the ubiquity of multiscale characteristics in highly complex nonlinear dynamic systems [1]-[3], this paper presents a new orthogonal projection operator wavelet kernel, aiming at developing an efficient computational learning approach for nonlinear dynamical system identification. In the framework of multiresolution analysis, the proposed projection operator wavelet kernel can fulfill the multiscale, multidimensional learning to estimate complex dependencies. The special advantage of the projection operator wavelet kernel developed in this paper lies in the fact that it has a closed-form expression, which greatly facilitates its application in kernel learning. To the best of our knowledge, it is the first closed-form orthogonal projection wavelet kernel reported in the literature. It provides a link between grid-based wavelets and mesh-free kernel-based methods. Simulation studies for identifying the parallel models of two benchmark nonlinear dynamical systems confirm its superiority in model accuracy and sparsity.",4
Speeding Up Cellular Neural Network Processing Ability by Embodying Memristors.,"Cellular neural networks (CNNs) are an efficient tool for image analysis and pattern recognition. Based on elementary cells connected to neighboring units, they are easy to install in hardware, carrying out massively parallel processes. This brief presents a new model of CNN with memory devices, which enhances further CNN performance. By introducing a memristive element in basic cells, we carry out different experiments, allowing the analysis of the functions traditionally carried out by the standard CNN. Without modifying the templates considered by the scientific literature, this simple variation originates a significant improvement in approximately 30 % of performances in pattern recognition and image processing. These progresses were experimentally calculated on the time the system requires to reach a fixed point. Moreover, the different role that each parameter has in the developed method was also analyzed to better understand the complex processing ability of these systems.",4
Model-Based Reinforcement Learning for Infinite-Horizon Approximate Optimal Tracking.,"This brief paper provides an approximate online adaptive solution to the infinite-horizon optimal tracking problem for control-affine continuous-time nonlinear systems with unknown drift dynamics. To relax the persistence of excitation condition, model-based reinforcement learning is implemented using a concurrent-learning-based system identifier to simulate experience by evaluating the Bellman error over unexplored areas of the state space. Tracking of the desired trajectory and convergence of the developed policy to a neighborhood of the optimal policy are established via Lyapunov-based stability analysis. Simulation results demonstrate the effectiveness of the developed technique.",4
An Optimization-Based Method for Feature Ranking in Nonlinear Regression Problems.,"In this paper, we consider the feature ranking problem, where, given a set of training instances, the task is to associate a score with the features in order to assess their relevance. Feature ranking is a very important tool for decision support systems, and may be used as an auxiliary step of feature selection to reduce the high dimensionality of real-world data. We focus on regression problems by assuming that the process underlying the generated data can be approximated by a continuous function (for instance, a feedforward neural network). We formally state the notion of relevance of a feature by introducing a minimum zero-norm inversion problem of a neural network, which is a nonsmooth, constrained optimization problem. We employ a concave approximation of the zero-norm function, and we define a smooth, global optimization problem to be solved in order to assess the relevance of the features. We present the new feature ranking method based on the solution of instances of the global optimization problem depending on the available training data. Computational experiments on both artificial and real data sets are performed, and point out that the proposed feature ranking method is a valid alternative to existing methods in terms of effectiveness. The obtained results also show that the method is costly in terms of CPU time, and this may be a limitation in the solution of large-dimensional problems.",4
An Integrated Learning and Filtering Approach for Fault Diagnosis of a Class of Nonlinear Dynamical Systems.,"This paper develops an integrated filtering and adaptive approximation-based approach for fault diagnosis of process and sensor faults in a class of continuous-time nonlinear systems with modeling uncertainties and measurement noise. The proposed approach integrates learning with filtering techniques to derive tight detection thresholds, which is accomplished in two ways: 1) by learning the modeling uncertainty through adaptive approximation methods and 2) by using filtering for dampening measurement noise. Upon the detection of a fault, two estimation models, one for process and the other for sensor faults, are initiated in order to identify the type of fault. Each estimation model utilizes learning to estimate the potential fault that has occurred, and adaptive isolation thresholds for each estimation model are designed. The fault type is deduced based on an exclusion-based logic, and fault detectability and identification conditions are rigorously derived, characterizing quantitatively the class of faults that can be detected and identified by the proposed scheme. Finally, simulation results are used to demonstrate the effectiveness of the proposed approach.",4
Symmetric Complex-Valued Hopfield Neural Networks.,"Complex-valued neural networks, which are extensions of ordinary neural networks, have been studied as interesting models by many researchers. Especially, complex-valued Hopfield neural networks (CHNNs) have been used to process multilevel data, such as gray-scale images. CHNNs with Hermitian connection weights always converge using asynchronous update. The noise tolerance of CHNNs deteriorates extremely as the resolution increases. Noise tolerance is one of the most controversial problems for CHNNs. It is known that rotational invariance reduces noise tolerance. In this brief, we propose symmetric CHNNs (SCHNNs), which have symmetric connection weights. We define their energy function and prove that the SCHNNs always converge. In addition, we show that the SCHNNs improve noise tolerance through computer simulations and explain this improvement from the standpoint of rotational invariance.",4
Adaptive Method for Nonsmooth Nonnegative Matrix Factorization.,"Nonnegative matrix factorization (NMF) is an emerging tool for meaningful low-rank matrix representation. In NMF, explicit constraints are usually required, such that NMF generates desired products (or factorizations), especially when the products have significant sparseness features. It is known that the ability of NMF in learning sparse representation can be improved by embedding a smoothness factor between the products. Motivated by this result, we propose an adaptive nonsmooth NMF (Ans-NMF) method in this paper. In our method, the embedded factor is obtained by using a data-related approach, so it matches well with the underlying products, implying a superior faithfulness of the representations. Besides, due to the usage of an adaptive selection scheme to this factor, the sparseness of the products can be separately constrained, leading to wider applicability and interpretability. Furthermore, since the adaptive selection scheme is processed through solving a series of typical linear programming problems, it can be easily implemented. Simulations using computer-generated data and real-world data show the advantages of the proposed Ans-NMF method over the state-of-the-art methods.",4
Learning in Variable-Dimensional Spaces.,"This paper proposes a unified approach to learning in environments in which patterns can be represented in variable-dimension domains, which nicely includes the case in which there are missing features. The proposal is based on the representation of the environment by pointwise constraints that are shown to model naturally pattern relationships that come out in problems of information retrieval, computer vision, and related fields. The given interpretation of learning leads to capturing the truly different aspects of similarity coming from the content at different dimensions and the pattern links. It turns out that functions that process real-valued features and functions that operate on symbolic entities are learned within a unified framework of regularization that can also be expressed using the kernel machines mathematical and algorithmic apparatus. Interestingly, in the extreme cases in which only the content or only the links are available, our theory returns classic kernel machines or graph regularization, respectively. We show experimental results that provide clear evidence of the remarkable improvements that are obtained when both types of similarities are exploited on artificial and real-world benchmarks.",4
Triplet Spike Time-Dependent Plasticity in a Floating-Gate Synapse.,"Synapse plays an important role in learning in a neural network; the learning rules that modify the synaptic strength based on the timing difference between the pre- and postsynaptic spike occurrence are termed spike time-dependent plasticity (STDP) rules. The most commonly used rule posits weight change based on time difference between one presynaptic spike and one postsynaptic spike and is hence termed doublet STDP (D-STDP). However, D-STDP could not reproduce results of many biological experiments; a triplet STDP (T-STDP) that considers triplets of spikes as the fundamental unit has been proposed recently to explain these observations. This paper describes the compact implementation of a synapse using a single floating-gate (FG) transistor that can store a weight in a nonvolatile manner and demonstrates the T-STDP learning rule by modifying drain voltages according to triplets of spikes. We describe a mathematical procedure to obtain control voltages for the FG device for T-STDP and also show measurement results from an FG synapse fabricated in TSMC 0.35-mum CMOS process to support the theory. Possible very large scale integration implementation of drain voltage waveform generator circuits is also presented with the simulation results.",4
Sparse Principal Component Analysis via Rotation and Truncation.,"Sparse principal component analysis (sparse PCA) aims at finding a sparse basis to improve the interpretability over the dense basis of PCA, while still covering the data subspace as much as possible. In contrast to most existing work that addresses the problem by adding sparsity penalties on various objectives of PCA, we propose a new method, sparse PCA via rotation and truncation (SPCArt), which finds a rotation matrix and a sparse basis such that the sparse basis approximates the basis of PCA after the rotation. The algorithm of SPCArt consists of three alternating steps: 1) rotating the PCA basis; 2) truncating small entries; and 3) updating the rotation matrix. Its performance bounds are also given. The SPCArt is efficient, with each iteration scaling linearly with the data dimension. Parameter choice is simple, due to explicit physical explanations. We give a unified view to several existing sparse PCA methods and discuss the connections with SPCArt. Some ideas from SPCArt are extended to GPower, a popular sparse PCA algorithm, to address its limitations. Experimental results demonstrate that SPCArt achieves the state-of-the-art performance, along with a good tradeoff among various criteria, including sparsity, explained variance, orthogonality, balance of sparsity among loadings, and computational speed.",4
Cross-Modality Feature Learning Through Generic Hierarchical Hyperlingual-Words.,"Recognizing facial images captured under visible light has long been discussed in the past decades. However, there are many impact factors that hinder its successful application in real-world, e.g., illumination, pose variations. Recent work has concentrated on different spectrals, i.e., near infrared, that can only be perceived by specifically designed device to avoid the illumination problem. However, this inevitably introduces a new problem, namely, cross-modality classification. In brief, images registered in the system are in one modality, while images that captured momentarily used as the tests are in another modality. In addition, there could be many within-modality variations-pose and expression-leading to a more complicated problem for the researchers. To address this problem, we propose a novel framework called hierarchical hyperlingual-words (Hwords) in this paper. First, we design a novel structure, called generic Hwords, to capture the high-level semantics across different modalities and within each modality in weakly supervised fashion, meaning only modality pair and variations information are needed in the training. Second, to improve the discriminative power of Hwords, we propose a novel distance metric through the hierarchical structure of Hwords. Extensive experiments on multimodality face databases demonstrate the superiority of our method compared with the state-of-the-art works on face recognition tasks subject to pose and expression variations.",4
Identification of Boolean Networks Using Premined Network Topology Information.,"This brief aims to reduce the data requirement for the identification of Boolean networks (BNs) by using the premined network topology information. First, a matching table is created and used for sifting the true from the false dependences among the nodes in the BNs. Then, a dynamic extension to matching table is developed to enable the dynamic locating of matching pairs to start as soon as possible. Next, based on the pseudocommutative property of the semitensor product, a position-transform mining is carried out to further improve data utilization. Combining the above, the topology of the BNs can be premined for the subsequent identification. Examples are given to illustrate the efficiency of reducing the data requirement. Some excellent features, such as the online and parallel processing ability, are also demonstrated.",4
A Maximum Entropy Framework for Semisupervised and Active Learning With Unknown and Label-Scarce Classes.,"We investigate semisupervised learning (SL) and pool-based active learning (AL) of a classifier for domains with label-scarce (LS) and unknown categories, i.e., defined categories for which there are initially no labeled examples. This scenario manifests, e.g., when a category is rare, or expensive to label. There are several learning issues when there are unknown categories: 1) it is a priori unknown which subset of (possibly many) measured features are needed to discriminate unknown from common classes and 2) label scarcity suggests that overtraining is a concern. Our classifier exploits the inductive bias that an unknown class consists of the subset of the unlabeled pool's samples that are atypical (relative to the common classes) with respect to certain key (albeit a priori unknown) features and feature interactions. Accordingly, we treat negative log- p -values on raw features as nonnegatively weighted derived feature inputs to our class posterior, with zero weights identifying irrelevant features. Through a hierarchical class posterior, our model accommodates multiple common classes, multiple LS classes, and unknown classes. For learning, we propose a novel semisupervised objective customized for the LS/unknown category scenarios. While several works minimize class decision uncertainty on unlabeled samples, we instead preserve this uncertainty [maximum entropy (maxEnt)] to avoid overtraining. Our experiments on a variety of UCI Machine learning (ML) domains show: 1) the use of p -value features coupled with weight constraints leads to sparse solutions and gives significant improvement over the use of raw features and 2) for LS SL and AL, unlabeled samples are helpful, and should be used to preserve decision uncertainty (maxEnt), rather than to minimize it, especially during the early stages of AL. Our AL system, leveraging a novel sample-selection scheme, discovers unknown classes and discriminates LS classes from common ones, with sparing use of oracle labeling.",4
Machine Learning Capabilities of a Simulated Cerebellum.,"This paper describes the learning and control capabilities of a biologically constrained bottom-up model of the mammalian cerebellum. Results are presented from six tasks: 1) eyelid conditioning; 2) pendulum balancing; 3) proportional-integral-derivative control; 4) robot balancing; 5) pattern recognition; and 6) MNIST handwritten digit recognition. These tasks span several paradigms of machine learning, including supervised learning, reinforcement learning, control, and pattern recognition. Results over these six domains indicate that the cerebellar simulation is capable of robustly identifying static input patterns even when randomized across the sensory apparatus. This capability allows the simulated cerebellum to perform several different supervised learning and control tasks. On the other hand, both reinforcement learning and temporal pattern recognition prove problematic due to the delayed nature of error signals and the simulator's inability to solve the credit assignment problem. These results are consistent with previous findings which hypothesize that in the human brain, the basal ganglia is responsible for reinforcement learning, while the cerebellum handles supervised learning.",4
Manifold-Based Reinforcement Learning via Locally Linear Reconstruction.,"Feature representation is critical not only for pattern recognition tasks but also for reinforcement learning (RL) methods to solve learning control problems under uncertainties. In this paper, a manifold-based RL approach using the principle of locally linear reconstruction (LLR) is proposed for Markov decision processes with large or continuous state spaces. In the proposed approach, an LLR-based feature learning scheme is developed for value function approximation in RL, where a set of smooth feature vectors is generated by preserving the local approximation properties of neighboring points in the original state space. By using the proposed feature learning scheme, an LLR-based approximate policy iteration (API) algorithm is designed for learning control problems with large or continuous state spaces. The relationship between the value approximation error of a new data point and the estimated values of its nearest neighbors is analyzed. In order to compare different feature representation and learning approaches for RL, a comprehensive simulation and experimental study was conducted on three benchmark learning control problems. It is illustrated that under a wide range of parameter settings, the LLR-based API algorithm can obtain better learning control performance than the previous API methods with different feature representation schemes.",4
Distributed Recurrent Neural Networks for Cooperative Control of Manipulators: A Game-Theoretic Perspective.,"This paper considers cooperative kinematic control of multiple manipulators using distributed recurrent neural networks and provides a tractable way to extend existing results on individual manipulator control using recurrent neural networks to the scenario with the coordination of multiple manipulators. The problem is formulated as a constrained game, where energy consumptions for each manipulator, saturations of control input, and the topological constraints imposed by the communication graph are considered. An implicit form of the Nash equilibrium for the game is obtained by converting the problem into its dual space. Then, a distributed dynamic controller based on recurrent neural networks is devised to drive the system toward the desired Nash equilibrium to seek the optimal solution of the cooperative control. Global stability and solution optimality of the proposed neural networks are proved in the theory. Simulations demonstrate the effectiveness of the proposed method.",4
High-Order Measurements for Residual Classifiers.,"Residual classifiers are common in dictionary-based multiclass classification. This paper proposes the concept of performance functions for residual classifiers. A performance function for multiclass classifications is a conceptual measurement function that combines local and global measurements. In general, the performance function is nonlinear. To explore the properties of the performance function, we employ the Taylor series expansion technique and derive a family of measurement functions. Specifically, the linear measurement and the quadratic measurement (QM) are derived. By exploiting the effect of the higher order terms in the performance function as well as the fundamental nondecreasing constrain, we derive the normalized QM (NQM). We present the classifier for multiclass classification using the proposed measurements. The proposed algorithms are tested against frontal faces and handwritten digit recognition tasks. Our tests show that the QM classifier achieves competitive classification results compared with baseline methods. NQM shows better stability with different parameter configurations.",4
Graph Theory-Based Pinning Synchronization of Stochastic Complex Dynamical Networks.,"This paper is concerned with the adaptive pinning synchronization problem of stochastic complex dynamical networks (CDNs). Based on algebraic graph theory and Lyapunov theory, pinning controller design conditions are derived, and the rigorous convergence analysis of synchronization errors in the probability sense is also conducted. Compared with the existing results, the topology structures of stochastic CDN are allowed to be unknown due to the use of graph theory. In particular, it is shown that the selection of nodes for pinning depends on the unknown lower bounds of coupling strengths. Finally, an example on a Chua's circuit network is given to validate the effectiveness of the theoretical results.",4
Learning a Coupled Linearized Method in Online Setting.,"Based on the alternating direction method of multipliers, in this paper, we propose, analyze, and test a coupled linearized method, which aims to minimize an unconstrained problem consisting of a loss term and a regularization term in an online setting. To solve this problem, we first transform it into an equivalent constrained minimization problem with a separable structure. Then, we split the corresponding augmented Lagrangian function and minimize the resulting subproblems distributedly with one variable by fixing another one. This method is easy to execute without calculating matrix inversion by implementing three linearized operations per iteration, and at each iteration, we can obtain a closed-form solution. In particular, our update rule contains the well-known soft-thresholding operator as a special case. Moreover, upper bound on the regret of the proposed method is analyzed. Under some mild conditions, it can achieve O(1/ radicalT) convergence rate for convex learning problems and O((log T)/ T) for strongly convex learning. Numerical experiments and comparisons with several state-of-the-art methods are reported, which demonstrate the efficiency and effectiveness of our approach.",4
A Scoring Scheme for Online Feature Selection: Simulating Model Performance Without Retraining.,"Increasing the number of features increases the complexity of a model even if the additional feature does not improve its decision-making capacity. Irrelevant features may also cause overfitting and reduce interpretability of the concerned model. It is, therefore, important that the features are optimally selected before a model is built. In the case of online learning, new instances are periodically discovered, and the respective model is tactically retrained as required. Similarly, there are many real-life situations where hundreds of new features are discovered periodically, and the existing model needs to be retrained or tested for its performance improvement. Supervised selection of feature subset usually requires creation of multiple suboptimal models, thus incurring time-intensive computations. Unsupervised selections, although faster, largely rely on some subjective definition of feature relevance. In this paper, we introduce a score that accurately determines the importance of the features. The proposed score is appropriate for online feature selection scenarios for its low time complexity and ability to interpret performance improvement of the current model after the addition of a new feature, without invoking a retraining.",4
Impulsive Synchronization of Reaction-Diffusion Neural Networks With Mixed Delays and Its Application to Image Encryption.,"This paper presents a new impulsive synchronization criterion of two identical reaction-diffusion neural networks with discrete and unbounded distributed delays. The new criterion is established by applying an impulse-time-dependent Lyapunov functional combined with the use of a new type of integral inequality for treating the reaction-diffusion terms. The impulse-time-dependent feature of the proposed Lyapunov functional can capture more hybrid dynamical behaviors of the impulsive reaction-diffusion neural networks than the conventional impulse-time-independent Lyapunov functions/functionals, while the new integral inequality, which is derived from Wirtinger's inequality, overcomes the conservatism introduced by the integral inequality used in the previous results. Numerical examples demonstrate the effectiveness of the proposed method. Later, the developed impulsive synchronization method is applied to build a spatiotemporal chaotic cryptosystem that can transmit an encrypted image. The experimental results verify that the proposed image-encrypting cryptosystem has the advantages of large key space and high security against some traditional attacks.",4
Nonparametric Density Estimation Based on Self-Organizing Incremental Neural Network for Large Noisy Data.,"With the ongoing development and expansion of communication networks and sensors, massive amounts of data are continuously generated in real time from real environments. Beforehand, prediction of a distribution underlying such data is difficult; furthermore, the data include substantial amounts of noise. These factors make it difficult to estimate probability densities. To handle these issues and massive amounts of data, we propose a nonparametric density estimator that rapidly learns data online and has high robustness. Our approach is an extension of both kernel density estimation (KDE) and a self-organizing incremental neural network (SOINN); therefore, we call our approach KDESOINN. An SOINN provides a clustering method that learns about the given data as networks of prototype of data; more specifically, an SOINN can learn the distribution underlying the given data. Using this information, KDESOINN estimates the probability density function. The results of our experiments show that KDESOINN outperforms or achieves performance comparable to the current state-of-the-art approaches in terms of robustness, learning time, and accuracy.",4
Dynamic Energy Management System for a Smart Microgrid.,"This paper presents the development of an intelligent dynamic energy management system (I-DEMS) for a smart microgrid. An evolutionary adaptive dynamic programming and reinforcement learning framework is introduced for evolving the I-DEMS online. The I-DEMS is an optimal or near-optimal DEMS capable of performing grid-connected and islanded microgrid operations. The primary sources of energy are sustainable, green, and environmentally friendly renewable energy systems (RESs), e.g., wind and solar; however, these forms of energy are uncertain and nondispatchable. Backup battery energy storage and thermal generation were used to overcome these challenges. Using the I-DEMS to schedule dispatches allowed the RESs and energy storage devices to be utilized to their maximum in order to supply the critical load at all times. Based on the microgrid's system states, the I-DEMS generates energy dispatch control signals, while a forward-looking network evaluates the dispatched control signals over time. Typical results are presented for varying generation and load profiles, and the performance of I-DEMS is compared with that of a decision tree approach-based DEMS (D-DEMS). The robust performance of the I-DEMS was illustrated by examining microgrid operations under different battery energy storage conditions.",4
Growing Echo-State Network With Multiple Subreservoirs.,"An echo-state network (ESN) is an effective alternative to gradient methods for training recurrent neural network. However, it is difficult to determine the structure (mainly the reservoir) of the ESN to match with the given application. In this paper, a growing ESN (GESN) is proposed to design the size and topology of the reservoir automatically. First, the GESN makes use of the block matrix theory to add hidden units to the existing reservoir group by group, which leads to a GESN with multiple subreservoirs. Second, every subreservoir weight matrix in the GESN is created with a predefined singular value spectrum, which ensures the echo-sate property of the ESN without posterior scaling of the weights. Third, during the growth of the network, the output weights of the GESN are updated in an incremental way. Moreover, the convergence of the GESN is proved. Finally, the GESN is tested on some artificial and real-world time-series benchmarks. Simulation results show that the proposed GESN has better prediction performance and faster leaning speed than some ESNs with fixed sizes and topologies.",4
Bottom-Up Visual Saliency Estimation With Deep Autoencoder-Based Sparse Reconstruction.,"Research on visual perception indicates that the human visual system is sensitive to center-surround (C-S) contrast in the bottom-up saliency-driven attention process. Different from the traditional contrast computation of feature difference, models based on reconstruction have emerged to estimate saliency by starting from original images themselves instead of seeking for certain ad hoc features. However, in the existing reconstruction-based methods, the reconstruction parameters of each area are calculated independently without taking their global correlation into account. In this paper, inspired by the powerful feature learning and data reconstruction ability of deep autoencoders, we construct a deep C-S inference network and train it with the data sampled randomly from the entire image to obtain a unified reconstruction pattern for the current image. In this way, global competition in sampling and learning processes can be integrated into the nonlocal reconstruction and saliency estimation of each pixel, which can achieve better detection results than the models with separate consideration on local and global rarity. Moreover, by learning from the current scene, the proposed model can achieve the feature extraction and interaction simultaneously in an adaptive way, which can form a better generalization ability to handle more types of stimuli. Experimental results show that in accordance with different inputs, the network can learn distinct basic features for saliency modeling in its code layer. Furthermore, in a comprehensive evaluation on several benchmark data sets, the proposed method can outperform the existing state-of-the-art algorithms.",4
Hierarchical Change-Detection Tests.,"We present hierarchical change-detection tests (HCDTs), as effective online algorithms for detecting changes in datastreams. HCDTs are characterized by a hierarchical architecture composed of a detection layer and a validation layer. The detection layer steadily analyzes the input datastream by means of an online, sequential CDT, which operates as a low-complexity trigger that promptly detects possible changes in the process generating the data. The validation layer is activated when the detection one reveals a change, and performs an offline, more sophisticated analysis on recently acquired data to reduce false alarms. Our experiments show that, when the process generating the datastream is unknown, as it is mostly the case in the real world, HCDTs achieve a far more advantageous tradeoff between false-positive rate and detection delay than their single-layered, more traditional counterpart. Moreover, the successful interplay between the two layers permits HCDTs to automatically reconfigure after having detected and validated a change. Thus, HCDTs are able to reveal further departures from the postchange state of the data-generating process.",4
QRNN: $q$ -Generalized Random Neural Network.,"Artificial neural networks (ANNs) are widely used in applications with complex decision boundaries. A large number of activation functions have been proposed in the literature to achieve better representations of the observed data. However, only a few works employ Tsallis statistics, which has successfully been applied to various other fields. This paper presents a random neural network (RNN) with q -Gaussian activation functions [ q -generalized RNN (QRNN)] based on Tsallis statistics. The proposed method employs an additional parameter q (called the entropic index) which reflects the degree of nonextensivity. This approach has the flexibility to model complex decision boundaries of different shapes by varying the entropic index. We conduct numerical experiments to analyze the efficiency of QRNN compared with RNNs and several other classical methods. Statistical tests (Wilcoxon and Friedman) are used to validate our results and show that the QRNN performs significantly better than RNNs with different activation functions. In addition, we find that QRNN outperforms many of the compared classical methods, with the exception of support vector machines, in which case it still exhibits a substantial advantage in terms of implementation simplicity and speed.",4
A Novel Twin Support-Vector Machine With Pinball Loss.,"Twin support-vector machine (TSVM), which generates two nonparallel hyperplanes by solving a pair of smaller-sized quadratic programming problems (QPPs) instead of a single larger-sized QPP, works faster than the standard SVM, especially for the large-scale data sets. However, the traditional TSVM adopts hinge loss which easily leads to its sensitivity of the noise and instability for resampling. To enhance the performance of the TSVM, we present a novel TSVM with the pinball loss (Pin-TSVM) which deals with the quantile distance and is less sensitive to noise points. We further investigate its properties, including the noise insensitivity, between-class distance maximization, and within-class scatter minimization. In addition, we compare our Pin-TSVM with the twin parametric-margin SVM and the SVM with the pinball loss in theory. Numerical experiments on a synthetic data set and 14 benchmark data sets with different noises demonstrate the feasibility and validity of our proposed method.",4
Image Super-Resolution via Adaptive Regularization and Sparse Representation.,"Previous studies have shown that image patches can be well represented as a sparse linear combination of elements from an appropriately selected over-complete dictionary. Recently, single-image super-resolution (SISR) via sparse representation using blurred and downsampled low-resolution images has attracted increasing interest, where the aim is to obtain the coefficients for sparse representation by solving an l0 or l1 norm optimization problem. The l0 optimization is a nonconvex and NP-hard problem, while the l1 optimization usually requires many more measurements and presents new challenges even when the image is the usual size, so we propose a new approach for SISR recovery based on regularization nonconvex optimization. The proposed approach is potentially a powerful method for recovering SISR via sparse representations, and it can yield a sparser solution than the l1 regularization method. We also consider the best choice for lp regularization with all p in (0, 1), where we propose a scheme that adaptively selects the norm value for each image patch. In addition, we provide a method for estimating the best value of the regularization parameter lambda adaptively, and we discuss an alternate iteration method for selecting p and lambda . We perform experiments, which demonstrates that the proposed regularization nonconvex optimization method can outperform the convex optimization method and generate higher quality images.",4
Closed-Loop Modulation of the Pathological Disorders of the Basal Ganglia Network.,"A generalized predictive closed-loop control strategy to improve the basal ganglia activity patterns in Parkinson's disease (PD) is explored in this paper. Based on system identification, an input-output model is established to reveal the relationship between external stimulation and neuronal responses. The model contributes to the implementation of the generalized predictive control (GPC) algorithm that generates the optimal stimulation waveform to modulate the activities of neuronal nuclei. By analyzing the roles of two critical control parameters within the GPC law, optimal closed-loop control that has the capability of restoring the normal relay reliability of the thalamus with the least stimulation energy expenditure can be achieved. In comparison with open-loop deep brain stimulation and traditional static control schemes, the generalized predictive closed-loop control strategy can optimize the stimulation waveform without requiring any particular knowledge of the physiological properties of the system. This type of closed-loop control strategy generates an adaptive stimulation waveform with low energy expenditure with the potential to improve the treatments for PD.",4
Landslide Displacement Prediction With Uncertainty Based on Neural Networks With Random Hidden Weights.,"In this paper, we propose a new approach to establish a landslide displacement forecasting model based on artificial neural networks (ANNs) with random hidden weights. To quantify the uncertainty associated with the predictions, a framework for probabilistic forecasting of landslide displacement is developed. The aim of this paper is to construct prediction intervals (PIs) instead of deterministic forecasting. A lower-upper bound estimation (LUBE) method is adopted to construct ANN-based PIs, while a new single hidden layer feedforward ANN with random hidden weights for LUBE is proposed. Unlike the original implementation of LUBE, the input weights and hidden biases of the ANN are randomly chosen, and only the output weights need to be adjusted. Combining particle swarm optimization (PSO) and gravitational search algorithm (GSA), a hybrid evolutionary algorithm, PSOGSA, is utilized to optimize the output weights. Furthermore, a new ANN objective function, which combines a modified combinational coverage width-based criterion with one-norm regularization, is proposed. Two benchmark data sets and two real-world landslide data sets are presented to illustrate the capability and merit of our method. Experimental results reveal that the proposed method can construct high-quality PIs.",4
Neural Network-Based DOBC for a Class of Nonlinear Systems With Unmatched Disturbances.,"In this brief, the problem of composite anti-disturbance tracking control for a class of strict-feedback systems with unmatched unknown nonlinear functions and external disturbances is investigated. A disturbance-observer-based control (DOBC) in combination with a neural network scheme and back-stepping method is developed to achieve a composite anti-disturbance controller design that provides guaranteed performance. In the proposed method, a conventional disturbance observer and a radial basis function neural network (RBFNN) are combined into a new disturbance observer to estimate the unmatched disturbances. As compared with conventional DOBC methods, the primary merit of the proposed method is that the unknown nonlinear functions are approximated using the RBFNN technique, and not regarded as part of the disturbances or estimated by a conventional disturbance observer. Hence, the proposed method can obtain higher control accuracy than the conventional DOBC methods. This advantage is validated by simulation studies.",4
Extended Dissipative State Estimation for Markov Jump Neural Networks With Unreliable Links.,"This paper is concerned with the problem of extended dissipativity-based state estimation for discrete-time Markov jump neural networks (NNs), where the variation of the piecewise time-varying transition probabilities of Markov chain is subject to a set of switching signals satisfying an average dwell-time property. The communication links between the NNs and the estimator are assumed to be imperfect, where the phenomena of signal quantization and data packet dropouts occur simultaneously. The aim of this paper is to contribute with a Markov switching estimator design method, which ensures that the resulting error system is extended stochastically dissipative, in the simultaneous presences of packet dropouts and signal quantization stemmed from unreliable communication links. Sufficient conditions for the solvability of such a problem are established. Based on the derived conditions, an explicit expression of the desired Markov switching estimator is presented. Finally, two illustrated examples are given to show the effectiveness of the proposed design method.",4
Directional Clustering Through Matrix Factorization.,"This paper deals with a clustering problem where feature vectors are clustered depending on the angle between feature vectors, that is, feature vectors are grouped together if they point roughly in the same direction. This directional distance measure arises in several applications, including document classification and human brain imaging. Using ideas from the field of constrained low-rank matrix factorization and sparse approximation, a novel approach is presented that differs from classical clustering methods, such as seminonnegative matrix factorization, K -EVD, or k -means clustering, yet combines some aspects of all these. As in nonnegative matrix factorization and K -EVD, the matrix decomposition is iteratively refined to optimize a data fidelity term; however, no positivity constraint is enforced directly nor do we need to explicitly compute eigenvectors. As in k -means and K -EVD, each optimization step is followed by a hard cluster assignment. This leads to an efficient algorithm that is shown here to outperform common competitors in terms of clustering performance and/or computation speed. In addition to a detailed theoretical analysis of some of the algorithm's main properties, the approach is empirically evaluated on a range of toy problems, several standard text clustering data sets, and a high-dimensional problem in brain imaging, where functional magnetic resonance imaging data are used to partition the human cerebral cortex into distinct functional regions.",4
Learning to Predict Sequences of Human Visual Fixations.,"Most state-of-the-art visual attention models estimate the probability distribution of fixating the eyes in a location of the image, the so-called saliency maps. Yet, these models do not predict the temporal sequence of eye fixations, which may be valuable for better predicting the human eye fixations, as well as for understanding the role of the different cues during visual exploration. In this paper, we present a method for predicting the sequence of human eye fixations, which is learned from the recorded human eye-tracking data. We use least-squares policy iteration (LSPI) to learn a visual exploration policy that mimics the recorded eye-fixation examples. The model uses a different set of parameters for the different stages of visual exploration that capture the importance of the cues during the scanpath. In a series of experiments, we demonstrate the effectiveness of using LSPI for combining multiple cues at different stages of the scanpath. The learned parameters suggest that the low-level and high-level cues (semantics) are similarly important at the first eye fixation of the scanpath, and the contribution of high-level cues keeps increasing during the visual exploration. Results show that our approach obtains the state-of-the-art performances on two challenging data sets: 1) OSIE data set and 2) MIT data set.",4
Exponential Stability of Complex-Valued Memristive Recurrent Neural Networks.,"In this brief, we establish a novel complex-valued memristive recurrent neural network (CVMRNN) to study its stability. As a generalization of real-valued memristive neural networks, CVMRNN can be separated into real and imaginary parts. By means of M -matrix and Lyapunov function, the existence, uniqueness, and exponential stability of the equilibrium point for CVMRNNs are investigated, and sufficient conditions are presented. Finally, the effectiveness of obtained results is illustrated by two numerical examples.",4
Out-of-Sample Extensions for Non-Parametric Kernel Methods.,"Choosing suitable kernels plays an important role in the performance of kernel methods. Recently, a number of studies were devoted to developing nonparametric kernels. Without assuming any parametric form of the target kernel, nonparametric kernel learning offers a flexible scheme to utilize the information of the data, which may potentially characterize the data similarity better. The kernel methods using nonparametric kernels are referred to as nonparametric kernel methods. However, many nonparametric kernel methods are restricted to transductive learning, where the prediction function is defined only over the data points given beforehand. They have no straightforward extension for the out-of-sample data points, and thus cannot be applied to inductive learning. In this paper, we show how to make the nonparametric kernel methods applicable to inductive learning. The key problem of out-of-sample extension is how to extend the nonparametric kernel matrix to the corresponding kernel function. A regression approach in the hyper reproducing kernel Hilbert space is proposed to solve this problem. Empirical results indicate that the out-of-sample performance is comparable to the in-sample performance in most cases. Experiments on face recognition demonstrate the superiority of our nonparametric kernel method over the state-of-the-art parametric kernel methods.",4
A Graph-Embedding Approach to Hierarchical Visual Word Mergence.,"Appropriately merging visual words are an effective dimension reduction method for the bag-of-visual-words model in image classification. The approach of hierarchically merging visual words has been extensively employed, because it gives a fully determined merging hierarchy. Existing supervised hierarchical merging methods take different approaches and realize the merging process with various formulations. In this paper, we propose a unified hierarchical merging approach built upon the graph-embedding framework. Our approach is able to merge visual words for any scenario, where a preferred structure and an undesired structure are defined, and, therefore, can effectively attend to all kinds of requirements for the word-merging process. In terms of computational efficiency, we show that our algorithm can seamlessly integrate a fast search strategy developed in our previous work and, thus, well maintain the state-of-the-art merging speed. To the best of our survey, the proposed approach is the first one that addresses the hierarchical visual word mergence in such a flexible and unified manner. As demonstrated, it can maintain excellent image classification performance even after a significant dimension reduction, and outperform all the existing comparable visual word-merging methods. In a broad sense, our work provides an open platform for applying, evaluating, and developing new criteria for hierarchical word-merging tasks.",4
Identification and Control for Singularly Perturbed Systems Using Multitime-Scale Neural Networks.,"Many well-established singular perturbation theories for singularly perturbed systems require the full knowledge of system model parameters. In order to obtain an accurate and faithful model, a new identification scheme for singularly perturbed nonlinear system using multitime-scale recurrent high-order neural networks (NNs) is proposed in this paper. Inspired by the optimal bounded ellipsoid algorithm, which is originally designed for discrete-time systems, a novel weight updating law is developed for continuous-time NNs identification process. Compared with other widely used gradient-descent updating algorithms, this new method can achieve faster convergence, due to its adaptively adjusted learning rate. Based on the identification results, a control scheme using singular perturbation theories is developed. By using singular perturbation methods, the system order is reduced, and the controller structure is simplified. The closed-loop stability is analyzed and the convergence of system states is guaranteed. The effectiveness of the identification and the control scheme is demonstrated by simulation results.",4
DISC: Deep Image Saliency Computing via Progressive Representation Learning.,"Salient object detection increasingly receives attention as an important component or step in several pattern recognition and image processing tasks. Although a variety of powerful saliency models have been intensively proposed, they usually involve heavy feature (or model) engineering based on priors (or assumptions) about the properties of objects and backgrounds. Inspired by the effectiveness of recently developed feature learning, we provide a novel deep image saliency computing (DISC) framework for fine-grained image saliency computing. In particular, we model the image saliency from both the coarse-and fine-level observations, and utilize the deep convolutional neural network (CNN) to learn the saliency representation in a progressive manner. In particular, our saliency model is built upon two stacked CNNs. The first CNN generates a coarse-level saliency map by taking the overall image as the input, roughly identifying saliency regions in the global context. Furthermore, we integrate superpixel-based local context information in the first CNN to refine the coarse-level saliency map. Guided by the coarse saliency map, the second CNN focuses on the local context to produce fine-grained and accurate saliency map while preserving object details. For a testing image, the two CNNs collaboratively conduct the saliency computing in one shot. Our DISC framework is capable of uniformly highlighting the objects of interest from complex background while preserving well object details. Extensive experiments on several standard benchmarks suggest that DISC outperforms other state-of-the-art methods and it also generalizes well across data sets without additional training. The executable version of DISC is available online: http://vision.sysu.edu.cn/projects/DISC.",4
Impulsive Effects and Stability Analysis on Memristive Neural Networks With Variable Delays.,"In this brief, hybrid impulsive and adaptive feedback controllers are simultaneously exerted on a general delayed memristive neural network (MNN) model to formulate a novel impulsive controlled MNN (IMNN) model with variable delays. By means of Lyapunov-Razumikhin technique and other analytical ways, several new stability criteria of the proposed IMNN model are obtained. In addition, by choosing appropriate impulses and external inputs, the convergence speed of IMNN can be increased, which implies that its dynamic behaviors will be optimized. Finally, the effectiveness of the obtained results is illustrated by one numerical example.",4
Artificial Epigenetic Networks: Automatic Decomposition of Dynamical Control Tasks Using Topological Self-Modification.,"This paper describes the artificial epigenetic network, a recurrent connectionist architecture that is able to dynamically modify its topology in order to automatically decompose and solve dynamical problems. The approach is motivated by the behavior of gene regulatory networks, particularly the epigenetic process of chromatin remodeling that leads to topological change and which underlies the differentiation of cells within complex biological organisms. We expected this approach to be useful in situations where there is a need to switch between different dynamical behaviors, and do so in a sensitive and robust manner in the absence of a priori information about problem structure. This hypothesis was tested using a series of dynamical control tasks, each requiring solutions that could express different dynamical behaviors at different stages within the task. In each case, the addition of topological self-modification was shown to improve the performance and robustness of controllers. We believe this is due to the ability of topological changes to stabilize attractors, promoting stability within a dynamical regime while allowing rapid switching between different regimes. Post hoc analysis of the controllers also demonstrated how the partitioning of the networks could provide new insights into problem structure.",4
Sampled-Data Synchronization Analysis of Markovian Neural Networks With Generally Incomplete Transition Rates.,"This paper investigates the problem of sampled-data synchronization for Markovian neural networks with generally incomplete transition rates. Different from traditional Markovian neural networks, each transition rate can be completely unknown or only its estimate value is known in this paper. Compared with most of existing Markovian neural networks, our model is more practical because the transition rates in Markovian processes are difficult to precisely acquire due to the limitations of equipment and the influence of uncertain factors. In addition, the time-dependent Lyapunov-Krasovskii functional is proposed to synchronize drive system and response system. By applying an extended Jensen's integral inequality and Wirtinger's inequality, new delay-dependent synchronization criteria are obtained, which fully utilize the upper bound of variable sampling interval and the sawtooth structure information of varying input delay. Moreover, the desired sampled-data controllers are obtained. Finally, two examples are provided to illustrate the effectiveness of the proposed method.",4
Adaptive Fault-Tolerant Synchronization Control of a Class of Complex Dynamical Networks With General Input Distribution Matrices and Actuator Faults.,"This paper is concerned with the problem of adaptive fault-tolerant synchronization control of a class of complex dynamical networks (CDNs) with actuator faults and unknown coupling weights. The considered input distribution matrix is assumed to be an arbitrary matrix, instead of a unit one. Within this framework, an adaptive fault-tolerant controller is designed to achieve synchronization for the CDN. Moreover, a convex combination technique and an important graph theory result are developed, such that the rigorous convergence analysis of synchronization errors can be conducted. In particular, it is shown that the proposed fault-tolerant synchronization control approach is valid for the CDN with both time-invariant and time-varying coupling weights. Finally, two simulation examples are provided to validate the effectiveness of the theoretical results.",4
A Proposal for Local $k$ Values for $k$ -Nearest Neighbor Rule.,"The k -nearest neighbor ( k -NN) classifier is one of the most widely used methods of classification due to several interesting features, including good generalization and easy implementation. Although simple, it is usually able to match and even outperform more sophisticated and complex methods. One of the problems with this approach is fixing the appropriate value of k . Although a good value might be obtained using cross validation, it is unlikely that the same value could be optimal for the whole space spanned by the training set. It is evident that different regions of the feature space would require different values of k due to the different distributions of prototypes. The situation of a query instance in the center of a class is very different from the situation of a query instance near the boundary between two classes. In this brief, we present a simple yet powerful approach to setting a local value of k . We associate a potentially different k to every prototype and obtain the best value of k by optimizing a criterion consisting of the local and global effects of the different k values in the neighborhood of the prototype. The proposed method has a fast training stage and the same complexity as the standard k -NN approach at the testing stage. The experiments show that this simple approach can significantly outperform the standard k -NN rule for both standard and class-imbalanced problems in a large set of different problems.",4
Hierarchical Image Segmentation Using Correlation Clustering.,"In this paper, we apply efficient implementations of integer linear programming to the problem of image segmentation. The image is first grouped into superpixels and then local information is extracted for each pair of spatially adjacent superpixels. Given local scores on a map of several hundred superpixels, we use correlation clustering to find the global segmentation that is most consistent with the local evidence. We show that, although correlation clustering is known to be NP-hard, finding the exact global solution is still feasible by breaking the segmentation problem down into subproblems. Each such sub-problem can be viewed as an automatically detected image part. We can further accelerate the process by using the cutting-plane method, which provides a hierarchical structure of the segmentations. The efficiency and improved performance of the proposed method is compared to several state-of-the-art methods and demonstrated on several standard segmentation data sets.",4
Adaptive Modulation for DFIG and STATCOM With High-Voltage Direct Current Transmission.,"This paper develops an adaptive modulation approach for power system control based on the approximate/adaptive dynamic programming method, namely, the goal representation heuristic dynamic programming (GrHDP). In particular, we focus on the fault recovery problem of a doubly fed induction generator (DFIG)-based wind farm and a static synchronous compensator (STATCOM) with high-voltage direct current (HVDC) transmission. In this design, the online GrHDP-based controller provides three adaptive supplementary control signals to the DFIG controller, STATCOM controller, and HVDC rectifier controller, respectively. The mechanism is to observe the system states and their derivatives and then provides supplementary control to the plant according to the utility function. With the GrHDP design, the controller can adaptively develop an internal goal representation signal according to the observed power system states, therefore, to achieve more effective learning and modulating. Our control approach is validated on a wind power integrated benchmark system with two areas connected by HVDC transmission lines. Compared with the classical direct HDP and proportional integral control, our GrHDP approach demonstrates the improved transient stability under system faults. Moreover, experiments under different system operating conditions with signal transmission delays are also carried out to further verify the effectiveness and robustness of the proposed approach.",4
Event-Triggered Generalized Dissipativity Filtering for Neural Networks With Time-Varying Delays.,"This paper is concerned with event-triggered generalized dissipativity filtering for a neural network (NN) with a time-varying delay. The signal transmission from the NN to its filter is completed through a communication channel. It is assumed that the network measurement of the NN is sampled periodically. An event-triggered communication scheme is introduced to design a suitable filter such that precious communication resources can be saved significantly while certain filtering performance can be ensured. On the one hand, the event-triggered communication scheme is devised to select only those sampled signals violating a certain threshold to be transmitted, which directly leads to saving of precious communication resources. On the other hand, the filtering error system is modeled as a time-delay system closely dependent on the parameters of the event-triggered scheme. Based on this model, a suitable filter is designed such that certain filtering performance can be ensured, provided that a set of linear matrix inequalities are satisfied. Furthermore, since a generalized dissipativity performance index is introduced, several kinds of event-triggered filtering issues, such as Hinfinity filtering, passive filtering, mixed Hinfinity and passive filtering, (Q,S,R) -dissipative filtering, and L2 - Linfinity filtering, are solved in a unified framework. Finally, two examples are given to illustrate the effectiveness of the proposed method.",4
Monitoring Nonlinear and Non-Gaussian Processes Using Gaussian Mixture Model-Based Weighted Kernel Independent Component Analysis.,"A kernel independent component analysis (KICA) is widely regarded as an effective approach for nonlinear and non-Gaussian process monitoring. However, the KICA-based monitoring methods treat every KIC equally and cannot highlight the useful KICs associated with fault information. Consequently, fault information may not be explored effectively, which may result in degraded fault detection performance. To overcome this problem, we propose a new nonlinear and non-Gaussian process monitoring method using Gaussian mixture model (GMM)-based weighted KICA (WKICA). In particular, in WKICA, GMM is first adopted to estimate the probabilities of the KICs extracted by KICA. The significant KICs embodying the dominant process variation are then discriminated based on the estimated probabilities and assigned with larger weights to capture the significant information during online fault detection. A nonlinear contribution plots method is also developed based on the idea of a sensitivity analysis to help identifying the fault variables after a fault is detected. Simulation studies conducted on a simple four-variable nonlinear system and the Tennessee Eastman benchmark process demonstrate the superiority of the proposed method over the conventional KICA-based method.",4
Discriminative Feature Extraction by a Neural Implementation of Canonical Correlation Analysis.,"The canonical correlation analysis (CCA) aims at measuring linear relationships between two sets of variables (views) that can be used for feature extraction in classification problems with multiview data. However, the correlated features extracted by the CCA may not be class discriminative, since CCA does not utilize the class labels in its traditional formulation. Although there is a method called discriminative CCA (DCCA) that aims to increase the discriminative ability of CCA inspired from the linear discriminant analysis (LDA), it has been shown that the extracted features with this method are identical to those by the LDA with respect to an orthogonal transformation. Therefore, DCCA is simply equivalent to applying single-view (regular) LDA to each one of the views separately. Besides, DCCA and the other similar DCCA approaches have generalization problems due to the sample covariance matrices used in their computation, which are sensitive to outliers and noisy samples. In this paper, we propose a method, called discriminative alternating regression (D-AR), to explore correlated and also discriminative features. D-AR utilizes two (alternating) multilayer perceptrons, each with a linear hidden layer, learning to predict both the class labels and the outputs of each other. We show that the features found by D-AR on training sets significantly accomplish higher classification accuracies on test sets of facial expression recognition, object recognition, and image retrieval experimental data sets.",4
Learning the Conformal Transformation Kernel for Image Recognition.,"In this paper, we present a multiclass data classifier, denoted by optimal conformal transformation kernel (OCTK), based on learning a specific kernel model, the CTK, and utilize it in two types of image recognition tasks, namely, face recognition and object categorization. We show that the learned CTK can lead to a desirable spatial geometry change in mapping data from the input space to the feature space, so that the local spatial geometry of the heterogeneous regions is magnified to favor a more refined distinguishing, while that of the homogeneous regions is compressed to neglect or suppress the intraclass variations. This nature of the learned CTK is of great benefit in image recognition, since in image recognition we always have to face a challenge that the images to be classified are with a large intraclass diversity and interclass similarity. Experiments on face recognition and object categorization show that the proposed OCTK classifier achieves the best or second best recognition result compared with that of the state-of-the-art classifiers, no matter what kind of feature or feature representation is used. In computational efficiency, the OCTK classifier can perform significantly faster than the linear support vector machine classifier (linear LIBSVM) can.",4
Multimodal Degradation Prognostics Based on Switching Kalman Filter Ensemble.,"For accurate prognostics, users have to determine the current health of the system and predict future degradation pattern of the system. An increasingly popular approach toward tackling prognostic problems involves the use of switching models to represent various degradation phases, which the system undergoes. Such approaches have the advantage of determining the exact degradation phase of the system and being able to handle nonlinear degradation models through piecewise linear approximation. However, limitations of such existing methods include, limited applicability due to the discretization of predicted remaining useful life, insufficient robustness due to the use of single models and others. This paper circumvents these limitations by proposing a hybrid of ensemble methods with switching methods. The proposed method first implements a switching Kalman filter (SKF) to classify between various linear degradation phases, then predict the future propagation of fault dimension using appropriate Kalman filters for each phase. This proposed method achieves both continuous and discrete prediction values representing the remaining life and degradation phase of the system, respectively. The proposed framework is shown via a case study on benchmark simulated aeroengine data sets. The evaluation of the proposed framework shows that the proposed method achieves better accuracy and robustness against noise compared with other methods reported in the literature. The results also indicate the effectiveness of the SKF in detecting the switching point between various degradation modes.",4
Density-Dependent Quantized Least Squares Support Vector Machine for Large Data Sets.,"Based on the knowledge that input data distribution is important for learning, a data density-dependent quantization scheme (DQS) is proposed for sparse input data representation. The usefulness of the representation scheme is demonstrated by using it as a data preprocessing unit attached to the well-known least squares support vector machine (LS-SVM) for application on big data sets. Essentially, the proposed DQS adopts a single shrinkage threshold to obtain a simple quantization scheme, which adapts its outputs to input data density. With this quantization scheme, a large data set is quantized to a small subset where considerable sample size reduction is generally obtained. In particular, the sample size reduction can save significant computational cost when using the quantized subset for feature approximation via the Nystrom method. Based on the quantized subset, the approximated features are incorporated into LS-SVM to develop a data density-dependent quantized LS-SVM (DQLS-SVM), where an analytic solution is obtained in the primal solution space. The developed DQLS-SVM is evaluated on synthetic and benchmark data with particular emphasis on large data sets. Extensive experimental results show that the learning machine incorporating DQS attains not only high computational efficiency but also good generalization performance.",4
Stability Analysis of Neural Networks With Two Delay Components Based on Dynamic Delay Interval Method.,"In this paper, a dynamic delay interval (DDI) method is proposed to deal with the stability problem of neural networks with two delay components. This method extends the fixed interval of a time-varying delay to a dynamic one, which relaxes the restriction on upper and lower bounds of the delay intervals. Combining the reciprocally convex combination technique and Wirtinger integral inequality, the DDI method leads to some much less conservative delay-dependent stability criteria based on a linear matrix inequality for neural networks with two delay components. Furthermore, the criteria for the system with a single time-varying delay are provided. Some examples are given to illustrate the effectiveness of the obtained results.",4
Adaptive Output Neural Network Control for a Class of Stochastic Nonlinear Systems With Dead-Zone Nonlinearities.,"This paper investigates the problem of adaptive output neural network (NN) control for a class of stochastic nonaffine and nonlinear systems with actuator dead-zone inputs. First, based on the intermediate value theorem, a novel design scheme that converts the nonaffine system into the corresponding affine system is developed. In particular, the priori knowledge of the bound of the derivative of the nonaffine and nonlinear functions is removed; then, by employing NNs to approximate the appropriate nonlinear functions, the corresponding adaptive NN tracking controller with the adjustable parameter updated laws is designed through a backstepping technique. Furthermore, it is shown that all the closed-loop signals are bounded in probability, and the system output tracking error can converge to a small neighborhood in the sense of a mean quartic value. Finally, experimental simulations are provided to demonstrate the efficiency of the proposed adaptive NN tracking control method.",4
A Cooperative Learning-Based Clustering Approach to Lip Segmentation Without Knowing Segment Number.,"It is usually hard to predetermine the true number of segments in lip segmentation. This paper, therefore, presents a clustering-based approach to lip segmentation without knowing the true segment number. The objective function in the proposed approach is a variant of the partition entropy (PE) and features that the coincident cluster centroids in pattern space can be equivalently substituted by one centroid with the function value unchanged. It is shown that the minimum of the proposed objective function can be reached provided that: 1) the number of positions occupied by cluster centroids in pattern space is equal to the true number of clusters and 2) these positions are coincident with the optimal cluster centroids obtained under PE criterion. In implementation, we first randomly initialize the clusters provided that the number of clusters is greater than or equal to the ground truth. Then, an iterative algorithm is utilized to minimize the proposed objective function. For each iterative step, not only is the winner, i.e., the centroid with the maximum membership degree, updated to adapt to the corresponding input data, but also the other centroids are adjusted with a specific cooperation strength, so that they are each close to the winner. Subsequently, the initial overpartition will be gradually faded out with the redundant centroids superposed over the convergence of the algorithm. Based upon the proposed algorithm, we present a lip segmentation scheme. Empirical studies have shown its efficacy in comparison with the existing methods.",4
A ParaBoost Method to Image Quality Assessment.,"An ensemble method for full-reference image quality assessment (IQA) based on the parallel boosting (ParaBoost) idea is proposed in this paper. We first extract features from existing image quality metrics and train them to form basic image quality scorers (BIQSs). Then, we select additional features to address specific distortion types and train them to construct auxiliary image quality scorers (AIQSs). Both BIQSs and AIQSs are trained on small image subsets of certain distortion types and, as a result, they are weak performers with respect to a wide variety of distortions. Finally, we adopt the ParaBoost framework, which is a statistical scorer selection scheme for support vector regression (SVR), to fuse the scores of BIQSs and AIQSs to evaluate the images containing a wide range of distortion types. This ParaBoost methodology can be easily extended to images of new distortion types. Extensive experiments are conducted to demonstrate the superior performance of the ParaBoost method, which outperforms existing IQA methods by a significant margin. Specifically, the Spearman rank order correlation coefficients (SROCCs) of the ParaBoost method with respect to the LIVE, CSIQ, TID2008, and TID2013 image quality databases are 0.98, 0.97, 0.98, and 0.96, respectively.",4
3-D Laser-Based Multiclass and Multiview Object Detection in Cluttered Indoor Scenes.,"This paper investigates the problem of multiclass and multiview 3-D object detection for service robots operating in a cluttered indoor environment. A novel 3-D object detection system using laser point clouds is proposed to deal with cluttered indoor scenes with a fewer and imbalanced training data. Raw 3-D point clouds are first transformed to 2-D bearing angle images to reduce the computational cost, and then jointly trained multiple object detectors are deployed to perform the multiclass and multiview 3-D object detection. The reclassification technique is utilized on each detected low confidence bounding box in the system to reduce false alarms in the detection. The RUS-SMOTEboost algorithm is used to train a group of independent binary classifiers with imbalanced training data. Dense histograms of oriented gradients and local binary pattern features are combined as a feature set for the reclassification task. Based on the dalian university of technology (DUT)-3-D data set taken from various office and household environments, experimental results show the validity and good performance of the proposed method.",4
K-MEAP: Multiple Exemplars Affinity Propagation With Specified $K$ Clusters.,"Recently, an attractive clustering approach named multiexemplar affinity propagation (MEAP) has been proposed as an extension to the single exemplar-based AP. MEAP is able to automatically identify multiple exemplars for each cluster associated with a superexemplar. However, if the cluster number is a prior knowledge and can be specified by the user, MEAP is unable to make use of such knowledge directly in its learning process. Instead, it has to rely on rerunning the process as many times as it takes by tuning parameters until it generates the desired number of clusters. The process of MEAP rerunning may be very time-consuming. In this paper, we propose a new clustering algorithm called Multiple Exemplars Affinity Propagation with Specified K Clusters which is able to generate specified K clusters directly while retaining the advantages of MEAP. Two kinds of new additional messages are introduced in K-MEAP in order to control the number of clusters in the process of message passing. Detailed problem formulation, derived messages, and in-depth analysis of the proposed K-MEAP are provided. Experimental studies on 11 real-world data sets with different kinds of applications demonstrate that K-MEAP not only generates K clusters directly and efficiently without tuning parameters but also outperforms related approaches in terms of clustering accuracy.",4
Power Quality Analysis Using a Hybrid Model of the Fuzzy Min-Max Neural Network and Clustering Tree.,"A hybrid intelligent model comprising a modified fuzzy min-max (FMM) clustering neural network and a modified clustering tree (CT) is developed. A review of clustering models with rule extraction capabilities is presented. The hybrid FMM-CT model is explained. We first use several benchmark problems to illustrate the cluster evolution patterns from the proposed modifications in FMM. Then, we employ a case study with real data related to power quality monitoring to assess the usefulness of FMM-CT. The results are compared with those from other clustering models. More importantly, we extract explanatory rules from FMM-CT to justify its predictions. The empirical findings indicate the usefulness of the proposed model in tackling data clustering and power quality monitoring problems under different environments.",4
A Bi-Projection Neural Network for Solving Constrained Quadratic Optimization Problems.,"In this paper, a bi-projection neural network for solving a class of constrained quadratic optimization problems is proposed. It is proved that the proposed neural network is globally stable in the sense of Lyapunov, and the output trajectory of the proposed neural network will converge globally to an optimal solution. Compared with existing projection neural networks (PNNs), the proposed neural network has a very small model size owing to its bi-projection structure. Furthermore, an application to data fusion shows that the proposed neural network is very effective. Numerical results demonstrate that the proposed neural network is much faster than the existing PNNs.",4
Pull-Based Distributed Event-Triggered Consensus for Multiagent Systems With Directed Topologies.,"This paper mainly investigates consensus problem with a pull-based event-triggered feedback control. For each agent, the diffusion coupling feedbacks are based on the states of its in-neighbors at its latest triggering time, and the next triggering time of this agent is determined by its in-neighbors' information. The general directed topologies, including irreducible and reducible cases, are investigated. The scenario of distributed continuous communication is considered first. It is proved that if the network topology has a spanning tree, then the event-triggered coupling algorithm can realize the consensus for the multiagent system. Then, the results are extended to discontinuous communication, i.e., self-triggered control, where each agent computes its next triggering time in advance without having to observe the system's states continuously. The effectiveness of the theoretical results is illustrated by a numerical example finally.",4
Unsupervised Metric Fusion Over Multiview Data by Graph Random Walk-Based Cross-View Diffusion.,"Learning an ideal metric is crucial to many tasks in computer vision. Diverse feature representations may combat this problem from different aspects; as visual data objects described by multiple features can be decomposed into multiple views, thus often provide complementary information. In this paper, we propose a cross-view fusion algorithm that leads to a similarity metric for multiview data by systematically fusing multiple similarity measures. Unlike existing paradigms, we focus on learning distance measure by exploiting a graph structure of data samples, where an input similarity matrix can be improved through a propagation of graph random walk. In particular, we construct multiple graphs with each one corresponding to an individual view, and a cross-view fusion approach based on graph random walk is presented to derive an optimal distance measure by fusing multiple metrics. Our method is scalable to a large amount of data by enforcing sparsity through an anchor graph representation. To adaptively control the effects of different views, we dynamically learn view-specific coefficients, which are leveraged into graph random walk to balance multiviews. However, such a strategy may lead to an over-smooth similarity metric where affinities between dissimilar samples may be enlarged by excessively conducting cross-view fusion. Thus, we figure out a heuristic approach to controlling the iteration number in the fusion process in order to avoid over smoothness. Extensive experiments conducted on real-world data sets validate the effectiveness and efficiency of our approach.",4
Why Deep Learning Works: A Manifold Disentanglement Perspective.,"Deep hierarchical representations of the data have been found out to provide better informative features for several machine learning applications. In addition, multilayer neural networks surprisingly tend to achieve better performance when they are subject to an unsupervised pretraining. The booming of deep learning motivates researchers to identify the factors that contribute to its success. One possible reason identified is the flattening of manifold-shaped data in higher layers of neural networks. However, it is not clear how to measure the flattening of such manifold-shaped data and what amount of flattening a deep neural network can achieve. For the first time, this paper provides quantitative evidence to validate the flattening hypothesis. To achieve this, we propose a few quantities for measuring manifold entanglement under certain assumptions and conduct experiments with both synthetic and real-world data. Our experimental results validate the proposition and lead to new insights on deep learning.",4
Accurate Maximum-Margin Training for Parsing With Context-Free Grammars.,"The task of natural language parsing can naturally be embedded in the maximum-margin framework for structured output prediction using an appropriate joint feature map and a suitable structured loss function. While there are efficient learning algorithms based on the cutting-plane method for optimizing the resulting quadratic objective with potentially exponential number of linear constraints, their efficiency crucially depends on the inference algorithms used to infer the most violated constraint in a current iteration. In this paper, we derive an extension of the well-known Cocke-Kasami-Younger (CKY) algorithm used for parsing with probabilistic context-free grammars for the case of loss-augmented inference enabling an effective training in the cutting-plane approach. The resulting algorithm is guaranteed to find an optimal solution in polynomial time exceeding the running time of the CKY algorithm by a term, which only depends on the number of possible loss values. In order to demonstrate the feasibility of the presented algorithm, we perform a set of experiments for parsing English sentences.",4
SpikeTemp: An Enhanced Rank-Order-Based Learning Approach for Spiking Neural Networks With Adaptive Structure.,"This paper presents an enhanced rank-order-based learning algorithm, called SpikeTemp, for spiking neural networks (SNNs) with a dynamically adaptive structure. The trained feed-forward SNN consists of two layers of spiking neurons: 1) an encoding layer which temporally encodes real-valued features into spatio-temporal spike patterns and 2) an output layer of dynamically grown neurons which perform spatio-temporal classification. Both Gaussian receptive fields and square cosine population encoding schemes are employed to encode real-valued features into spatio-temporal spike patterns. Unlike the rank-order-based learning approach, SpikeTemp uses the precise times of the incoming spikes for adjusting the synaptic weights such that early spikes result in a large weight change and late spikes lead to a smaller weight change. This removes the need to rank all the incoming spikes and, thus, reduces the computational cost of SpikeTemp. The proposed SpikeTemp algorithm is demonstrated on several benchmark data sets and on an image recognition task. The results show that SpikeTemp can achieve better classification performance and is much faster than the existing rank-order-based learning approach. In addition, the number of output neurons is much smaller when the square cosine encoding scheme is employed. Furthermore, SpikeTemp is benchmarked against a selection of existing machine learning algorithms, and the results demonstrate the ability of SpikeTemp to classify different data sets after just one presentation of the training samples with comparable classification performance.",4
Information Theoretic Subspace Clustering.,"This paper addresses the problem of grouping the data points sampled from a union of multiple subspaces in the presence of outliers. Information theoretic objective functions are proposed to combine structured low-rank representations (LRRs) to capture the global structure of data and information theoretic measures to handle outliers. In theoretical part, we point out that group sparsity-induced measures ( l2,1 -norm, lalpha -norm, and correntropy) can be justified from the viewpoint of half-quadratic (HQ) optimization, which facilitates both convergence study and algorithmic development. In particular, a general formulation is accordingly proposed to unify HQ-based group sparsity methods into a common framework. In algorithmic part, we develop information theoretic subspace clustering methods via correntropy. With the help of Parzen window estimation, correntropy is used to handle either outliers under any distributions or sample-specific errors in data. Pairwise link constraints are further treated as a prior structure of LRRs. Based on the HQ framework, iterative algorithms are developed to solve the nonconvex information theoretic loss functions. Experimental results on three benchmark databases show that our methods can further improve the robustness of LRR subspace clustering and outperform other state-of-the-art subspace clustering methods.",4
Adaptive Scaling of Cluster Boundaries for Large-Scale Social Media Data Clustering.,"The large scale and complex nature of social media data raises the need to scale clustering techniques to big data and make them capable of automatically identifying data clusters with few empirical settings. In this paper, we present our investigation and three algorithms based on the fuzzy adaptive resonance theory (Fuzzy ART) that have linear computational complexity, use a single parameter, i.e., the vigilance parameter to identify data clusters, and are robust to modest parameter settings. The contribution of this paper lies in two aspects. First, we theoretically demonstrate how complement coding, commonly known as a normalization method, changes the clustering mechanism of Fuzzy ART, and discover the vigilance region (VR) that essentially determines how a cluster in the Fuzzy ART system recognizes similar patterns in the feature space. The VR gives an intrinsic interpretation of the clustering mechanism and limitations of Fuzzy ART. Second, we introduce the idea of allowing different clusters in the Fuzzy ART system to have different vigilance levels in order to meet the diverse nature of the pattern distribution of social media data. To this end, we propose three vigilance adaptation methods, namely, the activation maximization (AM) rule, the confliction minimization (CM) rule, and the hybrid integration (HI) rule. With an initial vigilance value, the resulting clustering algorithms, namely, the AM-ART, CM-ART, and HI-ART, can automatically adapt the vigilance values of all clusters during the learning epochs in order to produce better cluster boundaries. Experiments on four social media data sets show that AM-ART, CM-ART, and HI-ART are more robust than Fuzzy ART to the initial vigilance value, and they usually achieve better or comparable performance and much faster speed than the state-of-the-art clustering algorithms that also do not require a predefined number of clusters.",4
Optimal Output Regulation for Heterogeneous Multiagent Systems via Adaptive Dynamic Programming.,"In this paper, the optimal output regulation problem for partially model-free heterogeneous linear multiagent systems with disturbance generated by an exosystem is addressed by using adaptive dynamic programming and double compensator method. The topology graph for the information exchange of the agents has a spanning tree. The dynamic of individual agent is assumed to be nonidentical and of different dimensions. One distributed compensator is designed to deal with the nonidentical agents, and the other compensator is used to handle the optimal performance index. By constructing the double compensator, the distributed feedback control laws are designed to make the output of each agent synchronize with the reference output and minimize the energy of the output error simultaneously. To overcome the lack of the dynamics knowledge of each agent, a novel online policy iteration algorithm is developed to obtain the optimal feedback gain matrix. Finally, two examples are presented to illustrate the effectiveness of our results.",4
Synchronization Analysis and Design of Coupled Boolean Networks Based on Periodic Switching Sequences.,"A novel synchronization analysis method is developed to solve the complete synchronization problem of many Boolean networks (BNs) coupled in the leader-follower configuration. First, an error system is constructed in terms of the algebraic representation using the semitensor product of matrices. Then, the synchronization problem of coupled BNs is converted into a problem whether all the trajectories of the error system are convergent to the zero vector. Second, according to the structure analysis of this error system, which is in the form of a switched system with leader BN states as the switching signal, a necessary and sufficient synchronization condition is derived. An algorithm is developed, which helps to determine as soon as possible whether complete synchronization among coupled BNs is achieved. Finally, a constructive design approach to follower BNs is provided. All of these follower BNs designed by our approach can completely synchronize with a given leader BN from the (Tt+1) th step at most, where Tt is the transient period of the leader BN.",4
Can the Virtual Labels Obtained by Traditional LP Approaches Be Well Encoded in WLR?,"Semisupervised dimension reduction via virtual label regression first derives the virtual labels of unlabeled data by employing a newly designed label propagation (LP) approach (called Special random walk (SRW)) and then encodes them in a weighted linear regression model. Nie et al. (2011) highlighted two important characteristics of SRW nonexistent in the previous LP approaches: outlier detection and probability value output, which guarantee the elegant encoding of the resultant virtual labels in the weighted label regression. However, in this brief, we show that the relationship between the SRW and the previous work on LP is very close. Naturally, a problem deserving investigation is whether traditional LP approaches are indeed unable to share the above two characteristics of SRW. We aim to address this problem.",4
Bayesian Recurrent Neural Network for Language Modeling.,"A language model (LM) is calculated as the probability of a word sequence that provides the solution to word prediction for a variety of information systems. A recurrent neural network (RNN) is powerful to learn the large-span dynamics of a word sequence in the continuous space. However, the training of the RNN-LM is an ill-posed problem because of too many parameters from a large dictionary size and a high-dimensional hidden layer. This paper presents a Bayesian approach to regularize the RNN-LM and apply it for continuous speech recognition. We aim to penalize the too complicated RNN-LM by compensating for the uncertainty of the estimated model parameters, which is represented by a Gaussian prior. The objective function in a Bayesian classification network is formed as the regularized cross-entropy error function. The regularized model is constructed not only by calculating the regularized parameters according to the maximum a posteriori criterion but also by estimating the Gaussian hyperparameter by maximizing the marginal likelihood. A rapid approximation to a Hessian matrix is developed to implement the Bayesian RNN-LM (BRNN-LM) by selecting a small set of salient outer-products. The proposed BRNN-LM achieves a sparser model than the RNN-LM. Experiments on different corpora show the robustness of system performance by applying the rapid BRNN-LM under different conditions.",4
Scalable Linear Visual Feature Learning via Online Parallel Nonnegative Matrix Factorization.,"Visual feature learning, which aims to construct an effective feature representation for visual data, has a wide range of applications in computer vision. It is often posed as a problem of nonnegative matrix factorization (NMF), which constructs a linear representation for the data. Although NMF is typically parallelized for efficiency, traditional parallelization methods suffer from either an expensive computation or a high runtime memory usage. To alleviate this problem, we propose a parallel NMF method called alternating least square block decomposition (ALSD), which efficiently solves a set of conditionally independent optimization subproblems based on a highly parallelized fine-grained grid-based blockwise matrix decomposition. By assigning each block optimization subproblem to an individual computing node, ALSD can be effectively implemented in a MapReduce-based Hadoop framework. In order to cope with dynamically varying visual data, we further present an incremental version of ALSD, which is able to incrementally update the NMF solution with a low computational cost. Experimental results demonstrate the efficiency and scalability of the proposed methods as well as their applications to image clustering and image retrieval.",4
Using Digital Masks to Enhance the Bandwidth Tolerance and Improve the Performance of On-Chip Reservoir Computing Systems.,"Reservoir computing (RC) is a computing scheme related to recurrent neural network theory. As a model for neural activity in the brain, it attracts a lot of attention, especially because of its very simple training method. However, building a functional, on-chip, photonic implementation of RC remains a challenge. Scaling delay lines down from optical fiber scale to chip scale results in RC systems that compute faster, but at the same time requires that the input signals be scaled up in speed, which might be impractical or expensive. In this brief, we show that this problem can be alleviated by a masked RC system in which the amplitude of the input signal is modulated by a binary-valued mask. For a speech recognition task, we demonstrate that the necessary input sample rate can be a factor of 40 smaller than in a conventional RC system. In addition, we also show that linear discriminant analysis and input matrix optimization is a well-performing alternative to linear regression for reservoir training.",4
Semisupervised Multiclass Classification Problems With Scarcity of Labeled Data: A Theoretical Study.,"In recent years, the performance of semisupervised learning (SSL) has been theoretically investigated. However, most of this theoretical development has focused on binary classification problems. In this paper, we take it a step further by extending the work of Castelli and Cover to the multiclass paradigm. In particular, we consider the key problem in SSL of classifying an unseen instance x into one of K different classes, using a training data set sampled from a mixture density distribution and composed of l labeled records and u unlabeled examples. Even under the assumption of identifiability of the mixture and having infinite unlabeled examples, labeled records are needed to determine the K decision regions. Therefore, in this paper, we first investigate the minimum number of labeled examples needed to accomplish that task. Then, we propose an optimal multiclass learning algorithm, which is a generalization of the optimal procedure proposed in the literature for binary problems. Finally, we make use of this generalization to study the probability of error when the binary class constraint is relaxed.",4
Integration-Enhanced Zhang Neural Network for Real-Time-Varying Matrix Inversion in the Presence of Various Kinds of Noises.,"Matrix inversion often arises in the fields of science and engineering. Many models for matrix inversion usually assume that the solving process is free of noises or that the denoising has been conducted before the computation. However, time is precious for the real-time-varying matrix inversion in practice, and any preprocessing for noise reduction may consume extra time, possibly violating the requirement of real-time computation. Therefore, a new model for time-varying matrix inversion that is able to handle simultaneously the noises is urgently needed. In this paper, an integration-enhanced Zhang neural network (IEZNN) model is first proposed and investigated for real-time-varying matrix inversion. Then, the conventional ZNN model and the gradient neural network model are presented and employed for comparison. In addition, theoretical analyses show that the proposed IEZNN model has the global exponential convergence property. Moreover, in the presence of various kinds of noises, the proposed IEZNN model is proven to have an improved performance. That is, the proposed IEZNN model converges to the theoretical solution of the time-varying matrix inversion problem no matter how large the matrix-form constant noise is, and the residual errors of the proposed IEZNN model can be arbitrarily small for time-varying noises and random noises. Finally, three illustrative simulation examples, including an application to the inverse kinematic motion planning of a robot manipulator, are provided and analyzed to substantiate the efficacy and superiority of the proposed IEZNN model for real-time-varying matrix inversion.",4
Synchronization of Arbitrarily Switched Boolean Networks.,"This paper investigates the complete synchronization problem for the drive-response switched Boolean networks (SBNs) under arbitrary switching signals, where the switching signals of the response SBN follow those generated by the drive SBN at each time instant. First, the definition of complete synchronization is introduced for the drive-response SBNs under arbitrary switching signals. Second, the concept of switching reachable set starting from a given initial state set is put forward. Based on it, a necessary and sufficient condition is derived for the complete synchronization of the drive-response SBNs. Last, we give a simple algebraic expression for the switching reachable set in a given number of time steps, and two computable algebraic criteria are obtained for the complete synchronization of the SBNs. A biological example is given to demonstrate the effectiveness of the obtained main results.",4
Training Radial Basis Function Neural Networks for Classification via Class-Specific Clustering.,"In training radial basis function neural networks (RBFNNs), the locations of Gaussian neurons are commonly determined by clustering. Training inputs can be clustered on a fully unsupervised manner (input clustering), or some supervision can be introduced, for example, by concatenating the input vectors with weighted output vectors (input-output clustering). In this paper, we propose to apply clustering separately for each class (class-specific clustering). The idea has been used in some previous works, but without evaluating the benefits of the approach. We compare the class-specific, input, and input-output clustering approaches in terms of classification performance and computational efficiency when training RBFNNs. To accomplish this objective, we apply three different clustering algorithms and conduct experiments on 25 benchmark data sets. We show that the class-specific approach significantly reduces the overall complexity of the clustering, and our experimental results demonstrate that it can also lead to a significant gain in the classification performance, especially for the networks with a relatively few Gaussian neurons. Among other applied clustering algorithms, we combine, for the first time, a dynamic evolutionary optimization method, multidimensional particle swarm optimization, and the class-specific clustering to optimize the number of cluster centroids and their locations.",4
Quantized Attention-Gated Kernel Reinforcement Learning for Brain-Machine Interface Decoding.,"Reinforcement learning (RL)-based decoders in brain-machine interfaces (BMIs) interpret dynamic neural activity without patients' real limb movements. In conventional RL, the goal state is selected by the user or defined by the physics of the problem, and the decoder finds an optimal policy essentially by assigning credit over time, which is normally very time-consuming. However, BMI tasks require finding a good policy in very few trials, which impose a limit on the complexity of the tasks that can be learned before the animal quits. Therefore, this paper explores the possibility of letting the agent infer potential goals through actions over space with multiple objects, using the instantaneous reward to assign credit spatially. A previous method, attention-gated RL employs a multilayer perceptron trained with backpropagation, but it is prone to local minima entrapment. We propose a quantized attention-gated kernel RL (QAGKRL) to avoid the local minima adaptation in spatial credit assignment and sparsify the network topology. The experimental results show that the QAGKRL achieves higher successful rates and more stable performance, indicating its powerful decoding ability for more sophisticated BMI tasks as required in clinical applications.",4
Image Categorization by Learning a Propagated Graphlet Path.,"Spatial pyramid matching is a standard architecture for categorical image retrieval. However, its performance is largely limited by the prespecified rectangular spatial regions when pooling local descriptors. In this paper, we propose to learn object-shaped and directional receptive fields for image categorization. In particular, different objects in an image are seamlessly constructed by superpixels, while the direction captures human gaze shifting path. By generating a number of superpixels in each image, we construct graphlets to describe different objects. They function as the object-shaped receptive fields for image comparison. Due to the huge number of graphlets in an image, a saliency-guided graphlet selection algorithm is proposed. A manifold embedding algorithm encodes graphlets with the semantics of training image tags. Then, we derive a manifold propagation to calculate the postembedding graphlets by leveraging visual saliency maps. The sequentially propagated graphlets constitute a path that mimics human gaze shifting. Finally, we use the learned graphlet path as receptive fields for local image descriptor pooling. The local descriptors from similar receptive fields of pairwise images more significantly contribute to the final image kernel. Thorough experiments demonstrate the advantage of our approach.",4
Shortcomings/Limitations of Blockwise Granger Causality and Advances of Blockwise New Causality.,"Multivariate blockwise Granger causality (BGC) is used to reflect causal interactions among blocks of multivariate time series. In particular, spectral BGC and conditional spectral BGC are used to disclose blockwise causal flow among different brain areas in various frequencies. In this paper, we demonstrate that: 1) BGC in time domain may not necessarily disclose true causality and 2) due to the use of the transfer function or its inverse matrix and partial information of the multivariate linear regression model, both of spectral BGC and conditional spectral BGC have shortcomings and/or limitations, which may inevitably lead to misinterpretation. We then, in time and frequency domains, develop two new multivariate blockwise causality methods for the linear regression model called blockwise new causality (BNC) and spectral BNC, respectively. By several examples, we confirm that BNC measures are more reasonable and sensitive to reflect true causality or trend of true causality than BGC or conditional BGC. Finally, for electroencephalograph data from an epilepsy patient, we analyze event-related potential causality and demonstrate that both of the BGC and BNC methods show significant causality flow in frequency domain, but the spectral BNC method yields satisfactory and convincing results, which are consistent with an event-related time-frequency power spectrum activity. The spectral BGC method is shown to generate misleading results. Thus, we deeply believe that our new blockwise causality definitions as well as our previous NC definitions may have wide applications to reflect true causality among two blocks of time series or two univariate time series in economics, neuroscience, and engineering.",4
A Boosting Approach to Exploit Instance Correlations for Multi-Instance Classification.,"We propose a Boosting approach for multi-instance (MI) classification. Lp -norm is integrated to localize the witness instances and formulate the bag scores from classifier outputs. The contributions are twofold. First, a flexible and concise model for Boosting is proposed by the Lp -norm localization and exponential loss optimization. The scores for bag-level classification are directly fused from the instance feature space without probabilistic assumptions. Second, gradient and Newton descent optimizations are applied to derive the weak learners for Boosting. In particular, the instance correlations are exploited by fitting the weights and Newton updates for the weak learner construction. The final Boosted classifiers are the sums of iteratively chosen weak learners. Experiments demonstrate that the proposed Lp -norm-localized Boosting approach significantly improves the MI classification performance. Compared with the state of the art, the approach achieves the highest MI classification accuracy on 7/10 benchmark data sets.",4
Online Solution of Two-Player Zero-Sum Games for Continuous-Time Nonlinear Systems With Completely Unknown Dynamics.,"Regarding two-player zero-sum games of continuous-time nonlinear systems with completely unknown dynamics, this paper presents an online adaptive algorithm for learning the Nash equilibrium solution, i.e., the optimal policy pair. First, for known systems, the simultaneous policy updating algorithm (SPUA) is reviewed. A new analytical method to prove the convergence is presented. Then, based on the SPUA, without using a priori knowledge of any system dynamics, an online algorithm is proposed to simultaneously learn in real time either the minimal nonnegative solution of the Hamilton-Jacobi-Isaacs (HJI) equation or the generalized algebraic Riccati equation for linear systems as a special case, along with the optimal policy pair. The approximate solution to the HJI equation and the admissible policy pair is reexpressed by the approximation theorem. The unknown constants or weights of each are identified simultaneously by resorting to the recursive least square method. The convergence of the online algorithm to the optimal solutions is provided. A practical online algorithm is also developed. Simulation results illustrate the effectiveness of the proposed method.",4
L(1)-Norm Low-Rank Matrix Decomposition by Neural Networks and Mollifiers.,"The L1-norm cost function of the low-rank approximation of the matrix with missing entries is not smooth, and also cannot be transformed into a standard linear or quadratic programming problem, and thus, the optimization of this cost function is still not well solved. To tackle this problem, first, a mollifier is used to smooth the cost function. High closeness of the smoothed function to the original one can be obtained by tuning the parameters contained in the mollifier. Next, a recurrent neural network is proposed to optimize the mollified function, which will converge to a local minimum. In addition, to boost the speed of the system, the mollifying process is implemented by a filtering procedure. The influence of two mollifier parameters is theoretically analyzed and experimentally confirmed, showing that one of the parameters is critical to computational efficiency and accuracy, while the other not. A large number of experiments on synthetic data show that the proposed method is competitive to the state-of-the-art methods. In particular, the experiments on large matrices and a real application in the structure from motion indicate that the memory requirement of the proposed algorithm is mild, making it suitable for real applications that often involve large-scale matrix decomposition.",4
Generalized Higher Order Orthogonal Iteration for Tensor Learning and Decomposition.,"Low-rank tensor completion (LRTC) has successfully been applied to a wide range of real-world problems. Despite the broad, successful applications, existing LRTC methods may become very slow or even not applicable for large-scale problems. To address this issue, a novel core tensor trace-norm minimization (CTNM) method is proposed for simultaneous tensor learning and decomposition, and has a much lower computational complexity. In our solution, first, the equivalence relation of trace norm of a low-rank tensor and its core tensor is induced. Second, the trace norm of the core tensor is used to replace that of the whole tensor, which leads to two much smaller scale matrix TNM problems. Finally, an efficient alternating direction augmented Lagrangian method is developed to solve our problems. Our CTNM formulation needs only O((R(N)+NRI)log( radical{I(N)})) observations to reliably recover an N th-order IxIx...xI tensor of n -rank (r,r,...,r) , compared with O(rI(N-1)) observations required by those tensor TNM methods ( I >> R >/= r ). Extensive experimental results show that CTNM is usually more accurate than them, and is orders of magnitude faster.",4
A Generalized Hopfield Network for Nonsmooth Constrained Convex Optimization: Lie Derivative Approach.,"This paper proposes a generalized Hopfield network for solving general constrained convex optimization problems. First, the existence and the uniqueness of solutions to the generalized Hopfield network in the Filippov sense are proved. Then, the Lie derivative is introduced to analyze the stability of the network using a differential inclusion. The optimality of the solution to the nonsmooth constrained optimization problems is shown to be guaranteed by the enhanced Fritz John conditions. The convergence rate of the generalized Hopfield network can be estimated by the second-order derivative of the energy function. The effectiveness of the proposed network is evaluated on several typical nonsmooth optimization problems and used to solve the hierarchical and distributed model predictive control four-tank benchmark.",4
Dynamic Learning From Neural Control for Strict-Feedback Systems With Guaranteed Predefined Performance.,"This paper focuses on dynamic learning from neural control for a class of nonlinear strict-feedback systems with predefined tracking performance attributes. To reduce the number of neural network (NN) approximators used and make the convergence of neural weights verified easily, state variables are introduced to transform the state-feedback control of the original strict-feedback systems into the output-feedback control of the system in the normal form. Then, using the output error transformation based on performance functions, the constrained tracking control problem of the normal systems is transformed into the stabilization problem of an equivalent unconstrained one. By combining the backstepping method, a high-gain observer with radial basis function (RBF) NNs, a novel adaptive neural control (ANC) scheme is proposed to guarantee the predefined tracking error performance as well as the ultimate boundedness of all other closed-loop signals. In particular, only one NN is employed to approximate the lumped unknown system dynamics during the controller design. Under the satisfaction of the partial persistent excitation condition for RBF NNs, the proposed stable ANC scheme is shown to be capable of achieving knowledge acquisition, expression, and storage of unknown system dynamics. The stored knowledge is reused to develop a neural learning controller for improving the control performance of the closed-loop system. When the initial condition satisfies the predefined performance, the proposed neural learning control can still guarantee the predefined tracking performance. Simulation results on a third-order one-link robot are given to show the effectiveness of the proposed method.",4
Brain Dynamics in Predicting Driving Fatigue Using a Recurrent Self-Evolving Fuzzy Neural Network.,"This paper proposes a generalized prediction system called a recurrent self-evolving fuzzy neural network (RSEFNN) that employs an on-line gradient descent learning rule to address the electroencephalography (EEG) regression problem in brain dynamics for driving fatigue. The cognitive states of drivers significantly affect driving safety; in particular, fatigue driving, or drowsy driving, endangers both the individual and the public. For this reason, the development of brain-computer interfaces (BCIs) that can identify drowsy driving states is a crucial and urgent topic of study. Many EEG-based BCIs have been developed as artificial auxiliary systems for use in various practical applications because of the benefits of measuring EEG signals. In the literature, the efficacy of EEG-based BCIs in recognition tasks has been limited by low resolutions. The system proposed in this paper represents the first attempt to use the recurrent fuzzy neural network (RFNN) architecture to increase adaptability in realistic EEG applications to overcome this bottleneck. This paper further analyzes brain dynamics in a simulated car driving task in a virtual-reality environment. The proposed RSEFNN model is evaluated using the generalized cross-subject approach, and the results indicate that the RSEFNN is superior to competing models regardless of the use of recurrent or nonrecurrent structures.",4
Learning to Perceive the World as Probabilistic or Deterministic via Interaction With Others: A Neuro-Robotics Experiment.,"We suggest that different behavior generation schemes, such as sensory reflex behavior and intentional proactive behavior, can be developed by a newly proposed dynamic neural network model, named stochastic multiple timescale recurrent neural network (S-MTRNN). The model learns to predict subsequent sensory inputs, generating both their means and their uncertainty levels in terms of variance (or inverse precision) by utilizing its multiple timescale property. This model was employed in robotics learning experiments in which one robot controlled by the S-MTRNN was required to interact with another robot under the condition of uncertainty about the other's behavior. The experimental results show that self-organized and sensory reflex behavior-based on probabilistic prediction-emerges when learning proceeds without a precise specification of initial conditions. In contrast, intentional proactive behavior with deterministic predictions emerges when precise initial conditions are available. The results also showed that, in situations where unanticipated behavior of the other robot was perceived, the behavioral context was revised adequately by adaptation of the internal neural dynamics to respond to sensory inputs during sensory reflex behavior generation. On the other hand, during intentional proactive behavior generation, an error regression scheme by which the internal neural activity was modified in the direction of minimizing prediction errors was needed for adequately revising the behavioral context. These results indicate that two different ways of treating uncertainty about perceptual events in learning, namely, probabilistic modeling and deterministic modeling, contribute to the development of different dynamic neuronal structures governing the two types of behavior generation schemes.",4
Pinning Synchronization of Directed Networks With Switching Topologies: A Multiple Lyapunov Functions Approach.,"This paper studies the global pinning synchronization problem for a class of complex networks with switching directed topologies. The common assumption in the existing related literature that each possible network topology contains a directed spanning tree is removed in this paper. Using tools from M -matrix theory and stability analysis of the switched nonlinear systems, a new kind of network topology-dependent multiple Lyapunov functions is proposed for analyzing the synchronization behavior of the whole network. It is theoretically shown that the global pinning synchronization in switched complex networks can be ensured if some nodes are appropriately pinned and the coupling is carefully selected. Interesting issues of how many and which nodes should be pinned for possibly realizing global synchronization are further addressed. Finally, some numerical simulations on coupled neural networks are provided to verify the theoretical results.",4
Supervised Learning Using Spike-Timing-Dependent Plasticity of Memristive Synapses.,"We propose a supervised learning model that enables error backpropagation for spiking neural network hardware. The method is modeled by modifying an existing model to suit the hardware implementation. An example of a network circuit for the model is also presented. In this circuit, a three-terminal ferroelectric memristor (3T-FeMEM), which is a field-effect transistor with a gate insulator composed of ferroelectric materials, is used as an electric synapse device to store the analog synaptic weight. Our model can be implemented by reflecting the network error to the write voltage of the 3T-FeMEMs and introducing a spike-timing-dependent learning function to the device. An XOR problem was successfully demonstrated as a benchmark learning by numerical simulations using the circuit properties to estimate the learning performance. In principle, the learning time per step of this supervised learning model and the circuit is independent of the number of neurons in each layer, promising a high-speed and low-power calculation in large-scale neural networks.",4
Organizing Books and Authors by Multilayer SOM.,"This paper introduces a new framework for the organization of electronic books (e-books) and their corresponding authors using a multilayer self-organizing map (MLSOM). An author is modeled by a rich tree-structured representation, and an MLSOM-based system is used as an efficient solution to the organizational problem of structured data. The tree-structured representation formulates author features in a hierarchy of author biography, books, pages, and paragraphs. To efficiently tackle the tree-structured representation, we used an MLSOM algorithm that serves as a clustering technique to handle e-books and their corresponding authors. A book and author recommender system is then implemented using the proposed framework. The effectiveness of our approach was examined in a large-scale data set containing 3868 authors along with the 10500 e-books that they wrote. We also provided visualization results of MLSOM for revealing the relevance patterns hidden from presented author clusters. The experimental results corroborate that the proposed method outperforms other content-based models (e.g., rate adapting poisson, latent Dirichlet allocation, probabilistic latent semantic indexing, and so on) and offers a promising solution to book recommendation, author recommendation, and visualization.",4
Sequential Compact Code Learning for Unsupervised Image Hashing.,"Effective hashing for large-scale image databases is a popular research area, attracting much attention in computer vision and visual information retrieval. Several recent methods attempt to learn either graph embedding or semantic coding for fast and accurate applications. In this paper, a novel unsupervised framework, termed evolutionary compact embedding (ECE), is introduced to automatically learn the task-specific binary hash codes. It can be regarded as an optimization algorithm that combines the genetic programming (GP) and a boosting trick. In our architecture, each bit of ECE is iteratively computed using a weak binary classification function, which is generated through GP evolving by jointly minimizing its empirical risk with the AdaBoost strategy on a training set. We address this as greedy optimization by embedding high-dimensional data points into a similarity-preserved Hamming space with a low dimension. We systematically evaluate ECE on two data sets, SIFT 1M and GIST 1M, showing the effectiveness and the accuracy of our method for a large-scale similarity search.",4
Cosaliency Detection Based on Intrasaliency Prior Transfer and Deep Intersaliency Mining.,"As an interesting and emerging topic, cosaliency detection aims at simultaneously extracting common salient objects in multiple related images. It differs from the conventional saliency detection paradigm in which saliency detection for each image is determined one by one independently without taking advantage of the homogeneity in the data pool of multiple related images. In this paper, we propose a novel cosaliency detection approach using deep learning models. Two new concepts, called intrasaliency prior transfer and deep intersaliency mining, are introduced and explored in the proposed work. For the intrasaliency prior transfer, we build a stacked denoising autoencoder (SDAE) to learn the saliency prior knowledge from auxiliary annotated data sets and then transfer the learned knowledge to estimate the intrasaliency for each image in cosaliency data sets. For the deep intersaliency mining, we formulate it by using the deep reconstruction residual obtained in the highest hidden layer of a self-trained SDAE. The obtained deep intersaliency can extract more intrinsic and general hidden patterns to discover the homogeneity of cosalient objects in terms of some higher level concepts. Finally, the cosaliency maps are generated by weighted integration of the proposed intrasaliency prior, deep intersaliency, and traditional shallow intersaliency. Comprehensive experiments over diverse publicly available benchmark data sets demonstrate consistent performance gains of the proposed method over the state-of-the-art cosaliency detection methods.",4
Enhanced Logical Stochastic Resonance in Synthetic Genetic Networks.,"In this brief, the concept of logical stochastic resonance is applied to implement the Set-Reset latch in a synthetic gene network derived from a bacteriophage lambda . Clear Set-Reset latch operation is obtained when the network is only subjected to periodic forcing. The correct probability of obtaining the desired logic operation first increases to unity and then decreases as the amplitude of the periodic forcing increases. In addition, the output logic operation can be easily morphed by tuning the frequency and the amplitude of the periodic forcing. At the same time, we indicate that adding moderate periodic forcing to the background Gaussian noise may increase the length of the optimal plateau of getting the desired logic operation in genetic regulatory network. We also point out that robust Set-Reset latch operation can be obtained using the interplay of periodic forcing and background noise when the noise strength is lower than what is required.",4
Human-Centered Saliency Detection.,"We introduce a new concept for detecting the saliency of 3-D shapes, that is, human-centered saliency (HCS) detection on the surface of shapes, whereby a given shape is analyzed not based on geometric or topological features directly obtained from the shape itself, but by studying how a human uses the object. Using virtual agents to simulate the ways in which humans interact with objects helps to understand shapes and detect their salient parts in relation to their functions. HCS detection is less affected by inconsistencies between the geometry or topology of the analyzed 3-D shapes. The potential benefit of the proposed method is that it is adaptable to variable shapes with the same semantics, as well as being robust against a geometrical and topological noise. Given a 3-D shape, its salient part is detected by automatically selecting a corresponding agent and making them interact with each other. Their adaption and alignment depend on an optimization framework and a training process. We demonstrate the detected salient parts for different types of objects together with the stability thereof. The salient parts can be used for important vision tasks, such as 3-D shape retrieval.",4
A Theoretical Foundation of Goal Representation Heuristic Dynamic Programming.,"Goal representation heuristic dynamic programming (GrHDP) control design has been developed in recent years. The control performance of this design has been demonstrated in several case studies, and also showed applicable to industrial-scale complex control problems. In this paper, we develop the theoretical analysis for the GrHDP design under certain conditions. It has been shown that the internal reinforcement signal is a bounded signal and the performance index can converge to its optimal value monotonically. The existence of the admissible control is also proved. Although the GrHDP control method has been investigated in many areas before, to the best of our knowledge, this is the first study of presenting the theoretical foundation of the internal reinforcement signal and how such an internal reinforcement signal can provide effective information to improve the control performance. Numerous simulation studies are used to validate the theoretical analysis and also demonstrate the effectiveness of the GrHDP design.",4
Is a Complex-Valued Stepsize Advantageous in Complex-Valued Gradient Learning Algorithms?,"Complex gradient methods have been widely used in learning theory, and typically aim to optimize real-valued functions of complex variables. The stepsize of complex gradient learning methods (CGLMs) is a positive number, and little is known about how a complex stepsize would affect the learning process. To this end, we undertake a comprehensive analysis of CGLMs with a complex stepsize, including the search space, convergence properties, and the dynamics near critical points. Furthermore, several adaptive stepsizes are derived by extending the Barzilai-Borwein method to the complex domain, in order to show that the complex stepsize is superior to the corresponding real one in approximating the information in the Hessian. A numerical example is presented to support the analysis.",4
Data-Driven Modeling for UGI Gasification Processes via an Enhanced Genetic BP Neural Network With Link Switches.,"In this brief, an enhanced genetic back-propagation neural network with link switches (EGA-BPNN-LS) is proposed to address a data-driven modeling problem for gasification processes inside United Gas Improvement (UGI) gasifiers. The online-measured temperature of crude gas produced during the gasification processes plays a dominant role in the syngas industry; however, it is difficult to model temperature dynamics via first principles due to the practical complexity of the gasification process, especially as reflected by severe changes in the gas temperature resulting from infrequent manipulations of the gasifier in practice. The proposed data-driven modeling approach, EGA-BPNN-LS, incorporates an NN-LS, an EGA, and the Levenberg-Marquardt (LM) algorithm. The approach cannot only learn the relationships between the control input and the system output from historical data using an optimized network structure through a combination of EGA and NN-LS but also makes use of the networks gradient information via the LM algorithm. EGA-BPNN-LS is applied to a set of data collected from the field to model the UGI gasification processes, and the effectiveness of EGA-BPNN-LS is verified.",4
Finite-Time State Estimation for Coupled Markovian Neural Networks With Sensor Nonlinearities.,"This paper investigates the issue of finite-time state estimation for coupled Markovian neural networks subject to sensor nonlinearities, where the Markov chain with partially unknown transition probabilities is considered. A Luenberger-type state estimator is proposed based on incomplete measurements, and the estimation error system is derived by using the Kronecker product. By using the Lyapunov method, sufficient conditions are established, which guarantee that the estimation error system is stochastically finite-time bounded and stochastically finite-time stable, respectively. Then, the estimator gains are obtained via solving a set of coupled linear matrix inequalities. Finally, a numerical example is given to illustrate the effectiveness of the proposed new design method.",4
Adaptive Filter Design Using Type-2 Fuzzy Cerebellar Model Articulation Controller.,"This paper aims to propose an efficient network and applies it as an adaptive filter for the signal processing problems. An adaptive filter is proposed using a novel interval type-2 fuzzy cerebellar model articulation controller (T2FCMAC). The T2FCMAC realizes an interval type-2 fuzzy logic system based on the structure of the CMAC. Due to the better ability of handling uncertainties, type-2 fuzzy sets can solve some complicated problems with outstanding effectiveness than type-1 fuzzy sets. In addition, the Lyapunov function is utilized to derive the conditions of the adaptive learning rates, so that the convergence of the filtering error can be guaranteed. In order to demonstrate the performance of the proposed adaptive T2FCMAC filter, it is tested in signal processing applications, including a nonlinear channel equalization system, a time-varying channel equalization system, and an adaptive noise cancellation system. The advantages of the proposed filter over the other adaptive filters are verified through simulations.",4
A Unified Framework for Representation-Based Subspace Clustering of Out-of-Sample and Large-Scale Data.,"Under the framework of spectral clustering, the key of subspace clustering is building a similarity graph, which describes the neighborhood relations among data points. Some recent works build the graph using sparse, low-rank, and l2 -norm-based representation, and have achieved the state-of-the-art performance. However, these methods have suffered from the following two limitations. First, the time complexities of these methods are at least proportional to the cube of the data size, which make those methods inefficient for solving the large-scale problems. Second, they cannot cope with the out-of-sample data that are not used to construct the similarity graph. To cluster each out-of-sample datum, the methods have to recalculate the similarity graph and the cluster membership of the whole data set. In this paper, we propose a unified framework that makes the representation-based subspace clustering algorithms feasible to cluster both the out-of-sample and the large-scale data. Under our framework, the large-scale problem is tackled by converting it as the out-of-sample problem in the manner of sampling, clustering, coding, and classifying. Furthermore, we give an estimation for the error bounds by treating each subspace as a point in a hyperspace. Extensive experimental results on various benchmark data sets show that our methods outperform several recently proposed scalable methods in clustering a large-scale data set.",4
LQR-Based Optimal Distributed Cooperative Design for Linear Discrete-Time Multiagent Systems.,"In this paper, a novel linear quadratic regulator (LQR)-based optimal distributed cooperative design method is developed for synchronization control of general linear discrete-time multiagent systems on a fixed, directed graph. Sufficient conditions are derived for synchronization, which restrict the graph eigenvalues into a bounded circular region in the complex plane. The synchronizing speed issue is also considered, and it turns out that the synchronizing region reduces as the synchronizing speed becomes faster. To obtain more desirable synchronizing capacity, the weighting matrices are selected by sufficiently utilizing the guaranteed gain margin of the optimal regulators. Based on the developed LQR-based cooperative design framework, an approximate dynamic programming technique is successfully introduced to overcome the (partially or completely) model-free cooperative design for linear multiagent systems. Finally, two numerical examples are given to illustrate the effectiveness of the proposed design methods.",4
Cooperative Strategy for Optimal Management of Smart Grids by Wavelet RNNs and Cloud Computing.,"Advanced smart grids have several power sources that contribute with their own irregular dynamic to the power production, while load nodes have another dynamic. Several factors have to be considered when using the owned power sources for satisfying the demand, i.e., production rate, battery charge and status, variable cost of externally bought energy, and so on. The objective of this paper is to develop appropriate neural network architectures that automatically and continuously govern power production and dispatch, in order to maximize the overall benefit over a long time. Such a control will improve the fundamental work of a smart grid. For this, status data of several components have to be gathered, and then an estimate of future power production and demand is needed. Hence, the neural network-driven forecasts are apt in this paper for renewable nonprogrammable energy sources. Then, the produced energy as well as the stored one can be supplied to consumers inside a smart grid, by means of digital technology. Among the sought benefits, reduced costs and increasing reliability and transparency are paramount.",4
Robust Adaptive Dynamic Programming of Two-Player Zero-Sum Games for Continuous-Time Linear Systems.,"In this brief, an online robust adaptive dynamic programming algorithm is proposed for two-player zero-sum games of continuous-time unknown linear systems with matched uncertainties, which are functions of system outputs and states of a completely unknown exosystem. The online algorithm is developed using the policy iteration (PI) scheme with only one iteration loop. A new analytical method is proposed for convergence proof of the PI scheme. The sufficient conditions are given to guarantee globally asymptotic stability and suboptimal property of the closed-loop system. Simulation studies are conducted to illustrate the effectiveness of the proposed method.",4
Stability of Analytic Neural Networks With Event-Triggered Synaptic Feedbacks.,"In this paper, we investigate stability of a class of analytic neural networks with the synaptic feedback via event-triggered rules. This model is general and include Hopfield neural network as a special case. These event-trigger rules can efficiently reduces loads of computation and information transmission at synapses of the neurons. The synaptic feedback of each neuron keeps a constant value based on the outputs of the other neurons at its latest triggering time but changes at its next triggering time, which is determined by a certain criterion. It is proved that every trajectory of the analytic neural network converges to certain equilibrium under this event-triggered rule for all the initial values except a set of zero measure. The main technique of the proof is the Lojasiewicz inequality to prove the finiteness of trajectory length. The realization of this event-triggered rule is verified by the exclusion of Zeno behaviors. Numerical examples are provided to illustrate the efficiency of the theoretical results.",4
Saliency-Aware Nonparametric Foreground Annotation Based on Weakly Labeled Data.,"In this paper, we focus on annotating the foreground of an image. More precisely, we predict both image-level labels (category labels) and object-level labels (locations) for objects within a target image in a unified framework. Traditional learning-based image annotation approaches are cumbersome, because they need to establish complex mathematical models and be frequently updated as the scale of training data varies considerably. Thus, we advocate the nonparametric method, which has shown potential in numerous applications and turned out to be attractive thanks to its advantages, i.e., lightweight training load and scalability. In particular, we exploit the salient object windows to describe images, which is beneficial to image retrieval and, thus, the subsequent image-level annotation and localization tasks. Our method, namely, saliency-aware nonparametric foreground annotation, is practical to alleviate the full label requirement of training data, and effectively addresses the problem of foreground annotation. The proposed method only relies on retrieval results from the image database, while pretrained object detectors are no longer necessary. Experimental results on the challenging PASCAL VOC 2007 and PASCAL VOC 2008 demonstrate the advance of our method.",4
Deep Learning of Part-Based Representation of Data Using Sparse Autoencoders With Nonnegativity Constraints.,"We demonstrate a new deep learning autoencoder network, trained by a nonnegativity constraint algorithm (nonnegativity-constrained autoencoder), that learns features that show part-based representation of data. The learning algorithm is based on constraining negative weights. The performance of the algorithm is assessed based on decomposing data into parts and its prediction performance is tested on three standard image data sets and one text data set. The results indicate that the nonnegativity constraint forces the autoencoder to learn features that amount to a part-based representation of data, while improving sparsity and reconstruction quality in comparison with the traditional sparse autoencoder and nonnegative matrix factorization. It is also shown that this newly acquired representation improves the prediction performance of a deep neural network.",4
Multiple Ordinal Regression by Maximizing the Sum of Margins.,"Human preferences are usually measured using ordinal variables. A system whose goal is to estimate the preferences of humans and their underlying decision mechanisms requires to learn the ordering of any given sample set. We consider the solution of this ordinal regression problem using a support vector machine algorithm. Specifically, the goal is to learn a set of classifiers with common direction vectors and different biases correctly separating the ordered classes. Current algorithms are either required to solve a quadratic optimization problem, which is computationally expensive, or based on maximizing the minimum margin (i.e., a fixed-margin strategy) between a set of hyperplanes, which biases the solution to the closest margin. Another drawback of these strategies is that they are limited to order the classes using a single ranking variable (e.g., perceived length). In this paper, we define a multiple ordinal regression algorithm based on maximizing the sum of the margins between every consecutive class with respect to one or more rankings (e.g., perceived length and weight). We provide derivations of an efficient, easy-to-implement iterative solution using a sequential minimal optimization procedure. We demonstrate the accuracy of our solutions in several data sets. In addition, we provide a key application of our algorithms in estimating human subjects' ordinal classification of attribute associations to object categories. We show that these ordinal associations perform better than the binary one typically employed in the literature.",4
Parameter as a Switch Between Dynamical States of a Network in Population Decoding.,"Population coding is a method to represent stimuli using the collective activities of a number of neurons. Nevertheless, it is difficult to extract information from these population codes with the noise inherent in neuronal responses. Moreover, it is a challenge to identify the right parameter of the decoding model, which plays a key role for convergence. To address the problem, a population decoding model is proposed for parameter selection. Our method successfully identified the key conditions for a nonzero continuous attractor. Both the theoretical analysis and the application studies demonstrate the correctness and effectiveness of this strategy.",4
L(1)-Minimization Algorithms for Sparse Signal Reconstruction Based on a Projection Neural Network.,"This paper presents several L1-minimization algorithms for sparse signal reconstruction based on a continuous-time projection neural network (PNN). First, a one-layer projection neural network is designed based on a projection operator and a projection matrix. The stability and global convergence of the proposed neural network are proved. Then, based on a discrete-time version of the PNN, several L1-minimization algorithms for sparse signal reconstruction are developed and analyzed. Experimental results based on random Gaussian sparse signals show the effectiveness and performance of the proposed algorithms. Moreover, experimental results based on two face image databases are presented that reveal the influence of sparsity to the recognition rate. The algorithms are shown to be robust to the amplitude and sparsity level of signals as well as efficient with high convergence rate compared with several existing L1-minimization algorithms.",4
Twin Neurons for Efficient Real-World Data Distribution in Networks of Neural Cliques: Applications in Power Management in Electronic Circuits.,"Associative memories are data structures that allow retrieval of previously stored messages given part of their content. They, thus, behave similarly to the human brain's memory that is capable, for instance, of retrieving the end of a song, given its beginning. Among different families of associative memories, sparse ones are known to provide the best efficiency (ratio of the number of bits stored to that of the bits used). Recently, a new family of sparse associative memories achieving almost optimal efficiency has been proposed. Their structure, relying on binary connections and neurons, induces a direct mapping between input messages and stored patterns. Nevertheless, it is well known that nonuniformity of the stored messages can lead to a dramatic decrease in performance. In this paper, we show the impact of nonuniformity on the performance of this recent model, and we exploit the structure of the model to improve its performance in practical applications, where data are not necessarily uniform. In order to approach the performance of networks with uniformly distributed messages presented in theoretical studies, twin neurons are introduced. To assess the adapted model, twin neurons are used with the real-world data to optimize power consumption of electronic circuits in practical test cases.",4
Adaptive Neural Network-Based Event-Triggered Control of Single-Input Single-Output Nonlinear Discrete-Time Systems.,"This paper presents a novel adaptive neural network (NN) control of single-input and single-output uncertain nonlinear discrete-time systems under event sampled NN inputs. In this control scheme, the feedback signals are transmitted, and the NN weights are tuned in an aperiodic manner at the event sampled instants. After reviewing the NN approximation property with event sampled inputs, an adaptive state estimator (SE), consisting of linearly parameterized NNs, is utilized to approximate the unknown system dynamics in an event sampled context. The SE is viewed as a model and its approximated dynamics and the state vector, during any two events, are utilized for the event-triggered controller design. An adaptive event-trigger condition is derived by using both the estimated NN weights and a dead-zone operator to determine the event sampling instants. This condition both facilitates the NN approximation and reduces the transmission of feedback signals. The ultimate boundedness of both the NN weight estimation error and the system state vector is demonstrated through the Lyapunov approach. As expected, during an initial online learning phase, events are observed more frequently. Over time with the convergence of the NN weights, the inter-event times increase, thereby lowering the number of triggered events. These claims are illustrated through the simulation results.",4
Kohonen's Map Approach for the Belief Mass Modeling.,"In the framework of the evidence theory, several approaches for estimating belief functions are proposed. However, they generally suffer from the problem of masses attribution in the case of compound hypotheses that lose much conceptual contribution of the theory. In this paper, an original method for estimating mass functions using Kohonen's map derived from the initial feature space and an initial classifier is proposed. Our approach allows a smart mass belief assignment, not only for simple hypotheses but also for disjunctions and conjunctions of hypotheses. Thus, it can model at the same time ignorance, imprecision, and paradox. The proposed method for a basic belief assignment (BBA) is of interest for solving estimation mass functions problems where a large quantity of multivariate data is available. Indeed, the use of Kohonen's map simplifies the process of assigning mass functions. The proposed method has been compared with the state-of-the-art BBA technique on benchmark database and applied on remote sensing data for image classification purpose. Experimentation shows that our approach gives similar or better results than other methods presented in the literature so far, with an ability to handle a large amount of data.",4
Exponential Synchronization of Coupled Stochastic Memristor-Based Neural Networks With Time-Varying Probabilistic Delay Coupling and Impulsive Delay.,"This paper deals with the exponential synchronization of coupled stochastic memristor-based neural networks with probabilistic time-varying delay coupling and time-varying impulsive delay. There is one probabilistic transmittal delay in the delayed coupling that is translated by a Bernoulli stochastic variable satisfying a conditional probability distribution. The disturbance is described by a Wiener process. Based on Lyapunov functions, Halanay inequality, and linear matrix inequalities, sufficient conditions that depend on the probability distribution of the delay coupling and the impulsive delay were obtained. Numerical simulations are used to show the effectiveness of the theoretical results.",4
Improved Learning Performance of Hardware Self-Organizing Map Using a Novel Neighborhood Function.,"Many self-organizing maps (SOMs) implemented on hardware restrict their neighborhood function values to negative powers of two. In this paper, we propose a novel hardware friendly neighborhood function that is aimed to improve the vector quantization performance of hardware SOM. The quantization performance of the hardware SOM with the proposed neighborhood function is examined by simulations. Simulation results show that the proposed function can improve the hardware SOM's vector quantization capability even though the function value is restricted to negative powers of two. Then, the hardware SOM is implemented on field-programmable gate array to find out the hardware cost and performance speed of the proposed neighborhood function. Experimental results show that the proposed neighborhood function can improve SOM's quantization performance without additional hardware cost or slowing down the operating speed. Due to fully parallel operation, the proposed SOM with 16x16 neurons achieves a performance of 25 344 million connections updates per second.",4
Zeroth-Order Method for Distributed Optimization With Approximate Projections.,"This paper studies the problem of minimizing a sum of (possible nonsmooth) convex functions that are corresponding to multiple interacting nodes, subject to a convex state constraint set. Time-varying directed network is considered here. Two types of computational constraints are investigated in this paper: one where the information of gradients is not available and the other where the projection steps can only be calculated approximately. We devise a distributed zeroth-order method, the implementation of which needs only functional evaluations and approximate projection. In particular, we show that the proposed method generates expected function value sequences that converge to the optimal value, provided that the projection errors decrease at appropriate rates.",4
Lag Synchronization of Memristor-Based Coupled Neural Networks via omega-Measure.,"This paper deals with the lag synchronization problem of memristor-based coupled neural networks with or without parameter mismatch using two different algorithms. Firstly, we consider the memristor-based neural networks with parameter mismatch, lag complete synchronization cannot be achieved due to parameter mismatch, the concept of lag quasi-synchronization is introduced. Based on the omega-measure method and generalized Halanay inequality, the error level is estimated, a new lag quasi-synchronization scheme is proposed to ensure that coupled memristor-based neural networks are in a state of lag synchronization with an error level. Secondly, by constructing Lyapunov functional and applying common Halanary inequality, several lag complete synchronization criteria for the memristor-based neural networks with parameter match are given, which are easy to verify. Finally, two examples are given to illustrate the effectiveness of the proposed lag quasi-synchronization or lag complete synchronization criteria, which well support theoretical results.",4
Reconciling Saliency and Object Center-Bias Hypotheses in Explaining Free-Viewing Fixations.,"Predicting where people look in natural scenes has attracted a lot of interest in computer vision and computational neuroscience over the past two decades. Two seemingly contrasting categories of cues have been proposed to influence where people look: 1) low-level image saliency and 2) high-level semantic information. Our first contribution is to take a detailed look at these cues to confirm the hypothesis proposed by Henderson and Nuthmann and Henderson that observers tend to look at the center of objects. We analyzed fixation data for scene free-viewing over 17 observers on 60 object-annotated images with various types of objects. Images contained different types of scenes, such as natural scenes, line drawings, and 3-D rendered scenes. Our second contribution is to propose a simple combined model of low-level saliency and object center bias that outperforms each individual component significantly over our data, as well as on the Object and Semantic Images and Eye-tracking data set by Xu et al. The results reconcile saliency with object center-bias hypotheses and highlight that both types of cues are important in guiding fixations. Our work opens new directions to understand strategies that humans use in observing scenes and objects, and demonstrates the construction of combined models of low-level saliency and high-level object-based information.",4
MSDLSR: Margin Scalable Discriminative Least Squares Regression for Multicategory Classification.,"In this brief, we propose a new margin scalable discriminative least squares regression (MSDLSR) model for multicategory classification. The main motivation behind the MSDLSR is to explicitly control the margin of DLSR model. We first prove that the DLSR is a relaxation of the traditional L2 -support vector machine. Based on this fact, we further provide a theorem on the margin of DLSR. With this theorem, we add an explicit constraint on DLSR to restrict the number of zeros of dragging values, so as to control the margin of DLSR. The new model is called MSDLSR. Theoretically, we analyze the determination of the margin and support vectors of MSDLSR. Extensive experiments illustrate that our method outperforms the current state-of-the-art approaches on various machine leaning and real-world data sets.",4
Space Structure and Clustering of Categorical Data.,"Learning from categorical data plays a fundamental role in such areas as pattern recognition, machine learning, data mining, and knowledge discovery. To effectively discover the group structure inherent in a set of categorical objects, many categorical clustering algorithms have been developed in the literature, among which k -modes-type algorithms are very representative because of their good performance. Nevertheless, there is still much room for improving their clustering performance in comparison with the clustering algorithms for the numeric data. This may arise from the fact that the categorical data lack a clear space structure as that of the numeric data. To address this issue, we propose, in this paper, a novel data-representation scheme for the categorical data, which maps a set of categorical objects into a Euclidean space. Based on the data-representation scheme, a general framework for space structure based categorical clustering algorithms (SBC) is designed. This framework together with the applications of two kinds of dissimilarities leads two versions of the SBC-type algorithms. To verify the performance of the SBC-type algorithms, we employ as references four representative algorithms of the k -modes-type algorithms. Experiments show that the proposed SBC-type algorithms significantly outperform the k -modes-type algorithms.",4
Assessing Short-Term Voltage Stability of Electric Power Systems by a Hierarchical Intelligent System.,"In the smart grid paradigm, growing integration of large-scale intermittent renewable energies has introduced significant uncertainties to the operations of an electric power system. This makes real-time dynamic security assessment (DSA) a necessity to enable enhanced situational-awareness against the risk of blackouts. Conventional DSA methods are mainly based on the time-domain simulation, which are insufficiently fast and knowledge-poor. In recent years, the intelligent system (IS) strategy has been identified as a promising approach to facilitate real-time DSA. While previous works mainly concentrate on the rotor angle stability, this paper focuses on another yet increasingly important dynamic insecurity phenomenon-the short-term voltage instability, which involves fast and complex load dynamics. The problem is modeled as a classification subproblem for transient voltage collapse and a prediction subproblem for unacceptable dynamic voltage deviation. A hierarchical IS is developed to address the two subproblems sequentially. The IS is based on ensemble learning of random-weights neural networks and is implemented in an offline training, a real-time application, and an online updating pattern. The simulation results on the New England 39-bus system verify its superiority in both learning speed and accuracy over some state-of-the-art learning algorithms.",4
A New Continuous-Time Equality-Constrained Optimization to Avoid Singularity.,"In equality-constrained optimization, a standard regularity assumption is often associated with feasible point methods, namely, that the gradients of constraints are linearly independent. In practice, the regularity assumption may be violated. In order to avoid such a singularity, a new projection matrix is proposed based on which a feasible point method to continuous-time, equality-constrained optimization is developed. First, the equality constraint is transformed into a continuous-time dynamical system with solutions that always satisfy the equality constraint. Second, a new projection matrix without singularity is proposed to realize the transformation. An update (or say a controller) is subsequently designed to decrease the objective function along the solutions of the transformed continuous-time dynamical system. The invariance principle is then applied to analyze the behavior of the solution. Furthermore, the proposed method is modified to address cases in which solutions do not satisfy the equality constraint. Finally, the proposed optimization approach is applied to three examples to demonstrate its effectiveness.",4
Neuromorphic Artificial Touch for Categorization of Naturalistic Textures.,"We implemented neuromorphic artificial touch and emulated the firing behavior of mechanoreceptors by injecting the raw outputs of a biomimetic tactile sensor into an Izhikevich neuronal model. Naturalistic textures were evaluated with a passive touch protocol. The resulting neuromorphic spike trains were able to classify ten naturalistic textures ranging from textiles to glass to BioSkin, with accuracy as high as 97%. Remarkably, rather than on firing rate features calculated over the stimulation window, the highest achieved decoding performance was based on the precise spike timing of the neuromorphic output as captured by Victor Purpura distance. We also systematically varied the sliding velocity and the contact force to investigate the role of sensing conditions in categorizing the stimuli via the artificial sensory system. We found that the decoding performance based on the timing of neuromorphic spike events was robust for a broad range of sensing conditions. Being able to categorize naturalistic textures in different sensing conditions, these neurorobotic results pave the way to the use of neuromorphic tactile sensors in future real-life neuroprosthetic applications.",4
Convergence Rate for Discrete-Time Multiagent Systems With Time-Varying Delays and General Coupling Coefficients.,"Multiagent systems (MASs) are ubiquitous in our real world. There is an increasing attention focusing on the consensus (or synchronization) problem of MASs over the past decade. Although there are numerous results reported on the convergence of a discrete-time MAS based on the infinite products of matrices, few results are on the convergence rate. Because of the switching topology, the traditional eigenvalue analysis and the Lyapunov function methods are both invalid for the convergence rate analysis of an MAS with a switching topology. Therefore, the estimation of the convergence rate for a discrete-time MAS with time-varying delays remains a difficult problem. To overcome the essential difficulty of switching topology, this paper aims at developing a contractive-set approach to analyze the convergence rate of a discrete-time MAS in the presence of time-varying delays and generalized coupling coefficients. Using the proposed approach, we obtain an upper bound of the convergence rate under the condition of joint connectivity. In particular, the proposed method neither requires the nonnegative property of the coupling coefficients nor the basic assumption of a uniform lower bound for all positive coupling coefficients, which have been widely applied in the existing works on this topic. As an application of the main results, we will show that the classical Vicsek model with time delays can realize synchronization if the initial topology is connected.",4
Adaptive Actor-Critic Design-Based Integral Sliding-Mode Control for Partially Unknown Nonlinear Systems With Input Disturbances.,"This paper is concerned with the problem of integral sliding-mode control for a class of nonlinear systems with input disturbances and unknown nonlinear terms through the adaptive actor-critic (AC) control method. The main objective is to design a sliding-mode control methodology based on the adaptive dynamic programming (ADP) method, so that the closed-loop system with time-varying disturbances is stable and the nearly optimal performance of the sliding-mode dynamics can be guaranteed. In the first step, a neural network (NN)-based observer and a disturbance observer are designed to approximate the unknown nonlinear terms and estimate the input disturbances, respectively. Based on the NN approximations and disturbance estimations, the discontinuous part of the sliding-mode control is constructed to eliminate the effect of the disturbances and attain the expected equivalent sliding-mode dynamics. Then, the ADP method with AC structure is presented to learn the optimal control for the sliding-mode dynamics online. Reconstructed tuning laws are developed to guarantee the stability of the sliding-mode dynamics and the convergence of the weights of critic and actor NNs. Finally, the simulation results are presented to illustrate the effectiveness of the proposed method.",4
Similarity Constraints-Based Structured Output Regression Machine: An Approach to Image Super-Resolution.,"For regression-based single-image super-resolution (SR) problem, the key is to establish a mapping relation between high-resolution (HR) and low-resolution (LR) image patches for obtaining a visually pleasing quality image. Most existing approaches typically solve it by dividing the model into several single-output regression problems, which obviously ignores the circumstance that a pixel within an HR patch affects other spatially adjacent pixels during the training process, and thus tends to generate serious ringing artifacts in resultant HR image as well as increase computational burden. To alleviate these problems, we propose to use structured output regression machine (SORM) to simultaneously model the inherent spatial relations between the HR and LR patches, which is propitious to preserve sharp edges. In addition, to further improve the quality of reconstructed HR images, a nonlocal (NL) self-similarity prior in natural images is introduced to formulate as a regularization term to further enhance the SORM-based SR results. To offer a computation-effective SORM method, we use a relative small nonsupport vector samples to establish the accurate regression model and an accelerating algorithm for NL self-similarity calculation. Extensive SR experiments on various images indicate that the proposed method can achieve more promising performance than the other state-of-the-art SR methods in terms of both visual quality and computational cost.",4
Neurodynamics-Based Robust Pole Assignment for High-Order Descriptor Systems.,"In this paper, a neurodynamic optimization approach is proposed for synthesizing high-order descriptor linear systems with state feedback control via robust pole assignment. With a new robustness measure serving as the objective function, the robust eigenstructure assignment problem is formulated as a pseudoconvex optimization problem. A neurodynamic optimization approach is applied and shown to be capable of maximizing the robust stability margin for high-order singular systems with guaranteed optimality and exact pole assignment. Two numerical examples and vehicle vibration control application are discussed to substantiate the efficacy of the proposed approach.",4
A Unified Approach to Adaptive Neural Control for Nonlinear Discrete-Time Systems With Nonlinear Dead-Zone Input.,"In this paper, an effective adaptive control approach is constructed to stabilize a class of nonlinear discrete-time systems, which contain unknown functions, unknown dead-zone input, and unknown control direction. Different from linear dead zone, the dead zone, in this paper, is a kind of nonlinear dead zone. To overcome the noncausal problem, which leads to the control scheme infeasible, the systems can be transformed into a m -step-ahead predictor. Due to nonlinear dead-zone appearance, the transformed predictor still contains the nonaffine function. In addition, it is assumed that the gain function of dead-zone input and the control direction are unknown. These conditions bring about the difficulties and the complicacy in the controller design. Thus, the implicit function theorem is applied to deal with nonaffine dead-zone appearance, the problem caused by the unknown control direction can be resolved through applying the discrete Nussbaum gain, and the neural networks are used to approximate the unknown function. Based on the Lyapunov theory, all the signals of the resulting closed-loop system are proved to be semiglobal uniformly ultimately bounded. Moreover, the tracking error is proved to be regulated to a small neighborhood around zero. The feasibility of the proposed approach is demonstrated by a simulation example.",4
Adaptive Portfolio Optimization for Multiple Electricity Markets Participation.,"The increase of distributed energy resources, mainly based on renewable sources, requires new solutions that are able to deal with this type of resources' particular characteristics (namely, the renewable energy sources intermittent nature). The smart grid concept is increasing its consensus as the most suitable solution to facilitate the small players' participation in electric power negotiations while improving energy efficiency. The opportunity for players' participation in multiple energy negotiation environments (smart grid negotiation in addition to the already implemented market types, such as day-ahead spot markets, balancing markets, intraday negotiations, bilateral contracts, forward and futures negotiations, and among other) requires players to take suitable decisions on whether to, and how to participate in each market type. This paper proposes a portfolio optimization methodology, which provides the best investment profile for a market player, considering different market opportunities. The amount of power that each supported player should negotiate in each available market type in order to maximize its profits, considers the prices that are expected to be achieved in each market, in different contexts. The price forecasts are performed using artificial neural networks, providing a specific database with the expected prices in the different market types, at each time. This database is then used as input by an evolutionary particle swarm optimization process, which originates the most advantage participation portfolio for the market player. The proposed approach is tested and validated with simulations performed in multiagent simulator of competitive electricity markets, using real electricity markets data from the Iberian operator-MIBEL.",4
Robust Integral of Neural Network and Error Sign Control of MIMO Nonlinear Systems.,"This paper presents a novel state-feedback control scheme for the tracking control of a class of multi-input multioutput continuous-time nonlinear systems with unknown dynamics and bounded disturbances. First, the control law consisting of the robust integral of a neural network (NN) output plus sign of the tracking error feedback multiplied with an adaptive gain is introduced. The NN in the control law learns the system dynamics in an online manner, while the NN residual reconstruction errors and the bounded disturbances are overcome by the error sign signal. Since both of the NN output and the error sign signal are included in the integral, the continuity of the control input is ensured. The controller structure and the NN weight update law are novel in contrast with the previous effort, and the semiglobal asymptotic tracking performance is still guaranteed by using the Lyapunov analysis. In addition, the NN weights and all other signals are proved to be bounded simultaneously. The proposed approach also relaxes the need for the upper bounds of certain terms, which are usually required in the previous designs. Finally, the theoretical results are substantiated with simulations.",4
A Multiobjective Sparse Feature Learning Model for Deep Neural Networks.,"Hierarchical deep neural networks are currently popular learning models for imitating the hierarchical architecture of human brain. Single-layer feature extractors are the bricks to build deep networks. Sparse feature learning models are popular models that can learn useful representations. But most of those models need a user-defined constant to control the sparsity of representations. In this paper, we propose a multiobjective sparse feature learning model based on the autoencoder. The parameters of the model are learnt by optimizing two objectives, reconstruction error and the sparsity of hidden units simultaneously to find a reasonable compromise between them automatically. We design a multiobjective induced learning procedure for this model based on a multiobjective evolutionary algorithm. In the experiments, we demonstrate that the learning procedure is effective, and the proposed multiobjective model can learn useful sparse features.",4
Neural-Dynamic-Method-Based Dual-Arm CMG Scheme With Time-Varying Constraints Applied to Humanoid Robots.,"We propose a dual-arm cyclic-motion-generation (DACMG) scheme by a neural-dynamic method, which can remedy the joint-angle-drift phenomenon of a humanoid robot. In particular, according to a neural-dynamic design method, first, a cyclic-motion performance index is exploited and applied. This cyclic-motion performance index is then integrated into a quadratic programming (QP)-type scheme with time-varying constraints, called the time-varying-constrained DACMG (TVC-DACMG) scheme. The scheme includes the kinematic motion equations of two arms and the time-varying joint limits. The scheme can not only generate the cyclic motion of two arms for a humanoid robot but also control the arms to move to the desired position. In addition, the scheme considers the physical limit avoidance. To solve the QP problem, a recurrent neural network is presented and used to obtain the optimal solutions. Computer simulations and physical experiments demonstrate the effectiveness and the accuracy of such a TVC-DACMG scheme and the neural network solver.",4
Classifying Stress From Heart Rate Variability Using Salivary Biomarkers as Reference.,"An accurate and noninvasive stress assessment from human physiology is a strenuous task. In this paper, a pattern recognition system to learn complex correlates between heart rate variability (HRV) features and salivary stress biomarkers is proposed. Using the Trier social stress test, heart rate and salivary measurements were obtained from volunteers under varying levels of stress induction. Measurements of salivary alpha-amylase and cortisol were used as objective measures of stress, and were correlated with the HRV features using fuzzy ARTMAP (FAM). In improving the predictive ability of the ARTMAPs, techniques, such as genetic algorithms for parameter optimization and voting ensembles, were employed. The ensemble of FAMs can be used for predicting stress responses of salivary alpha-amylase or cortisol using heart rate measurements as the input. Using alpha-amylase as the stress indicator, the ensemble was able to classify stress from heart rate features with 75% accuracy, and 80% accuracy when cortisol was used.",4
Geometric Bioinspired Networks for Recognition of 2-D and 3-D Low-Level Structures and Transformations.,"This paper presents the design of radial basis function geometric bioinspired networks and their applications. Until now, the design of neural networks has been inspired by the biological models of neural networks but mostly using vector calculus and linear algebra. However, these designs have never shown the role of geometric computing. The question is how biological neural networks handle complex geometric representations involving Lie group operations like rotations. Even though the actual artificial neural networks are biologically inspired, they are just models which cannot reproduce a plausible biological process. Until now researchers have not shown how, using these models, one can incorporate them into the processing of geometric computing. Here, for the first time in the artificial neural networks domain, we address this issue by designing a kind of geometric RBF using the geometric algebra framework. As a result, using our artificial networks, we show how geometric computing can be carried out by the artificial neural networks. Such geometric neural networks have a great potential in robot vision. This is the most important aspect of this contribution to propose artificial geometric neural networks for challenging tasks in perception and action. In our experimental analysis, we show the applicability of our geometric designs, and present interesting experiments using 2-D data of real images and 3-D screw axis data. In general, our models should be used to process different types of inputs, such as visual cues, touch (texture, elasticity, temperature), taste, and sound. One important task of a perception-action system is to fuse a variety of cues coming from the environment and relate them via a sensor-motor manifold with motor modules to carry out diverse reasoned actions.",4
Asymptotic Stability of a Class of Neutral Delay Neuron System in a Critical Case.,"In this brief, the asymptotic stability properties of a neutral delay neuron system are studied mainly in a critical case when the exponential stability is not possible. If a critical value of the coefficient in the neutral delay neuron system is considered, then the difficulty for our investigation is caused by the fact that the spectrum of the linear operator is asymptotically approximated to the imaginary axis. It is obvious that, in such a case, the equation is not exponentially stable, and one needs more subtle methods in order to characterize this type of asymptotic stability. Hence, first, the local asymptotic stability for the neutral delay neuron system is studied, and the main tools involved are the asymptotic expansions of characteristic roots, Laplace transforms, and function series, and a complete analysis of the stability diagram is also presented. Then, based on the energy method, the globally asymptotic stability results for the neutral delay neuron system are derived.",4
Multicriteria Similarity-Based Anomaly Detection Using Pareto Depth Analysis.,"We consider the problem of identifying patterns in a data set that exhibits anomalous behavior, often referred to as anomaly detection. Similarity-based anomaly detection algorithms detect abnormally large amounts of similarity or dissimilarity, e.g., as measured by the nearest neighbor Euclidean distances between a test sample and the training samples. In many application domains, there may not exist a single dissimilarity measure that captures all possible anomalous patterns. In such cases, multiple dissimilarity measures can be defined, including nonmetric measures, and one can test for anomalies by scalarizing using a nonnegative linear combination of them. If the relative importance of the different dissimilarity measures are not known in advance, as in many anomaly detection applications, the anomaly detection algorithm may need to be executed multiple times with different choices of weights in the linear combination. In this paper, we propose a method for similarity-based anomaly detection using a novel multicriteria dissimilarity measure, the Pareto depth. The proposed Pareto depth analysis (PDA) anomaly detection algorithm uses the concept of Pareto optimality to detect anomalies under multiple criteria without having to run an algorithm multiple times with different choices of weights. The proposed PDA approach is provably better than using linear combinations of the criteria, and shows superior performance on experiments with synthetic and real data sets.",4
A Neurodynamic Approach for Real-Time Scheduling via Maximizing Piecewise Linear Utility.,"In this paper, we study a set of real-time scheduling problems whose objectives can be expressed as piecewise linear utility functions. This model has very wide applications in scheduling-related problems, such as mixed criticality, response time minimization, and tardiness analysis. Approximation schemes and matrix vectorization techniques are applied to transform scheduling problems into linear constraint optimization with a piecewise linear and concave objective; thus, a neural network-based optimization method can be adopted to solve such scheduling problems efficiently. This neural network model has a parallel structure, and can also be implemented on circuits, on which the converging time can be significantly limited to meet real-time requirements. Examples are provided to illustrate how to solve the optimization problem and to form a schedule. An approximation ratio bound of 0.5 is further provided. Experimental studies on a large number of randomly generated sets suggest that our algorithm is optimal when the set is nonoverloaded, and outperforms existing typical scheduling strategies when there is overload. Moreover, the number of steps for finding an approximate solution remains at the same level when the size of the problem (number of jobs within a set) increases.",4
Nonlinear Model Predictive Control Based on a Self-Organizing Recurrent Neural Network.,"A nonlinear model predictive control (NMPC) scheme is developed in this paper based on a self-organizing recurrent radial basis function (SR-RBF) neural network, whose structure and parameters are adjusted concurrently in the training process. The proposed SR-RBF neural network is represented in a general nonlinear form for predicting the future dynamic behaviors of nonlinear systems. To improve the modeling accuracy, a spiking-based growing and pruning algorithm and an adaptive learning algorithm are developed to tune the structure and parameters of the SR-RBF neural network, respectively. Meanwhile, for the control problem, an improved gradient method is utilized for the solution of the optimization problem in NMPC. The stability of the resulting control system is proved based on the Lyapunov stability theory. Finally, the proposed SR-RBF neural network-based NMPC (SR-RBF-NMPC) is used to control the dissolved oxygen (DO) concentration in a wastewater treatment process (WWTP). Comparisons with other existing methods demonstrate that the SR-RBF-NMPC can achieve a considerably better model fitting for WWTP and a better control performance for DO concentration.",4
Spatiochromatic Context Modeling for Color Saliency Analysis.,"Visual saliency is one of the most noteworthy perceptual abilities of human vision. Recent progress in cognitive psychology suggests that: 1) visual saliency analysis is mainly completed by the bottom-up mechanism consisting of feedforward low-level processing in primary visual cortex (area V1) and 2) color interacts with spatial cues and is influenced by the neighborhood context, and thus it plays an important role in a visual saliency analysis. From a computational perspective, the most existing saliency modeling approaches exploit multiple independent visual cues, irrespective of their interactions (or are not computed explicitly), and ignore contextual influences induced by neighboring colors. In addition, the use of color is often underestimated in the visual saliency analysis. In this paper, we propose a simple yet effective color saliency model that considers color as the only visual cue and mimics the color processing in V1. Our approach uses region-/boundary-defined color features with spatiochromatic filtering by considering local color-orientation interactions, therefore captures homogeneous color elements, subtle textures within the object and the overall salient object from the color image. To account for color contextual influences, we present a divisive normalization method for chromatic stimuli through the pooling of contrary/complementary color units. We further define a color perceptual metric over the entire scene to produce saliency maps for color regions and color boundaries individually. These maps are finally globally integrated into a one single saliency map. The final saliency map is produced by Gaussian blurring for robustness. We evaluate the proposed method on both synthetic stimuli and several benchmark saliency data sets from the visual saliency analysis to salient object detection. The experimental results demonstrate that the use of color as a unique visual cue achieves competitive results on par with or better than 12 state-of-the-art approaches.",4
Optimal Formation of Multirobot Systems Based on a Recurrent Neural Network.,"The optimal formation problem of multirobot systems is solved by a recurrent neural network in this paper. The desired formation is described by the shape theory. This theory can generate a set of feasible formations that share the same relative relation among robots. An optimal formation means that finding one formation from the feasible formation set, which has the minimum distance to the initial formation of the multirobot system. Then, the formation problem is transformed into an optimization problem. In addition, the orientation, scale, and admissible range of the formation can also be considered as the constraints in the optimization problem. Furthermore, if all robots are identical, their positions in the system are exchangeable. Then, each robot does not necessarily move to one specific position in the formation. In this case, the optimal formation problem becomes a combinational optimization problem, whose optimal solution is very hard to obtain. Inspired by the penalty method, this combinational optimization problem can be approximately transformed into a convex optimization problem. Due to the involvement of the Euclidean norm in the distance, the objective function of these optimization problems are nonsmooth. To solve these nonsmooth optimization problems efficiently, a recurrent neural network approach is employed, owing to its parallel computation ability. Finally, some simulations and experiments are given to validate the effectiveness and efficiency of the proposed optimal formation approach.",4
Feature Combination and the kNN Framework in Object Classification.,"In object classification, feature combination can usually be used to combine the strength of multiple complementary features and produce better classification results than any single one. While multiple kernel learning (MKL) is a popular approach to feature combination in object classification, it does not always perform well in practical applications. On one hand, the optimization process in MKL usually involves a huge consumption of computation and memory space. On the other hand, in some cases, MKL is found to perform no better than the baseline combination methods. This observation motivates us to investigate the underlying mechanism of feature combination with average combination and weighted average combination. As a result, we empirically find that in average combination, it is better to use a sample of the most powerful features instead of all, whereas in one type of weighted average combination, the best classification accuracy comes from a nearly sparse combination. We integrate these observations into the k-nearest neighbors (kNNs) framework, based on which we further discuss some issues related to sparse solution and MKL. Finally, by making use of the kNN framework, we present a new weighted average combination method, which is shown to perform better than MKL in both accuracy and efficiency in experiments. We believe that the work in this paper is helpful in exploring the mechanism underlying feature combination.",4
Oversampling the Minority Class in the Feature Space.,"The imbalanced nature of some real-world data is one of the current challenges for machine learning researchers. One common approach oversamples the minority class through convex combination of its patterns. We explore the general idea of synthetic oversampling in the feature space induced by a kernel function (as opposed to input space). If the kernel function matches the underlying problem, the classes will be linearly separable and synthetically generated patterns will lie on the minority class region. Since the feature space is not directly accessible, we use the empirical feature space (EFS) (a Euclidean space isomorphic to the feature space) for oversampling purposes. The proposed method is framed in the context of support vector machines, where the imbalanced data sets can pose a serious hindrance. The idea is investigated in three scenarios: 1) oversampling in the full and reduced-rank EFSs; 2) a kernel learning technique maximizing the data class separation to study the influence of the feature space structure (implicitly defined by the kernel function); and 3) a unified framework for preferential oversampling that spans some of the previous approaches in the literature. We support our investigation with extensive experiments over 50 imbalanced data sets.",4
Feedback Controller Design for the Synchronization of Boolean Control Networks.,This brief investigates the partial and complete synchronization of two Boolean control networks (BCNs). Necessary and sufficient conditions for partial and complete synchronization are established by the algebraic representations of logical dynamics. An algorithm is obtained to construct the feedback controller that guarantees the synchronization of master and slave BCNs. Two biological examples are provided to illustrate the effectiveness of the obtained results.,4
Robust Low-Rank Tensor Recovery With Regularized Redescending M-Estimator.,"This paper addresses the robust low-rank tensor recovery problems. Tensor recovery aims at reconstructing a low-rank tensor from some linear measurements, which finds applications in image processing, pattern recognition, multitask learning, and so on. In real-world applications, data might be contaminated by sparse gross errors. However, the existing approaches may not be very robust to outliers. To resolve this problem, this paper proposes approaches based on the regularized redescending M-estimators, which have been introduced in robust statistics. The robustness of the proposed approaches is achieved by the regularized redescending M-estimators. However, the nonconvexity also leads to a computational difficulty. To handle this problem, we develop algorithms based on proximal and linearized block coordinate descent methods. By explicitly deriving the Lipschitz constant of the gradient of the data-fitting risk, the descent property of the algorithms is present. Moreover, we verify that the objective functions of the proposed approaches satisfy the Kurdyka-Lojasiewicz property, which establishes the global convergence of the algorithms. The numerical experiments on synthetic data as well as real data verify that our approaches are robust in the presence of outliers and still effective in the absence of outliers.",4
"A Derivative-Free Riemannian Powell's Method, Minimizing Hartley-Entropy-Based ICA Contrast.","Even though the Hartley-entropy-based contrast function guarantees an unmixing local minimum, the reported nonsmooth optimization techniques that minimize this nondifferentiable function encounter computational bottlenecks. Toward this, Powell's derivative-free optimization method has been extended to a Riemannian manifold, namely, oblique manifold, for the recovery of quasi-correlated sources by minimizing this contrast function. The proposed scheme has been demonstrated to converge faster than the related algorithms in the literature, besides the impressive source separation results in simulations involving synthetic sources having finite-support distributions and correlated images.",4
Data-Driven Zero-Sum Neuro-Optimal Control for a Class of Continuous-Time Unknown Nonlinear Systems With Disturbance Using ADP.,"This paper is concerned with a new data-driven zero-sum neuro-optimal control problem for continuous-time unknown nonlinear systems with disturbance. According to the input-output data of the nonlinear system, an effective recurrent neural network is introduced to reconstruct the dynamics of the nonlinear system. Considering the system disturbance as a control input, a two-player zero-sum optimal control problem is established. Adaptive dynamic programming (ADP) is developed to obtain the optimal control under the worst case of the disturbance. Three single-layer neural networks, including one critic and two action networks, are employed to approximate the performance index function, the optimal control law, and the disturbance, respectively, for facilitating the implementation of the ADP method. Convergence properties of the ADP method are developed to show that the system state will converge to a finite neighborhood of the equilibrium. The weight matrices of the critic and the two action networks are also convergent to finite neighborhoods of their optimal ones. Finally, the simulation results will show the effectiveness of the developed data-driven ADP methods.",4
Image Understanding Applications of Lattice Autoassociative Memories.,"Multivariate mathematical morphology (MMM) aims to extend the mathematical morphology from gray scale images to images whose pixels are high-dimensional vectors, such as remote sensing hyperspectral images and functional magnetic resonance images (fMRIs). Defining an ordering over the multidimensional image data space is a fundamental issue MMM, to ensure that ensuing morphological operators and filters are mathematically consistent. Recent approaches use the outputs of two-class classifiers to build such reduced orderings. This paper presents the applications of MMM built on reduced supervised orderings based on lattice autoassociative memories (LAAMs) recall error measured by the Chebyshev distance. Foreground supervised orderings use one set of training data from a foreground class, whereas background/foreground supervised orderings use two training data sets, one for each relevant class. The first case study refers to the realization of the thematic segmentation of the hyperspectral images using spatial-spectral information. Spectral classification is enhanced by a spatial processing consisting in the spatial correction guided by a watershed segmentation computed by the LAAM-based morphological operators. The approach improves the state-of-the-art hyperspectral spatial-spectral thematic map building approaches. The second case study is the analysis of resting state fMRI data, working on a data set of healthy controls, schizophrenia patients with and without auditory hallucinations. We perform two experiments: 1) the localization of differences in brain functional networks on population-dependent templates and 2) the classification of subjects into each possible pair of cases. In this data set, we find that the LAAM-based morphological features improve over the conventional correlation-based graph measure features often employed in fMRI data classification.",4
Hierarchical Temporal Memory Based on Spin-Neurons and Resistive Memory for Energy-Efficient Brain-Inspired Computing.,"Hierarchical temporal memory (HTM) tries to mimic the computing in cerebral neocortex. It identifies spatial and temporal patterns in the input for making inferences. This may require a large number of computationally expensive tasks, such as dot product evaluations. Nanodevices that can provide direct mapping for such primitives are of great interest. In this paper, we propose that the computing blocks for HTM can be mapped using low-voltage, magnetometallic spin-neurons combined with an emerging resistive crossbar network, which involves a comprehensive design at algorithm, architecture, circuit, and device levels. Simulation results show the possibility of more than 200x lower energy as compared with a 45-nm CMOS ASIC design.",4
Sequence Prediction With Sparse Distributed Hyperdimensional Coding Applied to the Analysis of Mobile Phone Use Patterns.,"Modeling and prediction of temporal sequences is central to many signal processing and machine learning applications. Prediction based on sequence history is typically performed using parametric models, such as fixed-order Markov chains ( n -grams), approximations of high-order Markov processes, such as mixed-order Markov models or mixtures of lagged bigram models, or with other machine learning techniques. This paper presents a method for sequence prediction based on sparse hyperdimensional coding of the sequence structure and describes how higher order temporal structures can be utilized in sparse coding in a balanced manner. The method is purely incremental, allowing real-time online learning and prediction with limited computational resources. Experiments with prediction of mobile phone use patterns, including the prediction of the next launched application, the next GPS location of the user, and the next artist played with the phone media player, reveal that the proposed method is able to capture the relevant variable-order structure from the sequences. In comparison with the n -grams and the mixed-order Markov models, the sparse hyperdimensional predictor clearly outperforms its peers in terms of unweighted average recall and achieves an equal level of weighted average recall as the mixed-order Markov chain but without the batch training of the mixed-order model.",4
Adaptive Neural Network Based Control of Noncanonical Nonlinear Systems.,"This paper presents a new study on the adaptive neural network-based control of a class of noncanonical nonlinear systems with large parametric uncertainties. Unlike commonly studied canonical form nonlinear systems whose neural network approximation system models have explicit relative degree structures, which can directly be used to derive parameterized controllers for adaptation, noncanonical form nonlinear systems usually do not have explicit relative degrees, and thus their approximation system models are also in noncanonical forms. It is well-known that the adaptive control of noncanonical form nonlinear systems involves the parameterization of system dynamics. As demonstrated in this paper, it is also the case for noncanonical neural network approximation system models. Effective control of such systems is an open research problem, especially in the presence of uncertain parameters. This paper shows that it is necessary to reparameterize such neural network system models for adaptive control design, and that such reparameterization can be realized using a relative degree formulation, a concept yet to be studied for general neural network system models. This paper then derives the parameterized controllers that guarantee closed-loop stability and asymptotic output tracking for noncanonical form neural network system models. An illustrative example is presented with the simulation results to demonstrate the control design procedure, and to verify the effectiveness of such a new design method.",4
A Granular Self-Organizing Map for Clustering and Gene Selection in Microarray Data.,"A new granular self-organizing map (GSOM) is developed by integrating the concept of a fuzzy rough set with the SOM. While training the GSOM, the weights of a winning neuron and the neighborhood neurons are updated through a modified learning procedure. The neighborhood is newly defined using the fuzzy rough sets. The clusters (granules) evolved by the GSOM are presented to a decision table as its decision classes. Based on the decision table, a method of gene selection is developed. The effectiveness of the GSOM is shown in both clustering samples and developing an unsupervised fuzzy rough feature selection (UFRFS) method for gene selection in microarray data. While the superior results of the GSOM, as compared with the related clustering methods, are provided in terms of beta -index, DB-index, Dunn-index, and fuzzy rough entropy, the genes selected by the UFRFS are not only better in terms of classification accuracy and a feature evaluation index, but also statistically more significant than the related unsupervised methods. The C-codes of the GSOM and UFRFS are available online at http://avatharamg.webs.com/software-code.",4
Model-Free Primitive-Based Iterative Learning Control Approach to Trajectory Tracking of MIMO Systems With Experimental Validation.,"This paper proposes a novel model-free trajectory tracking of multiple-input multiple-output (MIMO) systems by the combination of iterative learning control (ILC) and primitives. The optimal trajectory tracking solution is obtained in terms of previously learned solutions to simple tasks called primitives. The library of primitives that are stored in memory consists of pairs of reference input/controlled output signals. The reference input primitives are optimized in a model-free ILC framework without using knowledge of the controlled process. The guaranteed convergence of the learning scheme is built upon a model-free virtual reference feedback tuning design of the feedback decoupling controller. Each new complex trajectory to be tracked is decomposed into the output primitives regarded as basis functions. The optimal reference input for the control system to track the desired trajectory is next recomposed from the reference input primitives. This is advantageous because the optimal reference input is computed straightforward without the need to learn from repeated executions of the tracking task. In addition, the optimization problem specific to trajectory tracking of square MIMO systems is decomposed in a set of optimization problems assigned to each separate single-input single-output control channel that ensures a convenient model-free decoupling. The new model-free primitive-based ILC approach is capable of planning, reasoning, and learning. A case study dealing with the model-free control tuning for a nonlinear aerodynamic system is included to validate the new approach. The experimental results are given.",4
Near Optimal Event-Triggered Control of Nonlinear Discrete-Time Systems Using Neurodynamic Programming.,"This paper presents an event-triggered near optimal control of uncertain nonlinear discrete-time systems. Event-driven neurodynamic programming (NDP) is utilized to design the control policy. A neural network (NN)-based identifier, with event-based state and input vectors, is utilized to learn the system dynamics. An actor-critic framework is used to learn the cost function and the optimal control input. The NN weights of the identifier, the critic, and the actor NNs are tuned aperiodically once every triggered instant. An adaptive event-trigger condition to decide the trigger instants is derived. Thus, a suitable number of events are generated to ensure a desired accuracy of approximation. A near optimal performance is achieved without using value and/or policy iterations. A detailed analysis of nontrivial inter-event times with an explicit formula to show the reduction in computation is also derived. The Lyapunov technique is used in conjunction with the event-trigger condition to guarantee the ultimate boundedness of the closed-loop system. The simulation results are included to verify the performance of the controller. The net result is the development of event-driven NDP.",4
Adaptive Neural Control for a Class of Pure-Feedback Nonlinear Systems via Dynamic Surface Technique.,"This brief addresses the adaptive control problem for a class of pure-feedback systems with nonaffine functions possibly being nondifferentiable. Without using the mean value theorem, the difficulty of the control design for pure-feedback systems is overcome by modeling the nonaffine functions appropriately. With the help of neural network approximators, an adaptive neural controller is developed by combining the dynamic surface control (DSC) and minimal learning parameter (MLP) techniques. The key features of our approach are that, first, the restrictive assumptions on the partial derivative of nonaffine functions are removed, second, the DSC technique is used to avoid ""the explosion of complexity"" in the backstepping design, and the number of adaptive parameters is reduced significantly using the MLP technique, third, smooth robust compensators are employed to circumvent the influences of approximation errors and disturbances. Furthermore, it is proved that all the signals in the closed-loop system are semiglobal uniformly ultimately bounded. Finally, the simulation results are provided to demonstrate the effectiveness of the designed method.",4
The Application of Visual Saliency Models in Objective Image Quality Assessment: A Statistical Evaluation.,"Advances in image quality assessment have shown the potential added value of including visual attention aspects in its objective assessment. Numerous models of visual saliency are implemented and integrated in different image quality metrics (IQMs), but the gain in reliability of the resulting IQMs varies to a large extent. The causes and the trends of this variation would be highly beneficial for further improvement of IQMs, but are not fully understood. In this paper, an exhaustive statistical evaluation is conducted to justify the added value of computational saliency in objective image quality assessment, using 20 state-of-the-art saliency models and 12 best-known IQMs. Quantitative results show that the difference in predicting human fixations between saliency models is sufficient to yield a significant difference in performance gain when adding these saliency models to IQMs. However, surprisingly, the extent to which an IQM can profit from adding a saliency model does not appear to have direct relevance to how well this saliency model can predict human fixations. Our statistical analysis provides useful guidance for applying saliency models in IQMs, in terms of the effect of saliency model dependence, IQM dependence, and image distortion dependence. The testbed and software are made publicly available to the research community.",4
Manifold Ranking-Based Matrix Factorization for Saliency Detection.,"Saliency detection is used to identify the most important and informative area in a scene, and it is widely used in various vision tasks, including image quality assessment, image matching, and object recognition. Manifold ranking (MR) has been used to great effect for the saliency detection, since it not only incorporates the local spatial information but also utilizes the labeling information from background queries. However, MR completely ignores the feature information extracted from each superpixel. In this paper, we propose an MR-based matrix factorization (MRMF) method to overcome this limitation. MRMF models the ranking problem in the matrix factorization framework and embeds query sample labels in the coefficients. By incorporating spatial information and embedding labels, MRMF enforces similar saliency values on neighboring superpixels and ranks superpixels according to the learned coefficients. We prove that the MRMF has good generalizability, and develops an efficient optimization algorithm based on the Nesterov method. Experiments using popular benchmark data sets illustrate the promise of MRMF compared with the other state-of-the-art saliency detection methods.",4
Data-Driven Hinfinity Control for Nonlinear Distributed Parameter Systems.,"The data-driven Hinfinity control problem of nonlinear distributed parameter systems is considered in this paper. An off-policy learning method is developed to learn the Hinfinity control policy from real system data rather than the mathematical model. First, Karhunen-Loeve decomposition is used to compute the empirical eigenfunctions, which are then employed to derive a reduced-order model (ROM) of slow subsystem based on the singular perturbation theory. The Hinfinity control problem is reformulated based on the ROM, which can be transformed to solve the Hamilton-Jacobi-Isaacs (HJI) equation, theoretically. To learn the solution of the HJI equation from real system data, a data-driven off-policy learning approach is proposed based on the simultaneous policy update algorithm and its convergence is proved. For implementation purpose, a neural network (NN)- based action-critic structure is developed, where a critic NN and two action NNs are employed to approximate the value function, control, and disturbance policies, respectively. Subsequently, a least-square NN weight-tuning rule is derived with the method of weighted residuals. Finally, the developed data-driven off-policy learning approach is applied to a nonlinear diffusion-reaction process, and the obtained results demonstrate its effectiveness.",4
Enhanced Data-Driven Optimal Terminal ILC Using Current Iteration Control Knowledge.,"In this paper, an enhanced data-driven optimal terminal iterative learning control (E-DDOTILC) is proposed for a class of nonlinear and nonaffine discrete-time systems. A dynamical linearization approach is first developed with iterative operation points to formulate the relationship of system output and input into a linear affine form. Then, an ILC law is constructed with a nonlinear learning gain, which is a function about the system partial derivative with respect to the time-varying control input. In addition, a parameter updating law is designed to estimate the unknown partial derivatives iteratively. The input signals of the proposed E-DDOTILC are time-varying and updated utilizing not only the terminal tracking error of the previous run but also the input signals of the previous time instants in the current iteration. The proposed approach is a data-driven control strategy and only the I/O data are required for the controller design and analysis. The monotonic convergence and effectiveness of the proposed approach is further verified by both the rigorous mathematical analysis and the simulation results.",4
Semisupervised Support Vector Machines With Tangent Space Intrinsic Manifold Regularization.,"Semisupervised learning has been an active research topic in machine learning and data mining. One main reason is that labeling examples is expensive and time-consuming, while there are large numbers of unlabeled examples available in many practical problems. So far, Laplacian regularization has been widely used in semisupervised learning. In this paper, we propose a new regularization method called tangent space intrinsic manifold regularization. It is intrinsic to data manifold and favors linear functions on the manifold. Fundamental elements involved in the formulation of the regularization are local tangent space representations, which are estimated by local principal component analysis, and the connections that relate adjacent tangent spaces. Simultaneously, we explore its application to semisupervised classification and propose two new learning algorithms called tangent space intrinsic manifold regularized support vector machines (TiSVMs) and tangent space intrinsic manifold regularized twin SVMs (TiTSVMs). They effectively integrate the tangent space intrinsic manifold regularization consideration. The optimization of TiSVMs can be solved by a standard quadratic programming, while the optimization of TiTSVMs can be solved by a pair of standard quadratic programmings. The experimental results of semisupervised classification problems show the effectiveness of the proposed semisupervised learning algorithms.",4
Efficient Implementation of the Backpropagation Algorithm in FPGAs and Microcontrollers.,"The well-known backpropagation learning algorithm is implemented in a field-programmable gate array (FPGA) board and a microcontroller, focusing in obtaining efficient implementations in terms of a resource usage and computational speed. The algorithm was implemented in both cases using a training/validation/testing scheme in order to avoid overfitting problems. For the case of the FPGA implementation, a new neuron representation that reduces drastically the resource usage was introduced by combining the input and first hidden layer units in a single module. Further, a time-division multiplexing scheme was implemented for carrying out product computations taking advantage of the built-in digital signal processor cores. In both implementations, the floating-point data type representation normally used in a personal computer (PC) has been changed to a more efficient one based on a fixed-point scheme, reducing system memory variable usage and leading to an increase in computation speed. The results show that the modifications proposed produced a clear increase in computation speed in comparison with the standard PC-based implementation, demonstrating the usefulness of the intrinsic parallelism of FPGAs in neurocomputational tasks and the suitability of both implementations of the algorithm for its application to the real world problems.",4
Finite-Time Stabilizability and Instabilizability of Delayed Memristive Neural Networks With Nonlinear Discontinuous Controller.,"This paper is concerned about the finite-time stabilizability and instabilizability for a class of delayed memristive neural networks (DMNNs). Through the design of a new nonlinear controller, algebraic criteria based on M -matrix are established for the finite-time stabilizability of DMNNs, and the upper bound of the settling time for stabilization is estimated. In addition, finite-time instabilizability algebraic criteria are also established by choosing different parameters of the same nonlinear controller. The effectiveness and the superiority of the obtained results are supported by numerical simulations.",4
Intelligent Tracking Control for a Class of Uncertain High-Order Nonlinear Systems.,"This brief is concerned with the problem of intelligent tracking control for a class of high-order nonlinear systems with completely unknown nonlinearities. An intelligent adaptive control algorithm is presented by combining the adaptive backstepping technique with the neural networks' approximation ability. It is shown that the practical output tracking performance of the system is achieved using the proposed state-feedback controller under two mild assumptions. In particular, by introducing a parameter in the derivations, the tracking error between the time-varying target signal and the output can be reduced via tuning the controller design parameters. Moreover, in order to solve the problem of overparameterization, which is a common issue in adaptive control design, a controller with one adaptive law is also designed. Finally, simulation results are given to show the effectiveness of the theoretical approaches and the potential of the proposed new design techniques.",4
On the Performance of Manhattan Nonnegative Matrix Factorization.,"Extracting low-rank and sparse structures from matrices has been extensively studied in machine learning, compressed sensing, and conventional signal processing, and has been widely applied to recommendation systems, image reconstruction, visual analytics, and brain signal processing. Manhattan nonnegative matrix factorization (MahNMF) is an extension of the conventional NMF, which models the heavy-tailed Laplacian noise by minimizing the Manhattan distance between a nonnegative matrix X and the product of two nonnegative low-rank factor matrices. Fast algorithms have been developed to restore the low-rank and sparse structures of X in the MahNMF. In this paper, we study the statistical performance of the MahNMF in the frame of the statistical learning theory. We decompose the expected reconstruction error of the MahNMF into the estimation error and the approximation error. The estimation error is bounded by the generalization error bounds of the MahNMF, while the approximation error is analyzed using the asymptotic results of the minimum distortion of vector quantization. The generalization error bound is valuable for determining the size of the training sample needed to guarantee a desirable upper bound for the defect between the expected and empirical reconstruction errors. Statistical performance analysis shows how the reduced dimensionality affects the estimation and approximation errors. Our framework can also be used for analyzing the performance of the NMF.",4
Multistability and Instability of Neural Networks With Discontinuous Nonmonotonic Piecewise Linear Activation Functions.,"In this paper, we discuss the coexistence and dynamical behaviors of multiple equilibrium points for recurrent neural networks with a class of discontinuous nonmonotonic piecewise linear activation functions. It is proved that under some conditions, such n -neuron neural networks can have at least 5(n) equilibrium points, 3(n) of which are locally stable and the others are unstable, based on the contraction mapping theorem and the theory of strict diagonal dominance matrix. The investigation shows that the neural networks with the discontinuous activation functions introduced in this paper can have both more total equilibrium points and more locally stable equilibrium points than the ones with continuous Mexican-hat-type activation function or discontinuous two-level activation functions. An illustrative example with computer simulations is presented to verify the theoretical analysis.",4
Control of Large-Scale Boolean Networks via Network Aggregation.,"A major challenge to solve problems in control of Boolean networks is that the computational cost increases exponentially when the number of nodes in the network increases. We consider the problem of controllability and stabilizability of Boolean control networks, address the increasing cost problem by partitioning the network graph into several subnetworks, and analyze the subnetworks separately. Easily verifiable necessary conditions for controllability and stabilizability are proposed for a general aggregation structure. For acyclic aggregation, we develop a sufficient condition for stabilizability. It dramatically reduces the computational complexity if the number of nodes in each block of the acyclic aggregation is small enough compared with the number of nodes in the entire Boolean network.",4
Dynamical Behavior of Delayed Reaction-Diffusion Hopfield Neural Networks Driven by Infinite Dimensional Wiener Processes.,"In this paper, we focus on the long time behavior of the mild solution to delayed reaction-diffusion Hopfield neural networks (DRDHNNs) driven by infinite dimensional Wiener processes. We analyze the existence, uniqueness, and stability of this system under the local Lipschitz function by constructing an appropriate Lyapunov-Krasovskii function and utilizing the semigroup theory. Some easy-to-test criteria affecting the well-posedness and stability of the networks, such as infinite dimensional noise and diffusion effect, are obtained. The criteria can be used as theoretic guidance to stabilize DRDHNNs in practical applications when infinite dimensional noise is taken into consideration. Meanwhile, considering the fact that the standard Brownian motion is a special case of infinite dimensional Wiener process, we undertake an analysis of the local Lipschitz condition, which has a wider range than the global Lipschitz condition. Two samples are given to examine the availability of the results in this paper. Simulations are also given using the MATLAB.",4
CPG Network Optimization for a Biomimetic Robotic Fish via PSO.,"In this brief, we investigate the parameter optimization issue of a central pattern generator (CPG) network governed forward and backward swimming for a fully untethered, multijoint biomimetic robotic fish. Considering that the CPG parameters are tightly linked to the propulsive performance of the robotic fish, we propose a method for determination of relatively optimized control parameters. Within the framework of evolutionary computation, we use a combination of dynamic model and particle swarm optimization (PSO) algorithm to seek the CPG characteristic parameters for an enhanced performance. The PSO-based optimization scheme is validated with extensive experiments conducted on the actual robotic fish. Noticeably, the optimized results are shown to be superior to previously reported forward and backward swimming speeds.",4
Global neural dynamic surface tracking control of strict-feedback systems with application to hypersonic flight vehicle.,"This paper studies both indirect and direct global neural control of strict-feedback systems in the presence of unknown dynamics, using the dynamic surface control (DSC) technique in a novel manner. A new switching mechanism is designed to combine an adaptive neural controller in the neural approximation domain, together with the robust controller that pulls the transient states back into the neural approximation domain from the outside. In comparison with the conventional control techniques, which could only achieve semiglobally uniformly ultimately bounded stability, the proposed control scheme guarantees all the signals in the closed-loop system are globally uniformly ultimately bounded, such that the conventional constraints on initial conditions of the neural control system can be relaxed. The simulation studies of hypersonic flight vehicle (HFV) are performed to demonstrate the effectiveness of the proposed global neural DSC design.",4
Near-Optimal Controller for Nonlinear Continuous-Time Systems With Unknown Dynamics Using Policy Iteration.,"This paper presents a single-network adaptive critic-based controller for continuous-time systems with unknown dynamics in a policy iteration (PI) framework. It is assumed that the unknown dynamics can be estimated using the Takagi-Sugeno-Kang fuzzy model with arbitrary precision. The successful implementation of a PI scheme depends on the effective learning of critic network parameters. Network parameters must stabilize the system in each iteration in addition to approximating the critic and the cost. It is found that the critic updates according to the Hamilton-Jacobi-Bellman formulation sometimes lead to the instability of the closed-loop systems. In the proposed work, a novel critic network parameter update scheme is adopted, which not only approximates the critic at current iteration but also provides feasible solutions that keep the policy stable in the next step of training by combining a Lyapunov-based linear matrix inequalities approach with PI. The critic modeling technique presented here is the first of its kind to address this issue. Though multiple literature exists discussing the convergence of PI, however, to the best of our knowledge, there exists no literature, which focuses on the effect of critic network parameters on the convergence. Computational complexity in the proposed algorithm is reduced to the order of (Fz)(n-1) , where n is the fuzzy state dimensionality and Fz is the number of fuzzy zones in the states space. A genetic algorithm toolbox of MATLAB is used for searching stable parameters while minimizing the training error. The proposed algorithm also provides a way to solve for the initial stable control policy in the PI scheme. The algorithm is validated through real-time experiment on a commercial robotic manipulator. Results show that the algorithm successfully finds stable critic network parameters in real time for a highly nonlinear system.",4
Constrained Clustering With Nonnegative Matrix Factorization.,"Nonnegative matrix factorization (NMF) and symmetric NMF (SymNMF) have been shown to be effective for clustering linearly separable data and nonlinearly separable data, respectively. Nevertheless, many practical applications demand constrained algorithms in which a small number of constraints in the form of must-link and cannot-link are available. In this paper, we propose an NMF-based constrained clustering framework in which the similarity between two points on a must-link is enforced to approximate 1 and the similarity between two points on a cannot-link is enforced to approximate 0. We then formulate the framework using NMF and SymNMF to deal with clustering of linearly separable data and nonlinearly separable data, respectively. Furthermore, we present multiplicative update rules to solve them and show the correctness and convergence. Experimental results on various text data sets, University of California, Irvine (UCI) data sets, and gene expression data sets demonstrate the superiority of our algorithms over existing constrained clustering algorithms.",4
Stability Analysis for Delayed Neural Networks Considering Both Conservativeness and Complexity.,"This paper investigates delay-dependent stability for continuous neural networks with a time-varying delay. This paper aims at deriving a new stability criterion, considering tradeoff between conservativeness and calculation complexity. A new Lyapunov-Krasovskii functional with simple augmented terms and delay-dependent terms is constructed, and its derivative is estimated by several techniques, including free-weighting matrix and inequality estimation methods. Then, the influence of the techniques used on the conservativeness and the complexity is analyzed one by one. Moreover, useful guidelines for improving criterion and future work are briefly discussed. Finally, the advantages of the proposed criterion compared with the existing ones are verified based on three numerical examples.",4
Compound Rank- k Projections for Bilinear Analysis.,"In many real-world applications, data are represented by matrices or high-order tensors. Despite the promising performance, the existing 2-D discriminant analysis algorithms employ a single projection model to exploit the discriminant information for projection, making the model less flexible. In this paper, we propose a novel compound rank- k projection (CRP) algorithm for bilinear analysis. The CRP deals with matrices directly without transforming them into vectors, and it, therefore, preserves the correlations within the matrix and decreases the computation complexity. Different from the existing 2-D discriminant analysis algorithms, objective function values of CRP increase monotonically. In addition, the CRP utilizes multiple rank- k projection models to enable a larger search space in which the optimal solution can be found. In this way, the discriminant ability is enhanced. We have tested our approach on five data sets, including UUIm, CVL, Pointing'04, USPS, and Coil20. Experimental results show that the performance of our proposed CRP performs better than other algorithms in terms of classification accuracy.",4
A Switching Approach to Designing Finite-Time Synchronization Controllers of Coupled Neural Networks.,"This paper is concerned with the finite-time synchronization issue of nonlinear coupled neural networks by designing a new switching pinning controller. For the fixed network topology and control strength, the newly designed controller could optimize the synchronization time by regulating a parameter alpha (0 </= alpha < 1). The control law presented in this paper covers both continuous controllers and discontinuous ones, which were studied separately in the past. Some criteria are discussed in detail on how to shorten the synchronization time for the strongly connected networks. Finally, the results are generalized to any network topologies containing a directed spanning tree, and one numerical example is given to demonstrate the effectiveness of the theoretical results.",4
Learning Spike Time Codes Through Morphological Learning With Binary Synapses.,"In this brief, a neuron with nonlinear dendrites (NNLDs) and binary synapses that is able to learn temporal features of spike input patterns is considered. Since binary synapses are considered, learning happens through formation and elimination of connections between the inputs and the dendritic branches to modify the structure or morphology of the NNLD. A morphological learning algorithm inspired by the tempotron, i.e., a recently proposed temporal learning algorithm is presented in this brief. Unlike tempotron, the proposed learning rule uses a technique to automatically adapt the NNLD threshold during training. Experimental results indicate that our NNLD with 1-bit synapses can obtain accuracy similar to that of a traditional tempotron with 4-bit synapses in classifying single spike random latency and pairwise synchrony patterns. Hence, the proposed method is better suited for robust hardware implementation in the presence of statistical variations. We also present results of applying this rule to real-life spike classification problems from the field of tactile sensing.",4
A Complex-Valued Projection Neural Network for Constrained Optimization of Real Functions in Complex Variables.,"In this paper, we present a complex-valued projection neural network for solving constrained convex optimization problems of real functions with complex variables, as an extension of real-valued projection neural networks. Theoretically, by developing results on complex-valued optimization techniques, we prove that the complex-valued projection neural network is globally stable and convergent to the optimal solution. Obtained results are completely established in the complex domain and thus significantly generalize existing results of the real-valued projection neural networks. Numerical simulations are presented to confirm the obtained results and effectiveness of the proposed complex-valued projection neural network.",4
A Maximum Margin Approach for Semisupervised Ordinal Regression Clustering.,"Ordinal regression (OR) is generally defined as the task where the input samples are ranked on an ordinal scale. OR has found a wide variety of applications, and a great deal of work has been done on it. However, most of the existing work focuses on supervised/semisupervised OR classification, and the semisupervised OR clustering problems have not been explicitly addressed. In real-world OR applications, labeling a large number of training samples is usually time-consuming and costly, and instead, a set of unlabeled samples can be utilized to set up the OR model. Moreover, although the sample labels are unavailable, we can sometimes get the relative ranking information of the unlabeled samples. This sample ranking information can be utilized to refine the OR model. Hence, how to build an OR model on the unlabeled samples and incorporate the sample ranking information into the process of improving the clustering accuracy remains a key challenge for OR applications. In this paper, we consider the semisupervised OR clustering problems with sample-ranking constraints, which give the relative ranking information of the unlabeled samples, and put forward a maximum margin approach for semisupervised OR clustering ( [Formula: see text]SORC). On one hand, [Formula: see text]SORC seeks a set of parallel hyperplanes to partition the unlabeled samples into clusters. On the other hand, a loss function is put forward to incorporate the sample ranking information into the clustering process. As a result, the optimization function of [Formula: see text]SORC is formulated to maximize the margins of the closest neighboring clusters and meanwhile minimize the loss associated with the sample-ranking constraints. Extensive experiments on OR data sets show that the proposed [Formula: see text]SORC method outperforms the traditional semisupervised clustering methods considered.",4
Recurrent-Neural-Network-Based Multivariable Adaptive Control for a Class of Nonlinear Dynamic Systems With Time-Varying Delay.,"At the beginning, an approximate nonlinear autoregressive moving average (NARMA) model is employed to represent a class of multivariable nonlinear dynamic systems with time-varying delay. It is known that the disadvantages of robust control for the NARMA model are as follows: 1) suitable control parameters for larger time delay are more sensitive to achieving desirable performance; 2) it only deals with bounded uncertainty; and 3) the nominal NARMA model must be learned in advance. Due to the dynamic feature of the NARMA model, a recurrent neural network (RNN) is online applied to learn it. However, the system performance becomes deteriorated due to the poor learning of the larger variation of system vector functions. In this situation, a simple network is employed to compensate the upper bound of the residue caused by the linear parameterization of the approximation error of RNN. An e -modification learning law with a projection for weight matrix is applied to guarantee its boundedness without persistent excitation. Under suitable conditions, the semiglobally ultimately bounded tracking with the boundedness of estimated weight matrix is obtained by the proposed RNN-based multivariable adaptive control. Finally, simulations are presented to verify the effectiveness and robustness of the proposed control.",4
Alternative Multiview Maximum Entropy Discrimination.,"Maximum entropy discrimination (MED) is a general framework for discriminative estimation based on maximum entropy and maximum margin principles, and can produce hard-margin support vector machines under some assumptions. Recently, the multiview version of MED multiview MED (MVMED) was proposed. In this paper, we try to explore a more natural MVMED framework by assuming two separate distributions p1( Theta1) over the first-view classifier parameter Theta1 and p2( Theta2) over the second-view classifier parameter Theta2 . We name the new MVMED framework as alternative MVMED (AMVMED), which enforces the posteriors of two view margins to be equal. The proposed AMVMED is more flexible than the existing MVMED, because compared with MVMED, which optimizes one relative entropy, AMVMED assigns one relative entropy term to each of the two views, thus incorporating a tradeoff between the two views. We give the detailed solving procedure, which can be divided into two steps. The first step is solving our optimization problem without considering the equal margin posteriors from two views, and then, in the second step, we consider the equal posteriors. Experimental results on multiple real-world data sets verify the effectiveness of the AMVMED, and comparisons with MVMED are also reported.",4
Parallel Online Temporal Difference Learning for Motor Control.,"Temporal difference (TD) learning, a key concept in reinforcement learning, is a popular method for solving simulated control problems. However, in real systems, this method is often avoided in favor of policy search methods because of its long learning time. But policy search suffers from its own drawbacks, such as the necessity of informed policy parameterization and initialization. In this paper, we show that TD learning can work effectively in real robotic systems as well, using parallel model learning and planning. Using locally weighted linear regression and trajectory sampled planning with 14 concurrent threads, we can achieve a speedup of almost two orders of magnitude over regular TD control on simulated control benchmarks. For a real-world pendulum swing-up task and a two-link manipulator movement task, we report a speedup of 20x to 60x , with a real-time learning speed of less than half a minute. The results are competitive with state-of-the-art policy search.",4
H infinity tracking control of completely unknown continuous-time systems via off-policy reinforcement learning.,This paper deals with the design of an H infinity tracking controller for nonlinear continuous-time systems with completely unknown dynamics. A general bounded L2 -gain tracking problem with a discounted performance function is introduced for the H infinity tracking. A tracking Hamilton-Jacobi-Isaac (HJI) equation is then developed that gives a Nash equilibrium solution to the associated min-max optimization problem. A rigorous analysis of bounded L2 -gain and stability of the control solution obtained by solving the tracking HJI equation is provided. An upper-bound is found for the discount factor to assure local asymptotic stability of the tracking error dynamics. An off-policy reinforcement learning algorithm is used to learn the solution to the tracking HJI equation online without requiring any knowledge of the system dynamics. Convergence of the proposed algorithm to the solution to the tracking HJI equation is shown. Simulation examples are provided to verify the effectiveness of the proposed method.,4
Optimal control of nonlinear continuous-time systems in strict-feedback form.,"This paper proposes a novel optimal tracking control scheme for nonlinear continuous-time systems in strict-feedback form with uncertain dynamics. The optimal tracking problem is transformed into an equivalent optimal regulation problem through a feedforward adaptive control input that is generated by modifying the standard backstepping technique. Subsequently, a neural network-based optimal control scheme is introduced to estimate the cost, or value function, over an infinite horizon for the resulting nonlinear continuous-time systems in affine form when the internal dynamics are unknown. The estimated cost function is then used to obtain the optimal feedback control input; therefore, the overall optimal control input for the nonlinear continuous-time system in strict-feedback form includes the feedforward plus the optimal feedback terms. It is shown that the estimated cost function minimizes the Hamilton-Jacobi-Bellman estimation error in a forward-in-time manner without using any value or policy iterations. Finally, optimal output feedback control is introduced through the design of a suitable observer. Lyapunov theory is utilized to show the overall stability of the proposed schemes without requiring an initial admissible controller. Simulation examples are provided to validate the theoretical results.",4
Comparison Analysis: Granger Causality and New Causality and Their Applications to Motor Imagery.,"In this paper we first point out a fatal drawback that the widely used Granger causality (GC) needs to estimate the autoregressive model, which is equivalent to taking a series of backward recursive operations which are infeasible in many irreversible chemical reaction models. Thus, new causality (NC) proposed by Hu et al. (2011) is theoretically shown to be more sensitive to reveal true causality than GC. We then apply GC and NC to motor imagery (MI) which is an important mental process in cognitive neuroscience and psychology and has received growing attention for a long time. We study causality flow during MI using scalp electroencephalograms from nine subjects in Brain-computer interface competition IV held in 2008. We are interested in three regions: Cz (central area of the cerebral cortex), C3 (left area of the cerebral cortex), and C4 (right area of the cerebral cortex) which are considered to be optimal locations for recognizing MI states in the literature. Our results show that: 1) there is strong directional connectivity from Cz to C3/C4 during left- and right-hand MIs based on GC and NC; 2) during left-hand MI, there is directional connectivity from C4 to C3 based on GC and NC; 3) during right-hand MI, there is strong directional connectivity from C3 to C4 which is much clearly revealed by NC than by GC, i.e., NC largely improves the classification rate; and 4) NC is demonstrated to be much more sensitive to reveal causal influence between different brain regions than GC.",4
"Optimization in Quaternion Dynamic Systems: Gradient, Hessian, and Learning Algorithms.","The optimization of real scalar functions of quaternion variables, such as the mean square error or array output power, underpins many practical applications. Solutions typically require the calculation of the gradient and Hessian. However, real functions of quaternion variables are essentially nonanalytic, which are prohibitive to the development of quaternion-valued learning systems. To address this issue, we propose new definitions of quaternion gradient and Hessian, based on the novel generalized Hamilton-real (GHR) calculus, thus making a possible efficient derivation of general optimization algorithms directly in the quaternion field, rather than using the isomorphism with the real domain, as is current practice. In addition, unlike the existing quaternion gradients, the GHR calculus allows for the product and chain rule, and for a one-to-one correspondence of the novel quaternion gradient and Hessian with their real counterparts. Properties of the quaternion gradient and Hessian relevant to numerical applications are also introduced, opening a new avenue of research in quaternion optimization and greatly simplified the derivations of learning algorithms. The proposed GHR calculus is shown to yield the same generic algorithm forms as the corresponding real- and complex-valued algorithms. Advantages of the proposed framework are illuminated over illustrative simulations in quaternion signal processing and neural networks.",4
Learning Compositional Shape Models of Multiple Distance Metrics by Information Projection.,"This paper presents a novel compositional contour-based shape model by incorporating multiple distance metrics to account for varying shape distortions or deformations. Our approach contains two key steps: 1) contour feature generation and 2) generative model pursuit. For each category, we first densely sample an ensemble of local prototype contour segments from a few positive shape examples and describe each segment using three different types of distance metrics. These metrics are diverse and complementary with each other to capture various shape deformations. We regard the parameterized contour segment plus an additive residual as a basic subspace, namely, -ball, in the sense that it represents local shape variance under the certain distance metric. Using these -balls as features, we then propose a generative learning algorithm to pursue the compositional shape model, which greedily selects the most representative features under the information projection principle. In experiments, we evaluate our model on several public challenging data sets, and demonstrate that the integration of multiple shape distance metrics is capable of dealing various shape deformations, articulations, and background clutter, hence boosting system performance.",4
Learning Discriminative Stein Kernel for SPD Matrices and Its Applications.,"Stein kernel (SK) has recently shown promising performance on classifying images represented by symmetric positive definite (SPD) matrices. It evaluates the similarity between two SPD matrices through their eigenvalues. In this paper, we argue that directly using the original eigenvalues may be problematic because: 1) eigenvalue estimation becomes biased when the number of samples is inadequate, which may lead to unreliable kernel evaluation, and 2) more importantly, eigenvalues reflect only the property of an individual SPD matrix. They are not necessarily optimal for computing SK when the goal is to discriminate different classes of SPD matrices. To address the two issues, we propose a discriminative SK (DSK), in which an extra parameter vector is defined to adjust the eigenvalues of input SPD matrices. The optimal parameter values are sought by optimizing a proxy of classification performance. To show the generality of the proposed method, three kernel learning criteria that are commonly used in the literature are employed as a proxy. A comprehensive experimental study is conducted on a variety of image classification tasks to compare the proposed DSK with the original SK and other methods for evaluating the similarity between SPD matrices. The results demonstrate that the DSK can attain greater discrimination and better align with classification tasks by altering the eigenvalues. This makes it produce higher classification performance than the original SK and other commonly used methods.",4
Analog Programmable Distance Calculation Circuit for Winner Takes All Neural Network Realized in the CMOS Technology.,"This paper presents a programmable analog current-mode circuit used to calculate the distance between two vectors of currents, following two distance measures. The Euclidean (L2) distance is commonly used. However, in many situations, it can be replaced with the Manhattan (L1) one, which is computationally less intensive, whose realization comes with less power dissipation and lower hardware complexity. The presented circuit can be easily reprogrammed to operate with one of these distances. The circuit is one of the components of an analog winner takes all neural network (NN) implemented in the complementary metal-oxide-semiconductor 0.18- [Formula: see text] technology. The learning process of the realized NN has been successfully verified by the laboratory tests of the fabricated chip. The proposed distance calculation circuit (DCC) features a simple structure, which makes it suitable for networks with a relatively large number of neurons realized in hardware and operating in parallel. For example, the network with three inputs occupies a relatively small area of 3900 mum(2). When operating in the L2 mode, the circuit dissipates 85 [Formula: see text] of power from the 1.5 V voltage supply, at maximum data rate of 10 MHz. In the L1 mode, an average dissipated power is reduced to 55 [Formula: see text] from 1.2 V voltage supply, while data rate is 12 MHz in this case. The given data rates are provided for the worst case scenario, where input currents differ by 1%-2% only. In this case, the settling time of the comparators used in the DCC is quite long. However, that kind of situation is very rare in the overall learning process.",4
Online Supplementary ADP Learning Controller Design and Application to Power System Frequency Control With Large-Scale Wind Energy Integration.,"The emergence of smart grids has posed great challenges to traditional power system control given the multitude of new risk factors. This paper proposes an online supplementary learning controller (OSLC) design method to compensate the traditional power system controllers for coping with the dynamic power grid. The proposed OSLC is a supplementary controller based on approximate dynamic programming, which works alongside an existing power system controller. By introducing an action-dependent cost function as the optimization objective, the proposed OSLC is a nonidentifier-based method to provide an online optimal control adaptively as measurement data become available. The online learning of the OSLC enjoys the policy-search efficiency during policy iteration and the data efficiency of the least squares method. For the proposed OSLC, the stability of the controlled system during learning, the monotonic nature of the performance measure of the iterative supplementary controller, and the convergence of the iterative supplementary controller are proved. Furthermore, the efficacy of the proposed OSLC is demonstrated in a challenging power system frequency control problem in the presence of high penetration of wind generation.",4
A Nearest Neighbor Classifier Employing Critical Boundary Vectors for Efficient On-Chip Template Reduction.,"Aiming at efficient data condensation and improving accuracy, this paper presents a hardware-friendly template reduction (TR) method for the nearest neighbor (NN) classifiers by introducing the concept of critical boundary vectors. A hardware system is also implemented to demonstrate the feasibility of using an field-programmable gate array (FPGA) to accelerate the proposed method. Initially, k -means centers are used as substitutes for the entire template set. Then, to enhance the classification performance, critical boundary vectors are selected by a novel learning algorithm, which is completed within a single iteration. Moreover, to remove noisy boundary vectors that can mislead the classification in a generalized manner, a global categorization scheme has been explored and applied to the algorithm. The global characterization automatically categorizes each classification problem and rapidly selects the boundary vectors according to the nature of the problem. Finally, only critical boundary vectors and k -means centers are used as the new template set for classification. Experimental results for 24 data sets show that the proposed algorithm can effectively reduce the number of template vectors for classification with a high learning speed. At the same time, it improves the accuracy by an average of 2.17% compared with the traditional NN classifiers and also shows greater accuracy than seven other TR methods. We have shown the feasibility of using a proof-of-concept FPGA system of 256 64-D vectors to accelerate the proposed method on hardware. At a 50-MHz clock frequency, the proposed system achieves a 3.86 times higher learning speed than on a 3.4-GHz PC, while consuming only 1% of the power of that used by the PC.",4
Integrated Low-Rank-Based Discriminative Feature Learning for Recognition.,"Feature learning plays a central role in pattern recognition. In recent years, many representation-based feature learning methods have been proposed and have achieved great success in many applications. However, these methods perform feature learning and subsequent classification in two separate steps, which may not be optimal for recognition tasks. In this paper, we present a supervised low-rank-based approach for learning discriminative features. By integrating latent low-rank representation (LatLRR) with a ridge regression-based classifier, our approach combines feature learning with classification, so that the regulated classification error is minimized. In this way, the extracted features are more discriminative for the recognition tasks. Our approach benefits from a recent discovery on the closed-form solutions to noiseless LatLRR. When there is noise, a robust Principal Component Analysis (PCA)-based denoising step can be added as preprocessing. When the scale of a problem is large, we utilize a fast randomized algorithm to speed up the computation of robust PCA. Extensive experimental results demonstrate the effectiveness and robustness of our method.",4
A New Distance Metric for Unsupervised Learning of Categorical Data.,"Distance metric is the basis of many learning algorithms, and its effectiveness usually has a significant influence on the learning results. In general, measuring distance for numerical data is a tractable task, but it could be a nontrivial problem for categorical data sets. This paper, therefore, presents a new distance metric for categorical data based on the characteristics of categorical values. In particular, the distance between two values from one attribute measured by this metric is determined by both the frequency probabilities of these two values and the values of other attributes that have high interdependence with the calculated one. Dynamic attribute weight is further designed to adjust the contribution of each attribute-distance to the distance between the whole data objects. Promising experimental results on different real data sets have shown the effectiveness of the proposed distance metric.",4
Improper Complex-Valued Bhattacharyya Distance.,"Motivated by application of complex-valued signal processing techniques in statistical pattern recognition, classification, and Gaussian mixture (GM) modeling, this paper derives analytical expressions for computing the Bhattacharyya coefficient/distance (BC/BD) between two improper complex-valued Gaussian distributions. The BC/BD is one of the most widely used statistical measures for evaluating class separability in classification problems, feature extraction in pattern recognition, and for GM reduction (GMR) purposes. The BC provides an upper bound on the Bayes error, which is commonly known as the best criterion to evaluate feature sets. Although the computation of the BC/BD between real-valued signals is a well-known result, it has not yet been extended to the case of improper complex-valued Gaussian densities. This paper addresses this gap. We analyze the role of the pseudocovariance matrix, which characterizes the noncircularity of the signal, and show that it carries critical second-order statistical information for computing the BC/BD. We derive upper and lower bounds on the BD in terms of the eigenvalues of the covariance and pseudocovariance matrices of the underlying densities. The theoretical bounds are then used to introduce the concept of beta -dominance in the context of statistical distance measures. The BC is pseudometric, since it fails to satisfy the triangle inequality. Using the Matusita distance (a full-metric variant of the BC), we propose an intuitively pleasing indirect distance measure for comparing two general GMs. Finally, we investigate the application of the proposed BC/BD measures for GMR purposes and develop two BC-based GMR algorithms.",4
Change Detection in Synthetic Aperture Radar Images Based on Deep Neural Networks.,"This paper presents a novel change detection approach for synthetic aperture radar images based on deep learning. The approach accomplishes the detection of the changed and unchanged areas by designing a deep neural network. The main guideline is to produce a change detection map directly from two images with the trained deep neural network. The method can omit the process of generating a difference image (DI) that shows difference degrees between multitemporal synthetic aperture radar images. Thus, it can avoid the effect of the DI on the change detection results. The learning algorithm for deep architectures includes unsupervised feature learning and supervised fine-tuning to complete classification. The unsupervised feature learning aims at learning the representation of the relationships between the two images. In addition, the supervised fine-tuning aims at learning the concepts of the changed and unchanged pixels. Experiments on real data sets and theoretical analysis indicate the advantages, feasibility, and potential of the proposed method. Moreover, based on the results achieved by various traditional algorithms, respectively, deep learning can further improve the detection performance.",4
Probabilistic Slow Features for Behavior Analysis.,"A recently introduced latent feature learning technique for time-varying dynamic phenomena analysis is the so-called slow feature analysis (SFA). SFA is a deterministic component analysis technique for multidimensional sequences that, by minimizing the variance of the first-order time derivative approximation of the latent variables, finds uncorrelated projections that extract slowly varying features ordered by their temporal consistency and constancy. In this paper, we propose a number of extensions in both the deterministic and the probabilistic SFA optimization frameworks. In particular, we derive a novel deterministic SFA algorithm that is able to identify linear projections that extract the common slowest varying features of two or more sequences. In addition, we propose an expectation maximization (EM) algorithm to perform inference in a probabilistic formulation of SFA and similarly extend it in order to handle two and more time-varying data sequences. Moreover, we demonstrate that the probabilistic SFA (EM-SFA) algorithm that discovers the common slowest varying latent space of multiple sequences can be combined with dynamic time warping techniques for robust sequence time-alignment. The proposed SFA algorithms were applied for facial behavior analysis, demonstrating their usefulness and appropriateness for this task.",4
A Further Study on Mining DNA Motifs Using Fuzzy Self-Organizing Maps.,"Self-organizing map (SOM)-based motif mining, despite being a promising approach for problem solving, mostly fails to offer a consistent interpretation of clusters with respect to the mixed composition of signal and noise in the nodes. The main reason behind this shortcoming comes from the similarity metrics used in data assignment, specially designed with the biological interpretation for this domain, which are not meant to consider the inevitable noise mixture in the clusters. This limits the explicability of the majority of clusters that are supposedly noise dominated, degrading the overall system clarity in motif discovery. This paper aims to improve the explicability aspect of learning process by introducing a composite similarity function (CSF) that is specially designed for the k -mer-to-cluster similarity measure with respect to the degree of motif properties and embedded noise in the cluster. Our proposed motif finding algorithm in this paper is built on our previous work robust elicitation algorithms for discovering (READ) [1] and termed READ Deoxyribonucleic acid motifs using CSFs (READ(csf)), which performs slightly better than READ and shows some remarkable improvements over SOM-based SOMBRERO and SOMEA tools in terms of F-measure on the testing data sets. A real data set containing multiple motifs is used to explore the potential of the READ(csf) for more challenging biological data mining tasks. Visual comparisons with the verified logos extracted from JASPAR database demonstrate that our algorithm is promising to discover multiple motifs simultaneously.",4
Bayesian Robust Tensor Factorization for Incomplete Multiway Data.,"We propose a generative model for robust tensor factorization in the presence of both missing data and outliers. The objective is to explicitly infer the underlying low-CANDECOMP/PARAFAC (CP)-rank tensor capturing the global information and a sparse tensor capturing the local information (also considered as outliers), thus providing the robust predictive distribution over missing entries. The low-CP-rank tensor is modeled by multilinear interactions between multiple latent factors on which the column sparsity is enforced by a hierarchical prior, while the sparse tensor is modeled by a hierarchical view of Student-t distribution that associates an individual hyperparameter with each element independently. For model learning, we develop an efficient variational inference under a fully Bayesian treatment, which can effectively prevent the overfitting problem and scales linearly with data size. In contrast to existing related works, our method can perform model selection automatically and implicitly without the need of tuning parameters. More specifically, it can discover the groundtruth of CP rank and automatically adapt the sparsity inducing priors to various types of outliers. In addition, the tradeoff between the low-rank approximation and the sparse representation can be optimized in the sense of maximum model evidence. The extensive experiments and comparisons with many state-of-the-art algorithms on both synthetic and real-world data sets demonstrate the superiorities of our method from several perspectives.",4
Taylor O(h(3)) Discretization of ZNN Models for Dynamic Equality-Constrained Quadratic Programming With Application to Manipulators.,"In this paper, a new Taylor-type numerical differentiation formula is first presented to discretize the continuous-time Zhang neural network (ZNN), and obtain higher computational accuracy. Based on the Taylor-type formula, two Taylor-type discrete-time ZNN models (termed Taylor-type discrete-time ZNNK and Taylor-type discrete-time ZNNU models) are then proposed and discussed to perform online dynamic equality-constrained quadratic programming. For comparison, Euler-type discrete-time ZNN models (called Euler-type discrete-time ZNNK and Euler-type discrete-time ZNNU models) and Newton iteration, with interesting links being found, are also presented. It is proved herein that the steady-state residual errors of the proposed Taylor-type discrete-time ZNN models, Euler-type discrete-time ZNN models, and Newton iteration have the patterns of O(h(3)), O(h(2)), and O(h), respectively, with h denoting the sampling gap. Numerical experiments, including the application examples, are carried out, of which the results further substantiate the theoretical findings and the efficacy of Taylor-type discrete-time ZNN models. Finally, the comparisons with Taylor-type discrete-time derivative model and other Lagrange-type discrete-time ZNN models for dynamic equality-constrained quadratic programming substantiate the superiority of the proposed Taylor-type discrete-time ZNN models once again.",4
Generalization Performance of Regularized Ranking With Multiscale Kernels.,"The regularized kernel method for the ranking problem has attracted increasing attentions in machine learning. The previous regularized ranking algorithms are usually based on reproducing kernel Hilbert spaces with a single kernel. In this paper, we go beyond this framework by investigating the generalization performance of the regularized ranking with multiscale kernels. A novel ranking algorithm with multiscale kernels is proposed and its representer theorem is proved. We establish the upper bound of the generalization error in terms of the complexity of hypothesis spaces. It shows that the multiscale ranking algorithm can achieve satisfactory learning rates under mild conditions. Experiments demonstrate the effectiveness of the proposed method for drug discovery and recommendation tasks.",4
A Novel Framework for Learning Geometry-Aware Kernels.,"The data from real world usually have nonlinear geometric structure, which are often assumed to lie on or close to a low-dimensional manifold in a high-dimensional space. How to detect this nonlinear geometric structure of the data is important for the learning algorithms. Recently, there has been a surge of interest in utilizing kernels to exploit the manifold structure of the data. Such kernels are called geometry-aware kernels and are widely used in the machine learning algorithms. The performance of these algorithms critically relies on the choice of the geometry-aware kernels. Intuitively, a good geometry-aware kernel should utilize additional information other than the geometric information. In many applications, it is required to compute the out-of-sample data directly. However, most of the geometry-aware kernel methods are restricted to the available data given beforehand, with no straightforward extension for out-of-sample data. In this paper, we propose a framework for more general geometry-aware kernel learning. The proposed framework integrates multiple sources of information and enables us to develop flexible and effective kernel matrices. Then, we theoretically show how the learned kernel matrices are extended to the corresponding kernel functions, in which the out-of-sample data can be computed directly. Under our framework, a novel family of geometry-aware kernels is developed. Especially, some existing geometry-aware kernels can be viewed as instances of our framework. The performance of the kernels is evaluated on dimensionality reduction, classification, and clustering tasks. The empirical results show that our kernels significantly improve the performance.",4
Synchronization of Memristor-Based Coupling Recurrent Neural Networks With Time-Varying Delays and Impulses.,"Synchronization of an array of linearly coupled memristor-based recurrent neural networks with impulses and time-varying delays is investigated in this brief. Based on the Lyapunov function method, an extended Halanay differential inequality and a new delay impulsive differential inequality, some sufficient conditions are derived, which depend on impulsive and coupling delays to guarantee the exponential synchronization of the memristor-based recurrent neural networks. Impulses with and without delay and time-varying delay are considered for modeling the coupled neural networks simultaneously, which renders more practical significance of our current research. Finally, numerical simulations are given to verify the effectiveness of the theoretical results.",4
MLPNN Training via a Multiobjective Optimization of Training Error and Stochastic Sensitivity.,"The training of a multilayer perceptron neural network (MLPNN) concerns the selection of its architecture and the connection weights via the minimization of both the training error and a penalty term. Different penalty terms have been proposed to control the smoothness of the MLPNN for better generalization capability. However, controlling its smoothness using, for instance, the norm of weights or the Vapnik-Chervonenkis dimension cannot distinguish individual MLPNNs with the same number of free parameters or the same norm. In this paper, to enhance generalization capabilities, we propose a stochastic sensitivity measure (ST-SM) to realize a new penalty term for MLPNN training. The ST-SM determines the expectation of the squared output differences between the training samples and the unseen samples located within their Q -neighborhoods for a given MLPNN. It provides a direct measurement of the MLPNNs output fluctuations, i.e., smoothness. We adopt a two-phase Pareto-based multiobjective training algorithm for minimizing both the training error and the ST-SM as biobjective functions. Experiments on 20 UCI data sets show that the MLPNNs trained by the proposed algorithm yield better accuracies on testing data than several recent and classical MLPNN training methods.",4
Tree Ensembles on the Induced Discrete Space.,"Decision trees are widely used predictive models in machine learning. Recently, K -tree is proposed, where the original discrete feature space is expanded by generating all orderings of values of k discrete attributes and these orderings are used as the new attributes in decision tree induction. Although K -tree performs significantly better than the proper one, their exponential time complexity can prohibit their use. In this brief, we propose K -forest, an extension of random forest, where a subset of features is selected randomly from the induced discrete space. Simulation results on 17 data sets show that the novel ensemble classifier has significantly lower error rate compared with the random forest based on the original feature space.",4
Data Generators for Learning Systems Based on RBF Networks.,"There are plenty of problems where the data available is scarce and expensive. We propose a generator of semiartificial data with similar properties to the original data, which enables the development and testing of different data mining algorithms and the optimization of their parameters. The generated data allow large-scale experimentation and simulations without danger of overfitting. The proposed generator is based on radial basis function networks, which learn sets of Gaussian kernels. These Gaussian kernels can be used in a generative mode to generate new data from the same distributions. To assess the quality of the generated data, we evaluated the statistical properties of the generated data, structural similarity, and predictive similarity using supervised and unsupervised learning techniques. To determine usability of the proposed generator we conducted a large scale evaluation using 51 data sets. The results show a considerable similarity between the original and generated data and indicate that the method can be useful in several development and simulation scenarios. We analyze possible improvements in the classification performance by adding different amounts of the generated data to the training set, performance on high-dimensional data sets, and conditions when the proposed approach is successful.",4
Storage Free Smart Energy Management for Frequency Control in a Diesel-PV-Fuel Cell-Based Hybrid AC Microgrid.,"This paper proposes a novel, smart energy management scheme for a microgrid, consisting of a diesel generator and power electronic converter interfaced renewable energy-based generators, such as photovoltaic (PV) and fuel cell, for frequency regulation without any storage. In the proposed strategy, output of the PV is controlled in coordination with other generators using neurofuzzy controller, either only for transient frequency regulation or for both transient and steady-state frequency regulation, depending on the load demand, thereby eliminating the huge storage requirements. The option of demand response control is also explored along with the generation control. For accurate and quick tracking of maximum power point and its associated reserve power from the PV generator, this paper also proposes a novel adaptive-predictor-corrector-based tracking mechanism.",4
A Simple Method for Solving the SVM Regularization Path for Semidefinite Kernels.,"The support vector machine (SVM) remains a popular classifier for its excellent generalization performance and applicability of kernel methods; however, it still requires tuning of a regularization parameter, C , to achieve optimal performance. Regularization path-following algorithms efficiently solve the solution at all possible values of the regularization parameter relying on the fact that the SVM solution is piece-wise linear in C . The SVMPath originally introduced by Hastie et al., while representing a significant theoretical contribution, does not work with semidefinite kernels. Ong et al. introduce a method improved SVMPath (ISVMP) algorithm, which addresses the semidefinite kernel; however, Singular Value Decomposition or QR factorizations are required, and a linear programming solver is required to find the next C value at each iteration. We introduce a simple implementation of the path-following algorithm that automatically handles semidefinite kernels without requiring a method to detect singular matrices nor requiring specialized factorizations or an external solver. We provide theoretical results showing how this method resolves issues associated with the semidefinite kernel as well as discuss, in detail, the potential sources of degeneracy and cycling and how cycling is resolved. Moreover, we introduce an initialization method for unequal class sizes based upon artificial variables that work within the context of the existing path-following algorithm and do not require an external solver. Experiments compare performance with the ISVMP algorithm introduced by Ong et al. and show that the proposed method is competitive in terms of training time while also maintaining high accuracy.",4
A Nonnegative Latent Factor Model for Large-Scale Sparse Matrices in Recommender Systems via Alternating Direction Method.,"Nonnegative matrix factorization (NMF)-based models possess fine representativeness of a target matrix, which is critically important in collaborative filtering (CF)-based recommender systems. However, current NMF-based CF recommenders suffer from the problem of high computational and storage complexity, as well as slow convergence rate, which prevents them from industrial usage in context of big data. To address these issues, this paper proposes an alternating direction method (ADM)-based nonnegative latent factor (ANLF) model. The main idea is to implement the ADM-based optimization with regard to each single feature, to obtain high convergence rate as well as low complexity. Both computational and storage costs of ANLF are linear with the size of given data in the target matrix, which ensures high efficiency when dealing with extremely sparse matrices usually seen in CF problems. As demonstrated by the experiments on large, real data sets, ANLF also ensures fast convergence and high prediction accuracy, as well as the maintenance of nonnegativity constraints. Moreover, it is simple and easy to implement for real applications of learning systems.",4
Embedded Hardware-Efficient Real-Time Classification With Cascade Support Vector Machines.,"Cascade support vector machines (SVMs) are optimized to efficiently handle problems, where the majority of the data belong to one of the two classes, such as image object classification, and hence can provide speedups over monolithic (single) SVM classifiers. However, SVM classification is a computationally demanding task and existing hardware architectures for SVMs only consider monolithic classifiers. This paper proposes the acceleration of cascade SVMs through a hybrid processing hardware architecture optimized for the cascade SVM classification flow, accompanied by a method to reduce the required hardware resources for its implementation, and a method to improve the classification speed utilizing cascade information to further discard data samples. The proposed SVM cascade architecture is implemented on a Spartan-6 field-programmable gate array (FPGA) platform and evaluated for object detection on 800x600 (Super Video Graphics Array) resolution images. The proposed architecture, boosted by a neural network that processes cascade information, achieves a real-time processing rate of 40 frames/s for the benchmark face detection application. Furthermore, the hardware-reduction method results in the utilization of 25% less FPGA custom-logic resources and 20% peak power reduction compared with a baseline implementation.",4
Undamped Oscillations Generated by Hopf Bifurcations in Fractional-Order Recurrent Neural Networks With Caputo Derivative.,"In this paper, a fractional-order recurrent neural network is proposed and several topics related to the dynamics of such a network are investigated, such as the stability, Hopf bifurcations, and undamped oscillations. The stability domain of the trivial steady state is completely characterized with respect to network parameters and orders of the commensurate-order neural network. Based on the stability analysis, the critical values of the fractional order are identified, where Hopf bifurcations occur and a family of oscillations bifurcate from the trivial steady state. Then, the parametric range of undamped oscillations is also estimated and the frequency and amplitude of oscillations are determined analytically and numerically for such commensurate-order networks. Meanwhile, it is shown that the incommensurate-order neural network can also exhibit a Hopf bifurcation as the network parameter passes through a critical value which can be determined exactly. The frequency and amplitude of bifurcated oscillations are determined.",4
Effective Discriminative Feature Selection With Nontrivial Solution.,"Feature selection and feature transformation, the two main ways to reduce dimensionality, are often presented separately. In this paper, a feature selection method is proposed by combining the popular transformation-based dimensionality reduction method linear discriminant analysis (LDA) and sparsity regularization. We impose row sparsity on the transformation matrix of LDA through l2,1-norm regularization to achieve feature selection, and the resultant formulation optimizes for selecting the most discriminative features and removing the redundant ones simultaneously. The formulation is extended to the l2,p-norm regularized case, which is more likely to offer better sparsity when 0 < p < 1. Thus, the formulation is a better approximation to the feature selection problem. An efficient algorithm is developed to solve the l2,p-norm-based optimization problem and it is proved that the algorithm converges when 0 < p </= 2. Systematical experiments are conducted to understand the work of the proposed method. Promising experimental results on various types of real-world data sets demonstrate the effectiveness of our algorithm.",4
Global nonlinear kernel prediction for large data set with a particle swarm-optimized interval support vector regression.,"A new global nonlinear predictor with a particle swarm-optimized interval support vector regression (PSO-ISVR) is proposed to address three issues (viz., kernel selection, model optimization, kernel method speed) encountered when applying SVR in the presence of large data sets. The novel prediction model can reduce the SVR computing overhead by dividing input space and adaptively selecting the optimized kernel functions to obtain optimal SVR parameter by PSO. To quantify the quality of the predictor, its generalization performance and execution speed are investigated based on statistical learning theory. In addition, experiments using synthetic data as well as the stock volume weighted average price are reported to demonstrate the effectiveness of the developed models. The experimental results show that the proposed PSO-ISVR predictor can improve the computational efficiency and the overall prediction accuracy compared with the results produced by the SVR and other regression methods. The proposed PSO-ISVR provides an important tool for nonlinear regression analysis of big data.",4
Mixed H-Infinity and Passive Filtering for Discrete Fuzzy Neural Networks With Stochastic Jumps and Time Delays.,"In this brief, the problems of the mixed H-infinity and passivity performance analysis and design are investigated for discrete time-delay neural networks with Markovian jump parameters represented by Takagi-Sugeno fuzzy model. The main purpose of this brief is to design a filter to guarantee that the augmented Markovian jump fuzzy neural networks are stable in mean-square sense and satisfy a prescribed passivity performance index by employing the Lyapunov method and the stochastic analysis technique. Applying the matrix decomposition techniques, sufficient conditions are provided for the solvability of the problems, which can be formulated in terms of linear matrix inequalities. A numerical example is also presented to illustrate the effectiveness of the proposed techniques.",4
Finite-Time Consensus of Multiagent Systems With a Switching Protocol.,"In this paper, we study the problem of finite-time consensus of multiagent systems on a fixed directed interaction graph with a new protocol. Existing finite-time consensus protocols can be divided into two types: 1) continuous and 2) discontinuous, which were studied separately in the past. In this paper, we deal with both continuous and discontinuous protocols simultaneously, and design a centralized switching consensus protocol such that the finite-time consensus can be realized in a fast speed. The switching protocol depends on the range of the initial disagreement of the agents, for which we derive an exact bound to indicate at what time a continuous or a discontinuous protocol should be selected to use. Finally, we provide two numerical examples to illustrate the superiority of the proposed protocol and design method.",4
An Asynchronous Recurrent Network of Cellular Automaton-Based Neurons and Its Reproduction of Spiking Neural Network Activities.,"Modeling and implementation approaches for the reproduction of input-output relationships in biological nervous tissues contribute to the development of engineering and clinical applications. However, because of high nonlinearity, the traditional modeling and implementation approaches encounter difficulties in terms of generalization ability (i.e., performance when reproducing an unknown data set) and computational resources (i.e., computation time and circuit elements). To overcome these difficulties, asynchronous cellular automaton-based neuron (ACAN) models, which are described as special kinds of cellular automata that can be implemented as small asynchronous sequential logic circuits have been proposed. This paper presents a novel type of such ACAN and a theoretical analysis of its excitability. This paper also presents a novel network of such neurons, which can mimic input-output relationships of biological and nonlinear ordinary differential equation model neural networks. Numerical analyses confirm that the presented network has a higher generalization ability than other major modeling and implementation approaches. In addition, Field-Programmable Gate Array-implementations confirm that the presented network requires lower computational resources.",4
Robust Gradient Learning With Applications.,"This paper addresses the robust gradient learning (RGL) problem. Gradient learning models aim at learning the gradient vector of some target functions in supervised learning problems, which can be further used to applications, such as variable selection, coordinate covariance estimation, and supervised dimension reduction. However, existing GL models are not robust to outliers or heavy-tailed noise. This paper provides an RGL framework to address this problem in both regression and classification. This is achieved by introducing a robust regression loss function and proposing a robust classification loss. Moreover, our RGL algorithm works in an instance-based kernelized dictionary instead of some fixed reproducing kernel Hilbert space, which may provide more flexibility. To solve the proposed nonconvex model, a simple computational algorithm based on gradient descent is provided and the convergence of the proposed method is also analyzed. We then apply the proposed RGL model to applications, such as nonlinear variable selection and coordinate covariance estimation. The efficiency of our proposed model is verified on both synthetic and real data sets.",4
Asymptotic Normality of the Maximum Pseudolikelihood Estimator for Fully Visible Boltzmann Machines.,"Boltzmann machines (BMs) are a class of binary neural networks for which there have been numerous proposed methods of estimation. Recently, it has been shown that in the fully visible case of the BM, the method of maximum pseudolikelihood estimation (MPLE) results in parameter estimates, which are consistent in the probabilistic sense. In this brief, we investigate the properties of MPLE for the fully visible BMs further, and prove that MPLE also yields an asymptotically normal parameter estimator. These results can be used to construct confidence intervals and to test statistical hypotheses. These constructions provide a closed-form alternative to the current methods that require Monte Carlo simulation or resampling. We support our theoretical results by showing that the estimator behaves as expected in simulation studies.",4
Synchronization of Neural Networks With Control Packet Loss and Time-Varying Delay via Stochastic Sampled-Data Controller.,"This paper addresses the problem of exponential synchronization of neural networks with time-varying delays. A sampled-data controller with stochastically varying sampling intervals is considered. The novelty of this paper lies in the fact that the control packet loss from the controller to the actuator is considered, which may occur in many real-world situations. Sufficient conditions for the exponential synchronization in the mean square sense are derived in terms of linear matrix inequalities (LMIs) by constructing a proper Lyapunov-Krasovskii functional that involves more information about the delay bounds and by employing some inequality techniques. Moreover, the obtained LMIs can be easily checked for their feasibility through any of the available MATLAB tool boxes. Numerical examples are provided to validate the theoretical results.",4
A Projection Neural Network for Constrained Quadratic Minimax Optimization.,"This paper presents a projection neural network described by a dynamic system for solving constrained quadratic minimax programming problems. Sufficient conditions based on a linear matrix inequality are provided for global convergence of the proposed neural network. Compared with some of the existing neural networks for quadratic minimax optimization, the proposed neural network in this paper is capable of solving more general constrained quadratic minimax optimization problems, and the designed neural network does not include any parameter. Moreover, the neural network has lower model complexities, the number of state variables of which is equal to that of the dimension of the optimization problems. The simulation results on numerical examples are discussed to demonstrate the effectiveness and characteristics of the proposed neural network.",4
Low-Discrepancy Points for Deterministic Assignment of Hidden Weights in Extreme Learning Machines.,"The traditional extreme learning machine (ELM) approach is based on a random assignment of the hidden weight values, while the linear coefficients of the output layer are determined analytically. This brief presents an analysis based on geometric properties of the sampling points used to assign the weight values, investigating the replacement of random generation of such values with low-discrepancy sequences (LDSs). Such sequences are a family of sampling methods commonly employed for numerical integration, yielding a more efficient covering of multidimensional sets with respect to random sequences, without the need for any computationally intensive procedure. In particular, we prove that the universal approximation property of the ELM is guaranteed when LDSs are employed, and how an efficient covering affects the convergence positively. Furthermore, since LDSs are generated deterministically, the results do not have a probabilistic nature. Simulation results confirm, in practice, the good theoretical properties given by the combination of ELM with LDSs.",4
Extreme Learning Machine for Multilayer Perceptron.,"Extreme learning machine (ELM) is an emerging learning algorithm for the generalized single hidden layer feedforward neural networks, of which the hidden node parameters are randomly generated and the output weights are analytically computed. However, due to its shallow architecture, feature learning using ELM may not be effective for natural signals (e.g., images/videos), even with a large number of hidden nodes. To address this issue, in this paper, a new ELM-based hierarchical learning framework is proposed for multilayer perceptron. The proposed architecture is divided into two main components: 1) self-taught feature extraction followed by supervised feature classification and 2) they are bridged by random initialized hidden weights. The novelties of this paper are as follows: 1) unsupervised multilayer encoding is conducted for feature extraction, and an ELM-based sparse autoencoder is developed via l1 constraint. By doing so, it achieves more compact and meaningful feature representations than the original ELM; 2) by exploiting the advantages of ELM random feature mapping, the hierarchically encoded outputs are randomly projected before final decision making, which leads to a better generalization with faster learning speed; and 3) unlike the greedy layerwise training of deep learning (DL), the hidden layers of the proposed framework are trained in a forward manner. Once the previous layer is established, the weights of the current layer are fixed without fine-tuning. Therefore, it has much better learning efficiency than the DL. Extensive experiments on various widely used classification data sets show that the proposed algorithm achieves better and faster convergence than the existing state-of-the-art hierarchical learning methods. Furthermore, multiple applications in computer vision further confirm the generality and capability of the proposed learning scheme.",4
Sparse LSSVM in Primal Using Cholesky Factorization for Large-Scale Problems.,"For support vector machine (SVM) learning, least squares SVM (LSSVM), derived by duality LSSVM (D-LSSVM), is a widely used model, because it has an explicit solution. One obvious limitation of the model is that the solution lacks sparseness, which limits it from training large-scale problems efficiently. In this paper, we derive an equivalent LSSVM model in primal space LSSVM (P-LSSVM) by the representer theorem and prove that P-LSSVM can be solved exactly at some sparse solutions for problems with low-rank kernel matrices. Two algorithms are proposed for finding the sparse (approximate) solution of P-LSSVM by Cholesky factorization. One is based on the decomposition of the kernel matrix K as P P(T) with the best low-rank matrix P approximately by pivoting Cholesky factorization. The other is based on solving P-LSSVM by approximating the Cholesky factorization of the Hessian matrix with rank-one update scheme. For linear learning problems, theoretical analysis and experimental results support that P-LSSVM can give the sparsest solutions in all SVM learners. Experimental results on some large-scale nonlinear training problems show that our algorithms, based on P-LSSVM, can converge to acceptable test accuracies at very sparse solutions with a sparsity level <1%, and even as little as 0.01%. Hence, our algorithms are a better choice for large-scale training problems.",4
Successive overrelaxation for laplacian support vector machine.,"Semisupervised learning (SSL) problem, which makes use of both a large amount of cheap unlabeled data and a few unlabeled data for training, in the last few years, has attracted amounts of attention in machine learning and data mining. Exploiting the manifold regularization (MR), Belkin et al. proposed a new semisupervised classification algorithm: Laplacian support vector machines (LapSVMs), and have shown the state-of-the-art performance in SSL field. To further improve the LapSVMs, we proposed a fast Laplacian SVM (FLapSVM) solver for classification. Compared with the standard LapSVM, our method has several improved advantages as follows: 1) FLapSVM does not need to deal with the extra matrix and burden the computations related to the variable switching, which make it more suitable for large scale problems; 2) FLapSVM's dual problem has the same elegant formulation as that of standard SVMs. This means that the kernel trick can be applied directly into the optimization model; and 3) FLapSVM can be effectively solved by successive overrelaxation technology, which converges linearly to a solution and can process very large data sets that need not reside in memory. In practice, combining the strategies of random scheduling of subproblem and two stopping conditions, the computing speed of FLapSVM is rigidly quicker to that of LapSVM and it is a valid alternative to PLapSVM.",4
Model-Free Dual Heuristic Dynamic Programming.,"Model-based dual heuristic dynamic programming (MB-DHP) is a popular approach in approximating optimal solutions in control problems. Yet, it usually requires offline training for the model network, and thus resulting in extra computational cost. In this brief, we propose a model-free DHP (MF-DHP) design based on finite-difference technique. In particular, we adopt multilayer perceptron with one hidden layer for both the action and the critic networks design, and use delayed objective functions to train both the action and the critic networks online over time. We test both the MF-DHP and MB-DHP approaches with a discrete time example and a continuous time example under the same parameter settings. Our simulation results demonstrate that the MF-DHP approach can obtain a control performance competitive with that of the traditional MB-DHP approach while requiring less computational resources.",4
Finite-Time Consensus for Multiagent Systems With Cooperative and Antagonistic Interactions.,"This paper deals with finite-time consensus problems for multiagent systems that are subject to hybrid cooperative and antagonistic interactions. Two consensus protocols are constructed by employing the nearest neighbor rule. It is shown that under the presented protocols, the states of all agents can be guaranteed to reach an agreement in a finite time regarding consensus values that are the same in modulus but may not be the same in sign. In particular, the second protocol can enable all agents to reach a finite-time consensus with a settling time that is not dependent upon the initial states of agents. Simulation results are given to demonstrate the effectiveness and finite-time convergence of the proposed consensus protocols.",4
Approximate Orthogonal Sparse Embedding for Dimensionality Reduction.,"Locally linear embedding (LLE) is one of the most well-known manifold learning methods. As the representative linear extension of LLE, orthogonal neighborhood preserving projection (ONPP) has attracted widespread attention in the field of dimensionality reduction. In this paper, a unified sparse learning framework is proposed by introducing the sparsity or L1-norm learning, which further extends the LLE-based methods to sparse cases. Theoretical connections between the ONPP and the proposed sparse linear embedding are discovered. The optimal sparse embeddings derived from the proposed framework can be computed by iterating the modified elastic net and singular value decomposition. We also show that the proposed model can be viewed as a general model for sparse linear and nonlinear (kernel) subspace learning. Based on this general model, sparse kernel embedding is also proposed for nonlinear sparse feature extraction. Extensive experiments on five databases demonstrate that the proposed sparse learning framework performs better than the existing subspace learning algorithm, particularly in the cases of small sample sizes.",4
Robust Nonnegative Patch Alignment for Dimensionality Reduction.,"Dimensionality reduction is an important method to analyze high-dimensional data and has many applications in pattern recognition and computer vision. In this paper, we propose a robust nonnegative patch alignment for dimensionality reduction, which includes a reconstruction error term and a whole alignment term. We use correntropy-induced metric to measure the reconstruction error, in which the weight is learned adaptively for each entry. For the whole alignment, we propose locality-preserving robust nonnegative patch alignment (LP-RNA) and sparsity-preserviing robust nonnegative patch alignment (SP-RNA), which are unsupervised and supervised, respectively. In the LP-RNA, we propose a locally sparse graph to encode the local geometric structure of the manifold embedded in high-dimensional space. In particular, we select large p -nearest neighbors for each sample, then obtain the sparse representation with respect to these neighbors. The sparse representation is used to build a graph, which simultaneously enjoys locality, sparseness, and robustness. In the SP-RNA, we simultaneously use local geometric structure and discriminative information, in which the sparse reconstruction coefficient is used to characterize the local geometric structure and weighted distance is used to measure the separability of different classes. For the induced nonconvex objective function, we formulate it into a weighted nonnegative matrix factorization based on half-quadratic optimization. We propose a multiplicative update rule to solve this function and show that the objective function converges to a local optimum. Several experimental results on synthetic and real data sets demonstrate that the learned representation is more discriminative and robust than most existing dimensionality reduction methods.",4
Kernel-Based Least Squares Temporal Difference With Gradient Correction.,"A least squares temporal difference with gradient correction (LS-TDC) algorithm and its kernel-based version kernel-based LS-TDC (KLS-TDC) are proposed as policy evaluation algorithms for reinforcement learning (RL). LS-TDC is derived from the TDC algorithm. Attributed to TDC derived by minimizing the mean-square projected Bellman error, LS-TDC has better convergence performance. The least squares technique is used to omit the size-step tuning of the original TDC and enhance robustness. For KLS-TDC, since the kernel method is used, feature vectors can be selected automatically. The approximate linear dependence analysis is performed to realize kernel sparsification. In addition, a policy iteration strategy motivated by KLS-TDC is constructed to solve control learning problems. The convergence and parameter sensitivities of both LS-TDC and KLS-TDC are tested through on-policy learning, off-policy learning, and control learning problems. Experimental results, as compared with a series of corresponding RL algorithms, demonstrate that both LS-TDC and KLS-TDC have better approximation and convergence performance, higher efficiency for sample usage, smaller burden of parameter tuning, and less sensitivity to parameters.",4
Pinning Control Strategies for Synchronization of Linearly Coupled Neural Networks With Reaction-Diffusion Terms.,"Two types of coupled neural networks with reaction-diffusion terms are considered in this paper. In the first one, the nodes are coupled through their states. In the second one, the nodes are coupled through the spatial diffusion terms. For the former, utilizing Lyapunov functional method and pinning control technique, we obtain some sufficient conditions to guarantee that network can realize synchronization. In addition, considering that the theoretical coupling strength required for synchronization may be much larger than the needed value, we propose an adaptive strategy to adjust the coupling strength for achieving a suitable value. For the latter, we establish a criterion for synchronization using the designed pinning controllers. It is found that the coupled reaction-diffusion neural networks with state coupling under the given linear feedback pinning controllers can realize synchronization when the coupling strength is very large, which is contrary to the coupled reaction-diffusion neural networks with spatial diffusion coupling. Moreover, a general criterion for ensuring network synchronization is derived by pinning a small fraction of nodes with adaptive feedback controllers. Finally, two examples with numerical simulations are provided to demonstrate the effectiveness of the theoretical results.",4
Smart-Grid Backbone Network Real-Time Delay Reduction via Integer Programming.,"This research investigates an optimal delay-based virtual topology design using integer linear programming (ILP), which is applied to the current backbone networks such as smart-grid real-time communication systems. A network traffic matrix is applied and the corresponding virtual topology problem is solved using the ILP formulations that include a network delay-dependent objective function and lightpath routing, wavelength assignment, wavelength continuity, flow routing, and traffic loss constraints. The proposed optimization approach provides an efficient deterministic integration of intelligent sensing and decision making, and network learning features for superior smart grid operations by adaptively responding the time-varying network traffic data as well as operational constraints to maintain optimal virtual topologies. A representative optical backbone network has been utilized to demonstrate the proposed optimization framework whose simulation results indicate that superior smart-grid network performance can be achieved using commercial networks and integer programming.",4
The Kernel Adaptive Autoregressive-Moving-Average Algorithm.,"In this paper, we present a novel kernel adaptive recurrent filtering algorithm based on the autoregressive-moving-average (ARMA) model, which is trained with recurrent stochastic gradient descent in the reproducing kernel Hilbert spaces. This kernelized recurrent system, the kernel adaptive ARMA (KAARMA) algorithm, brings together the theories of adaptive signal processing and recurrent neural networks (RNNs), extending the current theory of kernel adaptive filtering (KAF) using the representer theorem to include feedback. Compared with classical feedforward KAF methods, the KAARMA algorithm provides general nonlinear solutions for complex dynamical systems in a state-space representation, with a deferred teacher signal, by propagating forward the hidden states. We demonstrate its capabilities to provide exact solutions with compact structures by solving a set of benchmark nondeterministic polynomial-complete problems involving grammatical inference. Simulation results show that the KAARMA algorithm outperforms equivalent input-space recurrent architectures using first- and second-order RNNs, demonstrating its potential as an effective learning solution for the identification and synthesis of deterministic finite automata.",4
Perception Evolution Network Based on Cognition Deepening Model--Adapting to the Emergence of New Sensory Receptor.,"The proposed perception evolution network (PEN) is a biologically inspired neural network model for unsupervised learning and online incremental learning. It is able to automatically learn suitable prototypes from learning data in an incremental way, and it does not require the predefined prototype number or the predefined similarity threshold. Meanwhile, being more advanced than the existing unsupervised neural network model, PEN permits the emergence of a new dimension of perception in the perception field of the network. When a new dimension of perception is introduced, PEN is able to integrate the new dimensional sensory inputs with the learned prototypes, i.e., the prototypes are mapped to a high-dimensional space, which consists of both the original dimension and the new dimension of the sensory inputs. In the experiment, artificial data and real-world data are used to test the proposed PEN, and the results show that PEN can work effectively.",4
Adaptive Neural Output Feedback Control of Output-Constrained Nonlinear Systems With Unknown Output Nonlinearity.,"This paper addresses the problem of adaptive neural output-feedback control for a class of special nonlinear systems with the hysteretic output mechanism and the unmeasured states. A modified Bouc-Wen model is first employed to capture the output hysteresis phenomenon in the design procedure. For its fusion with the neural networks and the Nussbaum-type function, two key lemmas are established using some extended properties of this model. To avoid the bad system performance caused by the output nonlinearity, a barrier Lyapunov function technique is introduced to guarantee the prescribed constraint of the tracking error. In addition, a robust filtering method is designed to cancel the restriction that all the system states require to be measured. Based on the Lyapunov synthesis, a new neural adaptive controller is constructed to guarantee the prescribed convergence of the tracking error and the semiglobal uniform ultimate boundedness of all the signals in the closed-loop system. Simulations are implemented to evaluate the performance of the proposed neural control algorithm in this paper.",4
A New Stochastic Computing Methodology for Efficient Neural Network Implementation.,"This paper presents a new methodology for the hardware implementation of neural networks (NNs) based on probabilistic laws. The proposed encoding scheme circumvents the limitations of classical stochastic computing (based on unipolar or bipolar encoding) extending the representation range to any real number using the ratio of two bipolar-encoded pulsed signals. Furthermore, the novel approach presents practically a total noise-immunity capability due to its specific codification. We introduce different designs for building the fundamental blocks needed to implement NNs. The validity of the present approach is demonstrated through a regression and a pattern recognition task. The low cost of the methodology in terms of hardware, along with its capacity to implement complex mathematical functions (such as the hyperbolic tangent), allows its use for building highly reliable systems and parallel computing.",4
Relevance Vector Machine for Survival Analysis.,"An accelerated failure time (AFT) model has been widely used for the analysis of censored survival or failure time data. However, the AFT imposes the restrictive log-linear relation between the survival time and the explanatory variables. In this paper, we introduce a relevance vector machine survival (RVMS) model based on Weibull AFT model that enables the use of kernel framework to automatically learn the possible nonlinear effects of the input explanatory variables on target survival times. We take advantage of the Bayesian inference technique in order to estimate the model parameters. We also introduce two approaches to accelerate the RVMS training. In the first approach, an efficient smooth prior is employed that improves the degree of sparsity. In the second approach, a fast marginal likelihood maximization procedure is used for obtaining a sparse solution of survival analysis task by sequential addition and deletion of candidate basis functions. These two approaches, denoted by smooth RVMS and fast RVMS, typically use fewer basis functions than RVMS and improve the RVMS training time; however, they cause a slight degradation in the RVMS performance. We compare the RVMS and the two accelerated approaches with the previous sparse kernel survival analysis method on a synthetic data set as well as six real-world data sets. The proposed kernel survival analysis models have been discovered to be more accurate in prediction, although they benefit from extra sparsity. The main advantages of our proposed models are: 1) extra sparsity that leads to a better generalization and avoids overfitting; 2) automatic relevance sample determination based on data that provide more accuracy, in particular for highly censored survival data; and 3) flexibility to utilize arbitrary number and types of kernel functions (e.g., non-Mercer kernels and multikernel learning).",4
Two Machine Learning Approaches for Short-Term Wind Speed Time-Series Prediction.,"The increasing liberalization of European electricity markets, the growing proportion of intermittent renewable energy being fed into the energy grids, and also new challenges in the patterns of energy consumption (such as electric mobility) require flexible and intelligent power grids capable of providing efficient, reliable, economical, and sustainable energy production and distribution. From the supplier side, particularly, the integration of renewable energy sources (e.g., wind and solar) into the grid imposes an engineering and economic challenge because of the limited ability to control and dispatch these energy sources due to their intermittent characteristics. Time-series prediction of wind speed for wind power production is a particularly important and challenging task, wherein prediction intervals (PIs) are preferable results of the prediction, rather than point estimates, because they provide information on the confidence in the prediction. In this paper, two different machine learning approaches to assess PIs of time-series predictions are considered and compared: 1) multilayer perceptron neural networks trained with a multiobjective genetic algorithm and 2) extreme learning machines combined with the nearest neighbors approach. The proposed approaches are applied for short-term wind speed prediction from a real data set of hourly wind speed measurements for the region of Regina in Saskatchewan, Canada. Both approaches demonstrate good prediction precision and provide complementary advantages with respect to different evaluation criteria.",4
DC Proximal Newton for Nonconvex Optimization Problems.,We introduce a novel algorithm for solving learning problems where both the loss function and the regularizer are nonconvex but belong to the class of difference of convex (DC) functions. Our contribution is a new general purpose proximal Newton algorithm that is able to deal with such a situation. The algorithm consists in obtaining a descent direction from an approximation of the loss function and then in performing a line search to ensure a sufficient descent. A theoretical analysis is provided showing that the iterates of the proposed algorithm admit as limit points stationary points of the DC objective function. Numerical experiments show that our approach is more efficient than the current state of the art for a problem with a convex loss function and a nonconvex regularizer. We have also illustrated the benefit of our algorithm in high-dimensional transductive learning problem where both the loss function and regularizers are nonconvex.,4
Generating Highly Accurate Predictions for Missing QoS Data via Aggregating Nonnegative Latent Factor Models.,"Automatic Web-service selection is an important research topic in the domain of service computing. During this process, reliable predictions for quality of service (QoS) based on historical service invocations are vital to users. This work aims at making highly accurate predictions for missing QoS data via building an ensemble of nonnegative latent factor (NLF) models. Its motivations are: 1) the fulfillment of nonnegativity constraints can better represent the positive value nature of QoS data, thereby boosting the prediction accuracy and 2) since QoS prediction is a learning task, it is promising to further improve the prediction accuracy with a carefully designed ensemble model. To achieve this, we first implement an NLF model for QoS prediction. This model is then diversified through feature sampling and randomness injection to form a diversified NLF model, based on which an ensemble is built. Comparison results between the proposed ensemble and several widely employed and state-of-the-art QoS predictors on two large, real data sets demonstrate that the former can outperform the latter well in terms of prediction accuracy.",4
QoS Differential Scheduling in Cognitive-Radio-Based Smart Grid Networks: An Adaptive Dynamic Programming Approach.,"As the next-generation power grid, smart grid will be integrated with a variety of novel communication technologies to support the explosive data traffic and the diverse requirements of quality of service (QoS). Cognitive radio (CR), which has the favorable ability to improve the spectrum utilization, provides an efficient and reliable solution for smart grid communications networks. In this paper, we study the QoS differential scheduling problem in the CR-based smart grid communications networks. The scheduler is responsible for managing the spectrum resources and arranging the data transmissions of smart grid users (SGUs). To guarantee the differential QoS, the SGUs are assigned to have different priorities according to their roles and their current situations in the smart grid. Based on the QoS-aware priority policy, the scheduler adjusts the channels allocation to minimize the transmission delay of SGUs. The entire transmission scheduling problem is formulated as a semi-Markov decision process and solved by the methodology of adaptive dynamic programming. A heuristic dynamic programming (HDP) architecture is established for the scheduling problem. By the online network training, the HDP can learn from the activities of primary users and SGUs, and adjust the scheduling decision to achieve the purpose of transmission delay minimization. Simulation results illustrate that the proposed priority policy ensures the low transmission delay of high priority SGUs. In addition, the emergency data transmission delay is also reduced to a significantly low level, guaranteeing the differential QoS in smart grid.",4
A Combined Adaptive Neural Network and Nonlinear Model Predictive Control for Multirate Networked Industrial Process Control.,"This paper investigates the multirate networked industrial process control problem in double-layer architecture. First, the output tracking problem for sampled-data nonlinear plant at device layer with sampling period T(d) is investigated using adaptive neural network (NN) control, and it is shown that the outputs of subsystems at device layer can track the decomposed setpoints. Then, the outputs and inputs of the device layer subsystems are sampled with sampling period T(u) at operation layer to form the index prediction, which is used to predict the overall performance index at lower frequency. Radial basis function NN is utilized as the prediction function due to its approximation ability. Then, considering the dynamics of the overall closed-loop system, nonlinear model predictive control method is proposed to guarantee the system stability and compensate the network-induced delays and packet dropouts. Finally, a continuous stirred tank reactor system is given in the simulation part to demonstrate the effectiveness of the proposed method.",4
Mirror Inverse Operations in Linear Nearest Neighbors Using Dynamic Learning Algorithm.,"We propose a new method to implement mirror inverse gate operations in 1-D linear nearest neighbor (LNN) array coupled through diagonal interactions, using a dynamic learning algorithm. This is accomplished by training a quantum system using a backpropagation technique, to find the parameters of the system Hamiltonian that implement the mirror inverse operation. We show how the training algorithm can be used as a tool for finding the parameters for implementing mirror inverse operations in LNN systems with increasing number of qubits. The key feature of our scheme is that once we find the system parameters using the learning algorithm, mirror inversion (MI) is accomplished simply by tuning the system parameters to these values and allowing the system to evolve for a chosen time interval. To validate our scheme, we compare our results against known results for an LNN system coupled through XY interactions. We also show how the scheme can be used to implement MI operations in the presence of unwanted couplings.",4
Variational inference with ARD prior for NIRS diffuse optical tomography.,"Diffuse optical tomography (DOT) reconstructs 3-D tomographic images of brain activities from observations by near-infrared spectroscopy (NIRS) that is formulated as an ill-posed inverse problem. This brief presents a method for NIRS DOT based on a hierarchical Bayesian approach introducing the automatic relevance determination prior and the variational Bayes technique. Although the sparseness of the estimation strongly depends on the hyperparameters, in general, our method has less dependency on the hyperparameters. We confirm through numerical experiments that a schematic phase diagram of sparseness with respect to the hyperparameters has two regions: in one region hyperparameters give sparse solutions and in the other they give dense ones. The experimental results are supported by our theoretical analyses in simple cases.",4
Semi-supervised nearest mean classification through a constrained log-likelihood.,"We cast a semi-supervised nearest mean classifier, previously introduced by the first author, in a more principled log-likelihood formulation that is subject to constraints. This, in turn, leads us to make the important suggestion to not only investigate error rates of semi-supervised learners but also consider the risk they originally aim to optimize. We demonstrate empirically that in terms of classification error, mixed results are obtained when comparing supervised to semi-supervised nearest mean classification, while in terms of log-likelihood on the test set, the semi-supervised method consistently outperforms its supervised counterpart. Comparisons to self-learning, a standard approach in semi-supervised learning, are included to further clarify the way, in which our constrained nearest mean classifier improves over regular, supervised nearest mean classification.",4
The minimum risk principle that underlies the criteria of bounded component analysis.,"This paper studies the problem of the blind extraction of a subset of bounded component signals from the observations of a linear mixture. In the first part of this paper, we analyze the geometric assumptions of the observations that characterize the problem, and their implications on the mixing matrix and latent sources. In the second part, we solve the problem by adopting the principle of minimizing the risk, which refers to the encoding complexity of the observations in the worst admissible situation. This principle provides an underlying justification of several bounded component analysis (BCA) criteria, including the minimum normalized volume criterion of the estimated sources or the maximum negentropy-likelihood criterion with a uniform reference model for the estimated sources. This unifying framework can explain the differences between the criteria in accordance with their considered hypotheses for the model of the observations. This paper is first presented for the case of the extraction of a complex and multidimensional source, and later is particularized for the case of the extraction of subsets of 1-D complex sources. The results also hold true in the case of real signals, where the obtained criteria for the extraction of a set of 1-D sources usually coincide with the existing BCA criteria.",4
Graph embedded nonparametric mutual information for supervised dimensionality reduction.,"In this paper, we propose a novel algorithm for dimensionality reduction that uses as a criterion the mutual information (MI) between the transformed data and their corresponding class labels. The MI is a powerful criterion that can be used as a proxy to the Bayes error rate. Furthermore, recent quadratic nonparametric implementations of MI are computationally efficient and do not require any prior assumptions about the class densities. We show that the quadratic nonparametric MI can be formulated as a kernel objective in the graph embedding framework. Moreover, we propose its linear equivalent as a novel linear dimensionality reduction algorithm. The derived methods are compared against the state-of-the-art dimensionality reduction algorithms with various classifiers and on various benchmark and real-life datasets. The experimental results show that nonparametric MI as an optimization objective for dimensionality reduction gives comparable and in most of the cases better results compared with other dimensionality reduction methods.",4
Variable neural adaptive robust control: a switched system approach.,Variable neural adaptive robust control strategies are proposed for the output tracking control of a class of multiinput multioutput uncertain systems. The controllers incorporate a novel variable-structure radial basis function (RBF) network as the self-organizing approximator for unknown system dynamics. It can determine the network structure online dynamically by adding or removing RBFs according to the tracking performance. The structure variation is systematically considered in the stability analysis of the closed-loop system using a switched system approach with the piecewise quadratic Lyapunov function. The performance of the proposed variable neural adaptive robust controllers is illustrated with simulations.,4
Self-organizing neural networks integrating domain knowledge and reinforcement learning.,"The use of domain knowledge in learning systems is expected to improve learning efficiency and reduce model complexity. However, due to the incompatibility with knowledge structure of the learning systems and real-time exploratory nature of reinforcement learning (RL), domain knowledge cannot be inserted directly. In this paper, we show how self-organizing neural networks designed for online and incremental adaptation can integrate domain knowledge and RL. Specifically, symbol-based domain knowledge is translated into numeric patterns before inserting into the self-organizing neural networks. To ensure effective use of domain knowledge, we present an analysis of how the inserted knowledge is used by the self-organizing neural networks during RL. To this end, we propose a vigilance adaptation and greedy exploitation strategy to maximize exploitation of the inserted domain knowledge while retaining the plasticity of learning and using new knowledge. Our experimental results based on the pursuit-evasion and minefield navigation problem domains show that such self-organizing neural network can make effective use of domain knowledge to improve learning efficiency and reduce model complexity.",4
Entropic One-Class Classifiers.,"The one-class classification problem is a well-known research endeavor in pattern recognition. The problem is also known under different names, such as outlier and novelty/anomaly detection. The core of the problem consists in modeling and recognizing patterns belonging only to a so-called target class. All other patterns are termed nontarget, and therefore, they should be recognized as such. In this paper, we propose a novel one-class classification system that is based on an interplay of different techniques. Primarily, we follow a dissimilarity representation-based approach; we embed the input data into the dissimilarity space (DS) by means of an appropriate parametric dissimilarity measure. This step allows us to process virtually any type of data. The dissimilarity vectors are then represented by weighted Euclidean graphs, which we use to determine the entropy of the data distribution in the DS and at the same time to derive effective decision regions that are modeled as clusters of vertices. Since the dissimilarity measure for the input data is parametric, we optimize its parameters by means of a global optimization scheme, which considers both mesoscopic and structural characteristics of the data represented through the graphs. The proposed one-class classifier is designed to provide both hard (Boolean) and soft decisions about the recognition of test patterns, allowing an accurate description of the classification process. We evaluate the performance of the system on different benchmarking data sets, containing either feature-based or structured patterns. Experimental results demonstrate the effectiveness of the proposed technique.",4
A Spiking Neural Network System for Robust Sequence Recognition.,"This paper proposes a biologically plausible network architecture with spiking neurons for sequence recognition. This architecture is a unified and consistent system with functional parts of sensory encoding, learning, and decoding. This is the first systematic model attempting to reveal the neural mechanisms considering both the upstream and the downstream neurons together. The whole system is a consistent temporal framework, where the precise timing of spikes is employed for information processing and cognitive computing. Experimental results show that the system is competent to perform the sequence recognition, being robust to noisy sensory inputs and invariant to changes in the intervals between input stimuli within a certain range. The classification ability of the temporal learning rule used in the system is investigated through two benchmark tasks that outperform the other two widely used learning rules for classification. The results also demonstrate the computational power of spiking neurons over perceptrons for processing spatiotemporal patterns. In summary, the system provides a general way with spiking neurons to encode external stimuli into spatiotemporal spikes, to learn the encoded spike patterns with temporal learning rules, and to decode the sequence order with downstream neurons. The system structure would be beneficial for developments in both hardware and software.",4
Neural Network-Based Event-Triggered State Feedback Control of Nonlinear Continuous-Time Systems.,"This paper presents a novel approximation-based event-triggered control of multi-input multi-output uncertain nonlinear continuous-time systems in affine form. The controller is approximated using a linearly parameterized neural network (NN) in the context of event-based sampling. After revisiting the NN approximation property in the context of event-based sampling, an event-triggered condition is proposed using the Lyapunov technique to reduce the network resource utilization and to generate the required number of events for the NN approximation. In addition, a novel weight update law for aperiodic tuning of the NN weights at triggered instants is proposed to relax the knowledge of complete system dynamics and to reduce the computation when compared with the traditional NN-based control. Nonetheless, a nonzero positive lower bound for the inter-event times is guaranteed to avoid the accumulation of events or Zeno behavior. For analyzing the stability, the event-triggered system is modeled as a nonlinear impulsive dynamical system and the Lyapunov technique is used to show local ultimate boundedness of all signals. Furthermore, in order to overcome the unnecessary triggered events when the system states are inside the ultimate bound, a dead-zone operator is used to reset the event-trigger errors to zero. Finally, the analytical design is substantiated with numerical results.",4
Global Exponential Stability for Complex-Valued Recurrent Neural Networks With Asynchronous Time Delays.,"In this paper, we investigate the global exponential stability for complex-valued recurrent neural networks with asynchronous time delays by decomposing complex-valued networks to real and imaginary parts and construct an equivalent real-valued system. The network model is described by a continuous-time equation. There are two main differences of this paper with previous works: 1) time delays can be asynchronous, i.e., delays between different nodes are different, which make our model more general and 2) we prove the exponential convergence directly, while the existence and uniqueness of the equilibrium point is just a direct consequence of the exponential convergence. Using three generalized norms, we present some sufficient conditions for the uniqueness and global exponential stability of the equilibrium point for delayed complex-valued neural networks. These conditions in our results are less restrictive because of our consideration of the excitatory and inhibitory effects between neurons; so previous works of other researchers can be extended. Finally, some numerical simulations are given to demonstrate the correctness of our obtained results.",4
Comparison of Seven Methods for Boolean Factor Analysis and Their Evaluation by Information Gain.,"An usual task in large data set analysis is searching for an appropriate data representation in a space of fewer dimensions. One of the most efficient methods to solve this task is factor analysis. In this paper, we compare seven methods for Boolean factor analysis (BFA) in solving the so-called bars problem (BP), which is a BFA benchmark. The performance of the methods is evaluated by means of information gain. Study of the results obtained in solving BP of different levels of complexity has allowed us to reveal strengths and weaknesses of these methods. It is shown that the Likelihood maximization Attractor Neural Network with Increasing Activity (LANNIA) is the most efficient BFA method in solving BP in many cases. Efficacy of the LANNIA method is also shown, when applied to the real data from the Kyoto Encyclopedia of Genes and Genomes database, which contains full genome sequencing for 1368 organisms, and to text data set R52 (from Reuters 21578) typically used for label categorization.",4
Hierarchical Theme and Topic Modeling.,"Considering the hierarchical data groupings in text corpus, e.g., words, sentences, and documents, we conduct the structural learning and infer the latent themes and topics for sentences and words from a collection of documents, respectively. The relation between themes and topics under different data groupings is explored through an unsupervised procedure without limiting the number of clusters. A tree stick-breaking process is presented to draw theme proportions for different sentences. We build a hierarchical theme and topic model, which flexibly represents the heterogeneous documents using Bayesian nonparametrics. Thematic sentences and topical words are extracted. In the experiments, the proposed method is evaluated to be effective to build semantic tree structure for sentences and the corresponding words. The superiority of using tree model for selection of expressive sentences for document summarization is illustrated.",4
Shape-Constrained Sparse and Low-Rank Decomposition for Auroral Substorm Detection.,"An auroral substorm is an important geophysical phenomenon that reflects the interaction between the solar wind and the Earth's magnetosphere. Detecting substorms is of practical significance in order to prevent disruption to communication and global positioning systems. However, existing detection methods can be inaccurate or require time-consuming manual analysis and are therefore impractical for large-scale data sets. In this paper, we propose an automatic auroral substorm detection method based on a shape-constrained sparse and low-rank decomposition (SCSLD) framework. Our method automatically detects real substorm onsets in large-scale aurora sequences, which overcomes the limitations of manual detection. To reduce noise interference inherent in current SLD methods, we introduce a shape constraint to force the noise to be assigned to the low-rank part (stationary background), thus ensuring the accuracy of the sparse part (moving object) and improving the performance. Experiments conducted on aurora sequences in solar cycle 23 (1996-2008) show that the proposed SCSLD method achieves good performance for motion analysis of aurora sequences. Moreover, the obtained results are highly consistent with manual analysis, suggesting that the proposed automatic method is useful and effective in practice.",4
Learning a Tracking and Estimation Integrated Graphical Model for Human Pose Tracking.,"We investigate the tracking of 2-D human poses in a video stream to determine the spatial configuration of body parts in each frame, but this is not a trivial task because people may wear different kinds of clothing and may move very quickly and unpredictably. The technology of pose estimation is typically applied, but it ignores the temporal context and cannot provide smooth, reliable tracking results. Therefore, we develop a tracking and estimation integrated model (TEIM) to fully exploit temporal information by integrating pose estimation with visual tracking. However, joint parsing of multiple articulated parts over time is difficult, because a full model with edges capturing all pairwise relationships within and between frames is loopy and intractable. In previous models, approximate inference was usually resorted to, but it cannot promise good results and the computational cost is large. We overcome these problems by exploring the idea of divide and conquer, which decomposes the full model into two much simpler tractable submodels. In addition, a novel two-step iteration strategy is proposed to efficiently conquer the joint parsing problem. Algorithmically, we design TEIM very carefully so that: 1) it enables pose estimation and visual tracking to compensate for each other to achieve desirable tracking results; 2) it is able to deal with the problem of tracking loss; and 3) it only needs past information and is capable of tracking online. Experiments are conducted on two public data sets in the wild with ground truth layout annotations, and the experimental results indicate the effectiveness of the proposed TEIM framework.",4
Synchronization and State Estimation of a Class of Hierarchical Hybrid Neural Networks With Time-Varying Delays.,"This paper addresses the problems of synchronization and state estimation for a class of discrete-time hierarchical hybrid neural networks (NNs) with time-varying delays. The hierarchical hybrid feature consists of a higher level nondeterministic switching and a lower level stochastic switching. The latter is used to describe the NNs subject to Markovian modes transitions, whereas the former is of the average dwell-time switching regularity to model the supervisory orchestrating mechanism among these Markov jump NNs. The considered time delays are not only time-varying but also dependent on the mode of NNs on the lower layer in the hierarchical structure. Despite quantization and random data missing, the synchronized controllers and state estimators are designed such that the resulting error system is exponentially stable with an expected decay rate and has a prescribed Hinfinity disturbance attenuation level. Two numerical examples are provided to show the validity and potential of the developed results.",4
Observer-Based Adaptive Neural Network Control for Nonlinear Systems in Nonstrict-Feedback Form.,"This paper focuses on the problem of adaptive neural network (NN) control for a class of nonlinear nonstrict-feedback systems via output feedback. A novel adaptive NN backstepping output-feedback control approach is first proposed for nonlinear nonstrict-feedback systems. The monotonicity of system bounding functions and the structure character of radial basis function (RBF) NNs are used to overcome the difficulties that arise from nonstrict-feedback structure. A state observer is constructed to estimate the immeasurable state variables. By combining adaptive backstepping technique with approximation capability of radial basis function NNs, an output-feedback adaptive NN controller is designed through backstepping approach. It is shown that the proposed controller guarantees semiglobal boundedness of all the signals in the closed-loop systems. Two examples are used to illustrate the effectiveness of the proposed approach.",4
Robust Adaptive Neural Tracking Control for a Class of Stochastic Nonlinear Interconnected Systems.,"In this paper, an adaptive neural decentralized control approach is proposed for a class of multiple input and multiple output uncertain stochastic nonlinear strong interconnected systems. Radial basis function neural networks are used to approximate the packaged unknown nonlinearities, and backstepping technique is utilized to construct an adaptive neural decentralized controller. The proposed control scheme can guarantee that all signals of the resulting closed-loop system are semiglobally uniformly ultimately bounded in the sense of fourth moment, and the tracking errors eventually converge to a small neighborhood around the origin. The main feature of this paper is that the proposed approach is capable of controlling the stochastic systems with strong interconnected nonlinearities both in the drift and diffusion terms that are the functions of all states of the overall system. Simulation results are used to illustrate the effectiveness of the suggested approach.",4
Learning Subspace-Based RBFNN Using Coevolutionary Algorithm for Complex Classification Tasks.,"Many real-world classification problems are characterized by samples of a complex distribution in the input space. The classification accuracy is determined by intrinsic properties of all samples in subspaces of features. This paper proposes a novel algorithm for the construction of radial basis function neural network (RBFNN) classifier based on subspace learning. In this paper, feature subspaces are obtained for every hidden node of the RBFNN during the learning process. The connection weights between the input layer and the hidden layer are adjusted to produce various subspaces with dominative features for different hidden nodes. The network structure and dominative features are encoded in two subpopulations that are cooperatively coevolved using the coevolutionary algorithm to achieve a better global optimality for the estimated RBFNN. Experimental results illustrate that the proposed algorithm is able to obtain RBFNN models with both better classification accuracy and simpler network structure when compared with other learning algorithms. Thus, the proposed model provides a more flexible and efficient approach to complex classification tasks by employing the local characteristics of samples in subspaces.",4
Optimal Communication Network-Based Hinfinity Quantized Control With Packet Dropouts for a Class of Discrete-Time Neural Networks With Distributed Time Delay.,"This paper is concerned with optimal communication network-based Hinfinity quantized control for a discrete-time neural network with distributed time delay. Control of the neural network (plant) is implemented via a communication network. Both quantization and communication network-induced data packet dropouts are considered simultaneously. It is assumed that the plant state signal is quantized by a logarithmic quantizer before transmission, and communication network-induced packet dropouts can be described by a Bernoulli distributed white sequence. A new approach is developed such that controller design can be reduced to the feasibility of linear matrix inequalities, and a desired optimal control gain can be derived in an explicit expression. It is worth pointing out that some new techniques based on a new sector-like expression of quantization errors, and the singular value decomposition of a matrix are developed and employed in the derivation of main results. An illustrative example is presented to show the effectiveness of the obtained results.",4
A Bias and Variance Analysis for Multistep-Ahead Time Series Forecasting.,"Multistep-ahead forecasts can either be produced recursively by iterating a one-step-ahead time series model or directly by estimating a separate model for each forecast horizon. In addition, there are other strategies; some of them combine aspects of both aforementioned concepts. In this paper, we present a comprehensive investigation into the bias and variance behavior of multistep-ahead forecasting strategies. We provide a detailed review of the different multistep-ahead strategies. Subsequently, we perform a theoretical study that derives the bias and variance for a number of forecasting strategies. Finally, we conduct a Monte Carlo experimental study that compares and evaluates the bias and variance performance of the different strategies. From the theoretical and the simulation studies, we analyze the effect of different factors, such as the forecast horizon and the time series length, on the bias and variance components, and on the different multistep-ahead strategies. Several lessons are learned, and recommendations are given concerning the advantages, disadvantages, and best conditions of use of each strategy.",4
Machine Learning Methods for Attack Detection in the Smart Grid.,"Attack detection problems in the smart grid are posed as statistical learning problems for different attack scenarios in which the measurements are observed in batch or online settings. In this approach, machine learning algorithms are used to classify measurements as being either secure or attacked. An attack detection framework is provided to exploit any available prior knowledge about the system and surmount constraints arising from the sparse structure of the problem in the proposed approach. Well-known batch and online learning algorithms (supervised and semisupervised) are employed with decision- and feature-level fusion to model the attack detection problem. The relationships between statistical and geometric properties of attack vectors employed in the attack scenarios and learning algorithms are analyzed to detect unobservable attacks using statistical learning methods. The proposed algorithms are examined on various IEEE test systems. Experimental analyses show that machine learning algorithms can detect attacks with performances higher than attack detection algorithms that employ state vector estimation methods in the proposed attack detection framework.",4
Data-Mining-Based Intelligent Differential Relaying for Transmission Lines Including UPFC and Wind Farms.,"This paper presents a data-mining-based intelligent differential relaying scheme for transmission lines, including flexible ac transmission system device, such as unified power flow controller (UPFC) and wind farms. Initially, the current and voltage signals are processed through extended Kalman filter phasor measurement unit for phasor estimation, and 21 potential features are computed at both ends of the line. Once the features are extracted at both ends, the corresponding differential features are derived. These differential features are fed to a data-mining model known as decision tree (DT) to provide the final relaying decision. The proposed technique has been extensively tested for single-circuit transmission line, including UPFC and wind farms with in-feed, double-circuit line with UPFC on one line and wind farm as one of the substations with wide variations in operating parameters. The test results obtained from simulation as well as in real-time digital simulator testing indicate that the DT-based intelligent differential relaying scheme is highly reliable and accurate with a response time of 2.25 cycles from the fault inception.",4
Finite-Horizon Near-Optimal Output Feedback Neural Network Control of Quantized Nonlinear Discrete-Time Systems With Input Constraint.,"The output feedback-based near-optimal regulation of uncertain and quantized nonlinear discrete-time systems in affine form with control constraint over finite horizon is addressed in this paper. First, the effect of input constraint is handled using a nonquadratic cost functional. Next, a neural network (NN)-based Luenberger observer is proposed to reconstruct both the system states and the control coefficient matrix so that a separate identifier is not needed. Then, approximate dynamic programming-based actor-critic framework is utilized to approximate the time-varying solution of the Hamilton-Jacobi-Bellman using NNs with constant weights and time-dependent activation functions. A new error term is defined and incorporated in the NN update law so that the terminal constraint error is also minimized over time. Finally, a novel dynamic quantizer for the control inputs with adaptive step size is designed to eliminate the quantization error overtime, thus overcoming the drawback of the traditional uniform quantizer. The proposed scheme functions in a forward-in-time manner without offline training phase. Lyapunov analysis is used to investigate the stability. Simulation results are given to show the effectiveness and feasibility of the proposed method.",4
Adaptive Position/Attitude Tracking Control of Aerial Robot With Unknown Inertial Matrix Based on a New Robust Neural Identifier.,"This paper presents a novel adaptive controller for controlling an autonomous helicopter with unknown inertial matrix to asymptotically track the desired trajectory. To identify the unknown inertial matrix included in the attitude dynamic model, this paper proposes a new structural identifier that differs from those previously proposed in that it additionally contains a neural networks (NNs) mechanism and a robust adaptive mechanism, respectively. Using the NNs to compensate the unknown aerodynamic forces online and the robust adaptive mechanism to cancel the combination of the overlarge NNs compensation error and the external disturbances, the new robust neural identifier exhibits a better identification performance in the complex flight environment. Moreover, an optimized algorithm is included in the NNs mechanism to alleviate the burdensome online computation. By the strict Lyapunov argument, the asymptotic convergence of the inertial matrix identification error, position tracking error, and attitude tracking error to arbitrarily small neighborhood of the origin is proved. The simulation and implementation results are provided to evaluate the performance of the proposed controller.",4
DL-ReSuMe: A Delay Learning-Based Remote Supervised Method for Spiking Neurons.,"Recent research has shown the potential capability of spiking neural networks (SNNs) to model complex information processing in the brain. There is biological evidence to prove the use of the precise timing of spikes for information coding. However, the exact learning mechanism in which the neuron is trained to fire at precise times remains an open problem. The majority of the existing learning methods for SNNs are based on weight adjustment. However, there is also biological evidence that the synaptic delay is not constant. In this paper, a learning method for spiking neurons, called delay learning remote supervised method (DL-ReSuMe), is proposed to merge the delay shift approach and ReSuMe-based weight adjustment to enhance the learning performance. DL-ReSuMe uses more biologically plausible properties, such as delay learning, and needs less weight adjustment than ReSuMe. Simulation results have shown that the proposed DL-ReSuMe approach achieves learning accuracy and learning speed improvements compared with ReSuMe.",4
Peaking-Free Output-Feedback Adaptive Neural Control Under a Nonseparation Principle.,"High-gain observers have been extensively applied to construct output-feedback adaptive neural control (ANC) for a class of feedback linearizable uncertain nonlinear systems under a nonlinear separation principle. Yet due to static-gain and linear properties, high-gain observers are usually subject to peaking responses and noise sensitivity. Existing adaptive neural network (NN) observers cannot effectively relax the limitations of high-gain observers. This paper presents an output-feedback indirect ANC strategy under a nonseparation principle, where a hybrid estimation scheme that integrates an adaptive NN observer with state variable filters is proposed to estimate plant states. By applying a single Lyapunov function candidate to the entire system, it is proved that the closed-loop system achieves practical asymptotic stability under a relatively low observer gain dominated by controller parameters. Our approach can completely avoid peaking responses without control saturation while keeping favourable noise rejection ability. Simulation results have shown effectiveness and superiority of this approach.",4
An Asynchronous Neuromorphic Event-Driven Visual Part-Based Shape Tracking.,"Object tracking is an important step in many artificial vision tasks. The current state-of-the-art implementations remain too computationally demanding for the problem to be solved in real time with high dynamics. This paper presents a novel real-time method for visual part-based tracking of complex objects from the output of an asynchronous event-based camera. This paper extends the pictorial structures model introduced by Fischler and Elschlager 40 years ago and introduces a new formulation of the problem, allowing the dynamic processing of visual input in real time at high temporal resolution using a conventional PC. It relies on the concept of representing an object as a set of basic elements linked by springs. These basic elements consist of simple trackers capable of successfully tracking a target with an ellipse-like shape at several kilohertz on a conventional computer. For each incoming event, the method updates the elastic connections established between the trackers and guarantees a desired geometric structure corresponding to the tracked object in real time. This introduces a high temporal elasticity to adapt to projective deformations of the tracked object in the focal plane. The elastic energy of this virtual mechanical system provides a quality criterion for tracking and can be used to determine whether the measured deformations are caused by the perspective projection of the perceived object or by occlusions. Experiments on real-world data show the robustness of the method in the context of dynamic face tracking.",4
Decentralized Output Feedback Adaptive NN Tracking Control for Time-Delay Stochastic Nonlinear Systems With Prescribed Performance.,"This paper studies the dynamic output feedback tracking control problem for stochastic interconnected time-delay systems with the prescribed performance. The subsystems are in the form of triangular structure. First, we design a reduced-order observer independent of time delay to estimate the unmeasured state variables online instead of the traditional full-order observer. Then, a new state transformation is proposed in consideration of the prescribed performance requirement. Using neural network to approximate the composite unknown nonlinear function, the corresponding decentralized output tracking controller is designed. It is strictly proved that the resulting closed-loop system is stable in probability in the sense of uniformly ultimately boundedness and that both transient-state and steady-state performances are preserved. Finally, a simulation example is given, and the result shows the effectiveness of the proposed control design method.",4
A bootstrap based Neyman-Pearson test for identifying variable importance.,"Selection of most informative features that leads to a small loss on future data are arguably one of the most important steps in classification, data analysis and model selection. Several feature selection (FS) algorithms are available; however, due to noise present in any data set, FS algorithms are typically accompanied by an appropriate cross-validation scheme. In this brief, we propose a statistical hypothesis test derived from the Neyman-Pearson lemma for determining if a feature is statistically relevant. The proposed approach can be applied as a wrapper to any FS algorithm, regardless of the FS criteria used by that algorithm, to determine whether a feature belongs in the relevant set. Perhaps more importantly, this procedure efficiently determines the number of relevant features given an initial starting point. We provide freely available software implementations of the proposed methodology.",4
"Robust consensus tracking control for multiagent systems with initial state shifts, disturbances, and switching topologies.","This paper deals with the consensus tracking control issues of multiagent systems and aims to solve them as accurately as possible over a finite time interval through an iterative learning approach. Based on the iterative rule, distributed algorithms are proposed for every agent using its nearest neighbor knowledge, for which the robustness problem is addressed against initial state shifts, disturbances, and switching topologies. These uncertainties are dynamically changing not only along the time axis but also the iteration axis. It is shown that the matrix norm conditions can be developed to achieve the convergence of the considered consensus tracking objectives, for which necessary and sufficient conditions are presented in terms of linear matrix inequalities to guarantee their feasibility in the sense of the spectral norm. Furthermore, simulation examples are given to illustrate the effectiveness and robustness of the obtained consensus tracking results.",4
Coupled attribute similarity learning on categorical data.,"Attribute independence has been taken as a major assumption in the limited research that has been conducted on similarity analysis for categorical data, especially unsupervised learning. However, in real-world data sources, attributes are more or less associated with each other in terms of certain coupling relationships. Accordingly, recent works on attribute dependency aggregation have introduced the co-occurrence of attribute values to explore attribute coupling, but they only present a local picture in analyzing categorical data similarity. This is inadequate for deep analysis, and the computational complexity grows exponentially when the data scale increases. This paper proposes an efficient data-driven similarity learning approach that generates a coupled attribute similarity measure for nominal objects with attribute couplings to capture a global picture of attribute similarity. It involves the frequency-based intra-coupled similarity within an attribute and the inter-coupled similarity upon value co-occurrences between attributes, as well as their integration on the object level. In particular, four measures are designed for the inter-coupled similarity to calculate the similarity between two categorical values by considering their relationships with other attributes in terms of power set, universal set, joint set, and intersection set. The theoretical analysis reveals the equivalent accuracy and superior efficiency of the measure based on the intersection set, particularly for large-scale data sets. Intensive experiments of data structure and clustering algorithms incorporating the coupled dissimilarity metric achieve a significant performance improvement on state-of-the-art measures and algorithms on 13 UCI data sets, which is confirmed by the statistical analysis. The experiment results show that the proposed coupled attribute similarity is generic, and can effectively and efficiently capture the intrinsic and global interactions within and between attributes for especially large-scale categorical data sets. In addition, two new coupled categorical clustering algorithms, i.e., CROCK and CLIMBO are proposed, and they both outperform the original ones in terms of clustering quality on UCI data sets and bibliographic data.",4
On learning navigation behaviors for small mobile robots with reservoir computing architectures.,"This paper proposes a general reservoir computing (RC) learning framework that can be used to learn navigation behaviors for mobile robots in simple and complex unknown partially observable environments. RC provides an efficient way to train recurrent neural networks by letting the recurrent part of the network (called reservoir) be fixed while only a linear readout output layer is trained. The proposed RC framework builds upon the notion of navigation attractor or behavior that can be embedded in the high-dimensional space of the reservoir after learning. The learning of multiple behaviors is possible because the dynamic robot behavior, consisting of a sensory-motor sequence, can be linearly discriminated in the high-dimensional nonlinear space of the dynamic reservoir. Three learning approaches for navigation behaviors are shown in this paper. The first approach learns multiple behaviors based on the examples of navigation behaviors generated by a supervisor, while the second approach learns goal-directed navigation behaviors based only on rewards. The third approach learns complex goal-directed behaviors, in a supervised way, using a hierarchical architecture whose internal predictions of contextual switches guide the sequence of basic navigation behaviors toward the goal.",4
A universal concept based on cellular neural networks for ultrafast and flexible solving of differential equations.,"This paper develops and validates a comprehensive and universally applicable computational concept for solving nonlinear differential equations (NDEs) through a neurocomputing concept based on cellular neural networks (CNNs). High-precision, stability, convergence, and lowest-possible memory requirements are ensured by the CNN processor architecture. A significant challenge solved in this paper is that all these cited computing features are ensured in all system-states (regular or chaotic ones) and in all bifurcation conditions that may be experienced by NDEs.One particular quintessence of this paper is to develop and demonstrate a solver concept that shows and ensures that CNN processors (realized either in hardware or in software) are universal solvers of NDE models. The solving logic or algorithm of given NDEs (possible examples are: Duffing, Mathieu, Van der Pol, Jerk, Chua, Rossler, Lorenz, Burgers, and the transport equations) through a CNN processor system is provided by a set of templates that are computed by our comprehensive templates calculation technique that we call nonlinear adaptive optimization. This paper is therefore a significant contribution and represents a cutting-edge real-time computational engineering approach, especially while considering the various scientific and engineering applications of this ultrafast, energy-and-memory-efficient, and high-precise NDE solver concept. For illustration purposes, three NDE models are demonstratively solved, and related CNN templates are derived and used: the periodically excited Duffing equation, the Mathieu equation, and the transport equation.",4
Impulsive stabilization and impulsive synchronization of discrete-time delayed neural networks.,"This paper investigates the problems of impulsive stabilization and impulsive synchronization of discrete-time delayed neural networks (DDNNs). Two types of DDNNs with stabilizing impulses are studied. By introducing the time-varying Lyapunov functional to capture the dynamical characteristics of discrete-time impulsive delayed neural networks (DIDNNs) and by using a convex combination technique, new exponential stability criteria are derived in terms of linear matrix inequalities. The stability criteria for DIDNNs are independent of the size of time delay but rely on the lengths of impulsive intervals. With the newly obtained stability results, sufficient conditions on the existence of linear-state feedback impulsive controllers are derived. Moreover, a novel impulsive synchronization scheme for two identical DDNNs is proposed. The novel impulsive synchronization scheme allows synchronizing two identical DDNNs with unknown delays. Simulation results are given to validate the effectiveness of the proposed criteria of impulsive stabilization and impulsive synchronization of DDNNs. Finally, an application of the obtained impulsive synchronization result for two identical chaotic DDNNs to a secure communication scheme is presented.",4
Multiclass semisupervised learning based upon kernel spectral clustering.,"This paper proposes a multiclass semisupervised learning algorithm by using kernel spectral clustering (KSC) as a core model. A regularized KSC is formulated to estimate the class memberships of data points in a semisupervised setting using the one-versus-all strategy while both labeled and unlabeled data points are present in the learning process. The propagation of the labels to a large amount of unlabeled data points is achieved by adding the regularization terms to the cost function of the KSC formulation. In other words, imposing the regularization term enforces certain desired memberships. The model is then obtained by solving a linear system in the dual. Furthermore, the optimal embedding dimension is designed for semisupervised clustering. This plays a key role when one deals with a large number of clusters.",4
Gaussian kernel width optimization for sparse Bayesian learning.,"Sparse kernel methods have been widely used in regression and classification applications. The performance and the sparsity of these methods are dependent on the appropriate choice of the corresponding kernel functions and their parameters. Typically, the kernel parameters are selected using a cross-validation approach. In this paper, a learning method that is an extension of the relevance vector machine (RVM) is presented. The proposed method can find the optimal values of the kernel parameters during the training procedure. This algorithm uses an expectation-maximization approach for updating kernel parameters as well as other model parameters; therefore, the speed of convergence and computational complexity of the proposed method are the same as the standard RVM. To control the convergence of this fully parameterized model, the optimization with respect to the kernel parameters is performed using a constraint on these parameters. The proposed method is compared with the typical RVM and other competing methods to analyze the performance. The experimental results on the commonly used synthetic data, as well as benchmark data sets, demonstrate the effectiveness of the proposed method in reducing the performance dependency on the initial choice of the kernel parameters.",4
Convolutive bounded component analysis algorithms for independent and dependent source separation.,"Bounded component analysis (BCA) is a framework that can be considered as a more general framework than independent component analysis (ICA) under the boundedness constraint on sources. Using this framework, it is possible to separate dependent as well as independent components from their mixtures. In this paper, as an extension of a recently introduced instantaneous BCA approach, we introduce a family of convolutive BCA criteria and corresponding algorithms. We prove that the global optima of the proposed criteria, under generic BCA assumptions, are equivalent to a set of perfect separators. The algorithms introduced in this paper are capable of separating not only the independent sources but also the sources that are dependent/correlated in both component (space) and sample (time) dimensions. Therefore, under the condition that the sources are bounded, they can be considered as extended convolutive ICA algorithms with additional dependent/correlated source separation capability. Furthermore, they have potential to provide improvement in separation performance, especially for short data records. This paper offers examples to illustrate the space-time correlated source separation capability through a copula distribution-based example. In addition, a frequency-selective Multiple Input Multiple Output equalization example demonstrates the clear performance advantage of the proposed BCA approach over the state-of-the-art ICA-based approaches in setups involving convolutive mixtures of digital communication sources.",4
Adaptive optimal control of highly dissipative nonlinear spatially distributed processes with neuro-dynamic programming.,"Highly dissipative nonlinear partial differential equations (PDEs) are widely employed to describe the system dynamics of industrial spatially distributed processes (SDPs). In this paper, we consider the optimal control problem of the general highly dissipative SDPs, and propose an adaptive optimal control approach based on neuro-dynamic programming (NDP). Initially, Karhunen-Loeve decomposition is employed to compute empirical eigenfunctions (EEFs) of the SDP based on the method of snapshots. These EEFs together with singular perturbation technique are then used to obtain a finite-dimensional slow subsystem of ordinary differential equations that accurately describes the dominant dynamics of the PDE system. Subsequently, the optimal control problem is reformulated on the basis of the slow subsystem, which is further converted to solve a Hamilton-Jacobi-Bellman (HJB) equation. HJB equation is a nonlinear PDE that has proven to be impossible to solve analytically. Thus, an adaptive optimal control method is developed via NDP that solves the HJB equation online using neural network (NN) for approximating the value function; and an online NN weight tuning law is proposed without requiring an initial stabilizing control policy. Moreover, by involving the NN estimation error, we prove that the original closed-loop PDE system with the adaptive optimal control policy is semiglobally uniformly ultimately bounded. Finally, the developed method is tested on a nonlinear diffusion-convection-reaction process and applied to a temperature cooling fin of high-speed aerospace vehicle, and the achieved results show its effectiveness.",4
Quaternion-valued echo state networks.,"Quaternion-valued echo state networks (QESNs) are introduced to cater for 3-D and 4-D processes, such as those observed in the context of renewable energy (3-D wind modeling) and human centered computing (3-D inertial body sensors). The introduction of QESNs is made possible by the recent emergence of quaternion nonlinear activation functions with local analytic properties, required by nonlinear gradient descent training algorithms. To make QENSs second-order optimal for the generality of quaternion signals (both circular and noncircular), we employ augmented quaternion statistics to introduce widely linear QESNs. To that end, the standard widely linear model is modified so as to suit the properties of dynamical reservoir, typically realized by recurrent neural networks. This allows for a full exploitation of second-order information in the data, contained both in the covariance and pseudocovariances, and a rigorous account of second-order noncircularity (improperness), and the corresponding power mismatch and coupling between the data components. Simulations in the prediction setting on both benchmark circular and noncircular signals and on noncircular real-world 3-D body motion data support the analysis.",4
Distance Metric Learning Using Privileged Information for Face Verification and Person Re-Identification.,"In this paper, we propose a new approach to improve face verification and person re-identification in the RGB images by leveraging a set of RGB-D data, in which we have additional depth images in the training data captured using depth cameras such as Kinect. In particular, we extract visual features and depth features from the RGB images and depth images, respectively. As the depth features are available only in the training data, we treat the depth features as privileged information, and we formulate this task as a distance metric learning with privileged information problem. Unlike the traditional face verification and person re-identification tasks that only use visual features, we further employ the extra depth features in the training data to improve the learning of distance metric in the training process. Based on the information-theoretic metric learning (ITML) method, we propose a new formulation called ITML with privileged information (ITML+) for this task. We also present an efficient algorithm based on the cyclic projection method for solving the proposed ITML+ formulation. Extensive experiments on the challenging faces data sets EUROCOM and CurtinFaces for face verification as well as the BIWI RGBD-ID data set for person re-identification demonstrate the effectiveness of our proposed approach.",4
Dynamic Uncertain Causality Graph for Knowledge Representation and Probabilistic Reasoning: Directed Cyclic Graph and Joint Probability Distribution.,"Probabilistic graphical models (PGMs) such as Bayesian network (BN) have been widely applied in uncertain causality representation and probabilistic reasoning. Dynamic uncertain causality graph (DUCG) is a newly presented model of PGMs, which can be applied to fault diagnosis of large and complex industrial systems, disease diagnosis, and so on. The basic methodology of DUCG has been previously presented, in which only the directed acyclic graph (DAG) was addressed. However, the mathematical meaning of DUCG was not discussed. In this paper, the DUCG with directed cyclic graphs (DCGs) is addressed. In contrast, BN does not allow DCGs, as otherwise the conditional independence will not be satisfied. The inference algorithm for the DUCG with DCGs is presented, which not only extends the capabilities of DUCG from DAGs to DCGs but also enables users to decompose a large and complex DUCG into a set of small, simple sub-DUCGs, so that a large and complex knowledge base can be easily constructed, understood, and maintained. The basic mathematical definition of a complete DUCG with or without DCGs is proved to be a joint probability distribution (JPD) over a set of random variables. The incomplete DUCG as a part of a complete DUCG may represent a part of JPD. Examples are provided to illustrate the methodology.",4
Manifold Learning for Multivariate Variable-Length Sequences With an Application to Similarity Search.,"Multivariate variable-length sequence data are becoming ubiquitous with the technological advancement in mobile devices and sensor networks. Such data are difficult to compare, visualize, and analyze due to the nonmetric nature of data sequence similarity measures. In this paper, we propose a general manifold learning framework for arbitrary-length multivariate data sequences driven by similarity/distance (parameter) learning in both the original data sequence space and the learned manifold. Our proposed algorithm transforms the data sequences in a nonmetric data sequence space into feature vectors in a manifold that preserves the data sequence space structure. In particular, the feature vectors in the manifold representing similar data sequences remain close to one another and far from the feature points corresponding to dissimilar data sequences. To achieve this objective, we assume a semisupervised setting where we have knowledge about whether some of data sequences are similar or dissimilar, called the instance-level constraints. Using this information, one learns the similarity measure for the data sequence space and the distance measures for the manifold. Moreover, we describe an approach to handle the similarity search problem given user-defined instance level constraints in the learned manifold using a consensus voting scheme. Experimental results on both synthetic data and real tropical cyclone sequence data are presented to demonstrate the feasibility of our manifold learning framework and the robustness of performing similarity search in the learned manifold.",4
A Divide-and-Conquer Method for Scalable Robust Multitask Learning.,"Multitask learning (MTL) aims at improving the generalization performance of multiple tasks by exploiting the shared factors among them. An important line of research in the MTL is the robust MTL (RMTL) methods, which use trace-norm regularization to capture task relatedness via a low-rank structure. The existing algorithms for the RMTL optimization problems rely on the accelerated proximal gradient (APG) scheme that needs repeated full singular value decomposition (SVD) operations. However, the time complexity of a full SVD is O(min(md(2),m(2)d)) for an RMTL problem with m tasks and d features, which becomes unaffordable in real-world MTL applications that often have a large number of tasks and high-dimensional features. In this paper, we propose a scalable solution for large-scale RMTL, with either the least squares loss or the squared hinge loss, by a divide-and-conquer method. The proposed method divides the original RMTL problem into several size-reduced subproblems, solves these cheaper subproblems in parallel by any base algorithm (e.g., APG) for RMTL, and then combines the results to obtain the final solution. Our theoretical analysis indicates that, with high probability, the recovery errors of the proposed divide-and-conquer algorithm are bounded by those of the base algorithm. Furthermore, in order to solve the subproblems with the least squares loss or the squared hinge loss, we propose two efficient base algorithms based on the linearized alternating direction method, respectively. Experimental results demonstrate that, with little loss of accuracy, our method is substantially faster than the state-of-the-art APG algorithms for RMTL.",4
Competition and Collaboration in Cooperative Coevolution of Elman Recurrent Neural Networks for Time-Series Prediction.,"Collaboration enables weak species to survive in an environment where different species compete for limited resources. Cooperative coevolution (CC) is a nature-inspired optimization method that divides a problem into subcomponents and evolves them while genetically isolating them. Problem decomposition is an important aspect in using CC for neuroevolution. CC employs different problem decomposition methods to decompose the neural network training problem into subcomponents. Different problem decomposition methods have features that are helpful at different stages in the evolutionary process. Adaptation, collaboration, and competition are needed for CC, as multiple subpopulations are used to represent the problem. It is important to add collaboration and competition in CC. This paper presents a competitive CC method for training recurrent neural networks for chaotic time-series prediction. Two different instances of the competitive method are proposed that employs different problem decomposition methods to enforce island-based competition. The results show improvement in the performance of the proposed methods in most cases when compared with standalone CC and other methods from the literature.",4
Nonsmooth Neural Network for Convex Time-Dependent Constraint Satisfaction Problems.,"This paper introduces a nonsmooth (NS) neural network that is able to operate in a time-dependent (TD) context and is potentially useful for solving some classes of NS-TD problems. The proposed network is named nonsmooth time-dependent network (NTN) and is an extension to a TD setting of a previous NS neural network for programming problems. Suppose C(t), t >/= 0, is a nonempty TD convex feasibility set defined by TD inequality constraints. The constraints are in general NS (nondifferentiable) functions of the state variables and time. NTN is described by the subdifferential with respect to the state variables of an NS-TD barrier function and a vector field corresponding to the unconstrained dynamics. This paper shows that for suitable values of the penalty parameter, the NTN dynamics displays two main phases. In the first phase, any solution of NTN not starting in C(0) at t=0 is able to reach the moving set C(.) in finite time th , whereas in the second phase, the solution tracks the moving set, i.e., it stays within C(t) for all subsequent times t >/= t(h). NTN is thus able to find an exact feasible solution in finite time and also to provide an exact feasible solution for subsequent times. This new and peculiar dynamics displayed by NTN is potentially useful for addressing some significant TD signal processing tasks. As an illustration, this paper discusses a number of examples where NTN is applied to the solution of NS-TD convex feasibility problems.",4
Emotional Multiagent Reinforcement Learning in Spatial Social Dilemmas.,"Social dilemmas have attracted extensive interest in the research of multiagent systems in order to study the emergence of cooperative behaviors among selfish agents. Understanding how agents can achieve cooperation in social dilemmas through learning from local experience is a critical problem that has motivated researchers for decades. This paper investigates the possibility of exploiting emotions in agent learning in order to facilitate the emergence of cooperation in social dilemmas. In particular, the spatial version of social dilemmas is considered to study the impact of local interactions on the emergence of cooperation in the whole system. A double-layered emotional multiagent reinforcement learning framework is proposed to endow agents with internal cognitive and emotional capabilities that can drive these agents to learn cooperative behaviors. Experimental results reveal that various network topologies and agent heterogeneities have significant impacts on agent learning behaviors in the proposed framework, and under certain circumstances, high levels of cooperation can be achieved among the agents.",4
Adaptive Robust Output Feedback Control for a Marine Dynamic Positioning System Based on a High-Gain Observer.,"This paper develops an adaptive robust output feedback control scheme for dynamically positioned ships with unavailable velocities and unknown dynamic parameters in an unknown time-variant disturbance environment. The controller is designed by incorporating the high-gain observer and radial basis function (RBF) neural networks in vectorial backstepping method. The high-gain observer provides the estimations of the ship position and heading as well as velocities. The RBF neural networks are employed to compensate for the uncertainties of ship dynamics. The adaptive laws incorporating a leakage term are designed to estimate the weights of RBF neural networks and the bounds of unknown time-variant environmental disturbances. In contrast to the existing results of dynamic positioning (DP) controllers, the proposed control scheme relies only on the ship position and heading measurements and does not require a priori knowledge of the ship dynamics and external disturbances. By means of Lyapunov functions, it is theoretically proved that our output feedback controller can control a ship's position and heading to the arbitrarily small neighborhood of the desired target values while guaranteeing that all signals in the closed-loop DP control system are uniformly ultimately bounded. Finally, simulations involving two ships are carried out, and simulation results demonstrate the effectiveness of the proposed control scheme.",4
Multistability for Delayed Neural Networks via Sequential Contracting.,"In this paper, we explore a variety of new multistability scenarios in the general delayed neural network system. Geometric structure embedded in equations is exploited and incorporated into the analysis to elucidate the underlying dynamics. Criteria derived from different geometric configurations lead to disparate numbers of equilibria. A new approach named sequential contracting is applied to conclude the global convergence to multiple equilibrium points of the system. The formulation accommodates both smooth sigmoidal and piecewise-linear activation functions. Several numerical examples illustrate the present analytic theory.",4
Simultaneous Computation of Two Independent Tasks Using Reservoir Computing Based on a Single Photonic Nonlinear Node With Optical Feedback.,"In this brief, we numerically demonstrate a photonic delay-based reservoir computing system, which processes, in parallel, two independent computational tasks even when the two tasks have unrelated input streams. Our approach is based on a single-longitudinal mode semiconductor ring laser (SRL) with optical feedback. The SRL emits in two directional optical modes. Each directional mode processes one individual task to mitigate possible crosstalk. We illustrate the feasibility of our scheme by analyzing the performance on two benchmark tasks: 1) chaotic time series prediction and 2) nonlinear channel equalization. We identify some feedback configurations for which the results for simultaneous prediction/classification indicate a good performance, but with slight degradation (as compared with the performance obtained for single task processing) due to nonlinear and linear interactions between the two directional modes of the laser. In these configurations, the system performs well on both tasks for a broad range of the parameters.",4
Synchronization in Networks of Linearly Coupled Dynamical Systems via Event-Triggered Diffusions.,"In this paper, we utilize event-triggered coupling configurations to realize synchronization of linearly coupled dynamical systems. Here, the diffusion couplings are set up from the latest observations of the nodes and their neighborhood and the next observation time is triggered by the proposed criteria based on the local neighborhood information as well. Two scenarios are considered: 1) continuous monitoring, in which each node can observe its neighborhood's instantaneous states and 2) discrete monitoring, in which each node can obtain only its neighborhood's states at the same time point when the coupling term is triggered. In both the cases, we prove that if the system with persistent coupling can synchronize, then these event-triggered coupling strategies can synchronize the system too.",4
Error bounds of adaptive dynamic programming algorithms for solving undiscounted optimal control problems.,"In this paper, we establish error bounds of adaptive dynamic programming algorithms for solving undiscounted infinite-horizon optimal control problems of discrete-time deterministic nonlinear systems. We consider approximation errors in the update equations of both value function and control policy. We utilize a new assumption instead of the contraction assumption in discounted optimal control problems. We establish the error bounds for approximate value iteration based on a new error condition. Furthermore, we also establish the error bounds for approximate policy iteration and approximate optimistic policy iteration algorithms. It is shown that the iterative approximate value function can converge to a finite neighborhood of the optimal value function under some conditions. To implement the developed algorithms, critic and action neural networks are used to approximate the value function and control policy, respectively. Finally, a simulation example is given to demonstrate the effectiveness of the developed algorithms.",4
Infinite horizon self-learning optimal control of nonaffine discrete-time nonlinear systems.,"In this paper, a novel iterative adaptive dynamic programming (ADP)-based infinite horizon self-learning optimal control algorithm, called generalized policy iteration algorithm, is developed for nonaffine discrete-time (DT) nonlinear systems. Generalized policy iteration algorithm is a general idea of interacting policy and value iteration algorithms of ADP. The developed generalized policy iteration algorithm permits an arbitrary positive semidefinite function to initialize the algorithm, where two iteration indices are used for policy improvement and policy evaluation, respectively. It is the first time that the convergence, admissibility, and optimality properties of the generalized policy iteration algorithm for DT nonlinear systems are analyzed. Neural networks are used to implement the developed algorithm. Finally, numerical examples are presented to illustrate the performance of the developed algorithm.",4
Joint Learning of Multiple Sparse Matrix Gaussian Graphical Models.,"We consider joint learning of multiple sparse matrix Gaussian graphical models and propose the joint matrix graphical Lasso to discover the conditional independence structures among rows (columns) in the matrix variable under distinct conditions. The proposed approach borrows strength across the different graphical models and is based on the maximum likelihood with penalized row and column precision matrices, respectively. In particular, our model is more parsimonious and flexible than the joint vector graphical models. Furthermore, we establish the asymptotic properties of our model on consistency and sparsistency. And the asymptotic analysis shows that our model enjoys a better convergence rate than the joint vector graphical models. Extensive simulation experiments demonstrate that our methods outperform state-of-the-art methods in identifying graphical structures and estimating precision matrices. Moreover, the effectiveness of our methods is also illustrated via a real data set analysis. Sparsistency is shorthand for consistency of the sparsity pattern of the parameters.",4
Very sparse LSSVM reductions for large-scale data.,"Least squares support vector machines (LSSVMs) have been widely applied for classification and regression with comparable performance with SVMs. The LSSVM model lacks sparsity and is unable to handle large-scale data due to computational and memory constraints. A primal fixed-size LSSVM (PFS-LSSVM) introduce sparsity using Nystrom approximation with a set of prototype vectors (PVs). The PFS-LSSVM model solves an overdetermined system of linear equations in the primal. However, this solution is not the sparsest. We investigate the sparsity-error tradeoff by introducing a second level of sparsity. This is done by means of L0 -norm-based reductions by iteratively sparsifying LSSVM and PFS-LSSVM models. The exact choice of the cardinality for the initial PV set is not important then as the final model is highly sparse. The proposed method overcomes the problem of memory constraints and high computational costs resulting in highly sparse reductions to LSSVM models. The approximations of the two models allow to scale the models to large-scale datasets. Experiments on real-world classification and regression data sets from the UCI repository illustrate that these approaches achieve sparse models without a significant tradeoff in errors.",4
RSTFC: A Novel Algorithm for Spatio-Temporal Filtering and Classification of Single-Trial EEG.,"Learning optimal spatio-temporal filters is a key to feature extraction for single-trial electroencephalogram (EEG) classification. The challenges are controlling the complexity of the learning algorithm so as to alleviate the curse of dimensionality and attaining computational efficiency to facilitate online applications, e.g., brain-computer interfaces (BCIs). To tackle these barriers, this paper presents a novel algorithm, termed regularized spatio-temporal filtering and classification (RSTFC), for single-trial EEG classification. RSTFC consists of two modules. In the feature extraction module, an l2 -regularized algorithm is developed for supervised spatio-temporal filtering of the EEG signals. Unlike the existing supervised spatio-temporal filter optimization algorithms, the developed algorithm can simultaneously optimize spatial and high-order temporal filters in an eigenvalue decomposition framework and thus be implemented highly efficiently. In the classification module, a convex optimization algorithm for sparse Fisher linear discriminant analysis is proposed for simultaneous feature selection and classification of the typically high-dimensional spatio-temporally filtered signals. The effectiveness of RSTFC is demonstrated by comparing it with several state-of-the-arts methods on three brain-computer interface (BCI) competition data sets collected from 17 subjects. Results indicate that RSTFC yields significantly higher classification accuracies than the competing methods. This paper also discusses the advantage of optimizing channel-specific temporal filters over optimizing a temporal filter common to all channels.",4
Bidirectional Active Learning: A Two-Way Exploration Into Unlabeled and Labeled Data Set.,"In practical machine learning applications, human instruction is indispensable for model construction. To utilize the precious labeling effort effectively, active learning queries the user with selective sampling in an interactive way. Traditional active learning techniques merely focus on the unlabeled data set under a unidirectional exploration framework and suffer from model deterioration in the presence of noise. To address this problem, this paper proposes a novel bidirectional active learning algorithm that explores into both unlabeled and labeled data sets simultaneously in a two-way process. For the acquisition of new knowledge, forward learning queries the most informative instances from unlabeled data set. For the introspection of learned knowledge, backward learning detects the most suspiciously unreliable instances within the labeled data set. Under the two-way exploration framework, the generalization ability of the learning model can be greatly improved, which is demonstrated by the encouraging experimental results.",4
Hinfinity State Estimation for Discrete-Time Delayed Systems of the Neural Network Type With Multiple Missing Measurements.,"This paper investigates the Hinfinity state estimation problem for a class of discrete-time nonlinear systems of the neural network type with random time-varying delays and multiple missing measurements. These nonlinear systems include recurrent neural networks, complex network systems, Lur'e systems, and so on which can be described by a unified model consisting of a linear dynamic system and a static nonlinear operator. The missing phenomenon commonly existing in measurements is assumed to occur randomly by introducing mutually individual random variables satisfying certain kind of probability distribution. Throughout this paper, first a Luenberger-like estimator based on the imperfect output data is constructed to obtain the immeasurable system states. Then, by virtue of Lyapunov stability theory and stochastic method, the Hinfinity performance of the estimation error dynamical system (augmented system) is analyzed. Based on the analysis, the Hinfinity estimator gains are deduced such that the augmented system is globally mean square stable. In this paper, both the variation range and distribution probability of the time delay are incorporated into the control laws, which allows us to not only have more accurate models of the real physical systems, but also obtain less conservative results. Finally, three illustrative examples are provided to validate the proposed control laws.",4
Robust Multitask Multiview Tracking in Videos.,"Various sparse-representation-based methods have been proposed to solve tracking problems, and most of them employ least squares (LSs) criteria to learn the sparse representation. In many tracking scenarios, traditional LS-based methods may not perform well owing to the presence of heavy-tailed noise. In this paper, we present a tracking approach using an approximate least absolute deviation (LAD)-based multitask multiview sparse learning method to enjoy robustness of LAD and take advantage of multiple types of visual features, such as intensity, color, and texture. The proposed method is integrated in a particle filter framework, where learning the sparse representation for each view of the single particle is regarded as an individual task. The underlying relationship between tasks across different views and different particles is jointly exploited in a unified robust multitask formulation based on LAD. In addition, to capture the frequently emerging outlier tasks, we decompose the representation matrix to two collaborative components that enable a more robust and accurate approximation. We show that the proposed formulation can be effectively approximated by Nesterov's smoothing method and efficiently solved using the accelerated proximal gradient method. The presented tracker is implemented using four types of features and is tested on numerous synthetic sequences and real-world video sequences, including the CVPR2013 tracking benchmark and ALOV++ data set. Both the qualitative and quantitative results demonstrate the superior performance of the proposed approach compared with several state-of-the-art trackers.",4
Multiple actor-critic structures for continuous-time optimal control using input-output data.,"In industrial process control, there may be multiple performance objectives, depending on salient features of the input-output data. Aiming at this situation, this paper proposes multiple actor-critic structures to obtain the optimal control via input-output data for unknown nonlinear systems. The shunting inhibitory artificial neural network (SIANN) is used to classify the input-output data into one of several categories. Different performance measure functions may be defined for disparate categories. The approximate dynamic programming algorithm, which contains model module, critic network, and action network, is used to establish the optimal control in each category. A recurrent neural network (RNN) model is used to reconstruct the unknown system dynamics using input-output data. NNs are used to approximate the critic and action networks, respectively. It is proven that the model error and the closed unknown system are uniformly ultimately bounded. Simulation results demonstrate the performance of the proposed optimal control scheme for the unknown nonlinear system.",4
An Interval-Valued Neural Network Approach for Uncertainty Quantification in Short-Term Wind Speed Prediction.,"We consider the task of performing prediction with neural networks (NNs) on the basis of uncertain input data expressed in the form of intervals. We aim at quantifying the uncertainty in the prediction arising from both the input data and the prediction model. A multilayer perceptron NN is trained to map interval-valued input data onto interval outputs, representing the prediction intervals (PIs) of the real target values. The NN training is performed by nondominated sorting genetic algorithm-II, so that the PIs are optimized both in terms of accuracy (coverage probability) and dimension (width). Demonstration of the proposed method is given in two case studies: 1) a synthetic case study, in which the data have been generated with a 5-min time frequency from an autoregressive moving average model with either Gaussian or Chi-squared innovation distribution and 2) a real case study, in which experimental data consist of wind speed measurements with a time step of 1 h. Comparisons are given with a crisp (single-valued) approach. The results show that the crisp approach is less reliable than the interval-valued input approach in terms of capturing the variability in input.",4
An Information-Based Learning Approach to Dual Control.,"Dual control aims to concurrently learn and control an unknown system. However, actively learning the system conflicts directly with any given control objective for it will disturb the system during exploration. This paper presents a receding horizon approach to dual control, where a multiobjective optimization problem is solved repeatedly and subject to constraints representing system dynamics. Balancing a standard finite-horizon control objective, a knowledge gain objective is defined to explicitly quantify the information acquired when learning the system dynamics. Measures from information theory, such as entropy-based uncertainty, Fisher information, and relative entropy, are studied and used to quantify the knowledge gained as a result of the control actions. The resulting iterative framework is applied to Markov decision processes and discrete-time nonlinear systems. Thus, the broad applicability and usefulness of the presented approach is demonstrated in diverse problem settings. The framework is illustrated with multiple numerical examples.",4
A unified approach to universal prediction: generalized upper and lower bounds.,"We study sequential prediction of real-valued, arbitrary, and unknown sequences under the squared error loss as well as the best parametric predictor out of a large, continuous class of predictors. Inspired by recent results from computational learning theory, we refrain from any statistical assumptions and define the performance with respect to the class of general parametric predictors. In particular, we present generic lower and upper bounds on this relative performance by transforming the prediction task into a parameter learning problem. We first introduce the lower bounds on this relative performance in the mixture of experts framework, where we show that for any sequential algorithm, there always exists a sequence for which the performance of the sequential algorithm is lower bounded by zero. We then introduce a sequential learning algorithm to predict such arbitrary and unknown sequences, and calculate upper bounds on its total squared prediction error for every bounded sequence. We further show that in some scenarios, we achieve matching lower and upper bounds, demonstrating that our algorithms are optimal in a strong minimax sense such that their performances cannot be improved further. As an interesting result, we also prove that for the worst case scenario, the performance of randomized output algorithms can be achieved by sequential algorithms so that randomized output algorithms do not improve the performance.",4
Neural network-based adaptive dynamic surface control for permanent magnet synchronous motors.,"This brief considers the problem of neural networks (NNs)-based adaptive dynamic surface control (DSC) for permanent magnet synchronous motors (PMSMs) with parameter uncertainties and load torque disturbance. First, NNs are used to approximate the unknown and nonlinear functions of PMSM drive system and a novel adaptive DSC is constructed to avoid the explosion of complexity in the backstepping design. Next, under the proposed adaptive neural DSC, the number of adaptive parameters required is reduced to only one, and the designed neural controllers structure is much simpler than some existing results in literature, which can guarantee that the tracking error converges to a small neighborhood of the origin. Then, simulations are given to illustrate the effectiveness and potential of the new design technique.",4
Convergence analysis of the FOCUSS algorithm.,"Focal Underdetermined System Solver (FOCUSS) is a powerful and easy to implement tool for basis selection and inverse problems. One of the fundamental problems regarding this method is its convergence, which remains unsolved until now. We investigate the convergence of the FOCUSS algorithm in this paper. We first give a rigorous derivation for the FOCUSS algorithm by exploiting the auxiliary function. Following this, we further prove its convergence by stability analysis.",4
A simplified adaptive neural network prescribed performance controller for uncertain MIMO feedback linearizable systems.,"In this paper, the problem of deriving a continuous, state-feedback controller for a class of multiinput multioutput feedback linearizable systems is considered with special emphasis on controller simplification and reduction of the overall design complexity with respect to the current state of the art. The proposed scheme achieves prescribed bounds on the transient and steady-state performance of the output tracking errors despite the uncertainty in system nonlinearities. Contrary to the current state of the art, however, only a single neural network is utilized to approximate a scalar function that partly incorporates the system nonlinearities. Furthermore, the loss of model controllability problem, typically introduced owing to approximation model singularities, is avoided without attaching additional complexity to the control or adaptive law. Simulations are performed to verify and clarify the theoretical findings.",4
Novelty detection using level set methods.,"This paper presents a level set boundary description (LSBD) approach for novelty detection that treats the nonlinear boundary directly in the input space. The proposed approach consists of level set function (LSF) construction, boundary evolution, and termination of the training process. It employs kernel density estimation to construct the LSF of the initial boundary for the training data set. Then, a sign of the LSF-based algorithm is proposed to evolve the boundary and make it fit more tightly in the data distribution. The training process terminates when an expected fraction of rejected normal data is reached. The evolution process utilizes the signs of the LSF values at all training data points to decide whether to expand or shrink the boundary. Extensive experiments are conducted on benchmark data sets to evaluate the proposed LSBD method and compare it against four representative novelty detection methods. The experimental results demonstrate that the novelty detector modeled with the proposed LSBD can effectively detect anomalies.",4
Generalization performance of radial basis function networks.,"This paper studies the generalization performance of radial basis function (RBF) networks using local Rademacher complexities. We propose a general result on controlling local Rademacher complexities with the L1 -metric capacity. We then apply this result to estimate the RBF networks' complexities, based on which a novel estimation error bound is obtained. An effective approximation error bound is also derived by carefully investigating the Holder continuity of the lp loss function's derivative. Furthermore, it is demonstrated that the RBF network minimizing an appropriately constructed structural risk admits a significantly better learning rate when compared with the existing results. An empirical study is also performed to justify the application of our structural risk in model selection.",4
Bayesian nonparametric adaptive control using Gaussian processes.,"Most current model reference adaptive control (MRAC) methods rely on parametric adaptive elements, in which the number of parameters of the adaptive element are fixed a priori, often through expert judgment. An example of such an adaptive element is radial basis function networks (RBFNs), with RBF centers preallocated based on the expected operating domain. If the system operates outside of the expected operating domain, this adaptive element can become noneffective in capturing and canceling the uncertainty, thus rendering the adaptive controller only semiglobal in nature. This paper investigates a Gaussian process-based Bayesian MRAC architecture (GP-MRAC), which leverages the power and flexibility of GP Bayesian nonparametric models of uncertainty. The GP-MRAC does not require the centers to be preallocated, can inherently handle measurement noise, and enables MRAC to handle a broader set of uncertainties, including those that are defined as distributions over functions. We use stochastic stability arguments to show that GP-MRAC guarantees good closed-loop performance with no prior domain knowledge of the uncertainty. Online implementable GP inference methods are compared in numerical simulations against RBFN-MRAC with preallocated centers and are shown to provide better tracking and improved long-term learning.",4
Spatio-temporal learning with the online finite and infinite echo-state Gaussian processes.,"Successful biological systems adapt to change. In this paper, we are principally concerned with adaptive systems that operate in environments where data arrives sequentially and is multivariate in nature, for example, sensory streams in robotic systems. We contribute two reservoir inspired methods: 1) the online echostate Gaussian process (OESGP) and 2) its infinite variant, the online infinite echostate Gaussian process (OIESGP) Both algorithms are iterative fixed-budget methods that learn from noisy time series. In particular, the OESGP combines the echo-state network with Bayesian online learning for Gaussian processes. Extending this to infinite reservoirs yields the OIESGP, which uses a novel recursive kernel with automatic relevance determination that enables spatial and temporal feature weighting. When fused with stochastic natural gradient descent, the kernel hyperparameters are iteratively adapted to better model the target system. Furthermore, insights into the underlying system can be gleamed from inspection of the resulting hyperparameters. Experiments on noisy benchmark problems (one-step prediction and system identification) demonstrate that our methods yield high accuracies relative to state-of-the-art methods, and standard kernels with sliding windows, particularly on problems with irrelevant dimensions. In addition, we describe two case studies in robotic learning-by-demonstration involving the Nao humanoid robot and the Assistive Robot Transport for Youngsters (ARTY) smart wheelchair.",4
Exponential synchronization of complex networks of linear systems and nonlinear oscillators: a unified analysis.,"A unified approach to the analysis of synchronization for complex dynamical networks, i.e., networks of partial-state coupled linear systems and networks of full-state coupled nonlinear oscillators, is introduced. It is shown that the developed analysis can be used to describe the difference between the state of each node and the weighted sum of the states of those nodes playing the role of leaders in the networks, thus making it feasible to consider the error dynamics for the whole network system. Different from the other various methods given in the existing literature, the analysis employed in this paper is demonstrated successfully in not only providing the consistent convergence analysis with much simpler form, but also explicitly specifying the convergence rate.",4
Maintaining the integrity of sources in complex learning systems: intraference and the correlation preserving transform.,"The correlation preserving transform (CPT) is introduced to perform bivariate component analysis via decorrelating matrix decompositions, while at the same time preserving the integrity of original bivariate sources. Specifically, unlike existing bivariate uncorrelating matrix decomposition techniques, CPT is designed to preserve both the order of the data channels within every bivariate source and their mutual correlation properties. We introduce the notion of intraference to quantify the effects of interchannel mixing artifacts within recovered bivariate sources, and show that the integrity of separated sources is compromised when not accounting for the intrinsic correlations within bivariate sources, as is the case with current bivariate matrix decompositions. The CPT is based on augmented complex statistics and involves finding the correct conjugate eigenvectors associated with the pseudocovariance matrix, making it possible to maintain the physical meaning of the separated sources. The benefits of CPT are illustrated in the source separation and clustering scenarios, for both synthetic and real-world data.",4
Neural network-based finite-horizon optimal control of uncertain affine nonlinear discrete-time systems.,"In this paper, the finite-horizon optimal control design for nonlinear discrete-time systems in affine form is presented. In contrast with the traditional approximate dynamic programming methodology, which requires at least partial knowledge of the system dynamics, in this paper, the complete system dynamics are relaxed utilizing a neural network (NN)-based identifier to learn the control coefficient matrix. The identifier is then used together with the actor-critic-based scheme to learn the time-varying solution, referred to as the value function, of the Hamilton-Jacobi-Bellman (HJB) equation in an online and forward-in-time manner. Since the solution of HJB is time-varying, NNs with constant weights and time-varying activation functions are considered. To properly satisfy the terminal constraint, an additional error term is incorporated in the novel update law such that the terminal constraint error is also minimized over time. Policy and/or value iterations are not needed and the NN weights are updated once a sampling instant. The uniform ultimate boundedness of the closed-loop system is verified by standard Lyapunov stability theory under nonautonomous analysis. Numerical examples are provided to illustrate the effectiveness of the proposed method.",4
Neural network-based finite horizon stochastic optimal control design for nonlinear networked control systems.,"The stochastic optimal control of nonlinear networked control systems (NNCSs) using neuro-dynamic programming (NDP) over a finite time horizon is a challenging problem due to terminal constraints, system uncertainties, and unknown network imperfections, such as network-induced delays and packet losses. Since the traditional iteration or time-based infinite horizon NDP schemes are unsuitable for NNCS with terminal constraints, a novel time-based NDP scheme is developed to solve finite horizon optimal control of NNCS by mitigating the above-mentioned challenges. First, an online neural network (NN) identifier is introduced to approximate the control coefficient matrix that is subsequently utilized in conjunction with the critic and actor NNs to determine a time-based stochastic optimal control input over finite horizon in a forward-in-time and online manner. Eventually, Lyapunov theory is used to show that all closed-loop signals and NN weights are uniformly ultimately bounded with ultimate bounds being a function of initial conditions and final time. Moreover, the approximated control input converges close to optimal value within finite time. The simulation results are included to show the effectiveness of the proposed scheme.",4
Dimension selective self-organizing maps with time-varying structure for subspace and projected clustering.,"Subspace clustering is the task of identifying clusters in subspaces of the input dimensions of a given dataset. Noisy data in certain attributes cause difficulties for traditional clustering algorithms, because the high discrepancies within them can make objects appear too different to be grouped in the same cluster. This requires methods specially designed for subspace clustering. This paper presents our second approach to subspace and projected clustering based on self-organizing maps (SOMs), which is a local adaptive receptive field dimension selective SOM. By introducing a time-variant topology, our method is an improvement in terms of clustering quality, computational cost, and parameterization. This enables the method to identify the correct number of clusters and their respective relevant dimensions, and thus it presents nearly perfect results in synthetic datasets and surpasses our previous method in most of the real-world datasets considered.",4
Scaling up graph-based semisupervised learning via prototype vector machines.,"When the amount of labeled data are limited, semisupervised learning can improve the learner's performance by also using the often easily available unlabeled data. In particular, a popular approach requires the learned function to be smooth on the underlying data manifold. By approximating this manifold as a weighted graph, such graph-based techniques can often achieve state-of-the-art performance. However, their high time and space complexities make them less attractive on large data sets. In this paper, we propose to scale up graph-based semisupervised learning using a set of sparse prototypes derived from the data. These prototypes serve as a small set of data representatives, which can be used to approximate the graph-based regularizer and to control model complexity. Consequently, both training and testing become much more efficient. Moreover, when the Gaussian kernel is used to define the graph affinity, a simple and principled method to select the prototypes can be obtained. Experiments on a number of real-world data sets demonstrate encouraging performance and scaling properties of the proposed approach. It also compares favorably with models learned via l1 -regularization at the same level of model sparsity. These results demonstrate the efficacy of the proposed approach in producing highly parsimonious and accurate models for semisupervised learning.",4
An enhanced fuzzy min-max neural network for pattern classification.,"An enhanced fuzzy min-max (EFMM) network is proposed for pattern classification in this paper. The aim is to overcome a number of limitations of the original fuzzy min-max (FMM) network and improve its classification performance. The key contributions are three heuristic rules to enhance the learning algorithm of FMM. First, a new hyperbox expansion rule to eliminate the overlapping problem during the hyperbox expansion process is suggested. Second, the existing hyperbox overlap test rule is extended to discover other possible overlapping cases. Third, a new hyperbox contraction rule to resolve possible overlapping cases is provided. Efficacy of EFMM is evaluated using benchmark data sets and a real medical diagnosis task. The results are better than those from various FMM-based models, support vector machine-based, Bayesian-based, decision tree-based, fuzzy-based, and neural-based classifiers. The empirical findings show that the newly introduced rules are able to realize EFMM as a useful model for undertaking pattern classification problems.",4
A direct self-constructing neural controller design for a class of nonlinear systems.,"This paper is concerned with the problem of adaptive neural control for a class of uncertain or ill-defined nonaffine nonlinear systems. Using a self-organizing radial basis function neural network (RBFNN), a direct self-constructing neural controller (DSNC) is designed so that unknown nonlinearities can be approximated and the closed-loop system is stable. The key features of the proposed DSNC design scheme can be summarized as follows. First, different from the existing results in literature, a self-organizing RBFNN with adaptive threshold is constructed online for DSNC to improve the control performance. Second, the control law and adaptive law for the weights of RBFNN are established so that the closed-loop system is stable in the term of Lyapunov stability theory. Third, the tracking error is guaranteed to uniformly asymptotically converge to zero with the aid of an additional robustifying control term. An example is finally given to demonstrate the design procedure and the performance of the proposed method. Simulation results reveal the effectiveness of the proposed method.",4
A Recurrent Probabilistic Neural Network with Dimensionality Reduction Based on Time-series Discriminant Component Analysis.,"This paper proposes a probabilistic neural network (NN) developed on the basis of time-series discriminant component analysis (TSDCA) that can be used to classify high-dimensional time-series patterns. TSDCA involves the compression of high-dimensional time series into a lower dimensional space using a set of orthogonal transformations and the calculation of posterior probabilities based on a continuous-density hidden Markov model with a Gaussian mixture model expressed in the reduced-dimensional space. The analysis can be incorporated into an NN, which is named a time-series discriminant component network (TSDCN), so that parameters of dimensionality reduction and classification can be obtained simultaneously as network coefficients according to a backpropagation through time-based learning algorithm with the Lagrange multiplier method. The TSDCN is considered to enable high-accuracy classification of high-dimensional time-series patterns and to reduce the computation time taken for network training. The validity of the TSDCN is demonstrated for high-dimensional artificial data and electroencephalogram signals in the experiments conducted during the study.",4
Robust Blind Learning Algorithm for Nonlinear Equalization Using Input Decision Information.,"In this paper, we propose a new blind learning algorithm, namely, the Benveniste-Goursat input-output decision (BG-IOD), to enhance the convergence performance of neural network-based equalizers for nonlinear channel equalization. In contrast to conventional blind learning algorithms, where only the output of the equalizer is employed for updating system parameters, the BG-IOD exploits a new type of extra information, the input decision information obtained from the input of the equalizer, to mitigate the influence of the nonlinear equalizer structure on parameters learning, thereby leading to improved convergence performance. We prove that, with the input decision information, a desirable convergence capability that the output symbol error rate (SER) is always less than the input SER if the input SER is below a threshold, can be achieved. Then, the BG soft-switching technique is employed to combine the merits of both input and output decision information, where the former is used to guarantee SER convergence and the latter is to improve SER performance. Simulation results show that the proposed algorithm outperforms conventional blind learning algorithms, such as stochastic quadratic distance and dual mode constant modulus algorithm, in terms of both convergence performance and SER performance, for nonlinear equalization.",4
On Extended Dissipativity of Discrete-Time Neural Networks With Time Delay.,"In this brief, the problem of extended dissipativity analysis for discrete-time neural networks with time-varying delay is investigated. The definition of extended dissipativity of discrete-time neural networks is proposed, which unifies several performance measures, such as the Hinfinity performance, passivity, l2 - linfinity performance, and dissipativity. By introducing a triple-summable term in Lyapunov function, the reciprocally convex approach is utilized to bound the forward difference of the triple-summable term and then the extended dissipativity criterion for discrete-time neural networks with time-varying delay is established. The derived condition guarantees not only the extended dissipativity but also the stability of the neural networks. Two numerical examples are given to demonstrate the reduced conservatism and effectiveness of the obtained results.",4
Recurrent Neural Network for Computing the Drazin Inverse.,"This paper presents a recurrent neural network (RNN) for computing the Drazin inverse of a real matrix in real time. This recurrent neural network (RNN) is composed of n independent parts (subnetworks), where n is the order of the input matrix. These subnetworks can operate concurrently, so parallel and distributed processing can be achieved. In this way, the computational advantages over the existing sequential algorithms can be attained in real-time applications. The RNN defined in this paper is convenient for an implementation in an electronic circuit. The number of neurons in the neural network is the same as the number of elements in the output matrix, which represents the Drazin inverse. The difference between the proposed RNN and the existing ones for the Drazin inverse computation lies in their network architecture and dynamics. The conditions that ensure the stability of the defined RNN as well as its convergence toward the Drazin inverse are considered. In addition, illustrative examples and examples of application to the practical engineering problems are discussed to show the efficacy of the proposed neural network.",4
MRM-Lasso: A Sparse Multiview Feature Selection Method via Low-Rank Analysis.,"Learning about multiview data involves many applications, such as video understanding, image classification, and social media. However, when the data dimension increases dramatically, it is important but very challenging to remove redundant features in multiview feature selection. In this paper, we propose a novel feature selection algorithm, multiview rank minimization-based Lasso (MRM-Lasso), which jointly utilizes Lasso for sparse feature selection and rank minimization for learning relevant patterns across views. Instead of simply integrating multiple Lasso from view level, we focus on the performance of sample-level (sample significance) and introduce pattern-specific weights into MRM-Lasso. The weights are utilized to measure the contribution of each sample to the labels in the current view. In addition, the latent correlation across different views is successfully captured by learning a low-rank matrix consisting of pattern-specific weights. The alternating direction method of multipliers is applied to optimize the proposed MRM-Lasso. Experiments on four real-life data sets show that features selected by MRM-Lasso have better multiview classification performance than the baselines. Moreover, pattern-specific weights are demonstrated to be significant for learning about multiview data, compared with view-specific weights.",4
Global synchronization of complex dynamical networks through digital communication with limited data rate.,"This paper studies the global synchronization of complex dynamical network (CDN) under digital communication with limited bandwidth. To realize the digital communication, the so-called uniform-quantizer-sets are introduced to quantize the states of nodes, which are then encoded and decoded by newly designed encoders and decoders. To meet the requirement of the bandwidth constraint, a scaling function is utilized to guarantee the quantizers having bounded inputs and thus achieving bounded real-time quantization levels. Moreover, a new type of vector norm is introduced to simplify the expression of the bandwidth limit. Through mathematical induction, a sufficient condition is derived to ensure global synchronization of the CDNs. The lower bound on the sum of the real-time quantization levels is analyzed for different cases. Optimization method is employed to relax the requirements on the network topology and to determine the minimum of such lower bound for each case, respectively. Simulation examples are also presented to illustrate the established results.",4
Linear-time subspace clustering via bipartite graph modeling.,"We present a linear-time subspace clustering approach that combines sparse representations and bipartite graph modeling. The signals are modeled as drawn from a union of low-dimensional subspaces, and each signal is represented by a sparse combination of basis elements, termed atoms, which form the columns of a dictionary matrix. The sparse representation coefficients are arranged in a sparse affinity matrix, which defines a bipartite graph of two disjoint sets: 1) atoms and 2) signals. Subspace clustering is obtained by applying low-complexity spectral bipartite graph clustering that exploits the small number of atoms for complexity reduction. The complexity of the proposed approach is linear in the number of signals, thus it can rapidly cluster very large data collections. Performance evaluation of face clustering and temporal video segmentation demonstrates comparable clustering accuracies to state-of-the-art at a significantly lower computational load.",4
Adaptive Neural Network Dynamic Surface Control for a Class of Time-Delay Nonlinear Systems With Hysteresis Inputs and Dynamic Uncertainties.,"In this paper, an adaptive neural network (NN) dynamic surface control is proposed for a class of time-delay nonlinear systems with dynamic uncertainties and unknown hysteresis. The main advantages of the developed scheme are: 1) NNs are utilized to approximately describe nonlinearities and unknown dynamics of the nonlinear time-delay systems, making it possible to deal with unknown nonlinear uncertain systems and pursue the Linfinity performance of the tracking error; 2) using the finite covering lemma together with the NNs approximators, the Krasovskii function is abandoned, which paves the way for obtaining the Linfinity performance of the tracking error; 3) by introducing an initializing technique, the Linfinity performance of the tracking error can be achieved; 4) using a generalized Prandtl-Ishlinskii (PI) model, the limitation of the traditional PI hysteresis model is overcome; and 5) by applying the Young's inequalities to deal with the weight vector of the NNs, the updated laws are needed only at the last controller design step with only two parameters being estimated, which reduces the computational burden. It is proved that the proposed scheme can guarantee semiglobal stability of the closed-loop system and achieves the Linfinity performance of the tracking error. Simulation results for general second-order time-delay nonlinear systems and the tuning metal cutting system are presented to demonstrate the efficiency of the proposed method.",4
Matrix variate distribution-induced sparse representation for robust image classification.,"Sparse representation learning has been successfully applied into image classification, which represents a given image as a linear combination of an over-complete dictionary. The classification result depends on the reconstruction residuals. Normally, the images are stretched into vectors for convenience, and the representation residuals are characterized by l2 -norm or l1 -norm, which actually assumes that the elements in the residuals are independent and identically distributed variables. However, it is hard to satisfy the hypothesis when it comes to some structural errors, such as illuminations, occlusions, and so on. In this paper, we represent the image data in their intrinsic matrix form rather than concatenated vectors. The representation residual is considered as a matrix variate following the matrix elliptically contoured distribution, which is robust to dependent errors and has long tail regions to fit outliers. Then, we seek the maximum a posteriori probability estimation solution of the matrix-based optimization problem under sparse regularization. An alternating direction method of multipliers (ADMMs) is derived to solve the resulted optimization problem. The convergence of the ADMM is proven theoretically. Experimental results demonstrate that the proposed method is more effective than the state-of-the-art methods when dealing with the structural errors.",4
On the Universality of Axon P Systems.,"Axon P systems are computing models with a linear structure in the sense that all nodes (i.e., computing units) are arranged one by one along the axon. Such models have a good biological motivation: an axon in a nervous system is a complex information processor of impulse signals. Because the structure of axon P systems is linear, the computational power of such systems has been proved to be greatly restricted; in particular, axon P systems are not universal as language generators. It remains open whether axon P systems are universal as number generators. In this paper, we prove that axon P systems are universal as both number generators and function computing devices, and investigate the number of nodes needed to construct a universal axon P system. It is proved that four nodes (respectively, nine nodes) are enough for axon P systems to achieve universality as number generators (respectively, function computing devices). These results illustrate that the simple linear structure is enough for axon P systems to achieve a desired computational power.",4
Automatic Learning of Fine Operating Rules for Online Power System Security Control.,"Fine operating rules for security control and an automatic system for their online discovery were developed to adapt to the development of smart grids. The automatic system uses the real-time system state to determine critical flowgates, and then a continuation power flow-based security analysis is used to compute the initial transfer capability of critical flowgates. Next, the system applies the Monte Carlo simulations to expected short-term operating condition changes, feature selection, and a linear least squares fitting of the fine operating rules. The proposed system was validated both on an academic test system and on a provincial power system in China. The results indicated that the derived rules provide accuracy and good interpretability and are suitable for real-time power system security control. The use of high-performance computing systems enables these fine operating rules to be refreshed online every 15 min.",4
On the non-STDP behavior and its remedy in a floating-gate synapse.,"This brief describes the neuromorphic very large scale integration implementation of a synapse utilizing a single floating-gate (FG) transistor that can be used to store a weight in a nonvolatile manner and demonstrate biological learning rules such as spike-timing-dependent plasticity (STDP). The experimental STDP plot (change in weight against t=tpost - tpre ) of a traditional FG synapse from previous studies shows a depression instead of potentiation at some range of positive values of t -we call this non-STDP behavior. In this brief, we first analyze theoretically the reason for this anomaly and then present a simple solution based on changing control gate waveforms of the FG device to make the weight change conform closely to biological observations over a wide range of parameters. The experimental results from an FG synapse fabricated in AMS 0.35- mu m CMOS process design are also presented to justify the claim. Finally, we present the simulation results of a circuit designed to create the modified gate voltage waveform.",4
Universal Memcomputing Machines.,"We introduce the notion of universal memcomputing machines (UMMs): a class of brain-inspired general-purpose computing machines based on systems with memory, whereby processing and storing of information occur on the same physical location. We analytically prove that the memory properties of UMMs endow them with universal computing power (they are Turing-complete), intrinsic parallelism, functional polymorphism, and information overhead, namely, their collective states can support exponential data compression directly in memory. We also demonstrate that a UMM has the same computational power as a nondeterministic Turing machine, namely, it can solve nondeterministic polynomial (NP)-complete problems in polynomial time. However, by virtue of its information overhead, a UMM needs only an amount of memory cells (memprocessors) that grows polynomially with the problem size. As an example, we provide the polynomial-time solution of the subset-sum problem and a simple hardware implementation of the same. Even though these results do not prove the statement NP = P within the Turing paradigm, the practical realization of these UMMs would represent a paradigm shift from the present von Neumann architectures, bringing us closer to brain-like neural computation.",4
Spatiotemporal System Identification With Continuous Spatial Maps and Sparse Estimation.,"We present a framework for the identification of spatiotemporal linear dynamical systems. We use a state-space model representation that has the following attributes: 1) the number of spatial observation locations are decoupled from the model order; 2) the model allows for spatial heterogeneity; 3) the model representation is continuous over space; and 4) the model parameters can be identified in a simple and sparse estimation procedure. The model identification procedure we propose has four steps: 1) decomposition of the continuous spatial field using a finite set of basis functions where spatial frequency analysis is used to determine basis function width and spacing, such that the main spatial frequency contents of the underlying field can be captured; 2) initialization of states in closed form; 3) initialization of state-transition and input matrix model parameters using sparse regression-the least absolute shrinkage and selection operator method; and 4) joint state and parameter estimation using an iterative Kalman-filter/sparse-regression algorithm. To investigate the performance of the proposed algorithm we use data generated by the Kuramoto model of spatiotemporal cortical dynamics. The identification algorithm performs successfully, predicting the spatiotemporal field with high accuracy, whilst the sparse regression leads to a compact model.",4
Incremental Linear Discriminant Analysis: A Fast Algorithm and Comparisons.,"It has always been a challenging task to develop a fast and an efficient incremental linear discriminant analysis (ILDA) algorithm. For this purpose, we conduct a new study for linear discriminant analysis (LDA) in this paper and develop a new ILDA algorithm. We propose a new batch LDA algorithm called LDA/QR. LDA/QR is a simple and fast LDA algorithm, which is obtained by computing the economic QR factorization of the data matrix followed by solving a lower triangular linear system. The relationship between LDA/QR and uncorrelated LDA (ULDA) is also revealed. Based on LDA/QR, we develop a new incremental LDA algorithm called ILDA/QR. The main features of our ILDA/QR include that: 1) it can easily handle the update from one new sample or a chunk of new samples; 2) it has efficient computational complexity and space complexity; and 3) it is very fast and always achieves competitive classification accuracy compared with ULDA algorithm and existing ILDA algorithms. Numerical experiments based on some real-world data sets demonstrate that our ILDA/QR is very efficient and competitive with the state-of-the-art ILDA algorithms in terms of classification accuracy, computational complexity, and space complexity.",4
Sparse Density Estimation on the Multinomial Manifold.,"A new sparse kernel density estimator is introduced based on the minimum integrated square error criterion for the finite mixture model. Since the constraint on the mixing coefficients of the finite mixture model is on the multinomial manifold, we use the well-known Riemannian trust-region (RTR) algorithm for solving this problem. The first- and second-order Riemannian geometry of the multinomial manifold are derived and utilized in the RTR algorithm. Numerical examples are employed to demonstrate that the proposed approach is effective in constructing sparse kernel density estimators with an accuracy competitive with those of existing kernel density estimators.",4
Solving nonlinear equality constrained multiobjective optimization problems using neural networks.,"This paper develops a neural network architecture and a new processing method for solving in real time, the nonlinear equality constrained multiobjective optimization problem (NECMOP), where several nonlinear objective functions must be optimized in a conflicting situation. In this processing method, the NECMOP is converted to an equivalent scalar optimization problem (SOP). The SOP is then decomposed into several-separable subproblems processable in parallel and in a reasonable time by multiplexing switched capacitor circuits. The approach which we propose makes use of a decomposition-coordination principle that allows nonlinearity to be treated at a local level and where coordination is achieved through the use of Lagrange multipliers. The modularity and the regularity of the neural networks architecture herein proposed make it suitable for very large scale integration implementation. An application to the resolution of a physical problem is given to show that the approach used here possesses some advantages of the point of algorithmic view, and provides processes of resolution often simpler than the usual techniques.",4
Maximum Entropy Discrimination Poisson Regression for Software Reliability Modeling.,"Reliably predicting software defects is one of the most significant tasks in software engineering. Two of the major components of modern software reliability modeling approaches are: 1) extraction of salient features for software system representation, based on appropriately designed software metrics and 2) development of intricate regression models for count data, to allow effective software reliability data modeling and prediction. Surprisingly, research in the latter frontier of count data regression modeling has been rather limited. More specifically, a lack of simple and efficient algorithms for posterior computation has made the Bayesian approaches appear unattractive, and thus underdeveloped in the context of software reliability modeling. In this paper, we try to address these issues by introducing a novel Bayesian regression model for count data, based on the concept of max-margin data modeling, effected in the context of a fully Bayesian model treatment with simple and efficient posterior distribution updates. Our novel approach yields a more discriminative learning technique, making more effective use of our training data during model inference. In addition, it allows of better handling uncertainty in the modeled data, which can be a significant problem when the training data are limited. We derive elegant inference algorithms for our model under the mean-field paradigm and exhibit its effectiveness using the publicly available benchmark data sets.",4
Impulsive Multiconsensus of Second-Order Multiagent Networks Using Sampled Position Data.,"A multiconsensus problem of multiagent networks is solved in this paper, where multiconsensus refers to that the states of multiple agents in each subnetwork asymptotically converge to an individual consistent value when there exist information exchanges among subnetworks. A distributed impulsive protocol is proposed to achieve multiconsensus of second-order multiagent networks in terms of three categories: 1) stationary multiconsensus; 2) the first dynamic multiconsensus; and 3) the second dynamic multiconsensus. This impulsive protocol utilizes only sampled position data and is implemented at sampling instants. For those three categories of multiconsensus, the control parameters in the impulsive protocol are designed, respectively. Moreover, necessary and sufficient conditions are derived, under which each multiconsensus can be reached asymptotically. Several simulations are finally provided to demonstrate the effectiveness of the obtained theoretical results.",4
Performance Bounds of Quaternion Estimators.,"The quaternion widely linear (WL) estimator has been recently introduced for optimal second-order modeling of the generality of quaternion data, both second-order circular (proper) and second-order noncircular (improper). Experimental evidence exists of its performance advantage over the conventional strictly linear (SL) as well as the semi-WL (SWL) estimators for improper data. However, rigorous theoretical and practical performance bounds are still missing in the literature, yet this is crucial for the development of quaternion valued learning systems for 3-D and 4-D data. To this end, based on the orthogonality principle, we introduce a rigorous closed-form solution to quantify the degree of performance benefits, in terms of the mean square error, obtained when using the WL models. The cases when the optimal WL estimation can simplify into the SWL or the SL estimation are also discussed.",4
A Digital Liquid State Machine With Biologically Inspired Learning and Its Application to Speech Recognition.,"This paper presents a bioinspired digital liquid-state machine (LSM) for low-power very-large-scale-integration (VLSI)-based machine learning applications. To the best of the authors' knowledge, this is the first work that employs a bioinspired spike-based learning algorithm for the LSM. With the proposed online learning, the LSM extracts information from input patterns on the fly without needing intermediate data storage as required in offline learning methods such as ridge regression. The proposed learning rule is local such that each synaptic weight update is based only upon the firing activities of the corresponding presynaptic and postsynaptic neurons without incurring global communications across the neural network. Compared with the backpropagation-based learning, the locality of computation in the proposed approach lends itself to efficient parallel VLSI implementation. We use subsets of the TI46 speech corpus to benchmark the bioinspired digital LSM. To reduce the complexity of the spiking neural network model without performance degradation for speech recognition, we study the impacts of synaptic models on the fading memory of the reservoir and hence the network performance. Moreover, we examine the tradeoffs between synaptic weight resolution, reservoir size, and recognition performance and present techniques to further reduce the overhead of hardware implementation. Our simulation results show that in terms of isolated word recognition evaluated using the TI46 speech corpus, the proposed digital LSM rivals the state-of-the-art hidden Markov-model-based recognizer Sphinx-4 and outperforms all other reported recognizers including the ones that are based upon the LSM or neural networks.",4
Sparse Coding on Symmetric Positive Definite Manifolds Using Bregman Divergences.,"This paper introduces sparse coding and dictionary learning for symmetric positive definite (SPD) matrices, which are often used in machine learning, computer vision, and related areas. Unlike traditional sparse coding schemes that work in vector spaces, in this paper, we discuss how SPD matrices can be described by sparse combination of dictionary atoms, where the atoms are also SPD matrices. We propose to seek sparse coding by embedding the space of SPD matrices into the Hilbert spaces through two types of the Bregman matrix divergences. This not only leads to an efficient way of performing sparse coding but also an online and iterative scheme for dictionary learning. We apply the proposed methods to several computer vision tasks where images are represented by region covariance matrices. Our proposed algorithms outperform state-of-the-art methods on a wide range of classification tasks, including face recognition, action recognition, material classification, and texture categorization.",4
Sparse representation in kernel machines.,We study the properties of least square kernel regression with l1 coefficient regularization. The kernels can be flexibly chosen to be either positive definite or indefinite. Asymptotic learning rates are deduced under smoothness condition on the kernel. Sparse representation of the solution is characterized theoretically. Empirical simulations and real applications indicate that both good learning performance and sparse representation could be guaranteed.,4
Active Learning-Based Pedagogical Rule Extraction.,"Many of the state-of-the-art data mining techniques introduce nonlinearities in their models to cope with complex data relationships effectively. Although such techniques are consistently included among the top classification techniques in terms of predictive power, their lack of transparency renders them useless in any domain where comprehensibility is of importance. Rule-extraction algorithms remedy this by distilling comprehensible rule sets from complex models that explain how the classifications are made. This paper considers a new rule extraction technique, based on active learning. The technique generates artificial data points around training data with low confidence in the output score, after which these are labeled by the black-box model. The main novelty of the proposed method is that it uses a pedagogical approach without making any architectural assumptions of the underlying model. It can therefore be applied to any black-box technique. Furthermore, it can generate any rule format, depending on the chosen underlying rule induction technique. In a large-scale empirical study, we demonstrate the validity of our technique to extract trees and rules from artificial neural networks, support vector machines, and random forests, on 25 data sets of varying size and dimensionality. Our results show that not only do the generated rules explain the black-box models well (thereby facilitating the acceptance of such models), the proposed algorithm also performs significantly better than traditional rule induction techniques in terms of accuracy as well as fidelity.",4
Feedback Solution to Optimal Switching Problems With Switching Cost.,"The problem of optimal switching between nonlinear autonomous subsystems is investigated in this paper where the objective is not only bringing the states to close to the desired point, but also adjusting the switching pattern, in the sense of penalizing switching occurrences and assigning different preferences to utilization of different modes. The mode sequence is unspecified and a switching cost term is used in the cost function for penalizing each switching. It is shown that once a switching cost is incorporated, the optimal cost-to-go function depends on the subsystem which was active at the previous time step. Afterward, an approximate dynamic programming-based method is developed, which provides an approximation of the optimal solution to the problem in a feedback form and for different initial conditions. Finally, the performance of the method is analyzed through numerical examples.",4
Constrained Clustering With Imperfect Oracles.,"While clustering is usually an unsupervised operation, there are circumstances where we have access to prior belief that pairs of samples should (or should not) be assigned with the same cluster. Constrained clustering aims to exploit this prior belief as constraint (or weak supervision) to influence the cluster formation so as to obtain a data structure more closely resembling human perception. Two important issues remain open: 1) how to exploit sparse constraints effectively and 2) how to handle ill-conditioned/noisy constraints generated by imperfect oracles. In this paper, we present a novel pairwise similarity measure framework to address the above issues. Specifically, in contrast to existing constrained clustering approaches that blindly rely on all features for constraint propagation, our approach searches for neighborhoods driven by discriminative feature selection for more effective constraint diffusion. Crucially, we formulate a novel approach to handling the noisy constraint problem, which has been unrealistically ignored in the constrained clustering literature. Extensive comparative results show that our method is superior to the state-of-the-art constrained clustering approaches and can generally benefit existing pairwise similarity-based data clustering algorithms, such as spectral clustering and affinity propagation.",4
Scene recognition by manifold regularized deep learning architecture.,"Scene recognition is an important problem in the field of computer vision, because it helps to narrow the gap between the computer and the human beings on scene understanding. Semantic modeling is a popular technique used to fill the semantic gap in scene recognition. However, most of the semantic modeling approaches learn shallow, one-layer representations for scene recognition, while ignoring the structural information related between images, often resulting in poor performance. Modeled after our own human visual system, as it is intended to inherit humanlike judgment, a manifold regularized deep architecture is proposed for scene recognition. The proposed deep architecture exploits the structural information of the data, making for a mapping between visible layer and hidden layer. By the proposed approach, a deep architecture could be designed to learn the high-level features for scene recognition in an unsupervised fashion. Experiments on standard data sets show that our method outperforms the state-of-the-art used for scene recognition.",4
Mode-Dependent Stochastic Synchronization for Markovian Coupled Neural Networks With Time-Varying Mode-Delays.,"This paper investigates the stochastic synchronization problem for Markovian hybrid coupled neural networks with interval time-varying mode-delays and random coupling strengths. The coupling strengths are mutually independent random variables and the coupling configuration matrices are nonsymmetric. A mode-dependent augmented Lyapunov-Krasovskii functional (LKF) is proposed, where some terms involving triple or quadruple integrals are considered, which makes the LKF matrices mode-dependent as much as possible. This gives significant improvement in the synchronization criteria, i.e., less conservative results can be obtained. In addition, by applying an extended Jensen's integral inequality and the properties of random variables, new delay-dependent synchronization criteria are derived. The obtained criteria depend not only on upper and lower bounds of mode-delays but also on mathematical expectations and variances of the random coupling strengths. Finally, two numerical examples are provided to demonstrate the feasibility of the proposed results.",4
Dependent online kernel learning with constant number of random Fourier features.,"Traditional online kernel learning analysis assumes independently identically distributed (i.i.d.) about the training sequence. Recent studies reveal that when the loss function is smooth and strongly convex, given T i.i.d. training instances, a constant sampling complexity of random Fourier features is sufficient to ensure O(logT/T) convergence rate of excess risk, which is optimal in online kernel learning up to a logT factor. However, the i.i.d. hypothesis is too strong in practice, which greatly impairs their value. In this paper, we study the sampling complexity of random Fourier features in online kernel learning under non-i.i.d. assumptions. We prove that the sampling complexity under non-i.i.d. settings is also constant, but the convergence rate of excess risk is O(logT/T+ varphi) , where varphi is the mixing coefficient measuring the extent of non-i.i.d. of training sequence. We conduct experiments both on artificial and real large-scale data sets to verify our theories.",4
Automatic face naming by learning discriminative affinity matrices from weakly labeled images.,"Given a collection of images, where each image contains several faces and is associated with a few names in the corresponding caption, the goal of face naming is to infer the correct name for each face. In this paper, we propose two new methods to effectively solve this problem by learning two discriminative affinity matrices from these weakly labeled images. We first propose a new method called regularized low-rank representation by effectively utilizing weakly supervised information to learn a low-rank reconstruction coefficient matrix while exploring multiple subspace structures of the data. Specifically, by introducing a specially designed regularizer to the low-rank representation method, we penalize the corresponding reconstruction coefficients related to the situations where a face is reconstructed by using face images from other subjects or by using itself. With the inferred reconstruction coefficient matrix, a discriminative affinity matrix can be obtained. Moreover, we also develop a new distance metric learning method called ambiguously supervised structural metric learning by using weakly supervised information to seek a discriminative distance metric. Hence, another discriminative affinity matrix can be obtained using the similarity matrix (i.e., the kernel matrix) based on the Mahalanobis distances of the data. Observing that these two affinity matrices contain complementary information, we further combine them to obtain a fused affinity matrix, based on which we develop a new iterative scheme to infer the name of each face. Comprehensive experiments demonstrate the effectiveness of our approach.",4
Learning to rank for blind image quality assessment.,"Blind image quality assessment (BIQA) aims to predict perceptual image quality scores without access to reference images. State-of-the-art BIQA methods typically require subjects to score a large number of images to train a robust model. However, subjective quality scores are imprecise, biased, and inconsistent, and it is challenging to obtain a large-scale database, or to extend existing databases, because of the inconvenience of collecting images, training the subjects, conducting subjective experiments, and realigning human quality evaluations. To combat these limitations, this paper explores and exploits preference image pairs (PIPs) such as the quality of image Ia is better than that of image Ib for training a robust BIQA model. The preference label, representing the relative quality of two images, is generally precise and consistent, and is not sensitive to image content, distortion type, or subject identity; such PIPs can be generated at a very low cost. The proposed BIQA method is one of learning to rank. We first formulate the problem of learning the mapping from the image features to the preference label as one of classification. In particular, we investigate the utilization of a multiple kernel learning algorithm based on group lasso to provide a solution. A simple but effective strategy to estimate perceptual image quality scores is then presented. Experiments show that the proposed BIQA method is highly effective and achieves a performance comparable with that of state-of-the-art BIQA algorithms. Moreover, the proposed method can be easily extended to new distortion categories.",4
Noise Level Estimation for Model Selection in Kernel PCA Denoising.,"One of the main challenges in unsupervised learning is to find suitable values for the model parameters. In kernel principal component analysis (kPCA), for example, these are the number of components, the kernel, and its parameters. This paper presents a model selection criterion based on distance distributions (MDDs). This criterion can be used to find the number of components and the sigma(2) parameter of radial basis function kernels by means of spectral comparison between information and noise. The noise content is estimated from the statistical moments of the distribution of distances in the original dataset. This allows for a type of randomization of the dataset, without actually having to permute the data points or generate artificial datasets. After comparing the eigenvalues computed from the estimated noise with the ones from the input dataset, information is retained and maximized by a set of model parameters. In addition to the model selection criterion, this paper proposes a modification to the fixed-size method and uses the incomplete Cholesky factorization, both of which are used to solve kPCA in large-scale applications. These two approaches, together with the model selection MDD, were tested in toy examples and real life applications, and it is shown that they outperform other known algorithms.",4
Nonlinear model predictive control based on collective neurodynamic optimization.,"In general, nonlinear model predictive control (NMPC) entails solving a sequential global optimization problem with a nonconvex cost function or constraints. This paper presents a novel collective neurodynamic optimization approach to NMPC without linearization. Utilizing a group of recurrent neural networks (RNNs), the proposed collective neurodynamic optimization approach searches for optimal solutions to global optimization problems by emulating brainstorming. Each RNN is guaranteed to converge to a candidate solution by performing constrained local search. By exchanging information and iteratively improving the starting and restarting points of each RNN using the information of local and global best known solutions in a framework of particle swarm optimization, the group of RNNs is able to reach global optimal solutions to global optimization problems. The essence of the proposed collective neurodynamic optimization approach lies in the integration of capabilities of global search and precise local search. The simulation results of many cases are discussed to substantiate the effectiveness and the characteristics of the proposed approach.",4
Deep and shallow architecture of multilayer neural networks.,"This paper focuses on the deep and shallow architecture of multilayer neural networks (MNNs). The demonstration of whether or not an MNN can be replaced by another MNN with fewer layers is equivalent to studying the topological conjugacy of its hidden layers. This paper provides a systematic methodology to indicate when two hidden spaces are topologically conjugated. Furthermore, some criteria are presented for some specific cases.",4
Stability criteria for recurrent neural networks with time-varying delay based on secondary delay partitioning method.,"A secondary delay partitioning method is proposed to study the stability problem for a class of recurrent neural networks (RNNs) with time-varying delay. The total interval of the time-varying delay is first divided into two parts, and then each part is further divided into several subintervals. To deal with the state variables associated with these subintervals, an extended reciprocal convex combination approach and a double integral term with variable upper and lower limits of integral as a Lyapunov functional are proposed, which help to obtain the stability criterion. The main feature of the proposed result is more effective for the RNNs with fast time-varying delay. A numerical example is used to show the effectiveness of the proposed stability result.",4
L1 -norm low-rank matrix factorization by variational Bayesian method.,"The L1 -norm low-rank matrix factorization (LRMF) has been attracting much attention due to its wide applications to computer vision and pattern recognition. In this paper, we construct a new hierarchical Bayesian generative model for the L1 -norm LRMF problem and design a mean-field variational method to automatically infer all the parameters involved in the model by closed-form equations. The variational Bayesian inference in the proposed method can be understood as solving a weighted LRMF problem with different weights on matrix elements based on their significance and with L2 -regularization penalties on parameters. Throughout the inference process of our method, the weights imposed on the matrix elements can be adaptively fitted so that the adverse influence of noises and outliers embedded in data can be largely suppressed, and the parameters can be appropriately regularized so that the generalization capability of the problem can be statistically guaranteed. The robustness and the efficiency of the proposed method are substantiated by a series of synthetic and real data experiments, as compared with the state-of-the-art L1 -norm LRMF methods. Especially, attributed to the intrinsic generalization capability of the Bayesian methodology, our method can always predict better on the unobserved ground truth data than existing methods.",4
Data imputation through the identification of local anomalies.,"We introduce a comprehensive and statistical framework in a model free setting for a complete treatment of localized data corruptions due to severe noise sources, e.g., an occluder in the case of a visual recording. Within this framework, we propose: 1) a novel algorithm to efficiently separate, i.e., detect and localize, possible corruptions from a given suspicious data instance and 2) a maximum a posteriori estimator to impute the corrupted data. As a generalization to Euclidean distance, we also propose a novel distance measure, which is based on the ranked deviations among the data attributes and empirically shown to be superior in separating the corruptions. Our algorithm first splits the suspicious instance into parts through a binary partitioning tree in the space of data attributes and iteratively tests those parts to detect local anomalies using the nominal statistics extracted from an uncorrupted (clean) reference data set. Once each part is labeled as anomalous versus normal, the corresponding binary patterns over this tree that characterize corruptions are identified and the affected attributes are imputed. Under a certain conditional independency structure assumed for the binary patterns, we analytically show that the false alarm rate of the introduced algorithm in detecting the corruptions is independent of the data and can be directly set without any parameter tuning. The proposed framework is tested over several well-known machine learning data sets with synthetically generated corruptions and experimentally shown to produce remarkable improvements in terms of classification purposes with strong corruption separation capabilities. Our experiments also indicate that the proposed algorithms outperform the typical approaches and are robust to varying training phase conditions.",4
Deformed graph laplacian for semisupervised learning.,"Graph Laplacian has been widely exploited in traditional graph-based semisupervised learning (SSL) algorithms to regulate the labels of examples that vary smoothly on the graph. Although it achieves a promising performance in both transductive and inductive learning, it is not effective for handling ambiguous examples (shown in Fig. 1). This paper introduces deformed graph Laplacian (DGL) and presents label prediction via DGL (LPDGL) for SSL. The local smoothness term used in LPDGL, which regularizes examples and their neighbors locally, is able to improve classification accuracy by properly dealing with ambiguous examples. Theoretical studies reveal that LPDGL obtains the globally optimal decision function, and the free parameters are easy to tune. The generalization bound is derived based on the robustness analysis. Experiments on a variety of real-world data sets demonstrate that LPDGL achieves top-level performance on both transductive and inductive settings by comparing it with popular SSL algorithms, such as harmonic functions, AnchorGraph regularization, linear neighborhood propagation, Laplacian regularized least square, and Laplacian support vector machine.",4
Asymmetric mixture model with simultaneous feature selection and model detection.,"A mixture model based on the symmetric Gaussian distribution that simultaneously treats the feature selection, and the model detection has recently received great attention for pattern recognition problems. However, in many applications, the distribution of the data has a non-Gaussian and nonsymmetric form. This brief presents a new asymmetric mixture model for model detection and model selection. In this brief, the proposed asymmetric distribution is modeled with multiple student's- t distributions, which are heavily tailed and more robust than Gaussian distributions. Our method has the flexibility to fit different shapes of observed data, such as non-Gaussian and nonsymmetric. Another advantage is that the proposed algorithm, which is based on the variational Bayesian learning, can simultaneously optimize over the number of the student's- t distribution that is used to model each asymmetric distribution, the number of components, and the saliency of the features. Numerical experiments on both synthetic and real-world datasets are conducted. The performance of the proposed model is compared with other mixture models, demonstrating the robustness, accuracy, and effectiveness of our method.",4
Non-divergence of stochastic discrete time algorithms for PCA neural networks.,"Learning algorithms play an important role in the practical application of neural networks based on principal component analysis, often determining the success, or otherwise, of these applications. These algorithms cannot be divergent, but it is very difficult to directly study their convergence properties, because they are described by stochastic discrete time (SDT) algorithms. This brief analyzes the original SDT algorithms directly, and derives some invariant sets that guarantee the nondivergence of these algorithms in a stochastic environment by selecting proper learning parameters. Our theoretical results are verified by a series of simulation examples.",4
Delay-based reservoir computing: noise effects in a combined analog and digital implementation.,"Reservoir computing is a paradigm in machine learning whose processing capabilities rely on the dynamical behavior of recurrent neural networks. We present a mixed analog and digital implementation of this concept with a nonlinear analog electronic circuit as a main computational unit. In our approach, the reservoir network can be replaced by a single nonlinear element with delay via time-multiplexing. We analyze the influence of noise on the performance of the system for two benchmark tasks: 1) a classification problem and 2) a chaotic time-series prediction task. Special attention is given to the role of quantization noise, which is studied by varying the resolution in the conversion interface between the analog and digital worlds.",4
Consensus-based distributed cooperative learning from closed-loop neural control systems.,"In this paper, the neural tracking problem is addressed for a group of uncertain nonlinear systems where the system structures are identical but the reference signals are different. This paper focuses on studying the learning capability of neural networks (NNs) during the control process. First, we propose a novel control scheme called distributed cooperative learning (DCL) control scheme, by establishing the communication topology among adaptive laws of NN weights to share their learned knowledge online. It is further proved that if the communication topology is undirected and connected, all estimated weights of NNs can converge to small neighborhoods around their optimal values over a domain consisting of the union of all state orbits. Second, as a corollary it is shown that the conclusion on the deterministic learning still holds in the decentralized adaptive neural control scheme where, however, the estimated weights of NNs just converge to small neighborhoods of the optimal values along their own state orbits. Thus, the learned controllers obtained by DCL scheme have the better generalization capability than ones obtained by decentralized learning method. A simulation example is provided to verify the effectiveness and advantages of the control schemes proposed in this paper.",4
Adaptive hidden Markov model with anomaly States for price manipulation detection.,"Price manipulation refers to the activities of those traders who use carefully designed trading behaviors to manually push up or down the underlying equity prices for making profits. With increasing volumes and frequency of trading, price manipulation can be extremely damaging to the proper functioning and integrity of capital markets. The existing literature focuses on either empirical studies of market abuse cases or analysis of particular manipulation types based on certain assumptions. Effective approaches for analyzing and detecting price manipulation in real time are yet to be developed. This paper proposes a novel approach, called adaptive hidden Markov model with anomaly states (AHMMAS) for modeling and detecting price manipulation activities. Together with wavelet transformations and gradients as the feature extraction methods, the AHMMAS model caters to price manipulation detection and basic manipulation type recognition. The evaluation experiments conducted on seven stock tick data from NASDAQ and the London Stock Exchange and 10 simulated stock prices by stochastic differential equation show that the proposed AHMMAS model can effectively detect price manipulation patterns and outperforms the selected benchmark models.",4
Backstepping fuzzy-neural-network control design for hybrid maglev transportation system.,"This paper focuses on the design of a backstepping fuzzy-neural-network control (BFNNC) for the online levitated balancing and propulsive positioning of a hybrid magnetic levitation (maglev) transportation system. The dynamic model of the hybrid maglev transportation system including levitated hybrid electromagnets to reduce the suspension power loss and the friction force during linear movement and a propulsive linear induction motor based on the concepts of mechanical geometry and motion dynamics is first constructed. The ultimate goal is to design an online fuzzy neural network (FNN) control methodology to cope with the problem of the complicated control transformation and the chattering control effort in backstepping control (BSC) design, and to directly ensure the stability of the controlled system without the requirement of strict constraints, detailed system information, and auxiliary compensated controllers despite the existence of uncertainties. In the proposed BFNNC scheme, an FNN control is utilized to be the major control role by imitating the BSC strategy, and adaptation laws for network parameters are derived in the sense of projection algorithm and Lyapunov stability theorem to ensure the network convergence as well as stable control performance. The effectiveness of the proposed control strategy for the hybrid maglev transportation system is verified by experimental results, and the superiority of the BFNNC scheme is indicated in comparison with the BSC strategy and the backstepping particle-swarm-optimization control system in previous research.",4
Consensus in continuous-time multiagent systems under discontinuous nonlinear protocols.,"In this paper, we provide a theoretical analysis for nonlinear discontinuous consensus protocols in networks of multiagents over weighted directed graphs. By integrating the analytic tools from nonsmooth stability analysis and graph theory, we investigate networks with both fixed topology and randomly switching topology. For networks with a fixed topology, we provide a sufficient and necessary condition for asymptotic consensus, and the consensus value can be explicitly calculated. As to networks with switching topologies, we provide a sufficient condition for the network to realize consensus almost surely. In particular, we consider the case that the switching sequence is independent and identically distributed. As applications of the theoretical results, we introduce a generalized blinking model and show that consensus can be realized almost surely under the proposed protocols. Numerical simulations are also provided to illustrate the theoretical results.",4
Scatter balance: an angle-based supervised dimensionality reduction.,"Subspace selection is widely applied in data classification, clustering, and visualization. The samples projected into subspace can be processed efficiently. In this paper, we research the linear discriminant analysis (LDA) and maximum margin criterion (MMC) algorithms intensively and analyze the effects of scatters to subspace selection. Meanwhile, we point out the boundaries of scatters in LDA and MMC algorithms to illustrate the differences and similarities of subspace selection in different circumstances. Besides, the effects of outlier classes on subspace selection are also analyzed. According to the above analysis, we propose a new subspace selection method called angle linear discriminant embedding (ALDE) on the basis of angle measurement. ALDE utilizes the cosine of the angle to get new within-class and between-class scatter matrices and avoids the small sample size problem simultaneously. To deal with high-dimensional data, we extend ALDE to a two-stage ALDE (TS-ALDE). The synthetic data experiments indicate that ALDE can balance the within-class and between-class scatters and be robust to outlier classes. The experimental results based on UCI machine-learning repository and image databases show that TS-ALDE has a lower time complexity than ALDE while processing high-dimensional data.",4
A scalable projective scaling algorithm for l(p) loss with convex penalizations.,"This paper presents an accurate, efficient, and scalable algorithm for minimizing a special family of convex functions, which have a lp loss function as an additive component. For this problem, well-known learning algorithms often have well-established results on accuracy and efficiency, but there exists rarely any report on explicit linear scalability with respect to the problem size. The proposed approach starts with developing a second-order learning procedure with iterative descent for general convex penalization functions, and then builds efficient algorithms for a restricted family of functions, which satisfy the Karmarkar's projective scaling condition. Under this condition, a light weight, scalable message passing algorithm (MPA) is further developed by constructing a series of simpler equivalent problems. The proposed MPA is intrinsically scalable because it only involves matrix-vector multiplication and avoids matrix inversion operations. The MPA is proven to be globally convergent for convex formulations; for nonconvex situations, it converges to a stationary point. The accuracy, efficiency, scalability, and applicability of the proposed method are verified through extensive experiments on sparse signal recovery, face image classification, and over-complete dictionary learning problems.",4
Semisupervised feature selection via spline regression for video semantic recognition.,"To improve both the efficiency and accuracy of video semantic recognition, we can perform feature selection on the extracted video features to select a subset of features from the high-dimensional feature set for a compact and accurate video data representation. Provided the number of labeled videos is small, supervised feature selection could fail to identify the relevant features that are discriminative to target classes. In many applications, abundant unlabeled videos are easily accessible. This motivates us to develop semisupervised feature selection algorithms to better identify the relevant video features, which are discriminative to target classes by effectively exploiting the information underlying the huge amount of unlabeled video data. In this paper, we propose a framework of video semantic recognition by semisupervised feature selection via spline regression (S(2)FS(2)R) . Two scatter matrices are combined to capture both the discriminative information and the local geometry structure of labeled and unlabeled training videos: A within-class scatter matrix encoding discriminative information of labeled training videos and a spline scatter output from a local spline regression encoding data distribution. An l2,1 -norm is imposed as a regularization term on the transformation matrix to ensure it is sparse in rows, making it particularly suitable for feature selection. To efficiently solve S(2)FS(2)R , we develop an iterative algorithm and prove its convergency. In the experiments, three typical tasks of video semantic recognition, such as video concept detection, video classification, and human action recognition, are used to demonstrate that the proposed S(2)FS(2)R achieves better performance compared with the state-of-the-art methods.",4
Efficient l1 -norm-based low-rank matrix approximations for large-scale problems using alternating rectified gradient method.,"Low-rank matrix approximation plays an important role in the area of computer vision and image processing. Most of the conventional low-rank matrix approximation methods are based on the l2 -norm (Frobenius norm) with principal component analysis (PCA) being the most popular among them. However, this can give a poor approximation for data contaminated by outliers (including missing data), because the l2 -norm exaggerates the negative effect of outliers. Recently, to overcome this problem, various methods based on the l1 -norm, such as robust PCA methods, have been proposed for low-rank matrix approximation. Despite the robustness of the methods, they require heavy computational effort and substantial memory for high-dimensional data, which is impractical for real-world problems. In this paper, we propose two efficient low-rank factorization methods based on the l1 -norm that find proper projection and coefficient matrices using the alternating rectified gradient method. The proposed methods are applied to a number of low-rank matrix approximation problems to demonstrate their efficiency and robustness. The experimental results show that our proposals are efficient in both execution time and reconstruction performance unlike other state-of-the-art methods.",4
Modified neural dynamic surface approach to output feedback of MIMO nonlinear systems.,"We report an adaptive output feedback dynamic surface control (DSC), maintaining the prescribed performance, for a class of uncertain nonlinear systems with multiinput and multioutput. Designing neural network observers and modifying the DSC method achieves several control objectives. First, to achieve output feedback control, the finite-time echo state networks (ESN) observer with fast convergence is designed to obtain the online system states. Thus, the immeasurable states in traditional state feedback control are estimated and the unknown functions are approximated by ESN. Then, a modified DSC approach is developed by introducing a high-order sliding mode differentiator to replace the first-order filter in each step. Thus, the effect of filter performance on closed-loop stability is reduced. Furthermore, the input to state stability guarantees that all signals of the whole closed-loop system are semiglobally uniformly ultimately bounded. Specifically, the performance functions make the tracking errors converge to a compact set around equilibrium. Two numerical examples illustrated the proposed control scheme with satisfactory results.",4
Lag Synchronization of Switched Neural Networks via Neural Activation Function and Applications in Image Encryption.,"This paper investigates the problem of global exponential lag synchronization of a class of switched neural networks with time-varying delays via neural activation function and applications in image encryption. The controller is dependent on the output of the system in the case of packed circuits, since it is hard to measure the inner state of the circuits. Thus, it is critical to design the controller based on the neuron activation function. Comparing the results, in this paper, with the existing ones shows that we improve and generalize the results derived in the previous literature. Several examples are also given to illustrate the effectiveness and potential applications in image encryption.",4
Hierarchical cooperative control for multiagent systems with switching directed topologies.,"The hierarchical cooperative control problem is concerned for a two-layer networked multiagent system under switching directed topologies. The group cooperative objective is to achieve finite-time formation control for the upper layer of leaders and containment control for the lower layer of followers. Two kinds of cooperative strategies, including centralized-distributed control and distributed-distributed control, are proposed for two types of switching laws: 1) random switching law with the dwell time and 2) Markov switching law with stationary distribution. Utilizing the state transition matrix methods and matrix measure techniques, some sufficient conditions are derived for asymptotical containment control and exponential almost sure containment control, respectively. Finally, some numerical examples are provided to demonstrate the effectiveness of the proposed control schemes.",4
VC-dimension of univariate decision trees.,"In this paper, we give and prove the lower bounds of the Vapnik-Chervonenkis (VC)-dimension of the univariate decision tree hypothesis class. The VC-dimension of the univariate decision tree depends on the VC-dimension values of its subtrees and the number of inputs. Via a search algorithm that calculates the VC-dimension of univariate decision trees exhaustively, we show that our VC-dimension bounds are tight for simple trees. To verify that the VC-dimension bounds are useful, we also use them to get VC-generalization bounds for complexity control using structural risk minimization in decision trees, i.e., pruning. Our simulation results show that structural risk minimization pruning using the VC-dimension bounds finds trees that are more accurate as those pruned using cross validation.",4
A kernel adaptive algorithm for quaternion-valued inputs.,"The use of quaternion data can provide benefit in applications like robotics and image recognition, and particularly for performing transforms in 3-D space. Here, we describe a kernel adaptive algorithm for quaternions. A least mean square (LMS)-based method was used, resulting in the derivation of the quaternion kernel LMS (Quat-KLMS) algorithm. Deriving this algorithm required describing the idea of a quaternion reproducing kernel Hilbert space (RKHS), as well as kernel functions suitable with quaternions. A modified HR calculus for Hilbert spaces was used to find the gradient of cost functions defined on a quaternion RKHS. In addition, the use of widely linear (or augmented) filtering is proposed to improve performance. The benefit of the Quat-KLMS and widely linear forms in learning nonlinear transformations of quaternion data are illustrated with simulations.",4
Memristor-based multilayer neural networks with online gradient descent training.,"Learning in multilayer neural networks (MNNs) relies on continuous updating of large matrices of synaptic weights by local rules. Such locality can be exploited for massive parallelism when implementing MNNs in hardware. However, these update rules require a multiply and accumulate operation for each synaptic weight, which is challenging to implement compactly using CMOS. In this paper, a method for performing these update operations simultaneously (incremental outer products) using memristor-based arrays is proposed. The method is based on the fact that, approximately, given a voltage pulse, the conductivity of a memristor will increment proportionally to the pulse duration multiplied by the pulse magnitude if the increment is sufficiently small. The proposed method uses a synaptic circuit composed of a small number of components per synapse: one memristor and two CMOS transistors. This circuit is expected to consume between 2% and 8% of the area and static power of previous CMOS-only hardware alternatives. Such a circuit can compactly implement hardware MNNs trainable by scalable algorithms based on online gradient descent (e.g., backpropagation). The utility and robustness of the proposed memristor-based circuit are demonstrated on standard supervised learning tasks.",4
A parametric classification rule based on the exponentially embedded family.,"In this paper, we extend the exponentially embedded family (EEF), a new approach to model order estimation and probability density function construction originally proposed by Kay in 2005, to multivariate pattern recognition. Specifically, a parametric classifier rule based on the EEF is developed, in which we construct a distribution for each class based on a reference distribution. The proposed method can address different types of classification problems in either a data-driven manner or a model-driven manner. In this paper, we demonstrate its effectiveness with examples of synthetic data classification and real-life data classification in a data-driven manner and the example of power quality disturbance classification in a model-driven manner. To evaluate the classification performance of our approach, the Monte-Carlo method is used in our experiments. The promising experimental results indicate many potential applications of the proposed method.",4
Optimal critic learning for robot control in time-varying environments.,"In this paper, optimal critic learning is developed for robot control in a time-varying environment. The unknown environment is described as a linear system with time-varying parameters, and impedance control is employed for the interaction control. Desired impedance parameters are obtained in the sense of an optimal realization of the composite of trajectory tracking and force regulation. Q -function-based critic learning is developed to determine the optimal impedance parameters without the knowledge of the system dynamics. The simulation results are presented and compared with existing methods, and the efficacy of the proposed method is verified.",4
Nuclear norm-based 2-DPCA for extracting features from images.,"The 2-D principal component analysis (2-DPCA) is a widely used method for image feature extraction. However, it can be equivalently implemented via image-row-based principal component analysis. This paper presents a structured 2-D method called nuclear norm-based 2-DPCA (N-2-DPCA), which uses a nuclear norm-based reconstruction error criterion. The nuclear norm is a matrix norm, which can provide a structured 2-D characterization for the reconstruction error image. The reconstruction error criterion is minimized by converting the nuclear norm-based optimization problem into a series of F-norm-based optimization problems. In addition, N-2-DPCA is extended to a bilateral projection-based N-2-DPCA (N-B2-DPCA). The virtue of N-B2-DPCA over N-2-DPCA is that an image can be represented with fewer coefficients. N-2-DPCA and N-B2-DPCA are applied to face recognition and reconstruction and evaluated using the Extended Yale B, CMU PIE, FRGC, and AR databases. Experimental results demonstrate the effectiveness of the proposed methods.",4
Synchronization of linearly coupled networks with delays via aperiodically intermittent pinning control.,"In this paper, we investigate the exponential synchronization problem for linearly coupled networks with delay by pinning a simple aperiodically intermittent controller. The network topology can be directed. Different from previous works, the intermittent control can be aperiodic. Two types of delay are considered. The first case is that the delay is time-varying and large, and in this case, there is no restriction imposed on the delay and the control (and/or rest) width. The other one is that the delay is small enough so that it is less than the minimum of control width. Different approaches are provided to investigate these two cases, and some criteria are given to realize exponential synchronization. Furthermore, by applying the adaptive approach to the second model, we establish a general adaptive theory for intermittent control, which can be applied not only to networks without time delay, but also to delayed networks, regardless of whether the intermittent control is periodic or aperiodic. Finally, the numerical simulations are given to verify the validness of the theoretical results.",4
Optimal codesign of nonlinear control systems based on a modified policy iteration method.,"This brief studies the optimal codesign of nonlinear control systems: simultaneous design of physical plants and related optimal control policies. Nonlinearity of the optimal codesign problem could come from either a nonquadratic cost function or the plant. After formulating the optimal codesign into a nonconvex optimization problem, an iterative scheme is proposed in this brief by adding an additional step of system-equivalence-based policy improvement to the conventional policy iteration. We have proved rigorously that the closed-loop system performance can be improved after each step of the proposed policy iteration scheme, and the convergence to a suboptimal solution is guaranteed. It is also shown that under certain conditions, this additional policy improvement step can be conducted by solving a quadratic programming problem. The linear version of the proposed methodology is addressed in the context of linear quadratic regulator. Finally, the effectiveness of the proposed methodology is illustrated through the optimal codesign of a load-positioning system.",4
On the role of astroglial syncytia in self-repairing spiking neural networks.,"It has been shown that brain-like self-repair can arise from the interactions between neurons and astrocytes where endocannabinoids are synthesized and released from active neurons. This retrograde messenger feeds back to local synapses directly and indirectly to distant synapses via astrocytes. This direct/indirect feedback of the endocannabinoid retrograde messenger results in the modulation of the probability of release (PR) at synaptic sites. When synapses fail, there is a corresponding falloff in the firing activity of the associated neurons, and hence the strength of the direct feedback messenger diminishes. This triggers an increase in PR of healthy synapses, due to the indirect messenger from other active neurons, which is the catalyst for the repair process. In this paper, the repair process is implemented by developing a new learning rule that captures the spike-timing-dependent plasticity and Bienenstock, Cooper, and Munro learning rules. The rule is activated by the increase in PR and results in a potentiation of the weight values, which reestablishes the firing activity of neurons. In addition, this self-repairing mechanism is extended to network-level repair where astrocyte to astrocyte communications are implemented using a linear gap junction model. This facilitates the implementation of an astroglial syncytium involving multiple astrocytes, which relays the indirect feedback messenger to distant neurons: each astrocyte is bidirectionally coupled to neurons. A detailed and comprehensive set of results with analysis is presented demonstrating repair at both cellular and network levels.",4
Linear regression-based efficient SVM learning for large-scale classification.,"For large-scale classification tasks, especially in the classification of images, additive kernels have shown a state-of-the-art accuracy. However, even with the recent development of fast algorithms, learning speed and the ability to handle large-scale tasks are still open problems. This paper proposes algorithms for large-scale support vector machines (SVM) classification and other tasks using additive kernels. First, a linear regression SVM framework for general nonlinear kernel is proposed using linear regression to approximate gradient computations in the learning process. Second, we propose a power mean SVM (PmSVM) algorithm for all additive kernels using nonsymmetric explanatory variable functions. This nonsymmetric kernel approximation has advantages over the existing methods: 1) it does not require closed-form Fourier transforms and 2) it does not require extra training for the approximation either. Compared on benchmark large-scale classification data sets with millions of examples or millions of dense feature dimensions, PmSVM has achieved the highest learning speed and highest accuracy among recent algorithms in most cases.",4
Energy-to-peak state estimation for Markov jump RNNs with time-varying delays via nonsynchronous filter with nonstationary mode transitions.,"In this paper, the problem of energy-to-peak state estimation for a class of discrete-time Markov jump recurrent neural networks (RNNs) with randomly occurring nonlinearities (RONs) and time-varying delays is investigated. A practical phenomenon of nonsynchronous jumps between RNNs modes and desired mode-dependent filters is considered, and a nonstationary mode transition among the filters is used to model the nonsynchronous jumps to different degrees that are also mode dependent. The RONs are used to model a class of sector-like nonlinearities that occur in a probabilistic way according to a Bernoulli sequence. The time-varying delays are supposed to be mode dependent and unknown, but with known lower and upper bounds a priori. Sufficient conditions on the existence of the nonsynchronous filters are obtained such that the filtering error system is stochastically stable and achieves a prescribed energy-to-peak performance index. Further to the recent study on the class of nonsynchronous estimation problem, a monotonicity is observed in obtaining filtering performance index, while changing the degree of nonsynchronous jumps. A numerical example is presented to verify the theoretical findings.",4
Dynamic State Estimation of Power Systems With Quantization Effects: A Recursive Filter Approach.,"In this paper, a recursive filter algorithm is developed to deal with the state estimation problem for power systems with quantized nonlinear measurements. The measurements from both the remote terminal units and the phasor measurement unit are subject to quantizations described by a logarithmic quantizer. Attention is focused on the design of a recursive filter such that, in the simultaneous presence of nonlinear measurements and quantization effects, an upper bound for the estimation error covariance is guaranteed and subsequently minimized. Instead of using the traditional approximation methods in nonlinear estimation that simply ignore the linearization errors, we treat both the linearization and quantization errors as norm-bounded uncertainties in the algorithm development so as to improve the performance of the estimator. For the power system with such kind of introduced uncertainties, a filter is designed in the framework of robust recursive estimation, and the developed filter algorithm is tested on the IEEE benchmark power system to demonstrate its effectiveness.",4
Twin support vector machine for clustering.,"The twin support vector machine (TWSVM) is one of the powerful classification methods. In this brief, a TWSVM-type clustering method, called twin support vector clustering (TWSVC), is proposed. Our TWSVC includes both linear and nonlinear versions. It determines k cluster center planes by solving a series of quadratic programming problems. To make TWSVC more efficient and stable, an initialization algorithm based on the nearest neighbor graph is also suggested. The experimental results on several benchmark data sets have shown a comparable performance of our TWSVC.",4
Passivity of switched recurrent neural networks with time-varying delays.,"This paper is concerned with the passivity analysis for switched neural networks subject to stochastic disturbances and time-varying delays. First, using the multiple Lyapunov functions method, a state-dependent switching law is designed to present a stochastic passivity condition. Second, a hysteresis switching law involving both the current state and the previous value of the switching signal are presented to avoid chattering resulted from the state-dependent switching. Third, based on the average dwell-time approach, a class of switching signals is determined to guarantee the switched neural network stochastically passive. Finally, three numerical examples are provided to illustrate the characteristics of three proposed switching laws.",4
Online Sequential Extreme Learning Machine With Kernels.,"The extreme learning machine (ELM) was recently proposed as a unifying framework for different families of learning algorithms. The classical ELM model consists of a linear combination of a fixed number of nonlinear expansions of the input vector. Learning in ELM is hence equivalent to finding the optimal weights that minimize the error on a dataset. The update works in batch mode, either with explicit feature mappings or with implicit mappings defined by kernels. Although an online version has been proposed for the former, no work has been done up to this point for the latter, and whether an efficient learning algorithm for online kernel-based ELM exists remains an open problem. By explicating some connections between nonlinear adaptive filtering and ELM theory, in this brief, we present an algorithm for this task. In particular, we propose a straightforward extension of the well-known kernel recursive least-squares, belonging to the kernel adaptive filtering (KAF) family, to the ELM framework. We call the resulting algorithm the kernel online sequential ELM (KOS-ELM). Moreover, we consider two different criteria used in the KAF field to obtain sparse filters and extend them to our context. We show that KOS-ELM, with their integration, can result in a highly efficient algorithm, both in terms of obtained generalization error and training time. Empirical evaluations demonstrate interesting results on some benchmarking datasets.",4
Stochastic stability of delayed neural networks with local impulsive effects.,"In this paper, the stability problem is studied for a class of stochastic neural networks (NNs) with local impulsive effects. The impulsive effects considered can be not only nonidentical in different dimensions of the system state but also various at distinct impulsive instants. Hence, the impulses here can encompass several typical impulses in NNs. The aim of this paper is to derive stability criteria such that stochastic NNs with local impulsive effects are exponentially stable in mean square. By means of the mathematical induction method, several easy-to-check conditions are obtained to ensure the mean square stability of NNs. Three examples are given to show the effectiveness of the proposed stability criterion.",4
Learning-regulated context relevant topographical map.,"Kohonen's self-organizing map (SOM) is used to map high-dimensional data into a low-dimensional representation (typically a 2-D or 3-D space) while preserving their topological characteristics. A major reason for its application is to be able to visualize data while preserving their relation in the high-dimensional input data space as much as possible. Here, we are seeking to go further by incorporating semantic meaning in the low-dimensional representation. In a conventional SOM, the semantic context of the data, such as class labels, does not have any influence on the formation of the map. As an abstraction of neural function, the SOM models bottom-up self-organization but not feedback modulation which is also ubiquitous in the brain. In this paper, we demonstrate a hierarchical neural network, which learns a topographical map that also reflects the semantic context of the data. Our method combines unsupervised, bottom-up topographical map formation with top-down supervised learning. We discuss the mathematical properties of the proposed hierarchical neural network and demonstrate its abilities with empirical experiments.",4
ML-Tree: a tree-structure-based approach to multilabel learning.,"Multilabel learning aims to predict labels of unseen instances by learning from training samples that are associated with a set of known labels. In this paper, we propose to use a hierarchical tree model for multilabel learning, and to develop the ML-Tree algorithm for finding the tree structure. ML-Tree considers a tree as a hierarchy of data and constructs the tree using the induction of one-against-all SVM classifiers at each node to recursively partition the data into child nodes. For each node, we define a predictive label vector to represent the predictive label transmission in the tree model for multilabel prediction and automatic discovery of the label relationships. If two labels co-occur frequently as predictive labels at leaf nodes, these labels are supposed to be relevant. The amount of predictive label co-occurrence provides an estimation of the label relationships. We examine the ML-Tree method on 11 real data sets of different domains and compare it with six well-established multilabel learning algorithms. The performances of these approaches are evaluated by 16 commonly used measures. We also conduct Friedman and Nemenyi tests to assess the statistical significance of the differences in performance. Experimental results demonstrate the effectiveness of our method.",4
Adaptive control of uncertain nonaffine nonlinear systems with input saturation using neural networks.,"This paper presents a tracking control methodology for a class of uncertain nonlinear systems subject to input saturation constraint and external disturbances. Unlike most previous approaches on saturated systems, which assumed affine nonlinear systems, in this paper, tracking control problem is solved for uncertain nonaffine nonlinear systems with input saturation. To deal with the saturation constraint, an auxiliary system is constructed and a modified tracking error is defined. Then, by employing implicit function theorem, mean value theorem, and modified tracking error, updating rules are derived based on the well-known back-propagation (BP) algorithm, which has been proven to be the most relevant updating rule to control problems. However, most of the previous approaches on BP algorithm suffer from lack of stability analysis. By injecting a damping term to the standard BP algorithm, uniformly ultimately boundedness of all the signals of the closed-loop system is ensured via Lyapunov's direct method. Furthermore, the presented approach employs nonlinear in parameter neural networks. Hence, the proposed scheme is applicable to systems with higher degrees of nonlinearity. Using a high-gain observer to reconstruct the states of the system, an output feedback controller is also presented. Finally, the simulation results performed on a Duffing-Holmes chaotic system, a generalized pendulum-type system, and a numerical system are presented to demonstrate the effectiveness of the suggested state and output feedback control schemes.",4
Robust Novelty Detection via Worst Case CVaR Minimization.,"Novelty detection models aim to find the minimum volume set covering a given probability mass. This paper proposes a robust single-class support vector machine (SSVM) for novelty detection, which is mainly based on the worst case conditional value-at-risk minimization. By assuming that every input is subject to an uncertainty with a specified symmetric support, this robust formulation results in a maximization term that is similar to the regularization term in the classical SSVM. When the uncertainty set is l1 -norm, linfinity -norm or box, its training can be reformulated to a linear program; while the uncertainty set is l2 -norm or ellipsoidal, its training is a tractable second-order cone program. The proposed method has a nice consistent statistical property. As the training size goes to infinity, the estimated normal region converges to the true provided that the magnitude of the uncertainty set decreases in a systematic way. The experimental results on three data sets clearly demonstrate its superiority over three benchmark models.",4
Application of Reinforcement Learning Algorithms for the Adaptive Computation of the Smoothing Parameter for Probabilistic Neural Network.,"In this paper, we propose new methods for the choice and adaptation of the smoothing parameter of the probabilistic neural network (PNN). These methods are based on three reinforcement learning algorithms: Q(0)-learning, Q(lambda)-learning, and stateless Q-learning. We regard three types of PNN classifiers: the model that uses single smoothing parameter for the whole network, the model that utilizes single smoothing parameter for each data attribute, and the model that possesses the matrix of smoothing parameters different for each data variable and data class. Reinforcement learning is applied as the method of finding such a value of the smoothing parameter, which ensures the maximization of the prediction ability. PNN models with smoothing parameters computed according to the proposed algorithms are tested on eight databases by calculating the test error with the use of the cross validation procedure. The results are compared with state-of-the-art methods for PNN training published in the literature up to date and, additionally, with PNN whose sigma is determined by means of the conjugate gradient approach. The results demonstrate that the proposed approaches can be used as alternative PNN training procedures.",4
Comparison of l(1)-Norm SVR and Sparse Coding Algorithms for Linear Regression.,"Support vector regression (SVR) is a popular function estimation technique based on Vapnik's concept of support vector machine. Among many variants, the l1-norm SVR is known to be good at selecting useful features when the features are redundant. Sparse coding (SC) is a technique widely used in many areas and a number of efficient algorithms are available. Both l1-norm SVR and SC can be used for linear regression. In this brief, the close connection between the l1-norm SVR and SC is revealed and some typical algorithms are compared for linear regression. The results show that the SC algorithms outperform the Newton linear programming algorithm, an efficient l1-norm SVR algorithm, in efficiency. The algorithms are then used to design the radial basis function (RBF) neural networks. Experiments on some benchmark data sets demonstrate the high efficiency of the SC algorithms. In particular, one of the SC algorithms, the orthogonal matching pursuit is two orders of magnitude faster than a well-known RBF network designing algorithm, the orthogonal least squares algorithm.",4
A Distributed Approach Toward Discriminative Distance Metric Learning.,"Distance metric learning (DML) is successful in discovering intrinsic relations in data. However, most algorithms are computationally demanding when the problem size becomes large. In this paper, we propose a discriminative metric learning algorithm, develop a distributed scheme learning metrics on moderate-sized subsets of data, and aggregate the results into a global solution. The technique leverages the power of parallel computation. The algorithm of the aggregated DML (ADML) scales well with the data size and can be controlled by the partition. We theoretically analyze and provide bounds for the error induced by the distributed treatment. We have conducted experimental evaluation of the ADML, both on specially designed tests and on practical image annotation tasks. Those tests have shown that the ADML achieves the state-of-the-art performance at only a fraction of the cost incurred by most existing methods.",4
Group Factor Analysis.,"Factor analysis (FA) provides linear factors that describe the relationships between individual variables of a data set. We extend this classical formulation into linear factors that describe the relationships between groups of variables, where each group represents either a set of related variables or a data set. The model also naturally extends canonical correlation analysis to more than two sets, in a way that is more flexible than previous extensions. Our solution is formulated as a variational inference of a latent variable model with structural sparsity, and it consists of two hierarchical levels: 1) the higher level models the relationships between the groups and 2) the lower models the observed variables given the higher level. We show that the resulting solution solves the group factor analysis (GFA) problem accurately, outperforming alternative FA-based solutions as well as more straightforward implementations of GFA. The method is demonstrated on two life science data sets, one on brain activation and the other on systems biology, illustrating its applicability to the analysis of different types of high-dimensional data sources.",4
Fick's Law Assisted Propagation for Semisupervised Learning.,"How to propagate the label information from labeled examples to unlabeled examples is a critical problem for graph-based semisupervised learning. Many label propagation algorithms have been developed in recent years and have obtained promising performance on various applications. However, the eigenvalues of iteration matrices in these algorithms are usually distributed irregularly, which slow down the convergence rate and impair the learning performance. This paper proposes a novel label propagation method called Fick's law assisted propagation (FLAP). Unlike the existing algorithms that are directly derived from statistical learning, FLAP is deduced on the basis of the theory of Fick's First Law of Diffusion, which is widely known as the fundamental theory in fluid-spreading. We prove that FLAP will converge with linear rate and show that FLAP makes eigenvalues of the iteration matrix distributed regularly. Comprehensive experimental evaluations on synthetic and practical datasets reveal that FLAP obtains encouraging results in terms of both accuracy and efficiency.",4
Incorporating Wind Power Forecast Uncertainties Into Stochastic Unit Commitment Using Neural Network-Based Prediction Intervals.,"Penetration of renewable energy resources, such as wind and solar power, into power systems significantly increases the uncertainties on system operation, stability, and reliability in smart grids. In this paper, the nonparametric neural network-based prediction intervals (PIs) are implemented for forecast uncertainty quantification. Instead of a single level PI, wind power forecast uncertainties are represented in a list of PIs. These PIs are then decomposed into quantiles of wind power. A new scenario generation method is proposed to handle wind power forecast uncertainties. For each hour, an empirical cumulative distribution function (ECDF) is fitted to these quantile points. The Monte Carlo simulation method is used to generate scenarios from the ECDF. Then the wind power scenarios are incorporated into a stochastic security-constrained unit commitment (SCUC) model. The heuristic genetic algorithm is utilized to solve the stochastic SCUC problem. Five deterministic and four stochastic case studies incorporated with interval forecasts of wind power are implemented. The results of these cases are presented and discussed together. Generation costs, and the scheduled and real-time economic dispatch reserves of different unit commitment strategies are compared. The experimental results show that the stochastic model is more robust than deterministic ones and, thus, decreases the risk in system operations of smart grids.",4
Digital implementation of a biological astrocyte model and its application.,"This paper presents a modified astrocyte model that allows a convenient digital implementation. This model is aimed at reproducing relevant biological astrocyte behaviors, which provide appropriate feedback control in regulating neuronal activities in the central nervous system. Accordingly, we investigate the feasibility of a digital implementation for a single astrocyte and a biological neuronal network model constructed by connecting two limit-cycle Hopf oscillators to an implementation of the proposed astrocyte model using oscillator-astrocyte interactions with weak coupling. Hardware synthesis, physical implementation on field-programmable gate array, and theoretical analysis confirm that the proposed astrocyte model, with considerably low hardware overhead, can mimic biological astrocyte model behaviors, resulting in desynchronization of the two coupled limit-cycle oscillators.",4
Synchronization of nonlinear coupled networks via aperiodically intermittent pinning control.,"In this paper, pinning synchronization problem for nonlinear coupled networks is investigated, which can be recurrently connected neural networks, cellular neural networks, Hodgkin-Huxley models, Lorenz chaotic oscillators, and so on. Nodes in the network are assumed to be identical and nodes' dynamical behaviors are described by continuous-time equations. The network topology is undirected and static. At first, the scope of accepted nonlinear coupling functions is defined, and the effect of nonlinear coupling functions on synchronization is carefully discussed. Then, the pinning control technique is used for synchronization, especially the control type is aperiodically intermittent. Some sufficient conditions to guarantee global synchronization are presented. Furthermore, the adaptive approach is also applied on the pinning control, and a centralized adaptive algorithm is designed and its validity is also proved. Finally, several numerical simulations are given to verify the obtained theoretical results.",4
Identification of the dynamic operating envelope of HCCI engines using class imbalance learning.,"Homogeneous charge compression ignition (HCCI) is a futuristic automotive engine technology that can significantly improve fuel economy and reduce emissions. HCCI engine operation is constrained by combustion instabilities, such as knock, ringing, misfires, high-variability combustion, and so on, and it becomes important to identify the operating envelope defined by these constraints for use in engine diagnostics and controller design. HCCI combustion is dominated by complex nonlinear dynamics, and a first-principle-based dynamic modeling of the operating envelope becomes intractable. In this paper, a machine learning approach is presented to identify the stable operating envelope of HCCI combustion, by learning directly from the experimental data. Stability is defined using thresholds on combustion features obtained from engine in-cylinder pressure measurements. This paper considers instabilities arising from engine misfire and high-variability combustion. A gasoline HCCI engine is used for generating stable and unstable data observations. Owing to an imbalance in class proportions in the data set, the models are developed both based on resampling the data set (by undersampling and oversampling) and based on a cost-sensitive learning method (by overweighting the minority class relative to the majority class observations). Support vector machines (SVMs) and recently developed extreme learning machines (ELM) are utilized for developing dynamic classifiers. The results compared against linear classification methods show that cost-sensitive nonlinear ELM and SVM classification algorithms are well suited for the problem. However, the SVM envelope model requires about 80% more parameters for an accuracy improvement of 3% compared with the ELM envelope model indicating that ELM models may be computationally suitable for the engine application. The proposed modeling approach shows that HCCI engine misfires and high-variability combustion can be predicted ahead of time, given the present values of available sensor measurements, making the models suitable for engine diagnostics and control applications.",4
Existence and uniform stability analysis of fractional-order complex-valued neural networks with time delays.,"This paper deals with the problem of existence and uniform stability analysis of fractional-order complex-valued neural networks with constant time delays. Complex-valued recurrent neural networks is an extension of real-valued recurrent neural networks that includes complex-valued states, connection weights, or activation functions. This paper explains sufficient condition for the existence and uniform stability analysis of such networks. Three numerical simulations are delineated to substantiate the effectiveness of the theoretical results.",4
A latent manifold Markovian dynamics Gaussian process.,"In this paper, we propose a Gaussian process (GP) model for analysis of nonlinear time series. Formulation of our model is based on the consideration that the observed data are functions of latent variables, with the associated mapping between observations and latent representations modeled through GP priors. In addition, to capture the temporal dynamics in the modeled data, we assume that subsequent latent representations depend on each other on the basis of a hidden Markov prior imposed over them. Derivation of our model is performed by marginalizing out the model parameters in closed form using GP priors for observation mappings, and appropriate stick-breaking priors for the latent variable (Markovian) dynamics. This way, we eventually obtain a nonparametric Bayesian model for dynamical systems that accounts for uncertainty in the modeled data. We provide efficient inference algorithms for our model on the basis of a truncated variational Bayesian approximation. We demonstrate the efficacy of our approach considering a number of applications dealing with real-world data, and compare it with the related state-of-the-art approaches.",4
Learning understandable neural networks with nonnegative weight constraints.,"People can understand complex structures if they relate to more isolated yet understandable concepts. Despite this fact, popular pattern recognition tools, such as decision tree or production rule learners, produce only flat models which do not build intermediate data representations. On the other hand, neural networks typically learn hierarchical but opaque models. We show how constraining neurons' weights to be nonnegative improves the interpretability of a network's operation. We analyze the proposed method on large data sets: the MNIST digit recognition data and the Reuters text categorization data. The patterns learned by traditional and constrained network are contrasted to those learned with principal component analysis and nonnegative matrix factorization.",4
Pareto-path multitask multiple kernel learning.,"A traditional and intuitively appealing Multitask Multiple Kernel Learning (MT-MKL) method is to optimize the sum (thus, the average) of objective functions with (partially) shared kernel function, which allows information sharing among the tasks. We point out that the obtained solution corresponds to a single point on the Pareto Front (PF) of a multiobjective optimization problem, which considers the concurrent optimization of all task objectives involved in the Multitask Learning (MTL) problem. Motivated by this last observation and arguing that the former approach is heuristic, we propose a novel support vector machine MT-MKL framework that considers an implicitly defined set of conic combinations of task objectives. We show that solving our framework produces solutions along a path on the aforementioned PF and that it subsumes the optimization of the average of objective functions as a special case. Using the algorithms we derived, we demonstrate through a series of experimental results that the framework is capable of achieving a better classification performance, when compared with other similar MTL approaches.",4
Feature selection using a neural framework with controlled redundancy.,"We first present a feature selection method based on a multilayer perceptron (MLP) neural network, called feature selection MLP (FSMLP). We explain how FSMLP can select essential features and discard derogatory and indifferent features. Such a method may pick up some useful but dependent (say correlated) features, all of which may not be needed. We then propose a general scheme for dealing with feature selection with ""controlled redundancy"" (CoR). The proposed scheme, named as FSMLP-CoR, can select features with a controlled redundancy both for classification and function approximation/prediction type problems. We have also proposed a new more effective training scheme named mFSMLP-CoR. The idea is general in nature and can be used with other learning schemes also. We demonstrate the effectiveness of the algorithms using several data sets including a synthetic data set. We also show that the selected features are adequate to solve the problem at hand. Here, we have considered a measure of linear dependency to control the redundancy. The use of nonlinear measures of dependency, such as mutual information, is straightforward. Here, there are some advantages of the proposed schemes. They do not require explicit evaluation of the feature subsets. Here, feature selection is integrated into designing of the decision-making system. Hence, it can look at all features together and pick up whatever is necessary. Our methods can account for possible nonlinear subtle interactions between features, as well as that between features, tools, and the problem being solved. They can also control the level of redundancy in the selected features. Of the two learning schemes, mFSMLP-CoR, not only improves the performance of the system, but also significantly reduces the dependency of the network's behavior on the initialization of connection weights.",4
Dynamic Surface Control Using Neural Networks for a Class of Uncertain Nonlinear Systems With Input Saturation.,"In this paper, a dynamic surface control (DSC) scheme is proposed for a class of uncertain strict-feedback nonlinear systems in the presence of input saturation and unknown external disturbance. The radial basis function neural network (RBFNN) is employed to approximate the unknown system function. To efficiently tackle the unknown external disturbance, a nonlinear disturbance observer (NDO) is developed. The developed NDO can relax the known boundary requirement of the unknown disturbance and can guarantee the disturbance estimation error converge to a bounded compact set. Using NDO and RBFNN, the DSC scheme is developed for uncertain nonlinear systems based on a backstepping method. Using a DSC technique, the problem of explosion of complexity inherent in the conventional backstepping method is avoided, which is specially important for designs using neural network approximations. Under the proposed DSC scheme, the ultimately bounded convergence of all closed-loop signals is guaranteed via Lyapunov analysis. Simulation results are given to show the effectiveness of the proposed DSC design using NDO and RBFNN.",4
Region-Based Object Recognition by Color Segmentation Using a Simplified PCNN.,"In this paper, we propose a region-based object recognition (RBOR) method to identify objects from complex real-world scenes. First, the proposed method performs color image segmentation by a simplified pulse-coupled neural network (SPCNN) for the object model image and test image, and then conducts a region-based matching between them. Hence, we name it as RBOR with SPCNN (SPCNN-RBOR). Hereinto, the values of SPCNN parameters are automatically set by our previously proposed method in terms of each object model. In order to reduce various light intensity effects and take advantage of SPCNN high resolution on low intensities for achieving optimized color segmentation, a transformation integrating normalized Red Green Blue (RGB) with opponent color spaces is introduced. A novel image segmentation strategy is suggested to group the pixels firing synchronously throughout all the transformed channels of an image. Based on the segmentation results, a series of adaptive thresholds, which is adjustable according to the specific object model is employed to remove outlier region blobs, form potential clusters, and refine the clusters in test images. The proposed SPCNN-RBOR method overcomes the drawback of feature-based methods that inevitably includes background information into local invariant feature descriptors when keypoints locate near object boundaries. A large number of experiments have proved that the proposed SPCNN-RBOR method is robust for diverse complex variations, even under partial occlusion and highly cluttered environments. In addition, the SPCNN-RBOR method works well in not only identifying textured objects, but also in less-textured ones, which significantly outperforms the current feature-based methods.",4
Retargeted Least Squares Regression Algorithm.,"This brief presents a framework of retargeted least squares regression (ReLSR) for multicategory classification. The core idea is to directly learn the regression targets from data other than using the traditional zero-one matrix as regression targets. The learned target matrix can guarantee a large margin constraint for the requirement of correct classification for each data point. Compared with the traditional least squares regression (LSR) and a recently proposed discriminative LSR models, ReLSR is much more accurate in measuring the classification error of the regression model. Furthermore, ReLSR is a single and compact model, hence there is no need to train two-class (binary) machines that are independent of each other. The convex optimization problem of ReLSR is solved elegantly and efficiently with an alternating procedure including regression and retargeting as substeps. The experimental evaluation over a range of databases identifies the validity of our method.",4
MEC--a near-optimal online reinforcement learning algorithm for continuous deterministic systems.,"In this paper, the first probably approximately correct (PAC) algorithm for continuous deterministic systems without relying on any system dynamics is proposed. It combines the state aggregation technique and the efficient exploration principle, and makes high utilization of online observed samples. We use a grid to partition the continuous state space into different cells to save samples. A near-upper Q operator is defined to produce a near-upper Q function using samples in each cell. The corresponding greedy policy effectively balances between exploration and exploitation. With the rigorous analysis, we prove that there is a polynomial time bound of executing nonoptimal actions in our algorithm. After finite steps, the final policy reaches near optimal in the framework of PAC. The implementation requires no knowledge of systems and has less computation complexity. Simulation studies confirm that it is a better performance than other similar PAC algorithms.",4
Dynamic Infinite Mixed-Membership Stochastic Blockmodel.,"Directional and pairwise measurements are often used to model interactions in a social network setting. The mixed-membership stochastic blockmodel (MMSB) was a seminal work in this area, and its ability has been extended. However, models such as MMSB face particular challenges in modeling dynamic networks, for example, with the unknown number of communities. Accordingly, this paper proposes a dynamic infinite mixed-membership stochastic blockmodel, a generalized framework that extends the existing work to potentially infinite communities inside a network in dynamic settings (i.e., networks are observed over time). Additional model parameters are introduced to reflect the degree of persistence among one's memberships at consecutive time stamps. Under this framework, two specific models, namely mixture time variant and mixture time invariant models, are proposed to depict two different time correlation structures. Two effective posterior sampling strategies and their results are presented, respectively, using synthetic and real-world data.",4
Reinforcement learning design-based adaptive tracking control with less learning parameters for nonlinear discrete-time MIMO systems.,"Based on the neural network (NN) approximator, an online reinforcement learning algorithm is proposed for a class of affine multiple input and multiple output (MIMO) nonlinear discrete-time systems with unknown functions and disturbances. In the design procedure, two networks are provided where one is an action network to generate an optimal control signal and the other is a critic network to approximate the cost function. An optimal control signal and adaptation laws can be generated based on two NNs. In the previous approaches, the weights of critic and action networks are updated based on the gradient descent rule and the estimations of optimal weight vectors are directly adjusted in the design. Consequently, compared with the existing results, the main contributions of this paper are: 1) only two parameters are needed to be adjusted, and thus the number of the adaptation laws is smaller than the previous results and 2) the updating parameters do not depend on the number of the subsystems for MIMO systems and the tuning rules are replaced by adjusting the norms on optimal weight vectors in both action and critic networks. It is proven that the tracking errors, the adaptation laws, and the control inputs are uniformly bounded using Lyapunov analysis method. The simulation examples are employed to illustrate the effectiveness of the proposed algorithm.",4
Targeting accurate object extraction from an image: a comprehensive study of natural image matting.,"With the development of digital multimedia technologies, image matting has gained increasing interests from both academic and industrial communities. The purpose of image matting is to precisely extract the foreground objects with arbitrary shapes from an image or a video frame for further editing. It is generally known that image matting is inherently an ill-posed problem because we need to output three images out of only one input image. In this paper, we provide a comprehensive survey of the existing image matting algorithms and evaluate their performance. In addition to the blue screen matting, we systematically divide all existing natural image matting methods into four categories: 1) color sampling-based; 2) propagation-based; 3) combination of sampling-based and propagation-based; and 4) learning-based approaches. Sampling-based methods assume that the foreground and background colors of an unknown pixel can be explicitly estimated by examining nearby pixels. Propagation-based methods are instead based on the assumption that foreground and background colors are locally smooth. Learning-based methods treat the matting process as a supervised or semisupervised learning problem. Via the learning process, users can construct a linear or nonlinear model between the alpha mattes and the image colors using a training set to estimate the alpha matte of an unknown pixel without any assumption about the characteristics of the testing image. With three benchmark data sets, the various matting algorithms are evaluated and compared using several metrics to demonstrate the strengths and weaknesses of each method both quantitatively and qualitatively. Finally, we conclude this paper by outlining the research trends and suggesting a number of promising directions for future development.",4
Two Efficient Twin ELM Methods With Prediction Interval.,"In the operational optimization and scheduling problems of actual industrial processes, such as iron and steel, and microelectronics, the operational indices and process parameters usually need to be predicted. However, for some input and output variables of these prediction models, there may exist a lot of uncertainties coming from themselves, the measurement error, the rough representation, and so on. In such cases, constructing a prediction interval (PI) for the output of the corresponding prediction model is very necessary. In this paper, two twin extreme learning machine (TELM) models for constructing PIs are proposed. First, we propose a regularized asymmetric least squares extreme learning machine (RALS-ELM) method, in which different weights of its squared error loss function are set according to whether the error of the model output is positive or negative in order that the above error can be differentiated in the parameter learning process, and Tikhonov regularization is introduced to reduce overfitting. Then, we propose an asymmetric Bayesian extreme learning machine (AB-ELM) method based on the Bayesian framework with the asymmetric Gaussian distribution (AB-ELM), in which the weights of its likelihood function are determined as the same method in RALS-ELM, and the type II maximum likelihood algorithm is derived to learn the parameters of AB-ELM. Based on RALS-ELM and AB-ELM, we use a pair of weights following the reciprocal relationship to obtain two nonparallel regressors, including a lower-bound regressor and an upper-bound regressor, respectively, which can be used for calculating the PIs. Finally, some discussions are given, about how to adjust the weights adaptively to meet the desired PI, how to use the proposed TELMs for nonlinear quantile regression, and so on. Results of numerical comparison on data from one synthetic regression problem, three University of California Irvine benchmark regression problems, and two actual industrial regression problems show the effectiveness of the proposed models.",4
Discriminative Hierarchical K-Means Tree for Large-Scale Image Classification.,"A key challenge in large-scale image classification is how to achieve efficiency in terms of both computation and memory without compromising classification accuracy. The learning-based classifiers achieve the state-of-the-art accuracies, but have been criticized for the computational complexity that grows linearly with the number of classes. The nonparametric nearest neighbor (NN)-based classifiers naturally handle large numbers of categories, but incur prohibitively expensive computation and memory costs. In this brief, we present a novel classification scheme, i.e., discriminative hierarchical K-means tree (D-HKTree), which combines the advantages of both learning-based and NN-based classifiers. The complexity of the D-HKTree only grows sublinearly with the number of categories, which is much better than the recent hierarchical support vector machines-based methods. The memory requirement is the order of magnitude less than the recent Naive Bayesian NN-based approaches. The proposed D-HKTree classification scheme is evaluated on several challenging benchmark databases and achieves the state-of-the-art accuracies, while with significantly lower computation cost and memory requirement.",4
On the additive properties of the fat-shattering dimension.,"The properties of the VC-dimension under various compositions are well-understood, but this is much less the case for classes of continuous functions. In this brief, we show that a commonly used scale-sensitive dimension, Vgamma, is much less well-behaved under Minkowski summation than its VC cousin, while the fat-shattering dimension retains some compositional similarity to the VC-dimension. As an application, we analyze the fat-shattering dimension of trigonometric functions and series.",4
Learning deep and wide: a spectral method for learning deep networks.,"Building intelligent systems that are capable of extracting high-level representations from high-dimensional sensory data lies at the core of solving many computer vision-related tasks. We propose the multispectral neural networks (MSNN) to learn features from multicolumn deep neural networks and embed the penultimate hierarchical discriminative manifolds into a compact representation. The low-dimensional embedding explores the complementary property of different views wherein the distribution of each view is sufficiently smooth and hence achieves robustness, given few labeled training data. Our experiments show that spectrally embedding several deep neural networks can explore the optimum output from the multicolumn networks and consistently decrease the error rate compared with a single deep network.",4
Hybrid manifold embedding.,"In this brief, we present a novel supervised manifold learning framework dubbed hybrid manifold embedding (HyME). Unlike most of the existing supervised manifold learning algorithms that give linear explicit mapping functions, the HyME aims to provide a more general nonlinear explicit mapping function by performing a two-layer learning procedure. In the first layer, a new clustering strategy called geodesic clustering is proposed to divide the original data set into several subsets with minimum nonlinearity. In the second layer, a supervised dimensionality reduction scheme called locally conjugate discriminant projection is performed on each subset for maximizing the discriminant information and minimizing the dimension redundancy simultaneously in the reduced low-dimensional space. By integrating these two layers in a unified mapping function, a supervised manifold embedding framework is established to describe both global and local manifold structure as well as to preserve the discriminative ability in the learned subspace. Experiments on various data sets validate the effectiveness of the proposed method.",4
Synchronization in an array of output-coupled Boolean networks with time delay.,"This brief presents an analytical study of synchronization in an array of coupled deterministic Boolean networks (BNs) with time delay. Two kinds of models are considered. In one model, the outputs contain time delay, while in another one, the outputs do not. One restriction in this brief is that the state delay and output delay are restricted to be equal. By referring to the algebraic representations of logical dynamics and using the techniques of semitensor product of matrices, some necessary and sufficient conditions are derived for the synchronization of delay-coupled BNs. Examples including a practical epigenetic example are given for illustration.",4
Mandatory leaf node prediction in hierarchical multilabel classification.,"In hierarchical classification, the output labels reside on a tree- or directed acyclic graph (DAG)-structured hierarchy. On testing, the prediction paths of a given test example may be required to end at leaf nodes of the label hierarchy. This is called mandatory leaf node prediction (MLNP) and is particularly useful, when the leaf nodes have much stronger semantic meaning than the internal nodes. However, while there have been a lot of MLNP methods in hierarchical multiclass classification, performing MLNP in hierarchical multilabel classification is difficult. In this paper, we propose novel MLNP algorithms that consider the global label hierarchy structure. We show that the joint posterior probability over all the node labels can be efficiently maximized by dynamic programming for label trees, or greedy algorithm for label DAGs. In addition, both algorithms can be further extended for the minimization of the expected symmetric loss. Experiments are performed on real-world MLNP data sets with label trees and label DAGs. The proposed method consistently outperforms other hierarchical and flat multilabel classification methods.",4
Adaptive neural PD control with semiglobal asymptotic stabilization guarantee.,"This paper proves that adaptive neural plus proportional-derivative (PD) control can lead to semiglobal asymptotic stabilization rather than uniform ultimate boundedness for a class of uncertain affine nonlinear systems. An integral Lyapunov function-based ideal control law is introduced to avoid the control singularity problem. A variable-gain PD control term without the knowledge of plant bounds is presented to semiglobally stabilize the closed-loop system. Based on a linearly parameterized raised-cosine radial basis function neural network, a key property of optimal approximation is exploited to facilitate stability analysis. It is proved that the closed-loop system achieves semiglobal asymptotic stability by the appropriate choice of control parameters. Compared with previous adaptive approximation-based semiglobal or asymptotic stabilization approaches, our approach not only significantly simplifies control design, but also relaxes constraint conditions on the plant. Two illustrative examples have been provided to verify the theoretical results.",4
Real-time gesture interface based on event-driven processing from stereo silicon retinas.,"We propose a real-time hand gesture interface based on combining a stereo pair of biologically inspired event-based dynamic vision sensor (DVS) silicon retinas with neuromorphic event-driven postprocessing. Compared with conventional vision or 3-D sensors, the use of DVSs, which output asynchronous and sparse events in response to motion, eliminates the need to extract movements from sequences of video frames, and allows significantly faster and more energy-efficient processing. In addition, the rate of input events depends on the observed movements, and thus provides an additional cue for solving the gesture spotting problem, i.e., finding the onsets and offsets of gestures. We propose a postprocessing framework based on spiking neural networks that can process the events received from the DVSs in real time, and provides an architecture for future implementation in neuromorphic hardware devices. The motion trajectories of moving hands are detected by spatiotemporally correlating the stereoscopically verged asynchronous events from the DVSs by using leaky integrate-and-fire (LIF) neurons. Adaptive thresholds of the LIF neurons achieve the segmentation of trajectories, which are then translated into discrete and finite feature vectors. The feature vectors are classified with hidden Markov models, using a separate Gaussian mixture model for spotting irrelevant transition gestures. The disparity information from stereovision is used to adapt LIF neuron parameters to achieve recognition invariant of the distance of the user to the sensor, and also helps to filter out movements in the background of the user. Exploiting the high dynamic range of DVSs, furthermore, allows gesture recognition over a 60-dB range of scene illuminance. The system achieves recognition rates well over 90% under a variety of variable conditions with static and dynamic backgrounds with naive users.",4
A parsimonious mixture of Gaussian trees model for oversampling in imbalanced and multimodal time-series classification.,"We propose a novel framework of using a parsimonious statistical model, known as mixture of Gaussian trees, for modeling the possibly multimodal minority class to solve the problem of imbalanced time-series classification. By exploiting the fact that close-by time points are highly correlated due to smoothness of the time-series, our model significantly reduces the number of covariance parameters to be estimated from O(d(2)) to O(Ld), where L is the number of mixture components and d is the dimensionality. Thus, our model is particularly effective for modeling high-dimensional time-series with limited number of instances in the minority positive class. In addition, the computational complexity for learning the model is only of the order O(Ln+d(2)) where n+ is the number of positively labeled samples. We conduct extensive classification experiments based on several well-known time-series data sets (both single- and multimodal) by first randomly generating synthetic instances from our learned mixture model to correct the imbalance. We then compare our results with several state-of-the-art oversampling techniques and the results demonstrate that when our proposed model is used in oversampling, the same support vector machines classifier achieves much better classification accuracy across the range of data sets. In fact, the proposed method achieves the best average performance 30 times out of 36 multimodal data sets according to the F-value metric. Our results are also highly competitive compared with nonoversampling-based classifiers for dealing with imbalanced time-series data sets.",4
Learning deep hierarchical visual feature coding.,"In this paper, we propose a hybrid architecture that combines the image modeling strengths of the bag of words framework with the representational power and adaptability of learning deep architectures. Local gradient-based descriptors, such as SIFT, are encoded via a hierarchical coding scheme composed of spatial aggregating restricted Boltzmann machines (RBM). For each coding layer, we regularize the RBM by encouraging representations to fit both sparse and selective distributions. Supervised fine-tuning is used to enhance the quality of the visual representation for the categorization task. We performed a thorough experimental evaluation using three image categorization data sets. The hierarchical coding scheme achieved competitive categorization accuracies of 79.7% and 86.4% on the Caltech-101 and 15-Scenes data sets, respectively. The visual representations learned are compact and the model's inference is fast, as compared with sparse coding methods. The low-level representations of descriptors that were learned using this method result in generic features that we empirically found to be transferrable between different image data sets. Further analysis reveal the significance of supervised fine-tuning when the architecture has two layers of representations as opposed to a single layer.",4
A deep connection between the Vapnik-Chervonenkis entropy and the Rademacher complexity.,"In this paper, we derive a deep connection between the Vapnik-Chervonenkis (VC) entropy and the Rademacher complexity. For this purpose, we first refine some previously known relationships between the two notions of complexity and then derive new results, which allow computing an admissible range for the Rademacher complexity, given a value of the VC-entropy, and vice versa. The approach adopted in this paper is new and relies on the careful analysis of the combinatorial nature of the problem. The obtained results improve the state of the art on this research topic.",4
Learning regularized LDA by clustering.,"As a supervised dimensionality reduction technique, linear discriminant analysis has a serious overfitting problem when the number of training samples per class is small. The main reason is that the between- and within-class scatter matrices computed from the limited number of training samples deviate greatly from the underlying ones. To overcome the problem without increasing the number of training samples, we propose making use of the structure of the given training data to regularize the between- and within-class scatter matrices by between- and within-cluster scatter matrices, respectively, and simultaneously. The within- and between-cluster matrices are computed from unsupervised clustered data. The within-cluster scatter matrix contributes to encoding the possible variations in intraclasses and the between-cluster scatter matrix is useful for separating extra classes. The contributions are inversely proportional to the number of training samples per class. The advantages of the proposed method become more remarkable as the number of training samples per class decreases. Experimental results on the AR and Feret face databases demonstrate the effectiveness of the proposed method.",4
Exponential stabilization for sampled-data neural-network-based control systems.,"This paper investigates the problem of sampled-data stabilization for neural-network-based control systems with an optimal guaranteed cost. Using time-dependent Lyapunov functional approach, some novel conditions are proposed to guarantee the closed-loop systems exponentially stable, which fully use the available information about the actual sampling pattern. Based on the derived conditions, the design methods of the desired sampled-data three-layer fully connected feedforward neural-network-based controller are established to obtain the largest sampling interval and the smallest upper bound of the cost function. A practical example is provided to demonstrate the effectiveness and feasibility of the proposed techniques.",4
Structure-constrained low-rank representation.,"Benefiting from its effectiveness in subspace segmentation, low-rank representation (LRR) and its variations have many applications in computer vision and pattern recognition, such as motion segmentation, image segmentation, saliency detection, and semisupervised learning. It is known that the standard LRR can only work well under the assumption that all the subspaces are independent. However, this assumption cannot be guaranteed in real-world problems. This paper addresses this problem and provides an extension of LRR, named structure-constrained LRR (SC-LRR), to analyze the structure of multiple disjoint subspaces, which is more general for real vision data. We prove that the relationship of multiple linear disjoint subspaces can be exactly revealed by SC-LRR, with a predefined weight matrix. As a nontrivial byproduct, we also illustrate that SC-LRR can be applied for semisupervised learning. The experimental results on different types of vision problems demonstrate the effectiveness of our proposed method.",4
A novel estimation algorithm based on data and low-order models for virtual unmodeled dynamics.,"In this paper, the challenging issue of estimating virtual unmodeled dynamics is addressed. A novel estimation algorithm based on historical data and the output of low-order approximation models for virtual un-modeled dynamics is presented. In particular, the virtual un-modeled dynamics are decomposed into known and unknown parts, where only the unknown part is to be estimated. The method effectively avoids the need to use the unknown control input directly, and enables the estimation of the un-modeled dynamics with a relatively simple algorithm. Moreover, it is shown that the proposed algorithm overcomes the difficulty in obtaining the control solutions caused by the fact that the controller input is embedded in un-modeled dynamics. Finally, simulation studies are presented to demonstrate the effectiveness of the proposed method.",4
Optimal control for unknown discrete-time nonlinear Markov jump systems using adaptive dynamic programming.,"In this paper, we develop and analyze an optimal control method for a class of discrete-time nonlinear Markov jump systems (MJSs) with unknown system dynamics. Specifically, an identifier is established for the unknown systems to approximate system states, and an optimal control approach for nonlinear MJSs is developed to solve the Hamilton-Jacobi-Bellman equation based on the adaptive dynamic programming technique. We also develop detailed stability analysis of the control approach, including the convergence of the performance index function for nonlinear MJSs and the existence of the corresponding admissible control. Neural network techniques are used to approximate the proposed performance index function and the control law. To demonstrate the effectiveness of our approach, three simulation studies, one linear case, one nonlinear case, and one single link robot arm case, are used to validate the performance of the proposed optimal control method.",4
Adaptive neural control for a class of nonlinear time-varying delay systems with unknown hysteresis.,"This paper investigates the fusion of unknown direction hysteresis model with adaptive neural control techniques in face of time-delayed continuous time nonlinear systems without strict-feedback form. Compared with previous works on the hysteresis phenomenon, the direction of the modified Bouc-Wen hysteresis model investigated in the literature is unknown. To reduce the computation burden in adaptation mechanism, an optimized adaptation method is successfully applied to the control design. Based on the Lyapunov-Krasovskii method, two neural-network-based adaptive control algorithms are constructed to guarantee that all the system states and adaptive parameters remain bounded, and the tracking error converges to an adjustable neighborhood of the origin. In final, some numerical examples are provided to validate the effectiveness of the proposed control methods.",4
Passivity and Passification of Memristor-Based Recurrent Neural Networks With Additive Time-Varying Delays.,"This paper presents a new design scheme for the passivity and passification of a class of memristor-based recurrent neural networks (MRNNs) with additive time-varying delays. The predictable assumptions on the boundedness and Lipschitz continuity of activation functions are formulated. The systems considered here are based on a different time-delay model suggested recently, which includes additive time-varying delay components in the state. The connection between the time-varying delay and its upper bound is considered when estimating the upper bound of the derivative of Lyapunov functional. It is recognized that the passivity condition can be expressed in a linear matrix inequality (LMI) format and by using characteristic function method. For state feedback passification, it is verified that it is apathetic to use immediate or delayed state feedback. By constructing a Lyapunov-Krasovskii functional and employing Jensen's inequality and reciprocal convex combination technique together with a tighter estimation of the upper bound of the cross-product terms derived from the derivatives of the Lyapunov functional, less conventional delay-dependent passivity criteria are established in terms of LMIs. Moreover, second-order reciprocally convex approach is employed for deriving the upper bound for terms with inverses of squared convex parameters. The model based on the memristor with additive time-varying delays widens the application scope for the design of neural networks. Finally, pertinent examples are given to show the advantages of the derived passivity criteria and the significant improvement of the theoretical approaches.",4
Learning With Mixed Hard/Soft Pointwise Constraints.,"A learning paradigm is proposed and investigated, in which the classical framework of learning from examples is enhanced by the introduction of hard pointwise constraints, i.e., constraints imposed on a finite set of examples that cannot be violated. Such constraints arise, e.g., when requiring coherent decisions of classifiers acting on different views of the same pattern. The classical examples of supervised learning, which can be violated at the cost of some penalization (quantified by the choice of a suitable loss function) play the role of soft pointwise constraints. Constrained variational calculus is exploited to derive a representer theorem that provides a description of the functional structure of the optimal solution to the proposed learning paradigm. It is shown that such an optimal solution can be represented in terms of a set of support constraints, which generalize the concept of support vectors and open the doors to a novel learning paradigm, called support constraint machines. The general theory is applied to derive the representation of the optimal solution to the problem of learning from hard linear pointwise constraints combined with soft pointwise constraints induced by supervised examples. In some cases, closed-form optimal solutions are obtained.",4
Adaptive Synchronization of Memristor-Based Neural Networks with Time-Varying Delays.,"In this paper, adaptive synchronization of memristor-based neural networks (MNNs) with time-varying delays is investigated. The dynamical analysis here employs results from the theory of differential equations with discontinuous right-hand sides as introduced by Filippov. Sufficient conditions for the global synchronization of MNNs are established with a general adaptive controller. The update gain of the controller can be adjusted to control the synchronization speed. The obtained results complement and improve the previously known results. Finally, numerical simulations are carried out to demonstrate the effectiveness of the obtained results.",4
MTC: A Fast and Robust Graph-Based Transductive Learning Method.,"Despite the great success of graph-based transductive learning methods, most of them have serious problems in scalability and robustness. In this paper, we propose an efficient and robust graph-based transductive classification method, called minimum tree cut (MTC), which is suitable for large-scale data. Motivated from the sparse representation of graph, we approximate a graph by a spanning tree. Exploiting the simple structure, we develop a linear-time algorithm to label the tree such that the cut size of the tree is minimized. This significantly improves graph-based methods, which typically have a polynomial time complexity. Moreover, we theoretically and empirically show that the performance of MTC is robust to the graph construction, overcoming another big problem of traditional graph-based methods. Extensive experiments on public data sets and applications on web-spam detection and interactive image segmentation demonstrate our method's advantages in aspect of accuracy, speed, and robustness.",4
Context Dependent Encoding Using Convolutional Dynamic Networks.,"Perception of sensory signals is strongly influenced by their context, both in space and time. In this paper, we propose a novel hierarchical model, called convolutional dynamic networks, that effectively utilizes this contextual information, while inferring the representations of the visual inputs. We build this model based on a predictive coding framework and use the idea of empirical priors to incorporate recurrent and top-down connections. These connections endow the model with contextual information coming from temporal as well as abstract knowledge from higher layers. To perform inference efficiently in this hierarchical model, we rely on a novel scheme based on a smoothing proximal gradient method. When trained on unlabeled video sequences, the model learns a hierarchy of stable attractors, representing low-level to high-level parts of the objects. We demonstrate that the model effectively utilizes contextual information to produce robust and stable representations for object recognition in video sequences, even in case of highly corrupted inputs.",4
An Improved TA-SVM Method Without Matrix Inversion and Its Fast Implementation for Nonstationary Datasets.,"Recently, a time-adaptive support vector machine (TA-SVM) is proposed for handling nonstationary datasets. While attractive performance has been reported and the new classifier is distinctive in simultaneously solving several SVM subclassifiers locally and globally by using an elegant SVM formulation in an alternative kernel space, the coupling of subclassifiers brings in the computation of matrix inversion, thus resulting to suffer from high computational burden in large nonstationary dataset applications. To overcome this shortcoming, an improved TA-SVM (ITA-SVM) is proposed using a common vector shared by all the SVM subclassifiers involved. ITA-SVM not only keeps an SVM formulation, but also avoids the computation of matrix inversion. Thus, we can realize its fast version, that is, improved time-adaptive core vector machine (ITA-CVM) for large nonstationary datasets by using the CVM technique. ITA-CVM has the merit of asymptotic linear time complexity for large nonstationary datasets as well as inherits the advantage of TA-SVM. The effectiveness of the proposed classifiers ITA-SVM and ITA-CVM is also experimentally confirmed.",4
A Unified Framework for Data Visualization and Coclustering.,"We propose a new theoretical framework for data visualization. This framework is based on iterative procedure looking up an appropriate approximation of the data matrix A by using two stochastic similarity matrices from the set of rows and the set of columns. This process converges to a steady state where the approximated data A is composed of g similar rows and l similar columns. Reordering A according to the first left and right singular vectors involves an optimal data reorganization revealing homogeneous block clusters. Furthermore, we show that our approach is related to a Markov chain model, to the double k-means with g xl block clusters and to a spectral coclustering. Numerical experiments on simulated and real data sets show the interest of our approach.",4
Properties and Performance of Imperfect Dual Neural Network-Based kWTA Networks.,"The dual neural network (DNN)-based k -winner-take-all ( k WTA) model is an effective approach for finding the k largest inputs from n inputs. Its major assumption is that the threshold logic units (TLUs) can be implemented in a perfect way. However, when differential bipolar pairs are used for implementing TLUs, the transfer function of TLUs is a logistic function. This brief studies the properties of the DNN- kWTA model under this imperfect situation. We prove that, given any initial state, the network settles down at the unique equilibrium point. Besides, the energy function of the model is revealed. Based on the energy function, we propose an efficient method to study the model performance when the inputs are with continuous distribution functions. Furthermore, for uniformly distributed inputs, we derive a formula to estimate the probability that the model produces the correct outputs. Finally, for the case that the minimum separation min of the inputs is given, we prove that if the gain of the activation function is greater than 1/4min max(ln 2n, 2 ln 1 - / ), then the network can produce the correct outputs with winner outputs greater than 1- and loser outputs less than , where is the threshold less than 0.5.",4
Hyperparameter Selection for Gaussian Process One-Class Classification.,"Gaussian processes (GPs) provide predicted outputs with a full conditional statistical description, which can be used to establish confidence intervals and to set hyperparameters. This characteristic provides GPs with competitive or better performance in various applications. However, the specificity of one-class classification (OCC) makes GPs unable to select suitable hyperparameters in their traditional way. This brief proposes to select hyperparameters for GP OCC using the prediction difference between edge and interior positive training samples. Experiments on 2-D artificial and University of California benchmark data sets verify the effectiveness of this method.",4
Variational Bayesian Inference Algorithms for Infinite Relational Model of Network Data.,"Network data show the relationship among one kind of objects, such as social networks and hyperlinks on the Web. Many statistical models have been proposed for analyzing these data. For modeling cluster structures of networks, the infinite relational model (IRM) was proposed as a Bayesian nonparametric extension of the stochastic block model. In this brief, we derive the inference algorithms for the IRM of network data based on the variational Bayesian (VB) inference methods. After showing the standard VB inference, we derive the collapsed VB (CVB) inference and its variant called the zeroth-order CVB inference. We compared the performances of the inference algorithms using six real network datasets. The CVB inference outperformed the VB inference in most of the datasets, and the differences were especially larger in dense networks.",4
Feedforward Categorization on AER Motion Events Using Cortex-Like Features in a Spiking Neural Network.,"This paper introduces an event-driven feedforward categorization system, which takes data from a temporal contrast address event representation (AER) sensor. The proposed system extracts bio-inspired cortex-like features and discriminates different patterns using an AER based tempotron classifier (a network of leaky integrate-and-fire spiking neurons). One of the system's most appealing characteristics is its event-driven processing, with both input and features taking the form of address events (spikes). The system was evaluated on an AER posture dataset and compared with two recently developed bio-inspired models. Experimental results have shown that it consumes much less simulation time while still maintaining comparable performance. In addition, experiments on the Mixed National Institute of Standards and Technology (MNIST) image dataset have demonstrated that the proposed system can work not only on raw AER data but also on images (with a preprocessing step to convert images into AER events) and that it can maintain competitive accuracy even when noise is added. The system was further evaluated on the MNIST dynamic vision sensor dataset (in which data is recorded using an AER dynamic vision sensor), with testing accuracy of 88.14%.",4
Fault Identification in Distributed Sensor Networks Based on Universal Probabilistic Modeling.,"This paper proposes a holistic modeling scheme for fault identification in distributed sensor networks. The proposed scheme is based on modeling the relationship between two datastreams by means of a hidden Markov model (HMM) trained on the parameters of linear time-invariant dynamic systems, which estimate the specific relationship over consecutive time windows. Every system state, including the nominal one, is represented by an HMM and the novel data are categorized according to the model producing the highest likelihood. The system is able to understand whether the novel data belong to the fault dictionary, are fault-free, or represent a new fault type. We extensively evaluated the discrimination capabilities of the proposed approach and contrasted it with a multilayer perceptron using data coming from the Barcelona water distribution network. Nine system states are present in the dataset and the recognition rates are provided in the confusion matrix form.",4
A Kernel Classification Framework for Metric Learning.,"Learning a distance metric from the given training samples plays a crucial role in many machine learning tasks, and various models and optimization algorithms have been proposed in the past decade. In this paper, we generalize several state-of-the-art metric learning methods, such as large margin nearest neighbor (LMNN) and information theoretic metric learning (ITML), into a kernel classification framework. First, doublets and triplets are constructed from the training samples, and a family of degree-2 polynomial kernel functions is proposed for pairs of doublets or triplets. Then, a kernel classification framework is established to generalize many popular metric learning methods such as LMNN and ITML. The proposed framework can also suggest new metric learning methods, which can be efficiently implemented, interestingly, using the standard support vector machine (SVM) solvers. Two novel metric learning methods, namely, doublet-SVM and triplet-SVM, are then developed under the proposed framework. Experimental results show that doublet-SVM and triplet-SVM achieve competitive classification accuracies with state-of-the-art metric learning methods but with significantly less training time.",4
Scalable Nonparametric Low-Rank Kernel Learning Using Block Coordinate Descent.,"Nonparametric kernel learning (NPKL) is a flexible approach to learn the kernel matrix directly without assuming any parametric form. It can be naturally formulated as a semidefinite program (SDP), which, however, is not very scalable. To address this problem, we propose the combined use of low-rank approximation and block coordinate descent (BCD). Low-rank approximation avoids the expensive positive semidefinite constraint in the SDP by replacing the kernel matrix variable with V(T)V, where V is a low-rank matrix. The resultant nonlinear optimization problem is then solved by BCD, which optimizes each column of V sequentially. It can be shown that the proposed algorithm has nice convergence properties and low computational complexities. Experiments on a number of real-world data sets show that the proposed algorithm outperforms state-of-the-art NPKL solvers.",4
Learning Stable Multilevel Dictionaries for Sparse Representations.,"Sparse representations using learned dictionaries are being increasingly used with success in several data processing and machine learning applications. The increasing need for learning sparse models in large-scale applications motivates the development of efficient, robust, and provably good dictionary learning algorithms. Algorithmic stability and generalizability are desirable characteristics for dictionary learning algorithms that aim to build global dictionaries, which can efficiently model any test data similar to the training samples. In this paper, we propose an algorithm to learn dictionaries for sparse representations from large scale data, and prove that the proposed learning algorithm is stable and generalizable asymptotically. The algorithm employs a 1-D subspace clustering procedure, the K-hyperline clustering, to learn a hierarchical dictionary with multiple levels. We also propose an information-theoretic scheme to estimate the number of atoms needed in each level of learning and develop an ensemble approach to learn robust dictionaries. Using the proposed dictionaries, the sparse code for novel test data can be computed using a low-complexity pursuit procedure. We demonstrate the stability and generalization characteristics of the proposed algorithm using simulations. We also evaluate the utility of the multilevel dictionaries in compressed recovery and subspace learning applications.",4
The generalization ability of online SVM classification based on Markov sampling.,"In this paper, we consider online support vector machine (SVM) classification learning algorithms with uniformly ergodic Markov chain (u.e.M.c.) samples. We establish the bound on the misclassification error of an online SVM classification algorithm with u.e.M.c. samples based on reproducing kernel Hilbert spaces and obtain a satisfactory convergence rate. We also introduce a novel online SVM classification algorithm based on Markov sampling, and present the numerical studies on the learning ability of online SVM classification based on Markov sampling for benchmark repository. The numerical studies show that the learning performance of the online SVM classification algorithm based on Markov sampling is better than that of classical online SVM classification based on random sampling as the size of training samples is larger.",4
Training Recurrent Neural Networks With the Levenberg-Marquardt Algorithm for Optimal Control of a Grid-Connected Converter.,"This paper investigates how to train a recurrent neural network (RNN) using the Levenberg-Marquardt (LM) algorithm as well as how to implement optimal control of a grid-connected converter (GCC) using an RNN. To successfully and efficiently train an RNN using the LM algorithm, a new forward accumulation through time (FATT) algorithm is proposed to calculate the Jacobian matrix required by the LM algorithm. This paper explores how to incorporate FATT into the LM algorithm. The results show that the combination of the LM and FATT algorithms trains RNNs better than the conventional backpropagation through time algorithm. This paper presents an analytical study on the optimal control of GCCs, including theoretically ideal optimal and suboptimal controllers. To overcome the inapplicability of the optimal GCC controller under practical conditions, a new RNN controller with an improved input structure is proposed to approximate the ideal optimal controller. The performance of an ideal optimal controller and a well-trained RNN controller was compared in close to real-life power converter switching environments, demonstrating that the proposed RNN controller can achieve close to ideal optimal control performance even under low sampling rate conditions. The excellent performance of the proposed RNN controller under challenging and distorted system conditions further indicates the feasibility of using an RNN to approximate optimal control in practical applications.",4
Distributed Containment Control for Multiple Unknown Second-Order Nonlinear Systems With Application to Networked Lagrangian Systems.,"In this paper, we consider the distributed containment control problem for multiagent systems with unknown nonlinear dynamics. More specifically, we focus on multiple second-order nonlinear systems and networked Lagrangian systems. We first study the distributed containment control problem for multiple second-order nonlinear systems with multiple dynamic leaders in the presence of unknown nonlinearities and external disturbances under a general directed graph that characterizes the interaction among the leaders and the followers. A distributed adaptive control algorithm with an adaptive gain design based on the approximation capability of neural networks is proposed. We present a necessary and sufficient condition on the directed graph such that the containment error can be reduced as small as desired. As a byproduct, the leaderless consensus problem is solved with asymptotical convergence. Because relative velocity measurements between neighbors are generally more difficult to obtain than relative position measurements, we then propose a distributed containment control algorithm without using neighbors' velocity information. A two-step Lyapunov-based method is used to study the convergence of the closed-loop system. Next, we apply the ideas to deal with the containment control problem for networked unknown Lagrangian systems under a general directed graph. All the proposed algorithms are distributed and can be implemented using only local measurements in the absence of communication. Finally, simulation examples are provided to show the effectiveness of the proposed control algorithms.",4
Real-time keypoint recognition using restricted Boltzmann machine.,"Feature point recognition is a key component in many vision-based applications, such as vision-based robot navigation, object recognition and classification, image-based modeling, and augmented reality. Real-time performance and high recognition rates are of crucial importance to these applications. In this brief, we propose a novel method for real-time keypoint recognition using restricted Boltzmann machine (RBM). RBMs are generative models that can learn probability distributions of many different types of data including labeled and unlabeled data sets. Due to the inherent noise of the training data sets, we use an RBM to model statistical distributions of the training data. Furthermore, the learned RBM can be used as a competitive classifier to recognize the keypoints in real-time during the tracking stage, thus making it advantageous to be employed in applications that require real-time performance. Experiments have been conducted under a variety of conditions to demonstrate the effectiveness and generalization of the proposed approach.",4
Synchronization on complex networks of networks.,"In this paper, pinning synchronization on complex networks of networks is investigated, where there are many subnetworks with the interactions among them. The subnetworks and their connections can be regarded as the nodes and interactions of the networks, respectively, which form the networks of networks. In this new setting, the aim is to design pinning controllers on the chosen nodes of each subnetwork so as to reach synchronization behavior. Some synchronization criteria are established for reaching pinning control on networks of networks. Furthermore, the pinning scheme is designed, which shows that the nodes with very low degrees and large degrees are good candidates for applying pinning controllers. Then, the attack and robustness of the pinning scheme are discussed. Finally, a simulation example is presented to verify the theoretical analysis in this paper.",4
Passivity and passification of memristor-based recurrent neural networks with time-varying delays.,"This paper presents new theoretical results on the passivity and passification of a class of memristor-based recurrent neural networks (MRNNs) with time-varying delays. The casual assumptions on the boundedness and Lipschitz continuity of neuronal activation functions are relaxed. By constructing appropriate Lyapunov-Krasovskii functionals and using the characteristic function technique, passivity conditions are cast in the form of linear matrix inequalities (LMIs), which can be checked numerically using an LMI toolbox. Based on these conditions, two procedures for designing passification controllers are proposed, which guarantee that MRNNs with time-varying delays are passive. Finally, two illustrative examples are presented to show the characteristics of the main results in detail.",4
Local linear regression for function learning: an analysis based on sample discrepancy.,"Local linear regression models, a kind of nonparametric structures that locally perform a linear estimation of the target function, are analyzed in the context of empirical risk minimization (ERM) for function learning. The analysis is carried out with emphasis on geometric properties of the available data. In particular, the discrepancy of the observation points used both to build the local regression models and compute the empirical risk is considered. This allows to treat indifferently the case in which the samples come from a random external source and the one in which the input space can be freely explored. Both consistency of the ERM procedure and approximating capabilities of the estimator are analyzed, proving conditions to ensure convergence. Since the theoretical analysis shows that the estimation improves as the discrepancy of the observation points becomes smaller, low-discrepancy sequences, a family of sampling methods commonly employed for efficient numerical integration, are also analyzed. Simulation results involving two different examples of function learning are provided.",4
Ordinal neural networks without iterative tuning.,"Ordinal regression (OR) is an important branch of supervised learning in between the multiclass classification and regression. In this paper, the traditional classification scheme of neural network is adapted to learn ordinal ranks. The model proposed imposes monotonicity constraints on the weights connecting the hidden layer with the output layer. To do so, the weights are transcribed using padding variables. This reformulation leads to the so-called inequality constrained least squares (ICLS) problem. Its numerical solution can be obtained by several iterative methods, for example, trust region or line search algorithms. In this proposal, the optimum is determined analytically according to the closed-form solution of the ICLS problem estimated from the Karush-Kuhn-Tucker conditions. Furthermore, following the guidelines of the extreme learning machine framework, the weights connecting the input and the hidden layers are randomly generated, so the final model estimates all its parameters without iterative tuning. The model proposed achieves competitive performance compared with the state-of-the-art neural networks methods for OR.",4
Discriminant locality preserving projections based on L1-norm maximization.,"Conventional discriminant locality preserving projection (DLPP) is a dimensionality reduction technique based on manifold learning, which has demonstrated good performance in pattern recognition. However, because its objective function is based on the distance criterion using L2-norm, conventional DLPP is not robust to outliers which are present in many applications. This paper proposes an effective and robust DLPP version based on L1-norm maximization, which learns a set of local optimal projection vectors by maximizing the ratio of the L1-norm-based locality preserving between-class dispersion and the L1-norm-based locality preserving within-class dispersion. The proposed method is proven to be feasible and also robust to outliers while overcoming the small sample size problem. The experimental results on artificial datasets, Binary Alphadigits dataset, FERET face dataset and PolyU palmprint dataset have demonstrated the effectiveness of the proposed method.",4
Confabulation-inspired association rule mining for rare and frequent itemsets.,"A new confabulation-inspired association rule mining (CARM) algorithm is proposed using an interestingness measure inspired by cogency. Cogency is only computed based on pairwise item conditional probability, so the proposed algorithm mines association rules by only one pass through the file. The proposed algorithm is also more efficient for dealing with infrequent items due to its cogency-inspired approach. The problem of associative classification is used here for evaluating the proposed algorithm. We evaluate CARM over both synthetic and real benchmark data sets obtained from the UC Irvine machine learning repository. Experiments show that the proposed algorithm is consistently faster due to its one time file access and consumes less memory space than the Conditional Frequent Patterns growth algorithm. In addition, statistical analysis reveals the superiority of the approach for classifying minority classes in unbalanced data sets.",4
Multiwavelet packet entropy and its application in transmission line fault recognition and classification.,"Multiwavelets possess better properties than traditional wavelets. Multiwavelet packet transformation has more high-frequency information. Spectral entropy can be applied as an analysis index to the complexity or uncertainty of a signal. This paper tries to define four multiwavelet packet entropies to extract the features of different transmission line faults, and uses a radial basis function (RBF) neural network to recognize and classify 10 fault types of power transmission lines. First, the preprocessing and postprocessing problems of multiwavelets are presented. Shannon entropy and Tsallis entropy are introduced, and their difference is discussed. Second, multiwavelet packet energy entropy, time entropy, Shannon singular entropy, and Tsallis singular entropy are defined as the feature extraction methods of transmission line fault signals. Third, the plan of transmission line fault recognition using multiwavelet packet entropies and an RBF neural network is proposed. Finally, the experimental results show that the plan with the four multiwavelet packet energy entropies defined in this paper achieves better performance in fault recognition. The performance with SA4 (symmetric antisymmetric) multiwavelet packet Tsallis singular entropy is the best among the combinations of different multiwavelet packets and the four multiwavelet packet entropies.",4
Single-trial classification of event-related potentials in rapid serial visual presentation tasks using supervised spatial filtering.,"Accurate detection of single-trial event-related potentials (ERPs) in the electroencephalogram (EEG) is a difficult problem that requires efficient signal processing and machine learning techniques. Supervised spatial filtering methods that enhance the discriminative information in EEG data are commonly used to improve single-trial ERP detection. We propose a convolutional neural network (CNN) with a layer dedicated to spatial filtering for the detection of ERPs and with training based on the maximization of the area under the receiver operating characteristic curve (AUC). The CNN is compared with three common classifiers: 1) Bayesian linear discriminant analysis; 2) multilayer perceptron (MLP); and 3) support vector machines. Prior to classification, the data were spatially filtered with xDAWN (for the maximization of the signal-to-signal-plus-noise ratio), common spatial pattern, or not spatially filtered. The 12 analytical techniques were tested on EEG data recorded in three rapid serial visual presentation experiments that required the observer to discriminate rare target stimuli from frequent nontarget stimuli. Classification performance discriminating targets from nontargets depended on both the spatial filtering method and the classifier. In addition, the nonlinear classifier MLP outperformed the linear methods. Finally, training based AUC maximization provided better performance than training based on the minimization of the mean square error. The results support the conclusion that the choice of the systems architecture is critical and both spatial filtering and classification must be considered together.",4
Adaptive neural control of MIMO nonlinear systems with a block-triangular pure-feedback control structure.,"This paper presents adaptive neural tracking control for a class of uncertain multiinput-multioutput (MIMO) nonlinear systems in block-triangular form. All subsystems within these MIMO nonlinear systems are of completely nonaffine pure-feedback form and allowed to have different orders. To deal with the nonaffine appearance of the control variables, the mean value theorem is employed to transform the systems into a block-triangular strict-feedback form with control coefficients being couplings among various inputs and outputs. A systematic procedure is proposed for the design of a new singularity-free adaptive neural tracking control strategy. Such a design procedure can remove the couplings among subsystems and hence avoids the possible circular control construction problem. As a consequence, all the signals in the closed-loop system are guaranteed to be semiglobally uniformly ultimately bounded. Moreover, the outputs of the systems are ensured to converge to a small neighborhood of the desired trajectories. Simulation studies verify the theoretical findings revealed in this paper.",4
Neural network-based motion control of an underactuated wheeled inverted pendulum model.,"In this paper, automatic motion control is investigated for one of wheeled inverted pendulum (WIP) models, which have been widely applied for modeling of a large range of two wheeled modern vehicles. First, the underactuated WIP model is decomposed into a fully actuated second order subsystem Sigmaa consisting of planar movement of vehicle forward and yaw angular motions, and a nonactuated first order subsystem Sigmab of pendulum motion. Due to the unknown dynamics of subsystem Sigmaa and the universal approximation ability of neural network (NN), an adaptive NN scheme has been employed for motion control of subsystem Sigmaa . The model reference approach has been used whereas the reference model is optimized by the finite time linear quadratic regulation technique. The pendulum motion in the passive subsystem Sigmab is indirectly controlled using the dynamic coupling with planar forward motion of subsystem Sigmaa , such that satisfactory tracking of a set pendulum tilt angle can be guaranteed. Rigours theoretic analysis has been established, and simulation studies have been performed to demonstrate the developed method.",4
Divisive Gaussian processes for nonstationary regression.,"Standard Gaussian process regression (GPR) assumes constant noise power throughout the input space and stationarity when combined with the squared exponential covariance function. This can be unrealistic and too restrictive for many real-world problems. Nonstationarity can be achieved by specific covariance functions, though prior knowledge about this nonstationarity can be difficult to obtain. On the other hand, the homoscedastic assumption is needed to allow GPR inference to be tractable. In this paper, we present a divisive GPR model which performs nonstationary regression under heteroscedastic noise using the pointwise division of two nonparametric latent functions. As the inference on the model is not analytically tractable, we propose a variational posterior approximation using expectation propagation (EP) which allows for accurate inference at reduced cost. We have also made a Markov chain Monte Carlo implementation with elliptical slice sampling to assess the quality of the EP approximation. Experiments support the usefulness of the proposed approach.",4
Mahalanobis distance on extended Grassmann manifolds for variational pattern analysis.,"In pattern classification problems, pattern variations are often modeled as a linear manifold or a low-dimensional subspace. Conventional methods use such models and define a measure of similarity or dissimilarity. However, these similarity measures are deterministic and do not take into account the distribution of linear manifolds or low-dimensional subspaces. Therefore, if the distribution is not isotopic, the distance measurements are not reliable, as well as vector-based distance measurement in the Euclidean space. We previously systematized the representations of variational patterns using the Grassmann manifold and introduce the Mahalanobis distance to the Grassmann manifold as a natural extension of Euclidean case. In this paper, we present two methods that flexibly extend the Mahalanobis distance on the extended Grassmann manifolds. These methods can be used to measure pattern (dis)similarity on the basis of the pattern structure. Experimental evaluation of the performance of the proposed methods demonstrated that they exhibit a lower error classification rate.",4
A Gaussian process model for data association and a semidefinite programming solution.,"In this paper, we propose a Bayesian model for the data association problem, in which trajectory smoothness is enforced through the use of Gaussian process priors. This model allows to score candidate associations using the evidence framework, thus casting the data association problem into an optimization problem. Under some additional mild assumptions, this optimization problem is shown to be equivalent to a constrained Max K-section problem. Furthermore, for K=2, a MaxCut formulation is obtained, to which an approximate solution can be efficiently found using an SDP relaxation. Solving this MaxCut problem is equivalent to finding the optimal association out of the combinatorially many possibilities. The obtained clustering depends only on two hyperparameters, which can also be selected by maximum evidence.",4
Online PLSA: batch updating techniques including out-of-vocabulary words.,"A novel method is proposed for updating an already trained asymmetric and symmetric probabilistic latent semantic analysis (PLSA) model within the context of a varying document stream. The proposed method is coined online PLSA (oPLSA). The oPLSA employs a fixed-size moving window over a document stream to incorporate new documents and at the same time to discard old ones (i.e., documents that fall outside the scope of the window). In addition, the oPLSA assimilates new words that had not been previously seen (out-of-vocabulary words), and discards the words that exclusively appear in the documents to be thrown away. To handle the new words, Good-Turing estimates for the probabilities of unseen words are exploited. The experimental results demonstrate the superiority in terms of accuracy of the oPLSA over well known PLSA updating methods, such as the PLSA folding-in (PLSA fold.), the PLSA rerun from the breakpoint, the quasi-Bayes PLSA, and the Incremental PLSA. A comparison with respect to the CPU run time reveals that the oPLSA is the second fastest method after the PLSA fold. However, the better accuracy of the oPLSA than that of the PLSA fold. pays off the longer computation time. The oPLSA and the other PLSA updating methods together with online LDA are tested for document clustering and F1 scores are also reported.",4
Improved Fault Classification in Series Compensated Transmission Line: Comparative Evaluation of Chebyshev Neural Network Training Algorithms.,"This paper presents the Chebyshev neural network (ChNN) as an improved artificial intelligence technique for power system protection studies and examines the performances of two ChNN learning algorithms for fault classification of series compensated transmission line. The training algorithms are least-square Levenberg-Marquardt (LSLM) and recursive least-square algorithm with forgetting factor (RLSFF). The performances of these algorithms are assessed based on their generalization capability in relating the fault current parameters with an event of fault in the transmission line. The proposed algorithm is fast in response as it utilizes postfault samples of three phase currents measured at the relaying end corresponding to half-cycle duration only. After being trained with only a small part of the generated fault data, the algorithms have been tested over a large number of fault cases with wide variation of system and fault parameters. Based on the studies carried out in this paper, it has been found that although the RLSFF algorithm is faster for training the ChNN in the fault classification application for series compensated transmission lines, the LSLM algorithm has the best accuracy in testing. The results prove that the proposed ChNN-based method is accurate, fast, easy to design, and immune to the level of compensations. Thus, it is suitable for digital relaying applications.",4
Artificial Electrical Morris-Lecar Neuron.,"In this paper, an experimental electronic neuron based on a complete Morris-Lecar model is presented, which is able to become an experimental unit tool to study collective association of coupled neurons. The circuit design is given according to the ionic currents of this model. The experimental results are compared with the theoretical prediction, leading to a good agreement between them, which therefore validate the circuit. The use of some parts of the circuit is also possible for other neurons models, namely for those based on ionic currents.",4
Semi-supervised domain adaptation on manifolds.,"In real-life problems, the following semi-supervised domain adaptation scenario is often encountered: we have full access to some source data, which is usually very large; the target data distribution is under certain unknown transformation of the source data distribution; meanwhile, only a small fraction of the target instances come with labels. The goal is to learn a prediction model by incorporating information from the source domain that is able to generalize well on the target test instances. We consider an explicit form of transformation functions and especially linear transformations that maps examples from the source to the target domain, and we argue that by proper preprocessing of the data from both source and target domains, the feasible transformation functions can be characterized by a set of rotation matrices. This naturally leads to an optimization formulation under the special orthogonal group constraints. We present an iterative coordinate descent solver that is able to jointly learn the transformation as well as the model parameters, while the geodesic update ensures the manifold constraints are always satisfied. Our framework is sufficiently general to work with a variety of loss functions and prediction problems. Empirical evaluations on synthetic and real-world experiments demonstrate the competitive performance of our method with respect to the state-of-the-art.",4
Fractional extreme value adaptive training method: fractional steepest descent approach.,"The application of fractional calculus to signal processing and adaptive learning is an emerging area of research. A novel fractional adaptive learning approach that utilizes fractional calculus is presented in this paper. In particular, a fractional steepest descent approach is proposed. A fractional quadratic energy norm is studied, and the stability and convergence of our proposed method are analyzed in detail. The fractional steepest descent approach is implemented numerically and its stability is analyzed experimentally.",4
Large-scale Nystrom kernel matrix approximation using randomized SVD.,"The Nystrom method is an efficient technique for the eigenvalue decomposition of large kernel matrices. However, to ensure an accurate approximation, a sufficient number of columns have to be sampled. On very large data sets, the singular value decomposition (SVD) step on the resultant data submatrix can quickly dominate the computations and become prohibitive. In this paper, we propose an accurate and scalable Nystrom scheme that first samples a large column subset from the input matrix, but then only performs an approximate SVD on the inner submatrix using the recent randomized low-rank matrix approximation algorithms. Theoretical analysis shows that the proposed algorithm is as accurate as the standard Nystrom method that directly performs a large SVD on the inner submatrix. On the other hand, its time complexity is only as low as performing a small SVD. Encouraging results are obtained on a number of large-scale data sets for low-rank approximation. Moreover, as the most computational expensive steps can be easily distributed and there is minimal data transfer among the processors, significant speedup can be further obtained with the use of multiprocessor and multi-GPU systems.",4
Actor-critic-based optimal tracking for partially unknown nonlinear discrete-time systems.,"This paper presents a partially model-free adaptive optimal control solution to the deterministic nonlinear discrete-time (DT) tracking control problem in the presence of input constraints. The tracking error dynamics and reference trajectory dynamics are first combined to form an augmented system. Then, a new discounted performance function based on the augmented system is presented for the optimal nonlinear tracking problem. In contrast to the standard solution, which finds the feedforward and feedback terms of the control input separately, the minimization of the proposed discounted performance function gives both feedback and feedforward parts of the control input simultaneously. This enables us to encode the input constraints into the optimization problem using a nonquadratic performance function. The DT tracking Bellman equation and tracking Hamilton-Jacobi-Bellman (HJB) are derived. An actor-critic-based reinforcement learning algorithm is used to learn the solution to the tracking HJB equation online without requiring knowledge of the system drift dynamics. That is, two neural networks (NNs), namely, actor NN and critic NN, are tuned online and simultaneously to generate the optimal bounded control policy. A simulation example is given to show the effectiveness of the proposed method.",4
Approximate N-Player Nonzero-Sum Game Solution for an Uncertain Continuous Nonlinear System.,"An approximate online equilibrium solution is developed for an N -player nonzero-sum game subject to continuous-time nonlinear unknown dynamics and an infinite horizon quadratic cost. A novel actor-critic-identifier structure is used, wherein a robust dynamic neural network is used to asymptotically identify the uncertain system with additive disturbances, and a set of critic and actor NNs are used to approximate the value functions and equilibrium policies, respectively. The weight update laws for the actor neural networks (NNs) are generated using a gradient-descent method, and the critic NNs are generated by least square regression, which are both based on the modified Bellman error that is independent of the system dynamics. A Lyapunov-based stability analysis shows that uniformly ultimately bounded tracking is achieved, and a convergence analysis demonstrates that the approximate control policies converge to a neighborhood of the optimal solutions. The actor, critic, and identifier structures are implemented in real time continuously and simultaneously. Simulations on two and three player games illustrate the performance of the developed method.",4
Topology-based clustering using polar self-organizing map.,"Cluster analysis of unlabeled data sets has been recognized as a key research topic in varieties of fields. In many practical cases, no a priori knowledge is specified, for example, the number of clusters is unknown. In this paper, grid clustering based on the polar self-organizing map (PolSOM) is developed to automatically identify the optimal number of partitions. The data topology consisting of both the distance and density is exploited in the grid clustering. The proposed clustering method also provides a visual representation as PolSOM allows the characteristics of clusters to be presented as a 2-D polar map in terms of the data feature and value. Experimental studies on synthetic and real data sets demonstrate that the proposed algorithm provides higher clustering accuracy and lower computational cost compared with six conventional methods.",4
Progressive Learning Machine: A New Approach for General Hybrid System Approximation.,"As the most important property of neural networks (NNs), the universal approximation capability of NNs is widely used in many applications. However, this property is generally proven for continuous systems. Most industrial systems are hybrid systems (e.g., piecewise continuous), which is a significant limitation for real applications. Recently, many identification methods have been proposed for hybrid system approximation; however, these methods only operate in linear hybrid systems. In this paper, the progressive learning machine-a new learning algorithm based on multi-NNs-is proposed for general hybrid nonlinear/linear system approximation. This algorithm classifies hybrid systems into several continuous systems and can approximate any hybrid system with zero output error. The performance of the proposed learning method is demonstrated via numerical examples and with experimental data from real applications.",4
Adaptive Batch Mode Active Learning.,"Active learning techniques have gained popularity to reduce human effort in labeling data instances for inducing a classifier. When faced with large amounts of unlabeled data, such algorithms automatically identify the exemplar and representative instances to be selected for manual annotation. More recently, there have been attempts toward a batch mode form of active learning, where a batch of data points is simultaneously selected from an unlabeled set. Real-world applications require adaptive approaches for batch selection in active learning, depending on the complexity of the data stream in question. However, the existing work in this field has primarily focused on static or heuristic batch size selection. In this paper, we propose two novel optimization-based frameworks for adaptive batch mode active learning (BMAL), where the batch size as well as the selection criteria are combined in a single formulation. We exploit gradient-descent-based optimization strategies as well as properties of submodular functions to derive the adaptive BMAL algorithms. The solution procedures have the same computational complexity as existing state-of-the-art static BMAL techniques. Our empirical results on the widely used VidTIMIT and the mobile biometric (MOBIO) data sets portray the efficacy of the proposed frameworks and also certify the potential of these approaches in being used for real-world biometric recognition applications.",4
Opportunistic Behavior in Motivated Learning Agents.,"This paper focuses on the novel motivated learning (ML) scheme and opportunistic behavior of an intelligent agent. It extends previously developed ML to opportunistic behavior in a multitask situation. Our paper describes the virtual world implementation of autonomous opportunistic agents learning in a dynamically changing environment, creating abstract goals, and taking advantage of arising opportunities to improve their performance. An opportunistic agent achieves better results than an agent based on ML only. It does so by minimizing the average value of all need signals rather than a dominating need. This paper applies to the design of autonomous embodied systems (robots) learning in real-time how to operate in a complex environment.",4
Multilinear sparse principal component analysis.,"In this brief, multilinear sparse principal component analysis (MSPCA) is proposed for feature extraction from the tensor data. MSPCA can be viewed as a further extension of the classical principal component analysis (PCA), sparse PCA (SPCA) and the recently proposed multilinear PCA (MPCA). The key operation of MSPCA is to rewrite the MPCA into multilinear regression forms and relax it for sparse regression. Differing from the recently proposed MPCA, MSPCA inherits the sparsity from the SPCA and iteratively learns a series of sparse projections that capture most of the variation of the tensor data. Each nonzero element in the sparse projections is selected from the most important variables/factors using the elastic net. Extensive experiments on Yale, Face Recognition Technology face databases, and COIL-20 object database encoded the object images as second-order tensors, and Weizmann action database as third-order tensors demonstrate that the proposed MSPCA algorithm has the potential to outperform the existing PCA-based subspace learning algorithms.",4
Extended dissipative analysis for neural networks with time-varying delays.,"In this brief, an extended dissipativity analysis was conducted for a neural network with time-varying delays. The concept of the extended dissipativity can be used to solve for the Hinfinity, L2-Linfinity, passive, and dissipative performance by adjusting the weighting matrices in a new performance index. In addition, the activation function dividing method is modified by introducing a tuning parameter. Examples are provided to show the effectiveness and less conservatism of the proposed method.",4
Hinfinity output tracking control of discrete-time nonlinear systems via standard neural network models.,"This brief proposes an output tracking control for a class of discrete-time nonlinear systems with disturbances. A standard neural network model is used to represent discrete-time nonlinear systems whose nonlinearity satisfies the sector conditions. Hinfinity control performance for the closed-loop system including the standard neural network model, the reference model, and state feedback controller is analyzed using Lyapunov-Krasovskii stability theorem and linear matrix inequality (LMI) approach. The Hinfinity controller, of which the parameters are obtained by solving LMIs, guarantees that the output of the closed-loop system closely tracks the output of a given reference model well, and reduces the influence of disturbances on the tracking error. Three numerical examples are provided to show the effectiveness of the proposed Hinfinity output tracking design approach.",4
Consensus acceleration in a class of predictive networks.,"A fastest consensus problem of topology fixed networks has been formulated as an optimal linear iteration problem and efficiently solved in the literature. Considering a kind of predictive mechanism, we show that the consensus evolution can be further accelerated while physically maintaining the network topology. The underlying mechanism is that an effective prediction is able to induce a network with a virtually denser topology. With this topology, an even faster consensus is expected to occur. The result is motivated by the predictive mechanism widely existing in natural systems.",4
Clipping in neurocontrol by adaptive dynamic programming.,"In adaptive dynamic programming, neurocontrol, and reinforcement learning, the objective is for an agent to learn to choose actions so as to minimize a total cost function. In this paper, we show that when discretized time is used to model the motion of the agent, it can be very important to do clipping on the motion of the agent in the final time step of the trajectory. By clipping, we mean that the final time step of the trajectory is to be truncated such that the agent stops exactly at the first terminal state reached, and no distance further. We demonstrate that when clipping is omitted, learning performance can fail to reach the optimum, and when clipping is done properly, learning performance can improve significantly. The clipping problem we describe affects algorithms that use explicit derivatives of the model functions of the environment to calculate a learning gradient. These include backpropagation through time for control and methods based on dual heuristic programming. However, the clipping problem does not significantly affect methods based on heuristic dynamic programming, temporal differences learning, or policy-gradient learning algorithms.",4
Separation of synchronous sources through phase locked matrix factorization.,"In this paper, we study the separation of synchronous sources (SSS) problem, which deals with the separation of sources whose phases are synchronous. This problem cannot be addressed through independent component analysis methods because synchronous sources are statistically dependent. We present a two-step algorithm, called phase locked matrix factorization (PLMF), to perform SSS. We also show that SSS is identifiable under some assumptions and that any global minimum of PLMFs cost function is a desirable solution for SSS. We extensively study the algorithm on simulated data and conclude that it can perform SSS with various numbers of sources and sensors and with various phase lags between the sources, both in the ideal (i.e., perfectly synchronous and nonnoisy) case, and with various levels of additive noise in the observed signals and of phase jitter in the sources.",4
Multiobjective optimization for model selection in kernel methods in regression.,"Regression plays a major role in many scientific and engineering problems. The goal of regression is to learn the unknown underlying function from a set of sample vectors with known outcomes. In recent years, kernel methods in regression have facilitated the estimation of nonlinear functions. However, two major (interconnected) problems remain open. The first problem is given by the bias-versus-variance tradeoff. If the model used to estimate the underlying function is too flexible (i.e., high model complexity), the variance will be very large. If the model is fixed (i.e., low complexity), the bias will be large. The second problem is to define an approach for selecting the appropriate parameters of the kernel function. To address these two problems, this paper derives a new smoothing kernel criterion, which measures the roughness of the estimated function as a measure of model complexity. Then, we use multiobjective optimization to derive a criterion for selecting the parameters of that kernel. The goal of this criterion is to find a tradeoff between the bias and the variance of the learned function. That is, the goal is to increase the model fit while keeping the model complexity in check. We provide extensive experimental evaluations using a variety of problems in machine learning, pattern recognition, and computer vision. The results demonstrate that the proposed approach yields smaller estimation errors as compared with methods in the state of the art.",4
Memristor crossbar-based neuromorphic computing system: a case study.,"By mimicking the highly parallel biological systems, neuromorphic hardware provides the capability of information processing within a compact and energy-efficient platform. However, traditional Von Neumann architecture and the limited signal connections have severely constrained the scalability and performance of such hardware implementations. Recently, many research efforts have been investigated in utilizing the latest discovered memristors in neuromorphic systems due to the similarity of memristors to biological synapses. In this paper, we explore the potential of a memristor crossbar array that functions as an autoassociative memory and apply it to brain-state-in-a-box (BSB) neural networks. Especially, the recall and training functions of a multianswer character recognition process based on the BSB model are studied. The robustness of the BSB circuit is analyzed and evaluated based on extensive Monte Carlo simulations, considering input defects, process variations, and electrical fluctuations. The results show that the hardware-based training scheme proposed in the paper can alleviate and even cancel out the majority of the noise issue.",4
A fast algorithm for nonnegative matrix factorization and its convergence.,"Nonnegative matrix factorization (NMF) has recently become a very popular unsupervised learning method because of its representational properties of factors and simple multiplicative update algorithms for solving the NMF. However, for the common NMF approach of minimizing the Euclidean distance between approximate and true values, the convergence of multiplicative update algorithms has not been well resolved. This paper first discusses the convergence of existing multiplicative update algorithms. We then propose a new multiplicative update algorithm for minimizing the Euclidean distance between approximate and true values. Based on the optimization principle and the auxiliary function method, we prove that our new algorithm not only converges to a stationary point, but also does faster than existing ones. To verify our theoretical results, the experiments on three data sets have been conducted by comparing our proposed algorithm with other existing methods.",4
LI-MLC: a label inference methodology for addressing high dimensionality in the label space for multilabel classification.,"Multilabel classification (MLC) has generated considerable research interest in recent years, as a technique that can be applied to many real-world scenarios. To process them with binary or multiclass classifiers, methods for transforming multilabel data sets (MLDs) have been proposed, as well as adapted algorithms able to work with this type of data sets. However, until now, few studies have addressed the problem of how to deal with MLDs having a large number of labels. This characteristic can be defined as high dimensionality in the label space (output attributes), in contrast to the traditional high dimensionality problem, which is usually focused on the feature space (by means of feature selection) or sample space (by means of instance selection). The purpose of this paper is to analyze dimensionality in the label space in MLDs, and to present a transformation methodology based on the use of association rules to discover label dependencies. These dependencies are used to reduce the label space, to ease the work of any MLC algorithm, and to infer the deleted labels in a final postprocessing stage. The proposed process is validated in an extensive experimentation with several MLDs and classification algorithms, resulting in a statistically significant improvement of performance in some cases, as will be shown.",4
Parsimonious extreme learning machine using recursive orthogonal least squares.,"Novel constructive and destructive parsimonious extreme learning machines (CP- and DP-ELM) are proposed in this paper. By virtue of the proposed ELMs, parsimonious structure and excellent generalization of multiinput-multioutput single hidden-layer feedforward networks (SLFNs) are obtained. The proposed ELMs are developed by innovative decomposition of the recursive orthogonal least squares procedure into sequential partial orthogonalization (SPO). The salient features of the proposed approaches are as follows: 1) Initial hidden nodes are randomly generated by the ELM methodology and recursively orthogonalized into an upper triangular matrix with dramatic reduction in matrix size; 2) the constructive SPO in the CP-ELM focuses on the partial matrix with the subcolumn of the selected regressor including nonzeros as the first column while the destructive SPO in the DP-ELM operates on the partial matrix including elements determined by the removed regressor; 3) termination criteria for CP- and DP-ELM are simplified by the additional residual error reduction method; and 4) the output weights of the SLFN need not be solved in the model selection procedure and is derived from the final upper triangular equation by backward substitution. Both single- and multi-output real-world regression data sets are used to verify the effectiveness and superiority of the CP- and DP-ELM in terms of parsimonious architecture and generalization accuracy. Innovative applications to nonlinear time-series modeling demonstrate superior identification results.",4
Deep networks are effective encoders of periodicity.,"We present a comparative theoretical analysis of representation in artificial neural networks with two extreme architectures, a shallow wide network and a deep narrow network, devised to maximally decouple their representative power due to layer width and network depth. We show that, given a specific activation function, models with comparable VC-dimension are required to guarantee zero error modeling of real functions over a binary input. However, functions that exhibit repeating patterns can be encoded much more efficiently in the deep representation, resulting in significant reduction in complexity. This paper provides some initial theoretical evidence of when and how depth can be extremely effective.",4
Pinning distributed synchronization of stochastic dynamical networks: a mixed optimization approach.,"This paper is concerned with the problem of pinning synchronization of nonlinear dynamical networks with multiple stochastic disturbances. Two kinds of pinning schemes are considered: 1) pinned nodes are fixed along the time evolution and 2) pinned nodes are switched from time to time according to a set of Bernoulli stochastic variables. Using Lyapunov function methods and stochastic analysis techniques, several easily verifiable criteria are derived for the problem of pinning distributed synchronization. For the case of fixed pinned nodes, a novel mixed optimization method is developed to select the pinned nodes and find feasible solutions, which is composed of a traditional convex optimization method and a constraint optimization evolutionary algorithm. For the case of switching pinning scheme, upper bounds of the convergence rate and the mean control gain are obtained theoretically. Simulation examples are provided to show the advantages of our proposed optimization method over previous ones and verify the effectiveness of the obtained results.",4
Sparse alignment for robust tensor learning.,"Multilinear/tensor extensions of manifold learning based algorithms have been widely used in computer vision and pattern recognition. This paper first provides a systematic analysis of the multilinear extensions for the most popular methods by using alignment techniques, thereby obtaining a general tensor alignment framework. From this framework, it is easy to show that the manifold learning based tensor learning methods are intrinsically different from the alignment techniques. Based on the alignment framework, a robust tensor learning method called sparse tensor alignment (STA) is then proposed for unsupervised tensor feature extraction. Different from the existing tensor learning methods, L1- and L2-norms are introduced to enhance the robustness in the alignment step of the STA. The advantage of the proposed technique is that the difficulty in selecting the size of the local neighborhood can be avoided in the manifold learning based tensor feature extraction algorithms. Although STA is an unsupervised learning method, the sparsity encodes the discriminative information in the alignment step and provides the robustness of STA. Extensive experiments on the well-known image databases as well as action and hand gesture databases by encoding object images as tensors demonstrate that the proposed STA algorithm gives the most competitive performance when compared with the tensor-based unsupervised learning methods.",4
